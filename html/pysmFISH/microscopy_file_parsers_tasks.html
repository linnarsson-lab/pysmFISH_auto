<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>pysmFISH.microscopy_file_parsers_tasks API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pysmFISH.microscopy_file_parsers_tasks</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from typing import *
import pickle
import yaml
import re
import shutil
import numpy as np
import zarr
import nd2reader
import xarray as xr
from pathlib import Path


import prefect
from prefect import task
from prefect.engine import signals

from pysmFISH.logger_utils import prefect_logging_setup


# from pysmFISH.utils import load_pipeline_config_file, create_dir, load_running_analysis_config_file


&#34;&#34;&#34; 
The parsing of the nikon files require the bftools. We use only the inf
command and the location is inferred using os.system(&#39;inf&#39;)
bftool 
&#34;&#34;&#34;


@task(name=&#39;nd2_files_selection&#39;)
def nd2_raw_files_selector(experiment_fpath: str) -&gt; list:
    &#34;&#34;&#34;
    Identify the nd2 raw microscopy files generated by
    the robofish machine. The files must contain CountXXXXX in the name. 

    Args:
        experiment_fpath: str 
            Path to the folder to process. It need to contain the &#39;_auto&#39;
            suffix in order to be process with the automated pipeline

    Returns:
        all_files_to_process: list
            List of PosixPath of the microscopy files to process
        
    &#34;&#34;&#34;

    logger = prefect.utilities.logging.get_logger(&#34;parsing&#34;)
    
    assert &#39;_auto&#39; in experiment_fpath.stem, signals.FAIL(&#39;no _auto in the experiment name&#39;)

    experiment_fpath = Path(experiment_fpath)
    searching_key = &#39;*Count*.nd2&#39;
    all_files_to_process = list(experiment_fpath.glob(searching_key))

    assert all_files_to_process, signals.FAIL(&#39;no .nd2 raw files to process&#39;)
    
    logger.debug(f&#39;Number of files to process {len(all_files_to_process)}.&#39;)
    return all_files_to_process



@task(name=&#39;nd2_autoparser&#39;)
def nikon_nd2_autoparser(nd2_file_path,parsed_raw_data_fpath):
    &#34;&#34;&#34;
    This parser not consider the possibility to have multiple experiment running at
    the same time with the raw imaging data present in the same folder. 
    Once the data are parsed by hybridization are saved in
    the same folder.

    NB: The file and the corresponding metadata file generated by the microscope
        must contain &#39;CountXXXXX&#39; in order to be processed

    The parsed_tmp and raw_data directories are created in a previous step of the 
    pipeline during data sorting

    QC step run before parsing take care of checking if the nd2 files are present
    and in the corresponding pickle configuration files are in the folder

    This nd2 parser process one .nd2 file

    Args:
        nd2_file_path: str
            Path to the .nd2 file to be parsed
        parsed_raw_data_fpath: str
            Path to the zarr file that will store the parsed data

    Returns:
        processing_info: list of tuples
        each tuple contain the path of the zarr storage and the number of fov
    &#34;&#34;&#34;

    logger = prefect_logging_setup(&#34;auto_parser&#34;)

    nd2_file_path = Path(nd2_file_path)
    nd2_fname = nd2_file_path.stem

    logger.debug(f&#39;processing file {nd2_fname}&#39;)

    experiment_fpath = nd2_file_path.parent
    experiment_name = nd2_file_path.parent.stem
    experiment_name = experiment_name.split(&#39;_auto&#39;)[0]
       
    raw_files_dir = experiment_fpath / &#39;raw_data&#39;
    parsed_tmp = experiment_fpath / &#39;parsed_tmp&#39;
    

    # Extract the Count code from the file name
    count_code = re.search(r&#39;(Count)\d{5}&#39;, nd2_file_path.stem).group()
    
    all_info_files = experiment_fpath.glob(&#39;*.pkl&#39;)
    
    info_file = [info_file for info_file in all_info_files if count_code  in info_file.stem][0]
    
    info_data = pickle.load(open(info_file, &#39;rb&#39;))
    hybridization_name = info_data[&#39;channels&#39;][&#39;Hybridization&#39;]
    
    try:
        nd2fh = nd2reader.ND2Reader(nd2_file_path)
    except:
        logger.error(&#39;Cannot load the nd2 file&#39;)
        signals.FAIL(&#39;Cannot load the nd2 file&#39;)
    else:
        # Collect metadata
        all_metadata = nd2fh.parser._raw_metadata
        parsed_metadata = nd2fh.parser._raw_metadata.get_parsed_metadata()
        
        channel = parsed_metadata[&#39;channels&#39;][0] # works because there is only one channel for file
        img_height = parsed_metadata[&#39;height&#39;]
        img_width = parsed_metadata[&#39;width&#39;]
        pixel_microns = parsed_metadata[&#39;pixel_microns&#39;]
        z_levels = parsed_metadata[&#39;z_levels&#39;]
        fields_of_view = parsed_metadata[&#39;fields_of_view&#39;]
        
        # Collect FOV coords
        x_data = np.array(all_metadata.x_data)
        x_data = x_data[:,np.newaxis]
        y_data = np.array(all_metadata.x_data)
        y_data = y_data[:,np.newaxis]
        z_data = np.array(all_metadata.z_data)
        z_data = z_data[:,np.newaxis]
        all_coords = np.hstack((z_data,x_data,y_data))
        fov_coords = all_coords[0::len(z_levels),:]
        
        tag_name = experiment_name + &#39;_&#39; + hybridization_name + &#39;_&#39; + channel
        
        
        # Save the file as zarr
        # zarr_store = parsed_tmp / (experiment_name + &#39;_&#39; + hybridization_name + &#39;_&#39; + channel + &#39;_raw_images_tmp.zarr&#39;)
        nd2fh.bundle_axes = &#39;zyx&#39;
        # set iteration over the fields of view
        nd2fh.iter_axes = &#39;v&#39;
        
        # Save coords of the FOV
        rows = np.arange(img_width)
        cols = np.arange(img_height)
        hybridization_num = int(hybridization_name.split(&#39;Hybridization&#39;)[-1])
        for fov in fields_of_view:
            img = np.array(nd2fh[fov],dtype=np.uint16)
            fov_attrs = {&#39;channel&#39;: channel,
                &#39;target_name&#39;: info_data[&#39;channels&#39;][channel],
                &#39;img_height&#39;: img_height,
                &#39;img_width&#39;: img_width,
                &#39;pixel_microns&#39;: pixel_microns,
                &#39;z_levels&#39;:list(z_levels),
                &#39;fov_num&#39;: fov,
                &#39;StitchingChannel&#39;: info_data[&#39;StitchingChannel&#39;],
                &#39;hybridization_num&#39;: hybridization_num,
                &#39;experiment_name&#39; : experiment_name} 
            datarray_name = tag_name + &#39;_fov_&#39; + str(fov) 
            img_xarray = xr.DataArray(img, coords={&#39;z_levels&#39;:z_levels,&#39;rows&#39;:rows, &#39;cols&#39;:cols}, 
                                    dims=[&#39;z_levels&#39;,&#39;rows&#39;,&#39;cols&#39;],attrs=fov_attrs, name=datarray_name)
            img_xarray = img_xarray.chunk(chunks=(1,img_width,img_height))
            ds = img_xarray.to_dataset(name = datarray_name)
            ds.to_zarr(parsed_raw_data_fpath, mode=&#39;a&#39;, consolidated=True)
                
        # Rename the nd2 files
        # new_file_name = tag_name + &#39;.nd2&#39;
        # new_file_path = raw_files_dir / new_file_name
        # nd2_file_path.rename(new_file_path)
        # nd2_file_path = new_file_path
        
        # # Copy the pkl files
        # new_file_name = tag_name + &#39;_info.pkl&#39;
        # new_file_path = raw_files_dir / new_file_name
        # # Must copy the pkl file in order to be able to use the file for the other channels
        # shutil.copy(str(info_file), str(new_file_path))
        
        # # Save the fov_coords
        # fname = experiment_fpath / &#39;tmp&#39; / (tag_name + &#39;_fovs_coords.npy&#39;)
        # np.save(fname, fov_coords)

        # fovs = list(fields_of_view)
        # list_store = [zarr_store] * len(fovs)
        # processing_info = list(zip(list_store,fovs))

        # return processing_info


@task(name=&#39;nd2_autoparser_single_files&#39;)
def nikon_nd2_autoparser_single_files(nd2_file_path,parsed_raw_data_fpath):
    &#34;&#34;&#34;
    This parser not consider the possibility to have multiple experiment running at
    the same time with the raw imaging data present in the same folder. 
    Once the data are parsed by hybridization are saved in
    the same folder.

    NB: The file and the corresponding metadata file generated by the microscope
        must contain &#39;CountXXXXX&#39; in order to be processed

    The parsed_tmp and raw_data directories are created in a previous step of the 
    pipeline during data sorting

    QC step run before parsing take care of checking if the nd2 files are present
    and in the corresponding pickle configuration files are in the folder

    This nd2 parser process one .nd2 file

    Args:
        nd2_file_path: str
            Path to the .nd2 file to be parsed
        parsed_raw_data_fpath: str
            Path to the zarr file that will store the parsed data

    Returns:
        processing_info: list of tuples
        each tuple contain the path of the zarr storage and the number of fov
    &#34;&#34;&#34;

    logger = prefect_logging_setup(&#34;auto_parser_single_files&#34;)

    nd2_file_path = Path(nd2_file_path)
    nd2_fname = nd2_file_path.stem

    logger.debug(f&#39;processing file {nd2_fname}&#39;)

    experiment_fpath = nd2_file_path.parent
    experiment_name = nd2_file_path.parent.stem
    experiment_name = experiment_name.split(&#39;_auto&#39;)[0]
       
    raw_files_dir = experiment_fpath / &#39;raw_data&#39;
    parsed_tmp = experiment_fpath / &#39;parsed_tmp&#39;
    

    # Extract the Count code from the file name
    count_code = re.search(r&#39;(Count)\d{5}&#39;, nd2_file_path.stem).group()
    
    all_info_files = experiment_fpath.glob(&#39;*.pkl&#39;)
    
    info_file = [info_file for info_file in all_info_files if count_code  in info_file.stem][0]
    
    info_data = pickle.load(open(info_file, &#39;rb&#39;))
    hybridization_name = info_data[&#39;channels&#39;][&#39;Hybridization&#39;]
    
    try:
        nd2fh = nd2reader.ND2Reader(nd2_file_path)
    except:
        logger.error(&#39;Cannot load the nd2 file&#39;)
        signals.FAIL(&#39;Cannot load the nd2 file&#39;)
    else:
        # Collect metadata
        all_metadata = nd2fh.parser._raw_metadata
        parsed_metadata = nd2fh.parser._raw_metadata.get_parsed_metadata()
        
        channel = parsed_metadata[&#39;channels&#39;][0] # works because there is only one channel for file
        img_height = parsed_metadata[&#39;height&#39;]
        img_width = parsed_metadata[&#39;width&#39;]
        pixel_microns = parsed_metadata[&#39;pixel_microns&#39;]
        z_levels = parsed_metadata[&#39;z_levels&#39;]
        fields_of_view = parsed_metadata[&#39;fields_of_view&#39;]
        
        # Collect FOV coords
        x_data = np.array(all_metadata.x_data)
        x_data = x_data[:,np.newaxis]
        y_data = np.array(all_metadata.x_data)
        y_data = y_data[:,np.newaxis]
        z_data = np.array(all_metadata.z_data)
        z_data = z_data[:,np.newaxis]
        all_coords = np.hstack((z_data,x_data,y_data))
        fov_coords = all_coords[0::len(z_levels),:]
        
        tag_name = experiment_name + &#39;_&#39; + hybridization_name + &#39;_&#39; + channel
        
        
        # Save the file as zarr
        zarr_store = parsed_tmp / (experiment_name + &#39;_&#39; + hybridization_name + &#39;_&#39; + channel + &#39;_raw_images_tmp.zarr&#39;)
        
        # Create empty zarr file
        dataset = xr.Dataset()
        dataset.to_zarr(zarr_store, mode=&#39;w&#39;, consolidated=True)
        
        nd2fh.bundle_axes = &#39;zyx&#39;
        # set iteration over the fields of view
        nd2fh.iter_axes = &#39;v&#39;
        
        # Save coords of the FOV
        rows = np.arange(img_width)
        cols = np.arange(img_height)
        hybridization_num = int(hybridization_name.split(&#39;Hybridization&#39;)[-1])
        for fov in fields_of_view:
            img = np.array(nd2fh[fov],dtype=np.uint16)
            fov_attrs = {&#39;channel&#39;: channel,
                &#39;target_name&#39;: info_data[&#39;channels&#39;][channel],
                &#39;img_height&#39;: img_height,
                &#39;img_width&#39;: img_width,
                &#39;pixel_microns&#39;: pixel_microns,
                &#39;z_levels&#39;:list(z_levels),
                &#39;fov_num&#39;: fov,
                &#39;StitchingChannel&#39;: info_data[&#39;StitchingChannel&#39;],
                &#39;hybridization_num&#39;: hybridization_num,
                &#39;experiment_name&#39; : experiment_name} 
            datarray_name = tag_name + &#39;_fov_&#39; + str(fov) 
            img_xarray = xr.DataArray(img, coords={&#39;z_levels&#39;:z_levels,&#39;rows&#39;:rows, &#39;cols&#39;:cols}, 
                                    dims=[&#39;z_levels&#39;,&#39;rows&#39;,&#39;cols&#39;],attrs=fov_attrs, name=datarray_name)
            img_xarray = img_xarray.chunk(chunks=(1,img_width,img_height))
            ds = img_xarray.to_dataset(name = datarray_name)
            ds.to_zarr(zarr_store, mode=&#39;a&#39;, consolidated=True)
                
        # # Rename the nd2 files
        # new_file_name = tag_name + &#39;.nd2&#39;
        # new_file_path = raw_files_dir / new_file_name
        # nd2_file_path.rename(new_file_path)
        # nd2_file_path = new_file_path
        
        # # Copy the pkl files
        # new_file_name = tag_name + &#39;_info.pkl&#39;
        # new_file_path = raw_files_dir / new_file_name
        # # Must copy the pkl file in order to be able to use the file for the other channels
        # shutil.copy(str(info_file), str(new_file_path))
        
        # Save the fov_coords
        # fname = experiment_fpath / &#39;tmp&#39; / (tag_name + &#39;_fovs_coords.npy&#39;)
        # np.save(fname, fov_coords)

        # fovs = list(fields_of_view)
        # list_store = [zarr_store] * len(fovs)
        # processing_info = list(zip(list_store,fovs))

        # return processing_info

@task(name=&#39;nd2_autoparser&#39;)
def nikon_nd2_autoparser_zarr_single_files(nd2_file_path,parsed_raw_data_fpath):
    &#34;&#34;&#34;
    This parser not consider the possibility to have multiple experiment running at
    the same time with the raw imaging data present in the same folder. 
    Once the data are parsed by hybridization are saved in
    the same folder.

    NB: The file and the corresponding metadata file generated by the microscope
        must contain &#39;CountXXXXX&#39; in order to be processed

    The parsed_tmp and raw_data directories are created in a previous step of the 
    pipeline during data sorting

    QC step run before parsing take care of checking if the nd2 files are present
    and in the corresponding pickle configuration files are in the folder

    This nd2 parser process one .nd2 file

    Args:
        nd2_file_path: str
            Path to the .nd2 file to be parsed
        parsed_raw_data_fpath: str
            Path to the zarr file that will store the parsed data

    Returns:
        processing_info: list of tuples
        each tuple contain the path of the zarr storage and the number of fov
    &#34;&#34;&#34;

    logger = prefect_logging_setup(&#34;auto_parser&#34;)

    nd2_file_path = Path(nd2_file_path)
    nd2_fname = nd2_file_path.stem

    logger.debug(f&#39;processing file {nd2_fname}&#39;)

    experiment_fpath = nd2_file_path.parent
    experiment_name = nd2_file_path.parent.stem
    experiment_name = experiment_name.split(&#39;_auto&#39;)[0]
       
    raw_files_dir = experiment_fpath / &#39;raw_data&#39;
    parsed_tmp = experiment_fpath / &#39;parsed_tmp&#39;
    

    # Extract the Count code from the file name
    count_code = re.search(r&#39;(Count)\d{5}&#39;, nd2_file_path.stem).group()
    
    all_info_files = experiment_fpath.glob(&#39;*.pkl&#39;)
    
    info_file = [info_file for info_file in all_info_files if count_code  in info_file.stem][0]
    
    info_data = pickle.load(open(info_file, &#39;rb&#39;))
    hybridization_name = info_data[&#39;channels&#39;][&#39;Hybridization&#39;]
    
    try:
        nd2fh = nd2reader.ND2Reader(nd2_file_path)
    except:
        logger.error(&#39;Cannot load the nd2 file&#39;)
        signals.FAIL(&#39;Cannot load the nd2 file&#39;)
    else:
        # Collect metadata
        all_metadata = nd2fh.parser._raw_metadata
        parsed_metadata = nd2fh.parser._raw_metadata.get_parsed_metadata()
        
        channel = parsed_metadata[&#39;channels&#39;][0] # works because there is only one channel for file
        img_height = parsed_metadata[&#39;height&#39;]
        img_width = parsed_metadata[&#39;width&#39;]
        pixel_microns = parsed_metadata[&#39;pixel_microns&#39;]
        z_levels = parsed_metadata[&#39;z_levels&#39;]
        fields_of_view = parsed_metadata[&#39;fields_of_view&#39;]
        
        # Collect FOV coords
        x_data = np.array(all_metadata.x_data)
        x_data = x_data[:,np.newaxis]
        y_data = np.array(all_metadata.x_data)
        y_data = y_data[:,np.newaxis]
        z_data = np.array(all_metadata.z_data)
        z_data = z_data[:,np.newaxis]
        all_coords = np.hstack((z_data,x_data,y_data))
        fov_coords = all_coords[0::len(z_levels),:]
        
        tag_name = experiment_name + &#39;_&#39; + hybridization_name + &#39;_&#39; + channel
        
        
        # Save the file as zarr
        zarr_store = parsed_tmp / (experiment_name + &#39;_&#39; + hybridization_name + &#39;_&#39; + channel + &#39;_raw_images_tmp.zarr&#39;)
        store = zarr.DirectoryStore(zarr_store)
        root = zarr.group(store=store,overwrite=True)

        
        nd2fh.bundle_axes = &#39;zyx&#39;
        # set iteration over the fields of view
        nd2fh.iter_axes = &#39;v&#39;
        
        # Save coords of the FOV
        rows = np.arange(img_width)
        cols = np.arange(img_height)
        hybridization_num = int(hybridization_name.split(&#39;Hybridization&#39;)[-1])
        for fov in fields_of_view:
            img = np.array(nd2fh[fov],dtype=np.uint16)        
            dset = root.create_dataset(fov, data=img, shape=img.shape, chunks=(1,None,None),overwrite=True)
            dset.attrs[&#39;channel&#39;] = channel
            dset.attrs[&#39;target_name&#39;] = info_data[&#39;channels&#39;][channel]
            dset.attrs[&#39;img_height&#39;] = img_height
            dset.attrs[&#39;img_width&#39;] = img_width
            dset.attrs[&#39;pixel_microns&#39;] = pixel_microns
            dset.attrs[&#39;z_levels&#39;] = list(z_levels)
            dset.attrs[&#39;fov_num&#39;] = fov
            dset.attrs[&#39;StitchingChannel&#39;] = info_data[&#39;StitchingChannel&#39;]
            dset.attrs[&#39;hybridization_num&#39;] = hybridization_num
            dset.attrs[&#39;experiment_name&#39;] = experiment_name

        zarr.convenience.consolidate_metadata(store)                
        # Rename the nd2 files
        # new_file_name = tag_name + &#39;.nd2&#39;
        # new_file_path = raw_files_dir / new_file_name
        # nd2_file_path.rename(new_file_path)
        # nd2_file_path = new_file_path
        
        # # Copy the pkl files
        # new_file_name = tag_name + &#39;_info.pkl&#39;
        # new_file_path = raw_files_dir / new_file_name
        # # Must copy the pkl file in order to be able to use the file for the other channels
        # shutil.copy(str(info_file), str(new_file_path))
        
        # # Save the fov_coords
        # fname = experiment_fpath / &#39;tmp&#39; / (tag_name + &#39;_fovs_coords.npy&#39;)
        # np.save(fname, fov_coords)

@task(name=&#39;nd2_autoparser&#39;)
def nikon_nd2_autoparser_zarr(nd2_file_path,parsed_raw_data_fpath,experiment_info):
    &#34;&#34;&#34;
    This parser not consider the possibility to have multiple experiment running at
    the same time with the raw imaging data present in the same folder. 
    Once the data are parsed by hybridization are saved in
    the same folder.

    NB: The file and the corresponding metadata file generated by the microscope
        must contain &#39;CountXXXXX&#39; in order to be processed

    The parsed_tmp and raw_data directories are created in a previous step of the 
    pipeline during data sorting

    QC step run before parsing take care of checking if the nd2 files are present
    and in the corresponding pickle configuration files are in the folder

    This nd2 parser process one .nd2 file

    Args:
        nd2_file_path: str
            Path to the .nd2 file to be parsed
        parsed_raw_data_fpath: str
            Path to the zarr file that will store the parsed data
        experiment_info: dict
            Dictionary with overall experiment info

    Returns:
        processing_info: list of tuples
        each tuple contain the path of the zarr storage and the number of fov
    &#34;&#34;&#34;

    logger = prefect_logging_setup(&#34;auto_parser&#34;)

    nd2_file_path = Path(nd2_file_path)
    nd2_fname = nd2_file_path.stem

    logger.debug(f&#39;processing file {nd2_fname}&#39;)

    experiment_fpath = nd2_file_path.parent
    experiment_name = nd2_file_path.parent.stem
    experiment_name = experiment_name.split(&#39;_auto&#39;)[0]
       
    raw_files_dir = experiment_fpath / &#39;raw_data&#39;
    
    # Extract the Count code from the file name
    count_code = re.search(r&#39;(Count)\d{5}&#39;, nd2_file_path.stem).group()
    
    all_info_files = experiment_fpath.glob(&#39;*.pkl&#39;)
    
    info_file = [info_file for info_file in all_info_files if count_code  in info_file.stem][0]
    
    info_data = pickle.load(open(info_file, &#39;rb&#39;))
    hybridization_name = info_data[&#39;channels&#39;][&#39;Hybridization&#39;]
    
    try:
        nd2fh = nd2reader.ND2Reader(nd2_file_path)
    except:
        logger.error(&#39;Cannot load the nd2 file&#39;)
        err = signals.FAIL(&#39;Cannot load the nd2 file&#39;)
        raise err
    else:
        # Collect metadata
        all_metadata = nd2fh.parser._raw_metadata
        parsed_metadata = nd2fh.parser._raw_metadata.get_parsed_metadata()
        
        channel = parsed_metadata[&#39;channels&#39;][0] # works because there is only one channel for file
        img_shape = np.array([parsed_metadata[&#39;height&#39;],parsed_metadata[&#39;width&#39;]])
        pixel_microns = parsed_metadata[&#39;pixel_microns&#39;]
        z_levels = parsed_metadata[&#39;z_levels&#39;]
        fields_of_view = parsed_metadata[&#39;fields_of_view&#39;]
        
        # Collect FOV coords
        x_data = np.array(all_metadata.x_data)
        #x_data = x_data[:,np.newaxis]
        y_data = np.array(all_metadata.x_data)
        #y_data = y_data[:,np.newaxis]
        z_data = np.array(all_metadata.z_data)
        #z_data = z_data[:,np.newaxis]
        #all_coords = np.hstack((z_data,x_data,y_data))
        #fov_coords = all_coords[0::len(z_levels),:]
        
        tag_name = experiment_name + &#39;_&#39; + hybridization_name + &#39;_&#39; + channel
        
        
        # Save the file as zarr
        store = zarr.DirectoryStore(parsed_raw_data_fpath)
        root = zarr.group(store=store,overwrite=False)

        
        nd2fh.bundle_axes = &#39;zyx&#39;
        # set iteration over the fields of view
        nd2fh.iter_axes = &#39;v&#39;
        
        # Save coords of the FOV
        rows = np.arange(parsed_metadata[&#39;width&#39;])
        cols = np.arange(parsed_metadata[&#39;height&#39;])
        hybridization_num = int(hybridization_name.split(&#39;Hybridization&#39;)[-1])
        for fov in fields_of_view:
            img = np.array(nd2fh[fov],dtype=np.uint16)      
            array_name = tag_name + &#39;_fov_&#39; + str(fov)
            dgrp = root.create_group(array_name)
            fov_name = &#39;raw_data_fov_&#39; + str(fov)
            # Remember that attrs must be JSON-serializable to be stored
            # in zarr
            dgrp.attrs[&#39;grp_name&#39;] = array_name
            dgrp.attrs[&#39;fov_name&#39;] = fov_name
            dgrp.attrs[&#39;channel&#39;] = channel
            dgrp.attrs[&#39;target_name&#39;] = info_data[&#39;channels&#39;][channel]
            dgrp.attrs[&#39;img_width&#39;] = parsed_metadata[&#39;width&#39;]
            dgrp.attrs[&#39;img_height&#39;] = parsed_metadata[&#39;height&#39;]
            dgrp.attrs[&#39;pixel_microns&#39;] = pixel_microns
            dgrp.attrs[&#39;z_levels&#39;] = list(z_levels)
            dgrp.attrs[&#39;fields_of_view&#39;] = list(fields_of_view)
            dgrp.attrs[&#39;fov_num&#39;] = fov
            dgrp.attrs[&#39;stitching_channel&#39;] = info_data[&#39;StitchingChannel&#39;]
            dgrp.attrs[&#39;stitching_type&#39;] = experiment_info[&#39;Stitching_type&#39;]
            dgrp.attrs[&#39;experiment_type&#39;] = experiment_info[&#39;Experiment_type&#39;]
            dgrp.attrs[&#39;hybridization_num&#39;] = hybridization_num
            dgrp.attrs[&#39;experiment_name&#39;] = experiment_name
            dgrp.attrs[&#39;fov_acquisition_coords_x&#39;] = x_data[fov]
            dgrp.attrs[&#39;fov_acquisition_coords_y&#39;] = y_data[fov]
            dgrp.attrs[&#39;fov_acquisition_coords_z&#39;] = z_data[fov]


            if info_data[&#39;StitchingChannel&#39;] == channel:
                dgrp.attrs[&#39;processing_type&#39;] = dgrp.attrs[&#39;stitching_type&#39;]
            elif &#39;_ST&#39; in dgrp.attrs[&#39;target_name&#39;]:
                dgrp.attrs[&#39;processing_type&#39;] = &#39;staining&#39;
            else:
                dgrp.attrs[&#39;processing_type&#39;] = &#39;fish&#39;

            dset = dgrp.create_dataset(fov_name, data=img, shape=img.shape, chunks=(1,None,None),overwrite=True)
               
        # Rename the nd2 files
        # new_file_name = tag_name + &#39;.nd2&#39;
        # new_file_path = raw_files_dir / new_file_name
        # nd2_file_path.rename(new_file_path)
        # nd2_file_path = new_file_path
        
        # # Copy the pkl files
        # new_file_name = tag_name + &#39;_info.pkl&#39;
        # new_file_path = raw_files_dir / new_file_name
        # # Must copy the pkl file in order to be able to use the file for the other channels
        # shutil.copy(str(info_file), str(new_file_path))
        
        # Save the fov_coords
        # fname = experiment_fpath / &#39;tmp&#39; / (tag_name + &#39;_fovs_coords.npy&#39;)
        # np.save(fname, fov_coords)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pysmFISH.microscopy_file_parsers_tasks.nd2_raw_files_selector"><code class="name flex">
<span>def <span class="ident">nd2_raw_files_selector</span></span>(<span>experiment_fpath: str) ‑> list</span>
</code></dt>
<dd>
<div class="desc"><p>Identify the nd2 raw microscopy files generated by
the robofish machine. The files must contain CountXXXXX in the name. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>experiment_fpath</code></strong></dt>
<dd>str
Path to the folder to process. It need to contain the '_auto'
suffix in order to be process with the automated pipeline</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>all_files_to_process</code></dt>
<dd>list
List of PosixPath of the microscopy files to process</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task(name=&#39;nd2_files_selection&#39;)
def nd2_raw_files_selector(experiment_fpath: str) -&gt; list:
    &#34;&#34;&#34;
    Identify the nd2 raw microscopy files generated by
    the robofish machine. The files must contain CountXXXXX in the name. 

    Args:
        experiment_fpath: str 
            Path to the folder to process. It need to contain the &#39;_auto&#39;
            suffix in order to be process with the automated pipeline

    Returns:
        all_files_to_process: list
            List of PosixPath of the microscopy files to process
        
    &#34;&#34;&#34;

    logger = prefect.utilities.logging.get_logger(&#34;parsing&#34;)
    
    assert &#39;_auto&#39; in experiment_fpath.stem, signals.FAIL(&#39;no _auto in the experiment name&#39;)

    experiment_fpath = Path(experiment_fpath)
    searching_key = &#39;*Count*.nd2&#39;
    all_files_to_process = list(experiment_fpath.glob(searching_key))

    assert all_files_to_process, signals.FAIL(&#39;no .nd2 raw files to process&#39;)
    
    logger.debug(f&#39;Number of files to process {len(all_files_to_process)}.&#39;)
    return all_files_to_process</code></pre>
</details>
</dd>
<dt id="pysmFISH.microscopy_file_parsers_tasks.nikon_nd2_autoparser"><code class="name flex">
<span>def <span class="ident">nikon_nd2_autoparser</span></span>(<span>nd2_file_path, parsed_raw_data_fpath)</span>
</code></dt>
<dd>
<div class="desc"><p>This parser not consider the possibility to have multiple experiment running at
the same time with the raw imaging data present in the same folder.
Once the data are parsed by hybridization are saved in
the same folder.</p>
<p>NB: The file and the corresponding metadata file generated by the microscope
must contain 'CountXXXXX' in order to be processed</p>
<p>The parsed_tmp and raw_data directories are created in a previous step of the
pipeline during data sorting</p>
<p>QC step run before parsing take care of checking if the nd2 files are present
and in the corresponding pickle configuration files are in the folder</p>
<p>This nd2 parser process one .nd2 file</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>nd2_file_path</code></strong></dt>
<dd>str
Path to the .nd2 file to be parsed</dd>
<dt><strong><code>parsed_raw_data_fpath</code></strong></dt>
<dd>str
Path to the zarr file that will store the parsed data</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>processing_info</code></dt>
<dd>list of tuples</dd>
</dl>
<p>each tuple contain the path of the zarr storage and the number of fov</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task(name=&#39;nd2_autoparser&#39;)
def nikon_nd2_autoparser(nd2_file_path,parsed_raw_data_fpath):
    &#34;&#34;&#34;
    This parser not consider the possibility to have multiple experiment running at
    the same time with the raw imaging data present in the same folder. 
    Once the data are parsed by hybridization are saved in
    the same folder.

    NB: The file and the corresponding metadata file generated by the microscope
        must contain &#39;CountXXXXX&#39; in order to be processed

    The parsed_tmp and raw_data directories are created in a previous step of the 
    pipeline during data sorting

    QC step run before parsing take care of checking if the nd2 files are present
    and in the corresponding pickle configuration files are in the folder

    This nd2 parser process one .nd2 file

    Args:
        nd2_file_path: str
            Path to the .nd2 file to be parsed
        parsed_raw_data_fpath: str
            Path to the zarr file that will store the parsed data

    Returns:
        processing_info: list of tuples
        each tuple contain the path of the zarr storage and the number of fov
    &#34;&#34;&#34;

    logger = prefect_logging_setup(&#34;auto_parser&#34;)

    nd2_file_path = Path(nd2_file_path)
    nd2_fname = nd2_file_path.stem

    logger.debug(f&#39;processing file {nd2_fname}&#39;)

    experiment_fpath = nd2_file_path.parent
    experiment_name = nd2_file_path.parent.stem
    experiment_name = experiment_name.split(&#39;_auto&#39;)[0]
       
    raw_files_dir = experiment_fpath / &#39;raw_data&#39;
    parsed_tmp = experiment_fpath / &#39;parsed_tmp&#39;
    

    # Extract the Count code from the file name
    count_code = re.search(r&#39;(Count)\d{5}&#39;, nd2_file_path.stem).group()
    
    all_info_files = experiment_fpath.glob(&#39;*.pkl&#39;)
    
    info_file = [info_file for info_file in all_info_files if count_code  in info_file.stem][0]
    
    info_data = pickle.load(open(info_file, &#39;rb&#39;))
    hybridization_name = info_data[&#39;channels&#39;][&#39;Hybridization&#39;]
    
    try:
        nd2fh = nd2reader.ND2Reader(nd2_file_path)
    except:
        logger.error(&#39;Cannot load the nd2 file&#39;)
        signals.FAIL(&#39;Cannot load the nd2 file&#39;)
    else:
        # Collect metadata
        all_metadata = nd2fh.parser._raw_metadata
        parsed_metadata = nd2fh.parser._raw_metadata.get_parsed_metadata()
        
        channel = parsed_metadata[&#39;channels&#39;][0] # works because there is only one channel for file
        img_height = parsed_metadata[&#39;height&#39;]
        img_width = parsed_metadata[&#39;width&#39;]
        pixel_microns = parsed_metadata[&#39;pixel_microns&#39;]
        z_levels = parsed_metadata[&#39;z_levels&#39;]
        fields_of_view = parsed_metadata[&#39;fields_of_view&#39;]
        
        # Collect FOV coords
        x_data = np.array(all_metadata.x_data)
        x_data = x_data[:,np.newaxis]
        y_data = np.array(all_metadata.x_data)
        y_data = y_data[:,np.newaxis]
        z_data = np.array(all_metadata.z_data)
        z_data = z_data[:,np.newaxis]
        all_coords = np.hstack((z_data,x_data,y_data))
        fov_coords = all_coords[0::len(z_levels),:]
        
        tag_name = experiment_name + &#39;_&#39; + hybridization_name + &#39;_&#39; + channel
        
        
        # Save the file as zarr
        # zarr_store = parsed_tmp / (experiment_name + &#39;_&#39; + hybridization_name + &#39;_&#39; + channel + &#39;_raw_images_tmp.zarr&#39;)
        nd2fh.bundle_axes = &#39;zyx&#39;
        # set iteration over the fields of view
        nd2fh.iter_axes = &#39;v&#39;
        
        # Save coords of the FOV
        rows = np.arange(img_width)
        cols = np.arange(img_height)
        hybridization_num = int(hybridization_name.split(&#39;Hybridization&#39;)[-1])
        for fov in fields_of_view:
            img = np.array(nd2fh[fov],dtype=np.uint16)
            fov_attrs = {&#39;channel&#39;: channel,
                &#39;target_name&#39;: info_data[&#39;channels&#39;][channel],
                &#39;img_height&#39;: img_height,
                &#39;img_width&#39;: img_width,
                &#39;pixel_microns&#39;: pixel_microns,
                &#39;z_levels&#39;:list(z_levels),
                &#39;fov_num&#39;: fov,
                &#39;StitchingChannel&#39;: info_data[&#39;StitchingChannel&#39;],
                &#39;hybridization_num&#39;: hybridization_num,
                &#39;experiment_name&#39; : experiment_name} 
            datarray_name = tag_name + &#39;_fov_&#39; + str(fov) 
            img_xarray = xr.DataArray(img, coords={&#39;z_levels&#39;:z_levels,&#39;rows&#39;:rows, &#39;cols&#39;:cols}, 
                                    dims=[&#39;z_levels&#39;,&#39;rows&#39;,&#39;cols&#39;],attrs=fov_attrs, name=datarray_name)
            img_xarray = img_xarray.chunk(chunks=(1,img_width,img_height))
            ds = img_xarray.to_dataset(name = datarray_name)
            ds.to_zarr(parsed_raw_data_fpath, mode=&#39;a&#39;, consolidated=True)</code></pre>
</details>
</dd>
<dt id="pysmFISH.microscopy_file_parsers_tasks.nikon_nd2_autoparser_single_files"><code class="name flex">
<span>def <span class="ident">nikon_nd2_autoparser_single_files</span></span>(<span>nd2_file_path, parsed_raw_data_fpath)</span>
</code></dt>
<dd>
<div class="desc"><p>This parser not consider the possibility to have multiple experiment running at
the same time with the raw imaging data present in the same folder.
Once the data are parsed by hybridization are saved in
the same folder.</p>
<p>NB: The file and the corresponding metadata file generated by the microscope
must contain 'CountXXXXX' in order to be processed</p>
<p>The parsed_tmp and raw_data directories are created in a previous step of the
pipeline during data sorting</p>
<p>QC step run before parsing take care of checking if the nd2 files are present
and in the corresponding pickle configuration files are in the folder</p>
<p>This nd2 parser process one .nd2 file</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>nd2_file_path</code></strong></dt>
<dd>str
Path to the .nd2 file to be parsed</dd>
<dt><strong><code>parsed_raw_data_fpath</code></strong></dt>
<dd>str
Path to the zarr file that will store the parsed data</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>processing_info</code></dt>
<dd>list of tuples</dd>
</dl>
<p>each tuple contain the path of the zarr storage and the number of fov</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task(name=&#39;nd2_autoparser_single_files&#39;)
def nikon_nd2_autoparser_single_files(nd2_file_path,parsed_raw_data_fpath):
    &#34;&#34;&#34;
    This parser not consider the possibility to have multiple experiment running at
    the same time with the raw imaging data present in the same folder. 
    Once the data are parsed by hybridization are saved in
    the same folder.

    NB: The file and the corresponding metadata file generated by the microscope
        must contain &#39;CountXXXXX&#39; in order to be processed

    The parsed_tmp and raw_data directories are created in a previous step of the 
    pipeline during data sorting

    QC step run before parsing take care of checking if the nd2 files are present
    and in the corresponding pickle configuration files are in the folder

    This nd2 parser process one .nd2 file

    Args:
        nd2_file_path: str
            Path to the .nd2 file to be parsed
        parsed_raw_data_fpath: str
            Path to the zarr file that will store the parsed data

    Returns:
        processing_info: list of tuples
        each tuple contain the path of the zarr storage and the number of fov
    &#34;&#34;&#34;

    logger = prefect_logging_setup(&#34;auto_parser_single_files&#34;)

    nd2_file_path = Path(nd2_file_path)
    nd2_fname = nd2_file_path.stem

    logger.debug(f&#39;processing file {nd2_fname}&#39;)

    experiment_fpath = nd2_file_path.parent
    experiment_name = nd2_file_path.parent.stem
    experiment_name = experiment_name.split(&#39;_auto&#39;)[0]
       
    raw_files_dir = experiment_fpath / &#39;raw_data&#39;
    parsed_tmp = experiment_fpath / &#39;parsed_tmp&#39;
    

    # Extract the Count code from the file name
    count_code = re.search(r&#39;(Count)\d{5}&#39;, nd2_file_path.stem).group()
    
    all_info_files = experiment_fpath.glob(&#39;*.pkl&#39;)
    
    info_file = [info_file for info_file in all_info_files if count_code  in info_file.stem][0]
    
    info_data = pickle.load(open(info_file, &#39;rb&#39;))
    hybridization_name = info_data[&#39;channels&#39;][&#39;Hybridization&#39;]
    
    try:
        nd2fh = nd2reader.ND2Reader(nd2_file_path)
    except:
        logger.error(&#39;Cannot load the nd2 file&#39;)
        signals.FAIL(&#39;Cannot load the nd2 file&#39;)
    else:
        # Collect metadata
        all_metadata = nd2fh.parser._raw_metadata
        parsed_metadata = nd2fh.parser._raw_metadata.get_parsed_metadata()
        
        channel = parsed_metadata[&#39;channels&#39;][0] # works because there is only one channel for file
        img_height = parsed_metadata[&#39;height&#39;]
        img_width = parsed_metadata[&#39;width&#39;]
        pixel_microns = parsed_metadata[&#39;pixel_microns&#39;]
        z_levels = parsed_metadata[&#39;z_levels&#39;]
        fields_of_view = parsed_metadata[&#39;fields_of_view&#39;]
        
        # Collect FOV coords
        x_data = np.array(all_metadata.x_data)
        x_data = x_data[:,np.newaxis]
        y_data = np.array(all_metadata.x_data)
        y_data = y_data[:,np.newaxis]
        z_data = np.array(all_metadata.z_data)
        z_data = z_data[:,np.newaxis]
        all_coords = np.hstack((z_data,x_data,y_data))
        fov_coords = all_coords[0::len(z_levels),:]
        
        tag_name = experiment_name + &#39;_&#39; + hybridization_name + &#39;_&#39; + channel
        
        
        # Save the file as zarr
        zarr_store = parsed_tmp / (experiment_name + &#39;_&#39; + hybridization_name + &#39;_&#39; + channel + &#39;_raw_images_tmp.zarr&#39;)
        
        # Create empty zarr file
        dataset = xr.Dataset()
        dataset.to_zarr(zarr_store, mode=&#39;w&#39;, consolidated=True)
        
        nd2fh.bundle_axes = &#39;zyx&#39;
        # set iteration over the fields of view
        nd2fh.iter_axes = &#39;v&#39;
        
        # Save coords of the FOV
        rows = np.arange(img_width)
        cols = np.arange(img_height)
        hybridization_num = int(hybridization_name.split(&#39;Hybridization&#39;)[-1])
        for fov in fields_of_view:
            img = np.array(nd2fh[fov],dtype=np.uint16)
            fov_attrs = {&#39;channel&#39;: channel,
                &#39;target_name&#39;: info_data[&#39;channels&#39;][channel],
                &#39;img_height&#39;: img_height,
                &#39;img_width&#39;: img_width,
                &#39;pixel_microns&#39;: pixel_microns,
                &#39;z_levels&#39;:list(z_levels),
                &#39;fov_num&#39;: fov,
                &#39;StitchingChannel&#39;: info_data[&#39;StitchingChannel&#39;],
                &#39;hybridization_num&#39;: hybridization_num,
                &#39;experiment_name&#39; : experiment_name} 
            datarray_name = tag_name + &#39;_fov_&#39; + str(fov) 
            img_xarray = xr.DataArray(img, coords={&#39;z_levels&#39;:z_levels,&#39;rows&#39;:rows, &#39;cols&#39;:cols}, 
                                    dims=[&#39;z_levels&#39;,&#39;rows&#39;,&#39;cols&#39;],attrs=fov_attrs, name=datarray_name)
            img_xarray = img_xarray.chunk(chunks=(1,img_width,img_height))
            ds = img_xarray.to_dataset(name = datarray_name)
            ds.to_zarr(zarr_store, mode=&#39;a&#39;, consolidated=True)</code></pre>
</details>
</dd>
<dt id="pysmFISH.microscopy_file_parsers_tasks.nikon_nd2_autoparser_zarr"><code class="name flex">
<span>def <span class="ident">nikon_nd2_autoparser_zarr</span></span>(<span>nd2_file_path, parsed_raw_data_fpath, experiment_info)</span>
</code></dt>
<dd>
<div class="desc"><p>This parser not consider the possibility to have multiple experiment running at
the same time with the raw imaging data present in the same folder.
Once the data are parsed by hybridization are saved in
the same folder.</p>
<p>NB: The file and the corresponding metadata file generated by the microscope
must contain 'CountXXXXX' in order to be processed</p>
<p>The parsed_tmp and raw_data directories are created in a previous step of the
pipeline during data sorting</p>
<p>QC step run before parsing take care of checking if the nd2 files are present
and in the corresponding pickle configuration files are in the folder</p>
<p>This nd2 parser process one .nd2 file</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>nd2_file_path</code></strong></dt>
<dd>str
Path to the .nd2 file to be parsed</dd>
<dt><strong><code>parsed_raw_data_fpath</code></strong></dt>
<dd>str
Path to the zarr file that will store the parsed data</dd>
<dt><strong><code>experiment_info</code></strong></dt>
<dd>dict
Dictionary with overall experiment info</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>processing_info</code></dt>
<dd>list of tuples</dd>
</dl>
<p>each tuple contain the path of the zarr storage and the number of fov</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task(name=&#39;nd2_autoparser&#39;)
def nikon_nd2_autoparser_zarr(nd2_file_path,parsed_raw_data_fpath,experiment_info):
    &#34;&#34;&#34;
    This parser not consider the possibility to have multiple experiment running at
    the same time with the raw imaging data present in the same folder. 
    Once the data are parsed by hybridization are saved in
    the same folder.

    NB: The file and the corresponding metadata file generated by the microscope
        must contain &#39;CountXXXXX&#39; in order to be processed

    The parsed_tmp and raw_data directories are created in a previous step of the 
    pipeline during data sorting

    QC step run before parsing take care of checking if the nd2 files are present
    and in the corresponding pickle configuration files are in the folder

    This nd2 parser process one .nd2 file

    Args:
        nd2_file_path: str
            Path to the .nd2 file to be parsed
        parsed_raw_data_fpath: str
            Path to the zarr file that will store the parsed data
        experiment_info: dict
            Dictionary with overall experiment info

    Returns:
        processing_info: list of tuples
        each tuple contain the path of the zarr storage and the number of fov
    &#34;&#34;&#34;

    logger = prefect_logging_setup(&#34;auto_parser&#34;)

    nd2_file_path = Path(nd2_file_path)
    nd2_fname = nd2_file_path.stem

    logger.debug(f&#39;processing file {nd2_fname}&#39;)

    experiment_fpath = nd2_file_path.parent
    experiment_name = nd2_file_path.parent.stem
    experiment_name = experiment_name.split(&#39;_auto&#39;)[0]
       
    raw_files_dir = experiment_fpath / &#39;raw_data&#39;
    
    # Extract the Count code from the file name
    count_code = re.search(r&#39;(Count)\d{5}&#39;, nd2_file_path.stem).group()
    
    all_info_files = experiment_fpath.glob(&#39;*.pkl&#39;)
    
    info_file = [info_file for info_file in all_info_files if count_code  in info_file.stem][0]
    
    info_data = pickle.load(open(info_file, &#39;rb&#39;))
    hybridization_name = info_data[&#39;channels&#39;][&#39;Hybridization&#39;]
    
    try:
        nd2fh = nd2reader.ND2Reader(nd2_file_path)
    except:
        logger.error(&#39;Cannot load the nd2 file&#39;)
        err = signals.FAIL(&#39;Cannot load the nd2 file&#39;)
        raise err
    else:
        # Collect metadata
        all_metadata = nd2fh.parser._raw_metadata
        parsed_metadata = nd2fh.parser._raw_metadata.get_parsed_metadata()
        
        channel = parsed_metadata[&#39;channels&#39;][0] # works because there is only one channel for file
        img_shape = np.array([parsed_metadata[&#39;height&#39;],parsed_metadata[&#39;width&#39;]])
        pixel_microns = parsed_metadata[&#39;pixel_microns&#39;]
        z_levels = parsed_metadata[&#39;z_levels&#39;]
        fields_of_view = parsed_metadata[&#39;fields_of_view&#39;]
        
        # Collect FOV coords
        x_data = np.array(all_metadata.x_data)
        #x_data = x_data[:,np.newaxis]
        y_data = np.array(all_metadata.x_data)
        #y_data = y_data[:,np.newaxis]
        z_data = np.array(all_metadata.z_data)
        #z_data = z_data[:,np.newaxis]
        #all_coords = np.hstack((z_data,x_data,y_data))
        #fov_coords = all_coords[0::len(z_levels),:]
        
        tag_name = experiment_name + &#39;_&#39; + hybridization_name + &#39;_&#39; + channel
        
        
        # Save the file as zarr
        store = zarr.DirectoryStore(parsed_raw_data_fpath)
        root = zarr.group(store=store,overwrite=False)

        
        nd2fh.bundle_axes = &#39;zyx&#39;
        # set iteration over the fields of view
        nd2fh.iter_axes = &#39;v&#39;
        
        # Save coords of the FOV
        rows = np.arange(parsed_metadata[&#39;width&#39;])
        cols = np.arange(parsed_metadata[&#39;height&#39;])
        hybridization_num = int(hybridization_name.split(&#39;Hybridization&#39;)[-1])
        for fov in fields_of_view:
            img = np.array(nd2fh[fov],dtype=np.uint16)      
            array_name = tag_name + &#39;_fov_&#39; + str(fov)
            dgrp = root.create_group(array_name)
            fov_name = &#39;raw_data_fov_&#39; + str(fov)
            # Remember that attrs must be JSON-serializable to be stored
            # in zarr
            dgrp.attrs[&#39;grp_name&#39;] = array_name
            dgrp.attrs[&#39;fov_name&#39;] = fov_name
            dgrp.attrs[&#39;channel&#39;] = channel
            dgrp.attrs[&#39;target_name&#39;] = info_data[&#39;channels&#39;][channel]
            dgrp.attrs[&#39;img_width&#39;] = parsed_metadata[&#39;width&#39;]
            dgrp.attrs[&#39;img_height&#39;] = parsed_metadata[&#39;height&#39;]
            dgrp.attrs[&#39;pixel_microns&#39;] = pixel_microns
            dgrp.attrs[&#39;z_levels&#39;] = list(z_levels)
            dgrp.attrs[&#39;fields_of_view&#39;] = list(fields_of_view)
            dgrp.attrs[&#39;fov_num&#39;] = fov
            dgrp.attrs[&#39;stitching_channel&#39;] = info_data[&#39;StitchingChannel&#39;]
            dgrp.attrs[&#39;stitching_type&#39;] = experiment_info[&#39;Stitching_type&#39;]
            dgrp.attrs[&#39;experiment_type&#39;] = experiment_info[&#39;Experiment_type&#39;]
            dgrp.attrs[&#39;hybridization_num&#39;] = hybridization_num
            dgrp.attrs[&#39;experiment_name&#39;] = experiment_name
            dgrp.attrs[&#39;fov_acquisition_coords_x&#39;] = x_data[fov]
            dgrp.attrs[&#39;fov_acquisition_coords_y&#39;] = y_data[fov]
            dgrp.attrs[&#39;fov_acquisition_coords_z&#39;] = z_data[fov]


            if info_data[&#39;StitchingChannel&#39;] == channel:
                dgrp.attrs[&#39;processing_type&#39;] = dgrp.attrs[&#39;stitching_type&#39;]
            elif &#39;_ST&#39; in dgrp.attrs[&#39;target_name&#39;]:
                dgrp.attrs[&#39;processing_type&#39;] = &#39;staining&#39;
            else:
                dgrp.attrs[&#39;processing_type&#39;] = &#39;fish&#39;

            dset = dgrp.create_dataset(fov_name, data=img, shape=img.shape, chunks=(1,None,None),overwrite=True)</code></pre>
</details>
</dd>
<dt id="pysmFISH.microscopy_file_parsers_tasks.nikon_nd2_autoparser_zarr_single_files"><code class="name flex">
<span>def <span class="ident">nikon_nd2_autoparser_zarr_single_files</span></span>(<span>nd2_file_path, parsed_raw_data_fpath)</span>
</code></dt>
<dd>
<div class="desc"><p>This parser not consider the possibility to have multiple experiment running at
the same time with the raw imaging data present in the same folder.
Once the data are parsed by hybridization are saved in
the same folder.</p>
<p>NB: The file and the corresponding metadata file generated by the microscope
must contain 'CountXXXXX' in order to be processed</p>
<p>The parsed_tmp and raw_data directories are created in a previous step of the
pipeline during data sorting</p>
<p>QC step run before parsing take care of checking if the nd2 files are present
and in the corresponding pickle configuration files are in the folder</p>
<p>This nd2 parser process one .nd2 file</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>nd2_file_path</code></strong></dt>
<dd>str
Path to the .nd2 file to be parsed</dd>
<dt><strong><code>parsed_raw_data_fpath</code></strong></dt>
<dd>str
Path to the zarr file that will store the parsed data</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>processing_info</code></dt>
<dd>list of tuples</dd>
</dl>
<p>each tuple contain the path of the zarr storage and the number of fov</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task(name=&#39;nd2_autoparser&#39;)
def nikon_nd2_autoparser_zarr_single_files(nd2_file_path,parsed_raw_data_fpath):
    &#34;&#34;&#34;
    This parser not consider the possibility to have multiple experiment running at
    the same time with the raw imaging data present in the same folder. 
    Once the data are parsed by hybridization are saved in
    the same folder.

    NB: The file and the corresponding metadata file generated by the microscope
        must contain &#39;CountXXXXX&#39; in order to be processed

    The parsed_tmp and raw_data directories are created in a previous step of the 
    pipeline during data sorting

    QC step run before parsing take care of checking if the nd2 files are present
    and in the corresponding pickle configuration files are in the folder

    This nd2 parser process one .nd2 file

    Args:
        nd2_file_path: str
            Path to the .nd2 file to be parsed
        parsed_raw_data_fpath: str
            Path to the zarr file that will store the parsed data

    Returns:
        processing_info: list of tuples
        each tuple contain the path of the zarr storage and the number of fov
    &#34;&#34;&#34;

    logger = prefect_logging_setup(&#34;auto_parser&#34;)

    nd2_file_path = Path(nd2_file_path)
    nd2_fname = nd2_file_path.stem

    logger.debug(f&#39;processing file {nd2_fname}&#39;)

    experiment_fpath = nd2_file_path.parent
    experiment_name = nd2_file_path.parent.stem
    experiment_name = experiment_name.split(&#39;_auto&#39;)[0]
       
    raw_files_dir = experiment_fpath / &#39;raw_data&#39;
    parsed_tmp = experiment_fpath / &#39;parsed_tmp&#39;
    

    # Extract the Count code from the file name
    count_code = re.search(r&#39;(Count)\d{5}&#39;, nd2_file_path.stem).group()
    
    all_info_files = experiment_fpath.glob(&#39;*.pkl&#39;)
    
    info_file = [info_file for info_file in all_info_files if count_code  in info_file.stem][0]
    
    info_data = pickle.load(open(info_file, &#39;rb&#39;))
    hybridization_name = info_data[&#39;channels&#39;][&#39;Hybridization&#39;]
    
    try:
        nd2fh = nd2reader.ND2Reader(nd2_file_path)
    except:
        logger.error(&#39;Cannot load the nd2 file&#39;)
        signals.FAIL(&#39;Cannot load the nd2 file&#39;)
    else:
        # Collect metadata
        all_metadata = nd2fh.parser._raw_metadata
        parsed_metadata = nd2fh.parser._raw_metadata.get_parsed_metadata()
        
        channel = parsed_metadata[&#39;channels&#39;][0] # works because there is only one channel for file
        img_height = parsed_metadata[&#39;height&#39;]
        img_width = parsed_metadata[&#39;width&#39;]
        pixel_microns = parsed_metadata[&#39;pixel_microns&#39;]
        z_levels = parsed_metadata[&#39;z_levels&#39;]
        fields_of_view = parsed_metadata[&#39;fields_of_view&#39;]
        
        # Collect FOV coords
        x_data = np.array(all_metadata.x_data)
        x_data = x_data[:,np.newaxis]
        y_data = np.array(all_metadata.x_data)
        y_data = y_data[:,np.newaxis]
        z_data = np.array(all_metadata.z_data)
        z_data = z_data[:,np.newaxis]
        all_coords = np.hstack((z_data,x_data,y_data))
        fov_coords = all_coords[0::len(z_levels),:]
        
        tag_name = experiment_name + &#39;_&#39; + hybridization_name + &#39;_&#39; + channel
        
        
        # Save the file as zarr
        zarr_store = parsed_tmp / (experiment_name + &#39;_&#39; + hybridization_name + &#39;_&#39; + channel + &#39;_raw_images_tmp.zarr&#39;)
        store = zarr.DirectoryStore(zarr_store)
        root = zarr.group(store=store,overwrite=True)

        
        nd2fh.bundle_axes = &#39;zyx&#39;
        # set iteration over the fields of view
        nd2fh.iter_axes = &#39;v&#39;
        
        # Save coords of the FOV
        rows = np.arange(img_width)
        cols = np.arange(img_height)
        hybridization_num = int(hybridization_name.split(&#39;Hybridization&#39;)[-1])
        for fov in fields_of_view:
            img = np.array(nd2fh[fov],dtype=np.uint16)        
            dset = root.create_dataset(fov, data=img, shape=img.shape, chunks=(1,None,None),overwrite=True)
            dset.attrs[&#39;channel&#39;] = channel
            dset.attrs[&#39;target_name&#39;] = info_data[&#39;channels&#39;][channel]
            dset.attrs[&#39;img_height&#39;] = img_height
            dset.attrs[&#39;img_width&#39;] = img_width
            dset.attrs[&#39;pixel_microns&#39;] = pixel_microns
            dset.attrs[&#39;z_levels&#39;] = list(z_levels)
            dset.attrs[&#39;fov_num&#39;] = fov
            dset.attrs[&#39;StitchingChannel&#39;] = info_data[&#39;StitchingChannel&#39;]
            dset.attrs[&#39;hybridization_num&#39;] = hybridization_num
            dset.attrs[&#39;experiment_name&#39;] = experiment_name

        zarr.convenience.consolidate_metadata(store)                </code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pysmFISH" href="index.html">pysmFISH</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pysmFISH.microscopy_file_parsers_tasks.nd2_raw_files_selector" href="#pysmFISH.microscopy_file_parsers_tasks.nd2_raw_files_selector">nd2_raw_files_selector</a></code></li>
<li><code><a title="pysmFISH.microscopy_file_parsers_tasks.nikon_nd2_autoparser" href="#pysmFISH.microscopy_file_parsers_tasks.nikon_nd2_autoparser">nikon_nd2_autoparser</a></code></li>
<li><code><a title="pysmFISH.microscopy_file_parsers_tasks.nikon_nd2_autoparser_single_files" href="#pysmFISH.microscopy_file_parsers_tasks.nikon_nd2_autoparser_single_files">nikon_nd2_autoparser_single_files</a></code></li>
<li><code><a title="pysmFISH.microscopy_file_parsers_tasks.nikon_nd2_autoparser_zarr" href="#pysmFISH.microscopy_file_parsers_tasks.nikon_nd2_autoparser_zarr">nikon_nd2_autoparser_zarr</a></code></li>
<li><code><a title="pysmFISH.microscopy_file_parsers_tasks.nikon_nd2_autoparser_zarr_single_files" href="#pysmFISH.microscopy_file_parsers_tasks.nikon_nd2_autoparser_zarr_single_files">nikon_nd2_autoparser_zarr_single_files</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>