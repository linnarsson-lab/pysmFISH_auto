{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8915474-c8bb-429d-9cef-140108d26fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7b80b4e-0e6d-4d20-af13-13082acc816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21afa93e-cbc2-4f0f-87f7-afd0312e4b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "408c55c2-34c8-4dbd-b379-04d3984022b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysmFISH.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "727dcf78-7732-494d-bf2c-c7b4061a9fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysmFISH.configuration_files import load_experiment_config_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb63673e-26ed-49cf-b2a9-db29d6dbac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cc070e-fa52-4bb9-be62-61c16a4d419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_fpath = Path('/fish/work_std/AMEXP20210518_EEL_M1C_opool2')\n",
    "date_tag = time.strftime(\"%y%m%d_%H_%M_%S\")\n",
    "pipeline_run_name = date_tag + '_' + experiment_fpath.stem\n",
    "run_type = 're-run'\n",
    "parsing_type = 'no_parsing'\n",
    "processing_engine = 'htcondor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb2ec9c-1b09-4e2d-8deb-6e4246e9ef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline = Pipeline(\n",
    "                        pipeline_run_name= pipeline_run_name,\n",
    "                        experiment_fpath= experiment_fpath,\n",
    "                        run_type= run_type,\n",
    "                        parsing_type= parsing_type,\n",
    "                        processing_engine= processing_engine\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f71503-a178-46fe-b3fc-feba239dfbce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline.run_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a95110-14b7-486a-a517-5a4e48539bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_pipeline.remove_duplicated_dots_graph_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deb03db-33f2-4769-b3ce-6fa37ad6630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_pipeline.cluster.close()\n",
    "running_pipeline.client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3aba62-1dd1-4a03-be55-83c3d721715a",
   "metadata": {},
   "source": [
    "# AMEXP20210521_EEL_M1C_HA1twist5x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2ecb29-27ee-4c65-87fb-74aabe639389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "fname_3 = '/fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/Count00003_AMEXP20210521_EEL_M1C_HA1twist5x_C1H03.pkl'\n",
    "data_3 = pickle.load(open(fname_3,'rb'))\n",
    "fname_17 = '/fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/Count00017_AMEXP20210521_EEL_M1C_HA1twist5x_C1H17.pkl'\n",
    "data_17 = pickle.load(open(fname_17,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52588b2f-c0ef-4fdb-befa-5d5f1214f820",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_fpath = Path('/fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x')\n",
    "date_tag = time.strftime(\"%y%m%d_%H_%M_%S\")\n",
    "pipeline_run_name = date_tag + '_' + experiment_fpath.stem\n",
    "run_type = 're-run'\n",
    "parsing_type = 'no_parsing'\n",
    "processing_engine = 'htcondor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a22f825b-e521-45d5-a3b6-0690ca7c85f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 194 µs, sys: 0 ns, total: 194 µs\n",
      "Wall time: 202 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "running_pipeline = Pipeline(\n",
    "                        pipeline_run_name= pipeline_run_name,\n",
    "                        experiment_fpath= experiment_fpath,\n",
    "                        run_type= run_type,\n",
    "                        parsing_type= parsing_type,\n",
    "                        processing_engine= processing_engine\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75cdb4b-be84-43a7-a17c-5b63ad762d60",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.worker - INFO - extra_processing_data already exist\n",
      "distributed.worker - INFO - pipeline_config already exist\n",
      "distributed.worker - INFO - output_figures already exist\n",
      "distributed.worker - INFO - probes already exist\n",
      "distributed.worker - INFO - tmp already exist\n",
      "distributed.worker - INFO - logs already exist\n",
      "distributed.worker - INFO - results already exist\n",
      "distributed.worker - INFO - microscope_tiles_coords already exist\n",
      "distributed.worker - INFO - raw_counts already exist\n",
      "distributed.worker - INFO - filtered_images already exist\n",
      "distributed.worker - INFO - registered_counts already exist\n",
      "distributed.worker - INFO - combined_rounds_images already exist\n",
      "INFO:root:Created logger\n",
      "INFO:root:Start parsing\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/home/simone/tmp_code/pysmFISH_auto, universal_newlines=False, shell=None, istream=<valid stream>)\n",
      "INFO:root:Saved current git commit version\n",
      "INFO:root:Checked config file\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "WARNING:py.warnings:/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 11315 instead\n",
      "  warnings.warn(\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 0\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 0 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp9p1bdwq1.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862880.0\n",
      "DEBUG:root:Dask dashboard info {'type': 'Scheduler', 'id': 'Scheduler-4b173e9f-34ad-4f42-ad2e-34fac84ae5fa', 'address': 'tcp://193.10.16.58:14214', 'services': {'dashboard': 11315}, 'started': 1622229075.396899, 'workers': {}}\n",
      "INFO:root:Started dask processing cluster\n",
      "INFO:root:client dashboard 11315\n",
      "INFO:root:Parsing started\n",
      "INFO:root:AMEXP20210521_EEL_M1C_HA1twist5x timing:                 Parsing completed in 5s.\n",
      "INFO:root:Started creation of the dataset\n",
      "INFO:root:AMEXP20210521_EEL_M1C_HA1twist5x timing:                Dataset creation completed in 8m 58s.\n",
      "INFO:root:Created analysis_config.yaml file\n",
      "INFO:root:Determined the tiles organization\n",
      "INFO:root:Created the running function dictionary\n",
      "INFO:root:AMEXP20210521_EEL_M1C_HA1twist5x timing:                Required steps completed in 2m 7s.\n",
      "INFO:root:\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 10\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 10 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpyvxcdbgw.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862881.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 8\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 8 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpnh0ai14b.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862882.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 6\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 6 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpbsdqt7xk.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862883.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 14\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 14 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp9nvh25qk.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862884.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 4\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 4 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpzl0cdpe5.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862885.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 5\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 5 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpn24w18tx.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862886.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 13\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 13 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp238_bror.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862887.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 12\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 12 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpk6hdruj6.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862888.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 11\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 11 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpxx34psp6.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862889.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 3\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 3 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpgsk3zr6s.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862890.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 9\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 9 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpmsv11vfa.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862891.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 7\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 7 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp9av61gdk.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862892.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 2\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 2 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp1k_j838t.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862893.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 1\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 1 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpkgl36yka.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862894.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 1 job: 1862894.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862894.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862894.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862894.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862894.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 9 job: 1862891.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862891.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862891.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862891.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862891.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 2 job: 1862893.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862893.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862893.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862893.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862893.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 3 job: 1862890.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862890.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862890.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862890.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862890.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 7 job: 1862892.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862892.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862892.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862892.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862892.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 10 job: 1862881.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862881.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862881.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 12 job: 1862888.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862888.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862888.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 14 job: 1862884.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862884.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862884.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 0 job: 1862880.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862880.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862880.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 11 job: 1862889.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862889.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862889.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 8 job: 1862882.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862882.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862882.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 5 job: 1862886.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862886.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862886.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 13 job: 1862887.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862887.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862887.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 6 job: 1862883.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862883.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862883.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862880.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862880.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862886.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862886.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862883.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862883.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862882.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862882.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862881.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862881.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862889.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862889.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862888.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862888.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862887.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862887.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862884.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862884.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 18\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 18 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpltv57xfd.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862909.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 15\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 15 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmptnemugs8.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862910.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 19\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 19 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpf3l68uf3.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862911.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 21\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 21 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmplx032gno.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862912.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 16\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 16 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpk50yjc8l.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862913.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 20\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 20 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp3r054cn1.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862914.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 14\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 14 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpdlnp5fkx.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862915.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 17\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 17 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpn9q2np1_.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862916.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 14 job: 1862915.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862915.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862915.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862915.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862915.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 14\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 14 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp8mdb_i45.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862917.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 17 job: 1862916.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862916.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862916.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862916.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862916.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 20 job: 1862914.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862914.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862914.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862914.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862914.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 14 job: 1862917.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862917.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862917.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862917.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862917.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 16 job: 1862913.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862913.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862913.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 19 job: 1862911.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862911.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862911.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 15 job: 1862910.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862910.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862910.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 21 job: 1862912.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862912.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862912.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 18 job: 1862909.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862909.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862909.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862910.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862910.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862913.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862913.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862909.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862909.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862911.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862911.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862912.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862912.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 23\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 23 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp93lt2pwh.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862922.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 22\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 22 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpbanzsj_3.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862923.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 21\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 21 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpr0x7v4a0.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862924.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 24\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 24 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpbhf49xcw.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862925.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 21 job: 1862924.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862924.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862924.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862924.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862924.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 21\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 21 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpcqedexbo.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862926.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 24 job: 1862925.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862925.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862925.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862925.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862925.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 22 job: 1862923.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862923.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862923.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 21 job: 1862926.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862926.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862926.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 23 job: 1862922.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862922.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862922.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862926.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862926.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862923.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862923.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862922.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862922.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 24\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 24 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmppv1ipi97.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862927.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 24 job: 1862927.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862927.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862927.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862927.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862927.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 31\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 31 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpxqq9myyu.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862932.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 37\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 37 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpy0jc2va4.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862933.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 32\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 32 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpu8c6_gil.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862934.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 35\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 35 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmphelzkz54.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862935.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 27\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 27 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmphz73o6dn.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862936.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 25\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 25 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpkyhtq16j.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862937.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 29\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 29 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp1uca7vbn.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862938.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 36\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 36 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpoa79nx8n.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862939.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 33\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 33 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpuwuj8jf6.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862940.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 30\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 30 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp3uk76kvu.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862941.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 28\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 28 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpiwvn4_iv.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862942.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 34\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 34 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpugdf0tbo.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862943.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 26\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 26 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp3am5uf83.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862944.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 24\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 24 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpi1hkvvaw.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862945.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 33 job: 1862940.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862940.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862940.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862940.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862940.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 34 job: 1862943.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862943.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862943.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862943.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862943.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 36 job: 1862939.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862939.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862939.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862939.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862939.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 24 job: 1862945.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862945.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862945.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862945.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862945.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 25 job: 1862937.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862937.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862937.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862937.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862937.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 26 job: 1862944.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862944.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862944.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862944.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862944.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 28 job: 1862942.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862942.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862942.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862942.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862942.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 29 job: 1862938.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862938.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862938.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 30 job: 1862941.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862941.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862941.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862938.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862938.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862941.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862941.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 4 job: 1862885.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862885.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862885.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 32 job: 1862934.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862934.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862934.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 27 job: 1862936.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862936.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862936.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862934.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862934.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862936.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862936.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862885.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862885.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 38\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 38 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpo08ol56m.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862946.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 39\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 39 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmptk017ix9.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862947.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 38 job: 1862946.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862946.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862946.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862946.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862946.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 39 job: 1862947.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862947.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862947.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862947.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862947.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 31 job: 1862932.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862932.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862932.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 37 job: 1862933.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862933.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862933.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862932.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862933.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862932.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862933.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 39\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 39 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp_yhyrstf.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862948.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 39 job: 1862948.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862948.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862948.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1862948.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1862948.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 40\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 40 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp_30rx0p4.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862949.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 43\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 43 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpch6hwd5n.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862950.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 47\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 47 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpz1ubpfmy.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862951.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 51\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 51 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpr4apnjax.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862952.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 52\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 52 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp8fqyz_t1.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862953.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 48\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 48 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpegl1c_37.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862954.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 45\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 45 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpfvqkssmf.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862955.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 49\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 49 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp998e2hki.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862956.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 39\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 39 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpywt2uq5i.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862957.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 46\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 46 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmprnmg27k9.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862958.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 42\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 42 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpciclv5ai.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862959.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 41\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 41 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpypso9aiu.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862960.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 44\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 44 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpkezt3mgc.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862961.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 50\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 50 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmptjsznnx3.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1862962.0\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "running_pipeline.run_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc2f915-faf4-4ef8-92e7-77dd3fd8ffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline.run_parsing_only()\n",
    "running_pipeline.run_required_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f2ad3b-3c92-4944-bdd9-89267a9a419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run only the remaining fov\n",
    "processed_data = (experiment_fpath / 'results').glob('*decoded*')\n",
    "fovs = []\n",
    "for fpath in processed_data:\n",
    "    fovs.append(int(fpath.stem.split('_')[-1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aa6ac0-67c9-4d85-b58d-a07f9ecd0d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_pipeline.data.dataset = running_pipeline.data.dataset.loc[~running_pipeline.data.dataset.fov_num.isin(fovs),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94876907-3bd5-47b0-847c-abd691e96d9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "running_pipeline.processing_barcoded_eel_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1902494a-792a-434d-8243-ea768e92409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8f55f67-52c0-4415-bad9-fc610df822ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysmFISH.io import simple_output_plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f4c1a00-f5e1-4547-88ce-bca7c55f963f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:dask_jobqueue.core:Starting worker: 470\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 470 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpx65tuu6u.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863467.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 469\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 469 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpdjw8acql.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863468.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 465\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 465 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmppl3wo096.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863469.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 475\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 475 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpdrnti5ju.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863470.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 467\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 467 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpp2ga0twn.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863471.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 468\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 468 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpd_ljrq68.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863472.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 471\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 471 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpzw9z7oxc.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863473.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 464\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 464 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpvp99xsfj.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863474.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 474\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 474 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpdix4iq1f.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863475.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 462\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 462 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpi2sun96m.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863476.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 466\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 466 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpt6d8i3e_.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863477.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 472\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 472 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp4w5wtp55.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863478.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 473\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 473 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpyev_bsuy.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863479.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 463\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 463 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp1zgyy9x9.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863480.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 462 job: 1863476.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863476.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863476.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863476.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863476.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 476\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 476 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpcv4jwc8l.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863481.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 463 job: 1863480.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863480.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863480.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 464 job: 1863474.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863474.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863474.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 466 job: 1863477.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863477.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863477.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863474.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863474.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863477.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863477.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863480.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863480.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 477\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 477 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpuvdqf58g.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863482.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 478\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 478 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpb7__aonm.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863483.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 479\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 479 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpdfcj_e0t.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863484.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 473 job: 1863479.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863479.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863479.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 472 job: 1863478.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863478.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863478.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863478.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863478.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863479.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863479.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 481\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 481 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpc9raycdk.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863485.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 480\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 480 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpodxkgmic.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863486.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 481 job: 1863485.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863485.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863485.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 480 job: 1863486.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863486.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863486.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863486.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863486.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863485.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863485.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 479 job: 1863484.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863484.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863484.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 476 job: 1863481.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863481.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863481.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 477 job: 1863482.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863482.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863482.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 478 job: 1863483.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863483.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863483.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863481.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863481.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863482.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863482.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863483.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863483.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863484.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863484.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 469 job: 1863468.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863468.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863468.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 465 job: 1863469.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863469.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863469.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 468 job: 1863472.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863472.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863472.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 470 job: 1863467.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863467.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863467.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 475 job: 1863470.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863470.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863470.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 471 job: 1863473.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863473.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863473.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 474 job: 1863475.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863475.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863475.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 467 job: 1863471.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863471.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863471.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863469.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863469.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863471.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863471.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863472.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863472.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863468.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863468.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863467.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863467.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863473.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863473.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863475.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863475.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863470.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863470.0\n"
     ]
    }
   ],
   "source": [
    "selected_Hdistance = 3/16\n",
    "stitching_selected = 'microscope_stitched' \n",
    "file_tag = 'decoded'\n",
    "simple_output_plotting(running_pipeline.experiment_fpath, stitching_selected, selected_Hdistance, running_pipeline.client, file_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075bccfb-f857-4e41-af04-c000289e4827",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.pyplot:Loaded backend agg version unknown.\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 483\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 483 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmps_oksreq.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863487.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 485\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 485 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpq7bxt1f7.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863488.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 482\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 482 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpy4nagl3o.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863489.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 486\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 486 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp23y6vfsl.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863490.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 488\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 488 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmponsgb9pe.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863491.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 490\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 490 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpfmyhkbsx.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863492.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 491\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 491 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp4hyf073n.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863493.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 492\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 492 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpyo0sty3x.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863494.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 489\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 489 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp97cwv56m.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863495.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 494\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 494 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp2829_am8.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863496.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 493\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 493 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpnxkotme4.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863497.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 481\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 481 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmpi402k8_7.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863498.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 484\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 484 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp7hxyultb.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863499.0\n",
      "DEBUG:dask_jobqueue.core:Starting worker: 487\n",
      "DEBUG:dask_jobqueue.core:writing job script: \n",
      "#!/usr/bin/env condor_submit\n",
      "\n",
      "MY.DaskWorkerName = \"htcondor--$F(MY.JobId)--\"\n",
      "RequestCpus = MY.DaskWorkerCores\n",
      "RequestMemory = floor(MY.DaskWorkerMemory / 1048576)\n",
      "RequestDisk = floor(MY.DaskWorkerDisk / 1024)\n",
      "MY.JobId = \"$(ClusterId).$(ProcId)\"\n",
      "MY.DaskWorkerCores = 20\n",
      "MY.DaskWorkerMemory = 200000000000\n",
      "MY.DaskWorkerDisk = 100000000\n",
      "LogDirectory = /fish/work_std/AMEXP20210521_EEL_M1C_HA1twist5x/logs\n",
      "Output = $(LogDirectory)/worker-$F(MY.JobId).out\n",
      "Error = $(LogDirectory)/worker-$F(MY.JobId).err\n",
      "Log = $(LogDirectory)/worker-$(ClusterId).log\n",
      "Stream_Output = True\n",
      "Stream_Error = True\n",
      "\n",
      "Environment = \"\"\n",
      "Arguments = \"-c '/home/simone/mini/envs/test_d/bin/python -m distributed.cli.dask_worker tcp://193.10.16.58:14214 --nthreads 20 --memory-limit 200.00GB --name 487 --nanny --death-timeout 60 --local-directory /tmp --protocol tcp://'\"\n",
      "Executable = /bin/sh\n",
      "\n",
      "Queue\n",
      "\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_submit /tmp/tmp_m62657t.sh\n",
      "DEBUG:dask_jobqueue.core:Starting job: 1863500.0\n",
      "distributed.utils - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/utils.py\", line 655, in log_errors\n",
      "    yield\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/scheduler.py\", line 4217, in retire_workers\n",
      "    await self.replicate(\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/scheduler.py\", line 3970, in replicate\n",
      "    assert count > 0\n",
      "AssertionError\n",
      "distributed.core - ERROR - Exception while handling op retire_workers\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/core.py\", line 497, in handle_comm\n",
      "    result = await result\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/scheduler.py\", line 4217, in retire_workers\n",
      "    await self.replicate(\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/scheduler.py\", line 3970, in replicate\n",
      "    assert count > 0\n",
      "AssertionError\n",
      "distributed.utils - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/utils.py\", line 655, in log_errors\n",
      "    yield\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/deploy/adaptive.py\", line 187, in scale_down\n",
      "    await self.scheduler.retire_workers(\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/core.py\", line 787, in send_recv_from_rpc\n",
      "    result = await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/core.py\", line 657, in send_recv\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/core.py\", line 497, in handle_comm\n",
      "    result = await result\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/scheduler.py\", line 4217, in retire_workers\n",
      "    await self.replicate(\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/scheduler.py\", line 3970, in replicate\n",
      "    assert count > 0\n",
      "AssertionError\n",
      "tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7f3edbee9550>>, <Task finished name='Task-6421256' coro=<AdaptiveCore.adapt() done, defined at /home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/deploy/adaptive_core.py:179> exception=AssertionError()>)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/tornado/ioloop.py\", line 765, in _discard_future_result\n",
      "    future.result()\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/deploy/adaptive_core.py\", line 203, in adapt\n",
      "    await self.scale_down(**recommendations)\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/deploy/adaptive.py\", line 187, in scale_down\n",
      "    await self.scheduler.retire_workers(\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/core.py\", line 787, in send_recv_from_rpc\n",
      "    result = await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/core.py\", line 657, in send_recv\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/core.py\", line 497, in handle_comm\n",
      "    result = await result\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/scheduler.py\", line 4217, in retire_workers\n",
      "    await self.replicate(\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/scheduler.py\", line 3970, in replicate\n",
      "    assert count > 0\n",
      "AssertionError\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 489 job: 1863495.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863495.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863495.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 481 job: 1863498.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863498.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863498.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 486 job: 1863490.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863490.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863490.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 490 job: 1863492.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863492.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863492.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 493 job: 1863497.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863497.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863497.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 488 job: 1863491.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863491.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863491.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 491 job: 1863493.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863493.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863493.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 485 job: 1863488.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863488.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863488.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 483 job: 1863487.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863487.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863487.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 492 job: 1863494.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863494.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863494.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 494 job: 1863496.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863496.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863496.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 484 job: 1863499.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863499.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863499.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 487 job: 1863500.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863500.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863500.0\n",
      "DEBUG:dask_jobqueue.core:Stopping worker: 482 job: 1863489.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863489.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863489.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863498.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863498.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863489.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863489.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863487.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863487.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863499.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863499.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863488.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863488.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863490.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863490.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863500.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863500.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863491.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863491.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863495.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863495.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863492.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863492.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863493.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863493.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863494.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863494.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863497.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863497.0\n",
      "DEBUG:dask_jobqueue.core:Executing the following command to command line\n",
      "condor_rm 1863496.0\n",
      "DEBUG:dask_jobqueue.core:Closed job 1863496.0\n"
     ]
    }
   ],
   "source": [
    "running_pipeline.QC_registration_error_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7bc3d3-2224-4808-9516-d73b60b66cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1353be49-47e6-41ce-a120-723fdc00cad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_pipeline.cluster.close()\n",
    "running_pipeline.client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59715ff3-cac2-4d4c-b876-e2832c763393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_d",
   "language": "python",
   "name": "test_d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
