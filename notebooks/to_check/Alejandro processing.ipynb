{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a61bb6f0-ff72-4c04-bcbc-7a49104023fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fbd8c20-5d08-4f0e-9ee6-4ba3802fb5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae1592fc-8764-4a4d-9c65-5ca6d0020789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/mini/envs/test_d/lib/python3.8/site-packages/dask_jobqueue/core.py:19: FutureWarning: format_bytes is deprecated and will be removed in a future release. Please use dask.utils.format_bytes instead.\n",
      "  from distributed.utils import format_bytes, parse_bytes, tmpfile\n",
      "/home/simone/mini/envs/test_d/lib/python3.8/site-packages/dask_jobqueue/core.py:19: FutureWarning: parse_bytes is deprecated and will be removed in a future release. Please use dask.utils.parse_bytes instead.\n",
      "  from distributed.utils import format_bytes, parse_bytes, tmpfile\n",
      "/home/simone/mini/envs/test_d/lib/python3.8/site-packages/dask_jobqueue/htcondor.py:6: FutureWarning: parse_bytes is deprecated and will be removed in a future release. Please use dask.utils.parse_bytes instead.\n",
      "  from distributed.utils import parse_bytes\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "from pysmFISH.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa34eaf-a343-4035-8003-cddeea86184a",
   "metadata": {},
   "source": [
    "# AMEXP20210609_EEL_V1C_HA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2952982f-5d6d-4011-8da9-4a6f9796eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_fpath = Path('/fish/work_std/AMEXP20210609_EEL_V1C_HA2')\n",
    "date_tag = time.strftime(\"%y%m%d_%H_%M_%S\")\n",
    "pipeline_run_name = date_tag + '_' + experiment_fpath.stem\n",
    "run_type = 're-run'\n",
    "parsing_type = 'no_parsing'\n",
    "processing_engine = 'htcondor'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197c4a4a-9e5f-4325-83e6-2e39244559a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline = Pipeline(\n",
    "                        pipeline_run_name= pipeline_run_name,\n",
    "                        experiment_fpath= experiment_fpath,\n",
    "                        run_type= run_type,\n",
    "                        parsing_type= parsing_type,\n",
    "                        processing_engine= processing_engine,\n",
    "                        chunk_size=40\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a267c2b-02f8-43d6-81f5-75644004c602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline.run_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc64974f-a433-4a0d-96dc-ead7b8fbe4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_pipeline.cluster.close()\n",
    "running_pipeline.client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac792ea2-b165-49ed-bcbb-86b466959eb9",
   "metadata": {},
   "source": [
    "## Test stitching and removal overlapping dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a1975-ae82-4a23-9491-8f456828a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_fpath = Path('/fish/fish_results/results_AMEXP20210609_EEL_V1C_HA2')\n",
    "date_tag = time.strftime(\"%y%m%d_%H_%M_%S\")\n",
    "pipeline_run_name = date_tag + '_' + experiment_fpath.stem\n",
    "run_type = 're-run'\n",
    "parsing_type = 'no_parsing'\n",
    "processing_engine = 'htcondor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc0531-3d49-4edd-924d-22df133e0292",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline = Pipeline(\n",
    "                        pipeline_run_name= pipeline_run_name,\n",
    "                        experiment_fpath= experiment_fpath,\n",
    "                        run_type= run_type,\n",
    "                        parsing_type= parsing_type,\n",
    "                        processing_engine= processing_engine,\n",
    "                        chunk_size=40,\n",
    "                        dataset_path = '/fish/fish_results/results_AMEXP20210609_EEL_V1C_HA2/210614_17_55_29_AMEXP20210609_EEL_V1C_HA2_img_data_dataset.parquet'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f2e3a8-08f9-4f08-ba4c-e2eb89ef719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline.run_from_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877d6f6b-72ec-44b7-b9f3-aeb6ef533fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline.determine_tiles_organization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8e6d52-f7b2-445f-9a70-f7c0c08bfcf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline.stitch_and_remove_dots_eel_graph_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eab8afa-7aff-4eb2-958f-33f374f3f521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysmFISH import io\n",
    "selected_Hdistance = 3 / 16\n",
    "stitching_selected = 'global_stitched'\n",
    "io.simple_output_plotting(running_pipeline.experiment_fpath, stitching_selected, \n",
    "                        selected_Hdistance, running_pipeline.client,file_tag='cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e8c35-7152-4a50-bd61-fdfe4d9746cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_pipeline.cluster.close()\n",
    "running_pipeline.client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25835e75-50f4-4fb6-8fe4-f089c2e91bc1",
   "metadata": {},
   "source": [
    "# AMEXP20210223_V1C_HA3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff32882-2bf7-4055-9889-4db726f28b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_fpath = Path('/fish/work_std/AMEXP20210223_V1C_HA3')\n",
    "date_tag = time.strftime(\"%y%m%d_%H_%M_%S\")\n",
    "pipeline_run_name = date_tag + '_' + experiment_fpath.stem\n",
    "run_type = 'new'\n",
    "parsing_type = 'original'\n",
    "processing_engine = 'htcondor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89571282-2713-4d60-90c0-fa2f96caea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline = Pipeline(\n",
    "                        pipeline_run_name= pipeline_run_name,\n",
    "                        experiment_fpath= experiment_fpath,\n",
    "                        run_type= run_type,\n",
    "                        parsing_type= parsing_type,\n",
    "                        processing_engine= processing_engine,\n",
    "                        chunk_size=40\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f33b38-99f0-4855-9e95-22ef3146b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline.run_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d8b4b6-5819-4ce2-843a-7d3a21ba13fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline.stitch_and_remove_dots_eel_graph_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808b1be5-f9bf-4765-9d9a-ffdfe92c8cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline.QC_registration_error_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a887a9-d403-4a0a-836f-1710bdbfb9ad",
   "metadata": {},
   "source": [
    "# AMEXP20210620_EEL_M1C_HA2  \n",
    "\n",
    "Added to the config file:\n",
    "\n",
    "Codebook: codebookHA2_20210522.parquet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b569cd-be4a-47f6-95cf-cb3c817d1ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89411a8d-8ac0-4109-b6a7-1150a30bd9ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_fpath = Path('/fish/work_std/AMEXP20210620_EEL_M1C_HA2')\n",
    "date_tag = time.strftime(\"%y%m%d_%H_%M_%S\")\n",
    "pipeline_run_name = date_tag + '_' + experiment_fpath.stem\n",
    "run_type = 're-run'\n",
    "parsing_type = 'no_parsing'\n",
    "processing_engine = 'htcondor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b808b2-69a4-423e-86ce-e3a33c64401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline = Pipeline(\n",
    "                        pipeline_run_name= pipeline_run_name,\n",
    "                        experiment_fpath= experiment_fpath,\n",
    "                        run_type= run_type,\n",
    "                        parsing_type= parsing_type,\n",
    "                        processing_engine= processing_engine,\n",
    "                        chunk_size=50,\n",
    "                        same_dot_radius_duplicate_dots = 100,\n",
    "                        save_bits_int=False,\n",
    "                        dataset_path='/fish/work_std/AMEXP20210620_EEL_M1C_HA2/210629_13_21_07_AMEXP20210620_EEL_M1C_HA2_img_data_dataset.parquet'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaf3766-9f58-4c70-a108-3ad7edba6fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline.run_parsing_only()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2963048c-14f3-4bba-ba22-c207454d5fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "running_pipeline.run_required_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c3de6-7ad1-47f2-bd31-420ea9b4b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_pipeline.data.dataset.loc[running_pipeline.data.dataset.stitching_type == 'both-beads','stitching_type'] = 'large-beads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb77241-11f3-4d39-ad78-5ec603b5a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_pipeline.metadata = running_pipeline.data.collect_metadata(running_pipeline.data.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581ed94-3e32-4920-aef5-f2005a563c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline.processing_barcoded_eel_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be712fe-dbcb-46c8-8b15-af9430af1cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a58c5d8-d3fc-4442-a531-fdefebace3e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "running_pipeline.QC_registration_error_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1354fa13-e8d5-46e7-901e-004da6bb920b",
   "metadata": {},
   "source": [
    "# AMEXP20210625_EEL_Pons_HA2\n",
    "\n",
    "The pipeline was not entered so all the pkl do not have it. In order to run properly you need to rebuild the dataset and the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e03cc9-9571-4b94-8059-c4eeb2bc7447",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_fpath = Path('/fish/work_std/AMEXP20210625_EEL_Pons_HA2')\n",
    "date_tag = time.strftime(\"%y%m%d_%H_%M_%S\")\n",
    "pipeline_run_name = date_tag + '_' + experiment_fpath.stem\n",
    "run_type = 're-run'\n",
    "parsing_type = 'no_parsing'\n",
    "processing_engine = 'htcondor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6270f837-0f8d-4917-93ff-cd48690c5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline = Pipeline(\n",
    "                        pipeline_run_name= pipeline_run_name,\n",
    "                        experiment_fpath= experiment_fpath,\n",
    "                        run_type= run_type,\n",
    "                        parsing_type= parsing_type,\n",
    "                        processing_engine= processing_engine,\n",
    "                        chunk_size=50,\n",
    "                        same_dot_radius_duplicate_dots = 100,\n",
    "                        save_bits_int=False,\n",
    "                        dataset_path = '/fish/work_std/AMEXP20210625_EEL_Pons_HA2/210708_07_42_29_AMEXP20210625_EEL_Pons_HA2_mod_img_data_dataset.parquet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9421d9-92d3-4dd1-9af2-9119e2443c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline.run_parsing_only()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27da7450-54b0-44bd-bf0b-71685be1c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_pipeline.data.dataset.loc[:, 'pipeline'] = 'eel-human-adult-brain'\n",
    "running_pipeline.data.dataset.to_parquet('/fish/work_std/AMEXP20210625_EEL_Pons_HA2/210708_07_42_29_AMEXP20210625_EEL_Pons_HA2_mod_img_data_dataset.parquet',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc9e960-a707-421b-8941-24108eee73c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_pipeline.metadata = running_pipeline.data.collect_metadata(running_pipeline.data.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa075515-e468-49f0-857c-49485100f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline.run_required_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d435a86-b58c-4b8a-9e99-238869673fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline.processing_barcoded_eel_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca214ffb-c1ff-4722-a889-ff2f37673a6f",
   "metadata": {},
   "source": [
    "# AMEXP20210701_EEL_Pons2_HA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b7b2b3-6234-41c6-b931-6c78f149b2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_fpath = Path('/fish/work_std/AMEXP20210701_EEL_Pons2_HA2')\n",
    "date_tag = time.strftime(\"%y%m%d_%H_%M_%S\")\n",
    "pipeline_run_name = date_tag + '_' + experiment_fpath.stem\n",
    "run_type = 're-run'\n",
    "parsing_type = 'no_parsing'\n",
    "processing_engine = 'htcondor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13169968-638e-43b4-be4a-ee9a8e8de706",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline = Pipeline(\n",
    "                        pipeline_run_name= pipeline_run_name,\n",
    "                        experiment_fpath= experiment_fpath,\n",
    "                        run_type= run_type,\n",
    "                        parsing_type= parsing_type,\n",
    "                        processing_engine= processing_engine,\n",
    "                        chunk_size=50,\n",
    "                        same_dot_radius_duplicate_dots = 100,\n",
    "                        save_bits_int=False,\n",
    "                        dataset_path='/fish/work_std/AMEXP20210701_EEL_Pons2_HA2/210709_12_36_37_AMEXP20210701_EEL_Pons2_HA2_mod_img_data_dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a22d7a0-872d-4b2a-9d0d-a6403327c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline.run_parsing_only()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a11301-768d-469d-a0f4-78bebb39f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_pipeline.data.dataset.loc[:, 'pipeline'] = 'eel-human-adult-brain'\n",
    "running_pipeline.data.dataset.to_parquet('/fish/work_std/AMEXP20210701_EEL_Pons2_HA2/210709_12_36_37_AMEXP20210701_EEL_Pons2_HA2_mod_img_data_dataset.parquet',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a26f10-f258-48d1-a142-250cb2a4128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_pipeline.metadata = running_pipeline.data.collect_metadata(running_pipeline.data.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbc16a7-dc11-4a15-ae35-b73e6de4c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline.run_required_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3185aefa-bedb-492d-a05c-946103f80ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline.processing_barcoded_eel_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b31ca-a0aa-4463-930d-d574699e5c73",
   "metadata": {},
   "source": [
    "# AMEXP20210707_EEL_V1C_HA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54acba13-f7ac-4961-bf29-817131e8128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_fpath = Path('/fish/work_std/AMEXP20210707_EEL_V1C_HA2')\n",
    "date_tag = time.strftime(\"%y%m%d_%H_%M_%S\")\n",
    "pipeline_run_name = date_tag + '_' + experiment_fpath.stem\n",
    "run_type = 're-run'\n",
    "parsing_type = 'no_parsing'\n",
    "processing_engine = 'htcondor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0c5bd8-6275-4099-990d-fe5e37434f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline = Pipeline(\n",
    "                        pipeline_run_name= pipeline_run_name,\n",
    "                        experiment_fpath= experiment_fpath,\n",
    "                        run_type= run_type,\n",
    "                        parsing_type= parsing_type,\n",
    "                        processing_engine= processing_engine,\n",
    "                        chunk_size=50,\n",
    "                        same_dot_radius_duplicate_dots = 100,\n",
    "                        save_bits_int=False,\n",
    "                        dataset_path = '/fish/work_std/AMEXP20210707_EEL_V1C_HA2/210715_20_09_56_AMEXP20210707_EEL_V1C_HA2_mod_img_data_dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51184fd0-579d-4382-9085-aac09449d61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_pipeline.data.dataset.loc[running_pipeline.data.dataset.round_num == 17, 'round_num'] = 13\n",
    "running_pipeline.data.dataset.loc[running_pipeline.data.dataset.round_num == 18, 'round_num'] = 14\n",
    "running_pipeline.data.dataset.round_num.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b1fdb4-613d-49f0-a371-dac91275b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_pipeline.data.save_dataset(running_pipeline.data.dataset, '/fish/work_std/AMEXP20210707_EEL_V1C_HA2/210715_20_09_56_AMEXP20210707_EEL_V1C_HA2_mod_img_data_dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71daa6f7-5c86-4990-8d1a-817d4a0be7aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "running_pipeline.run_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79ca092-5d4c-487d-b49c-ccf0c806e45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_pipeline.data.dataset.round_num.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3773a0d4-1992-4900-b818-63787963cd89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf136d53-e958-4bc1-ac2c-45f5132f74bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "running_pipeline.cluster.close()\n",
    "running_pipeline.client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a614d95d-2e71-45fd-9b8e-7f1d51b7de97",
   "metadata": {},
   "source": [
    "# AMEXP20210722_EEL_SNRN_HA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5004392-126b-46cf-b1be-880d1a36638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_fpath = Path('/fish/work_std/AMEXP20210722_EEL_SNRN_HA2')\n",
    "date_tag = time.strftime(\"%y%m%d_%H_%M_%S\")\n",
    "pipeline_run_name = date_tag + '_' + experiment_fpath.stem\n",
    "run_type = 're-run'\n",
    "parsing_type = 'no_parsing'\n",
    "processing_engine = 'htcondor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201b3b57-fd41-455c-98d0-2cc6286a59a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 132 µs, sys: 0 ns, total: 132 µs\n",
      "Wall time: 137 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "running_pipeline = Pipeline(\n",
    "                        pipeline_run_name= pipeline_run_name,\n",
    "                        experiment_fpath= experiment_fpath,\n",
    "                        run_type= run_type,\n",
    "                        parsing_type= parsing_type,\n",
    "                        processing_engine= processing_engine,\n",
    "                        chunk_size=50,\n",
    "                        same_dot_radius_duplicate_dots = 100,\n",
    "                        save_bits_int=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1527956d-b670-4a51-8f98-7261db442c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258f0ab2-eddd-4294-b46b-828903b4a3bc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.worker - INFO - extra_processing_data already exist\n",
      "distributed.worker - INFO - pipeline_config already exist\n",
      "distributed.worker - INFO - output_figures already exist\n",
      "distributed.worker - INFO - probes already exist\n",
      "distributed.worker - INFO - logs already exist\n",
      "distributed.worker - INFO - results already exist\n",
      "distributed.worker - INFO - microscope_tiles_coords already exist\n",
      "distributed.worker - INFO - Codebook_Atto425 has None as codebook\n",
      "distributed.worker - INFO - Codebook_Cy3 has None as codebook\n",
      "distributed.worker - INFO - Codebook_Cy7 has None as codebook\n",
      "distributed.worker - INFO - Codebook_DAPI has None as codebook\n",
      "distributed.worker - INFO - Codebook_FITC has None as codebook\n",
      "distributed.worker - INFO - Codebook_TxRed has None as codebook\n",
      "distributed.worker - INFO - Codebook_Europium has None as codebook\n",
      "distributed.utils - ERROR - 'start'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/utils.py\", line 655, in log_errors\n",
      "    yield\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/dashboard/components/shared.py\", line 312, in update\n",
      "    ts = metadata[\"keys\"][self.key]\n",
      "KeyError: 'start'\n",
      "tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7f79a6becbe0>>, <Task finished name='Task-3167' coro=<_needs_document_lock.<locals>._needs_document_lock_wrapper() done, defined at /home/simone/mini/envs/test_d/lib/python3.8/site-packages/bokeh/server/session.py:51> exception=KeyError('start')>)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/tornado/ioloop.py\", line 765, in _discard_future_result\n",
      "    future.result()\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/bokeh/server/session.py\", line 67, in _needs_document_lock_wrapper\n",
      "    result = func(self, *args, **kwargs)\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/bokeh/server/session.py\", line 195, in with_document_locked\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/bokeh/document/document.py\", line 1164, in wrapper\n",
      "    return doc._with_self_as_curdoc(invoke)\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/bokeh/document/document.py\", line 1150, in _with_self_as_curdoc\n",
      "    return f()\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/bokeh/document/document.py\", line 1163, in invoke\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/bokeh/document/document.py\", line 953, in remove_then_invoke\n",
      "    return callback(*args, **kwargs)\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/dashboard/components/shared.py\", line 333, in <lambda>\n",
      "    self.doc().add_next_tick_callback(lambda: self.update(prof, metadata))\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/bokeh/core/property/validation.py\", line 93, in func\n",
      "    return input_function(*args, **kwargs)\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/dashboard/components/shared.py\", line 312, in update\n",
      "    ts = metadata[\"keys\"][self.key]\n",
      "KeyError: 'start'\n",
      "distributed.utils - ERROR - Timed out during handshake while connecting to tcp://192.168.0.32:37827 after 10 s\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/comm/core.py\", line 319, in connect\n",
      "    handshake = await asyncio.wait_for(comm.read(), time_left())\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/asyncio/tasks.py\", line 490, in wait_for\n",
      "    raise exceptions.TimeoutError()\n",
      "asyncio.exceptions.TimeoutError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/utils.py\", line 655, in log_errors\n",
      "    yield\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/scheduler.py\", line 4217, in retire_workers\n",
      "    await self.replicate(\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/scheduler.py\", line 3977, in replicate\n",
      "    results = await asyncio.gather(\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/utils_comm.py\", line 384, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/utils_comm.py\", line 369, in retry\n",
      "    return await coro()\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/core.py\", line 855, in send_recv_from_rpc\n",
      "    comm = await self.pool.connect(self.addr)\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/core.py\", line 1006, in connect\n",
      "    comm = await connect(\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/comm/core.py\", line 324, in connect\n",
      "    raise IOError(\n",
      "OSError: Timed out during handshake while connecting to tcp://192.168.0.32:37827 after 10 s\n",
      "distributed.core - ERROR - Exception while handling op retire_workers\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/comm/core.py\", line 319, in connect\n",
      "    handshake = await asyncio.wait_for(comm.read(), time_left())\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/asyncio/tasks.py\", line 490, in wait_for\n",
      "    raise exceptions.TimeoutError()\n",
      "asyncio.exceptions.TimeoutError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/core.py\", line 497, in handle_comm\n",
      "    result = await result\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/scheduler.py\", line 4217, in retire_workers\n",
      "    await self.replicate(\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/scheduler.py\", line 3977, in replicate\n",
      "    results = await asyncio.gather(\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/utils_comm.py\", line 384, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/utils_comm.py\", line 369, in retry\n",
      "    return await coro()\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/core.py\", line 855, in send_recv_from_rpc\n",
      "    comm = await self.pool.connect(self.addr)\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/core.py\", line 1006, in connect\n",
      "    comm = await connect(\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/comm/core.py\", line 324, in connect\n",
      "    raise IOError(\n",
      "OSError: Timed out during handshake while connecting to tcp://192.168.0.32:37827 after 10 s\n",
      "distributed.utils - ERROR - Timed out during handshake while connecting to tcp://192.168.0.32:37827 after 10 s\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/comm/core.py\", line 319, in connect\n",
      "    handshake = await asyncio.wait_for(comm.read(), time_left())\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/asyncio/tasks.py\", line 490, in wait_for\n",
      "    raise exceptions.TimeoutError()\n",
      "asyncio.exceptions.TimeoutError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/utils.py\", line 655, in log_errors\n",
      "    yield\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/deploy/adaptive.py\", line 187, in scale_down\n",
      "    await self.scheduler.retire_workers(\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/core.py\", line 787, in send_recv_from_rpc\n",
      "    result = await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/core.py\", line 657, in send_recv\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/core.py\", line 497, in handle_comm\n",
      "    result = await result\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/scheduler.py\", line 4217, in retire_workers\n",
      "    await self.replicate(\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/scheduler.py\", line 3977, in replicate\n",
      "    results = await asyncio.gather(\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/utils_comm.py\", line 384, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/utils_comm.py\", line 369, in retry\n",
      "    return await coro()\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/core.py\", line 855, in send_recv_from_rpc\n",
      "    comm = await self.pool.connect(self.addr)\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/core.py\", line 1006, in connect\n",
      "    comm = await connect(\n",
      "  File \"/home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/comm/core.py\", line 324, in connect\n",
      "    raise IOError(\n",
      "OSError: Timed out during handshake while connecting to tcp://192.168.0.32:37827 after 10 s\n",
      "distributed.deploy.adaptive_core - ERROR - Adaptive stopping due to error Timed out during handshake while connecting to tcp://192.168.0.32:37827 after 10 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "running_pipeline.run_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aeb978-91bd-413a-9a2d-2538a54d1f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_pipeline.cluster.close()\n",
    "running_pipeline.client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e930b0a2-df87-4ec2-a88d-fe811a3608d1",
   "metadata": {},
   "source": [
    "# AMEXP20211102_EEL_AMY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7fedca-8c4b-4b51-86ec-6c47264a07b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the required parameters\n",
    "experiment_fpath = Path('/datb/sl/fish_rawdata/AMEXP20211102_EEL_AMY')\n",
    "dataset_name = '220203_10_59_47_AMEXP20211102_EEL_AMY_img_data_dataset.parquet'\n",
    "date_tag = time.strftime(\"%y%m%d_%H_%M_%S\")\n",
    "pipeline_run_name = date_tag + '_' + experiment_fpath.stem\n",
    "run_type = 're-run'\n",
    "parsing_type = 'no_parsing'\n",
    "processing_engine = 'unmanaged_cluster'\n",
    "start_from_preprocessed_imgs =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6222f18e-3aff-44e7-a949-79021dab7a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 134 µs, sys: 0 ns, total: 134 µs\n",
      "Wall time: 140 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Because you are running the pipeline locally you should define the number of cores and memory/core\n",
    "# 3-4 GB / code should be safe for running the processing\n",
    "running_pipeline = Pipeline(\n",
    "        pipeline_run_name= pipeline_run_name,\n",
    "        experiment_fpath= experiment_fpath,\n",
    "        run_type= run_type,\n",
    "        parsing_type= parsing_type,\n",
    "        processing_engine= processing_engine,\n",
    "        scheduler_port= 22517,\n",
    "        dashboard_port = 22525,\n",
    "        dataset_path = experiment_fpath / dataset_name,\n",
    "        start_from_preprocessed_imgs=start_from_preprocessed_imgs,\n",
    "        resume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144cc09-42bc-4b23-bf69-8f8447b93410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.worker - INFO - extra_processing_data already exist\n",
      "distributed.worker - INFO - pipeline_config already exist\n",
      "distributed.worker - INFO - output_figures already exist\n",
      "distributed.worker - INFO - probes already exist\n",
      "distributed.worker - INFO - logs already exist\n",
      "distributed.worker - INFO - results already exist\n",
      "distributed.worker - INFO - microscope_tiles_coords already exist\n",
      "distributed.worker - INFO - notebooks already exist\n",
      "distributed.deploy.ssh - INFO - distributed.scheduler - INFO - -----------------------------------------------\n",
      "distributed.deploy.ssh - INFO - distributed.scheduler - INFO - -----------------------------------------------\n",
      "distributed.deploy.ssh - INFO - distributed.scheduler - INFO - Clear task state\n",
      "distributed.deploy.ssh - INFO - distributed.scheduler - INFO -   Scheduler at:  tcp://193.10.16.58:22517\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:43593'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:34782'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:33109'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:45861'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:35519'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:36280'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:34704'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:44453'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:33004'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:40924'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:43556'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:42443'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:33489'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:44445'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:37901'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:33779'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:35408'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:38319'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:44419'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:36391'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:39144'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:37286'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:43626'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:44529'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:35699'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:33094'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:39561'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:35743'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:44266'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:45895'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:38699'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:33762'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:44736'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:44278'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:32920'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:35288'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:41895'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:33639'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:45652'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:40388'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:40997'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:39676'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:44788'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:38335'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:41188'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:43640'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:37858'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:37845'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:40492'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:38246'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:40631'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:42629'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:41264'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:35504'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:35462'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:45605'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:39814'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:40352'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:40027'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:38959'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:40510'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:46707'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:36270'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:46649'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:46646'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:46290'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:35109'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:41589'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:44100'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:43192'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:46521'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:43368'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:34940'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:41398'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:46108'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:33070'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:42644'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:34425'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:34923'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:41951'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:34893'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:40405'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:36621'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:43656'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:43314'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:39488'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:34810'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:43996'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:43690'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:38635'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:35790'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:40725'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:36169'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:43659'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:36880'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:35331'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:44385'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:35862'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:40086'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:36161'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:38703'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:46535'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:34852'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:33610'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:38084'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:45042'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:36311'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:46467'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:45934'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:38588'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:34132'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:40195'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:35499'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:45206'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:34122'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:44802'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:44453'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:39792'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:38898'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:33315'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:34767'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:38517'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:33831'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:45572'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:33297'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:42136'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:42036'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:36721'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:43961'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:45608'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:45940'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:35971'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:38694'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:36756'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:46309'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:38540'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:35655'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:38730'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:36761'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:45224'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:39539'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:41441'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:38874'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:39217'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:36174'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:44027'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:40795'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:32830'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:39471'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:41763'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:36618'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:39308'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:35244'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:45846'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:44295'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:35474'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:43918'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:46771'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:40762'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:37969'\n",
      "distributed.deploy.ssh - INFO - distributed.worker - INFO -       Start worker at:   tcp://192.168.0.33:41090\n",
      "distributed.deploy.ssh - INFO - distributed.worker - INFO -       Start worker at:   tcp://192.168.0.10:40523\n",
      "distributed.deploy.ssh - INFO - distributed.worker - INFO -       Start worker at:   tcp://192.168.0.12:44218\n",
      "distributed.deploy.ssh - INFO - distributed.worker - INFO -       Start worker at:   tcp://192.168.0.11:43954\n",
      "distributed.worker - INFO - cluster properties: htcondor_cluster_setup {'processing_engine': 'unmanaged_cluster', 'cores': 20, 'memory': '200GB', 'disk': '0.1GB', 'local_directory': '/tmp', 'logs_directory': '/datb/sl/fish_rawdata/AMEXP20211102_EEL_AMY/logs', 'adaptive': True, 'maximum_jobs': 15, 'scheduler_port': 22517, 'dashboard_port': 22525, 'scheduler_address': 'localhost', 'workers_addresses_list': ['monod10', 'monod11', 'monod12', 'monod33'], 'nprocs': 40, 'nthreads': 1} \n",
      "distributed.worker - INFO - Started unmanaged cluster\n",
      "distributed.worker - INFO - selected functions for eel-human-adult-brain\n",
      "distributed.worker - INFO - loaded ROBOFISH2_dark_img dark image\n"
     ]
    }
   ],
   "source": [
    "running_pipeline.run_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ca9ba32-e1a0-4d2a-b8bd-a5bf33e60ac6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.worker - INFO - extra_processing_data already exist\n",
      "distributed.worker - INFO - pipeline_config already exist\n",
      "distributed.worker - INFO - output_figures already exist\n",
      "distributed.worker - INFO - probes already exist\n",
      "distributed.worker - INFO - logs already exist\n",
      "distributed.worker - INFO - results already exist\n",
      "distributed.worker - INFO - microscope_tiles_coords already exist\n",
      "distributed.worker - INFO - notebooks already exist\n",
      "distributed.deploy.ssh - INFO - distributed.scheduler - INFO - -----------------------------------------------\n",
      "distributed.deploy.ssh - INFO - /home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/node.py:160: UserWarning: Port 8787 is already in use.\n",
      "distributed.deploy.ssh - INFO - Perhaps you already have a cluster running?\n",
      "distributed.deploy.ssh - INFO - Hosting the HTTP server on port 2959 instead\n",
      "distributed.deploy.ssh - INFO - warnings.warn(\n",
      "distributed.deploy.ssh - INFO - distributed.scheduler - INFO - -----------------------------------------------\n",
      "distributed.deploy.ssh - INFO - distributed.scheduler - INFO - Clear task state\n",
      "distributed.deploy.ssh - INFO - distributed.scheduler - INFO -   Scheduler at:  tcp://193.10.16.58:22517\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:45333'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:45223'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:38105'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:46092'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:33871'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:44967'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:44629'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:33114'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:46652'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:34805'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:35721'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:37545'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:40190'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:39347'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:36990'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:39091'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:44124'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:35422'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:44240'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:40631'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:43795'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:37819'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:35860'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:44952'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:36105'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:43386'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:43358'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:39679'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:45489'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:44440'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:45504'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:46450'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:45107'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:40635'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:46599'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:43427'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:40887'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:41843'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:34537'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:35290'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:41032'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:33767'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:33881'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:40099'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:39829'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:34689'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:37749'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:36722'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:43934'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:37156'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:33805'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:46251'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:35763'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:36476'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:44113'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:39866'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:45570'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:42679'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:39792'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:43271'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:46292'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:42241'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:38321'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:37759'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:40197'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:35891'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:38904'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:33175'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:38795'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:34152'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:37957'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:42132'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:39433'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:45991'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:41011'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:35563'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:40199'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:42502'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:37374'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:45266'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:34007'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:37723'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:36222'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:39942'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:35473'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:41981'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.12:43800'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:35613'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:39096'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:35276'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:46260'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:42075'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:42228'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:38464'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:41580'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:34442'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:43450'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:40154'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:35965'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:38798'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:45604'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:33646'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:38135'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:32967'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:45255'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:38793'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:44246'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:44636'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.33:39630'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:46779'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:39991'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:36988'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:36372'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:35396'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:33729'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:37944'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:34166'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:40217'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:33343'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:45984'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:38567'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.11:36727'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:39015'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:38445'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:35177'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:40808'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:44885'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:39157'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:42349'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:33233'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:43543'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:43504'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:44016'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:38495'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:41221'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:45510'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:44088'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:33351'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:36142'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:40625'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:35991'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:45511'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:34366'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:44658'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:35332'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:41520'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:38348'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:45083'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:35018'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:44290'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:38727'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:41567'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:42367'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:43450'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:35262'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:34654'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:36708'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:35745'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:38644'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:38159'\n",
      "distributed.deploy.ssh - INFO - distributed.worker - INFO -       Start worker at:   tcp://192.168.0.33:41497\n",
      "distributed.deploy.ssh - INFO - distributed.worker - INFO -       Start worker at:   tcp://192.168.0.12:42286\n",
      "distributed.deploy.ssh - INFO - distributed.worker - INFO -       Start worker at:   tcp://192.168.0.11:43655\n",
      "distributed.deploy.ssh - INFO - distributed.worker - INFO -       Start worker at:   tcp://192.168.0.10:44260\n",
      "distributed.worker - INFO - cluster properties: htcondor_cluster_setup {'processing_engine': 'unmanaged_cluster', 'cores': 20, 'memory': '200GB', 'disk': '0.1GB', 'local_directory': '/tmp', 'logs_directory': '/datb/sl/fish_rawdata/AMEXP20211102_EEL_AMY/logs', 'adaptive': True, 'maximum_jobs': 15, 'scheduler_port': 22517, 'dashboard_port': 8787, 'scheduler_address': 'localhost', 'workers_addresses_list': ['monod10', 'monod11', 'monod12', 'monod33'], 'nprocs': 40, 'nthreads': 1} \n",
      "distributed.worker - INFO - Started unmanaged cluster\n",
      "distributed.worker - INFO - selected functions for eel-human-adult-brain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.93 s, sys: 3.87 s, total: 10.8 s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "running_pipeline.run_setup()\n",
    "running_pipeline.run_cluster_activation()\n",
    "running_pipeline.run_parsing()\n",
    "running_pipeline.run_required_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faae5e72-e4fb-4403-85be-8a7a86ef69de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6860de-04e2-48e0-88c9-0c524a080f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4d517f-9514-45d1-8590-b56529c8699f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ccd831e-59ee-4d87-ad0c-1d1030c68621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysmFISH import io\n",
    "selected_Hdistance = 3 / 16\n",
    "stitching_selected = 'microscope_stitched'\n",
    "io.simple_output_plotting(running_pipeline.experiment_fpath, stitching_selected, \n",
    "                        selected_Hdistance, running_pipeline.client,input_file_tag='decoded',file_tag='microscope_stitched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada78a5-d114-418c-b0d5-7c4d4b89ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_output_plotting(experiment_fpath: str, stitching_selected: str, \n",
    "                            selected_Hdistance: float, client, input_file_tag:str, file_tag: str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22fd838d-4a15-4b5f-a0f7-fa1ba0897599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysmFISH import processing_cluster_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "808d9474-5927-4e10-bb56-0331f9eed7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.worker - INFO - Process Successfully terminated\n",
      "distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n"
     ]
    }
   ],
   "source": [
    "processing_cluster_setup.kill_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81a163-3e19-42cb-a642-ca9d81e6ea45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_d",
   "language": "python",
   "name": "test_d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
