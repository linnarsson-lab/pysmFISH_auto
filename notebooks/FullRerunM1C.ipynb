{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b293c31-3adb-4787-b6a8-47a870772158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/mini/envs/test_d/lib/python3.8/site-packages/dask_jobqueue/core.py:19: FutureWarning: format_bytes is deprecated and will be removed in a future release. Please use dask.utils.format_bytes instead.\n",
      "  from distributed.utils import format_bytes, parse_bytes, tmpfile\n",
      "/home/simone/mini/envs/test_d/lib/python3.8/site-packages/dask_jobqueue/core.py:19: FutureWarning: parse_bytes is deprecated and will be removed in a future release. Please use dask.utils.parse_bytes instead.\n",
      "  from distributed.utils import format_bytes, parse_bytes, tmpfile\n",
      "/home/simone/mini/envs/test_d/lib/python3.8/site-packages/dask_jobqueue/htcondor.py:6: FutureWarning: parse_bytes is deprecated and will be removed in a future release. Please use dask.utils.parse_bytes instead.\n",
      "  from distributed.utils import parse_bytes\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import time\n",
    "#import sys\n",
    "#sys.path.append('/datb/sl/alejandro/pysmFISH_auto/')\n",
    "from pysmFISH.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1809fc45-aabb-4c96-8949-1ed54a410944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the required parameters\n",
    "experiment_fpath = Path('/rawa/sl/fish_rawdata/AMEXP20210620_EEL_M1C_HA2/')\n",
    "dataset_name = '210629_13_21_07_AMEXP20210620_EEL_M1C_HA2_img_data_dataset.parquet'\n",
    "date_tag = time.strftime(\"%y%m%d_%H_%M_%S\")\n",
    "pipeline_run_name = date_tag + '_' + experiment_fpath.stem\n",
    "run_type = 're-run'\n",
    "parsing_type = 'no_parsing' # ''\n",
    "processing_engine = 'unmanaged_cluster' # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "727068bb-8472-4531-bce5-57fd8a4ab5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 149 µs, sys: 0 ns, total: 149 µs\n",
      "Wall time: 159 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Because you are running the pipeline locally you should define the number of cores and memory/core\n",
    "# 3-4 GB / code should be safe for running the processing\n",
    "\n",
    "running_pipeline = Pipeline(\n",
    "        pipeline_run_name= pipeline_run_name,\n",
    "        experiment_fpath= experiment_fpath,\n",
    "        run_type= run_type,\n",
    "        parsing_type= parsing_type,\n",
    "        processing_engine= processing_engine,\n",
    "        cores= 56 ,\n",
    "        memory='250GB',\n",
    "        chunk_size = 6,\n",
    "        same_dot_radius_duplicate_dots = 25,\n",
    "        dataset_path = experiment_fpath / dataset_name,\n",
    "        scheduler_port=9892,\n",
    "        workers_addresses_list=['monod10'],\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "834cd656-8a49-44c3-9a8b-74b23c7b901e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.worker - INFO - extra_processing_data already exist\n",
      "distributed.worker - INFO - pipeline_config already exist\n",
      "distributed.worker - INFO - output_figures already exist\n",
      "distributed.worker - INFO - probes already exist\n",
      "distributed.worker - INFO - logs already exist\n",
      "distributed.worker - INFO - results already exist\n",
      "distributed.worker - INFO - microscope_tiles_coords already exist\n",
      "distributed.worker - INFO - notebooks already exist\n",
      "distributed.deploy.ssh - INFO - distributed.scheduler - INFO - -----------------------------------------------\n",
      "distributed.deploy.ssh - INFO - /home/simone/mini/envs/test_d/lib/python3.8/site-packages/distributed/node.py:160: UserWarning: Port 8787 is already in use.\n",
      "distributed.deploy.ssh - INFO - Perhaps you already have a cluster running?\n",
      "distributed.deploy.ssh - INFO - Hosting the HTTP server on port 6561 instead\n",
      "distributed.deploy.ssh - INFO - warnings.warn(\n",
      "distributed.deploy.ssh - INFO - distributed.scheduler - INFO - -----------------------------------------------\n",
      "distributed.deploy.ssh - INFO - distributed.scheduler - INFO - Clear task state\n",
      "distributed.deploy.ssh - INFO - distributed.scheduler - INFO -   Scheduler at:   tcp://193.10.16.58:9892\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:43680'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:34562'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:40594'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:36503'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:34041'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:37147'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:44546'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:35694'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:40782'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:37116'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:39530'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:39305'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:39535'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:45443'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:32771'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:46004'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:46548'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:43364'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:37208'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:34260'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:46802'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:45618'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:36750'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:41958'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:39499'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:38312'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:33577'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:44788'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:42001'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:44389'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:38601'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:45638'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:42367'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:33564'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:38740'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:39689'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:46571'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:36872'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:39242'\n",
      "distributed.deploy.ssh - INFO - distributed.nanny - INFO -         Start Nanny at: 'tcp://192.168.0.10:35240'\n",
      "distributed.deploy.ssh - INFO - distributed.worker - INFO -       Start worker at:   tcp://192.168.0.10:45912\n",
      "distributed.worker - INFO - cluster properties: htcondor_cluster_setup {'processing_engine': 'unmanaged_cluster', 'cores': 56, 'memory': '250GB', 'disk': '0.1GB', 'local_directory': '/tmp', 'logs_directory': '/rawa/sl/fish_rawdata/AMEXP20210620_EEL_M1C_HA2/logs', 'adaptive': True, 'maximum_jobs': 15, 'scheduler_port': 9892, 'dashboard_port': 8787, 'scheduler_address': 'localhost', 'workers_addresses_list': ['monod10'], 'nprocs': 40, 'nthreads': 1} \n",
      "distributed.worker - INFO - Started unmanaged cluster\n",
      "distributed.worker - INFO - selected functions for eel-human-adult-brain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.99 s, sys: 2.77 s, total: 7.76 s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "running_pipeline.run_setup()\n",
    "running_pipeline.run_cluster_activation()\n",
    "running_pipeline.run_parsing()\n",
    "running_pipeline.run_required_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c49ec60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://193.10.16.58:9268/status'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_pipeline.client.dashboard_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14b90c1c-42db-4ece-9e15-c116d697d3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 15s, sys: 1min 5s, total: 5min 20s\n",
      "Wall time: 8min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "running_pipeline.stitch_and_remove_dots_eel_graph_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f766c93-44d9-4b4f-ab7a-f6314878724d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becedac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4ec16a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8656929f5fa765761431d849ea79b24b4fc84543f183ac423b82161e768f3175"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
