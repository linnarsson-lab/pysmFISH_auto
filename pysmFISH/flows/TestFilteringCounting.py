import prefect
from prefect import task, Flow, Parameter, flatten, unmapped
from prefect.engine.executors import DaskExecutor
from prefect.environments import LocalEnvironment
from prefect import Task
from prefect.environments.storage import Local

from pysmFISH.configuration_files_tasks import load_experiment_config_file
from pysmFISH.data_model import shoji_db_fish
from pysmFISH.io import load_analysis_parameters
from pysmFISH.utilities_tasks import consolidate_zarr_metadata
from pysmFISH.utilities_tasks import sorting_grps
from pysmFISH.prefect_tasks import single_fish_filter_count
from pysmFISH.prefect_tasks import single_beads_filter_count


from pysmFISH.utilities_tasks import open_consolidated_metadata

from prefect.utilities.debug import raise_on_exception


with Flow("filtering-counting",environment=LocalEnvironment(DaskExecutor(address='tcp://193.10.16.58:5810')),
            storage=Local(directory='/home/simone/tmp_code/flows')) as flow:
   
    experiment_fpath = Parameter('experiment_fpath', default = '/wsfish/smfish_ssd/AMEXP20201110_EEL_HumanH1930001V1C_auto')
    parsed_raw_data_fpath = Parameter('parsed_raw_data_fpath',default='/wsfish/smfish_ssd/AMEXP20201110_EEL_HumanH1930001V1C_auto/AMEXP20201110_EEL_HumanH1930001V1C_auto_img_data.zarr')
     
    # Load experiment configuration file generated by robofish machines
    load_exp_cfg = load_experiment_config_file()
    experiment_info = load_exp_cfg(experiment_fpath) 
    
    # Create the shoji database that will contain the data
    create_db = shoji_db_fish()
    ref = create_db(experiment_info)
    
    # Get the list of raw image groups to preprocess
    analysis_loader = load_analysis_parameters()
    analysis_parameters = analysis_loader(experiment_info['EXP_name'])
    analysis_parameters.set_upstream([ref])

    # Consolidate zarr metadata
    # consolidator = consolidate_zarr_metadata()
    # consolidated_zarr_grp = consolidator(parsed_raw_data_fpath)
    # consolidated_zarr_grp.set_upstream([parsed_raw_data_fpath])
    
    # To avoid time for consolidate data
    consolidated_zarr_grp = open_consolidated_metadata(parsed_raw_data_fpath)

    # Sort the type of images according to processing
    grp_sorter = sorting_grps()
    sorted_grps = grp_sorter(consolidated_zarr_grp,experiment_info,analysis_parameters)
    sorted_grps.set_upstream(consolidated_zarr_grp)


    # PORT
    # fish_counter = single_fish_filter_count(task_run_name=lambda **kwargs: f"filtering-counting-{kwargs['zarr_grp_name']}")
    # filtered_fish_images_metadata = fish_counter.map(zarr_grp_name=sorted_grps[0],
    #                         parsed_raw_data_fpath=unmapped(parsed_raw_data_fpath),
    #                         FlatFieldKernel=unmapped(sorted_grps[1]['PreprocessingFishFlatFieldKernel']),
    #                         FilteringSmallKernel=unmapped(sorted_grps[1]['PreprocessingFishFilteringSmallKernel']),
    #                         LaplacianKernel=unmapped(sorted_grps[1]['PreprocessingFishFilteringLaplacianKernel']),
    #                         min_distance=unmapped(sorted_grps[1]['CountingFishMinObjDistance']),
    #                         min_obj_size=unmapped(sorted_grps[1]['CountingFishMinObjSize']),
    #                         max_obj_size=unmapped(sorted_grps[1]['CountingFishMaxObjSize']),
    #                         num_peaks_per_label=unmapped(sorted_grps[1]['CountingFishNumPeaksPerLabel']))


    beads_counter = single_beads_filter_count(task_run_name=lambda **kwargs: f"filtering-counting-{kwargs['zarr_grp_name']}")
    filtered_beads_images_metadata = beads_counter.map(zarr_grp_name=sorted_grps[2][0:5],
                            parsed_raw_data_fpath=unmapped(parsed_raw_data_fpath),
                            FlatFieldKernel=unmapped(sorted_grps[3]['PreprocessingBeadsRegistrationFlatFieldKernel']),
                            FilteringSmallKernel=unmapped(sorted_grps[3]['PreprocessingBeadsRegistrationFilteringSmallKernel']),
                            LaplacianKernel=unmapped(sorted_grps[3]['PreprocessingBeadsRegistrationFilteringLaplacianKernel']),
                            min_distance=unmapped(sorted_grps[3]['CountingBeadsRegistrationMinObjDistance']),
                            min_obj_size=unmapped(sorted_grps[3]['CountingBeadsRegistrationMinObjSize']),
                            max_obj_size=unmapped(sorted_grps[3]['CountingBeadsRegistrationMaxObjSize']),
                            num_peaks_per_label=unmapped(sorted_grps[3]['CountingBeadsRegistrationNumPeaksPerLabel']))

    # Add processing for staining images


# with raise_on_exception():
#     flow.run()

flow.register(project_name="test")
# flow.run_agent()