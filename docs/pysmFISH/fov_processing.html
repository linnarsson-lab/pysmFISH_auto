<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>pysmFISH.fov_processing API documentation</title>
<meta name="description" content="Utility functions and computational graphs used to run processing for a single fov" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pysmFISH.fov_processing</code></h1>
</header>
<section id="section-intro">
<p>Utility functions and computational graphs used to run processing for a single fov</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Utility functions and computational graphs used to run processing for a single fov
&#34;&#34;&#34;

import pickle
import gc
import dask
import sys
import pandas as pd
import numpy as np
import zarr
from typing import *
from pathlib import Path
from dask import delayed
from dask import dataframe as dd
from dask.base import tokenize
from skimage import img_as_uint


import pysmFISH
from pysmFISH import dots_calling
from pysmFISH import io
from pysmFISH import fovs_registration
from pysmFISH import barcodes_analysis
from pysmFISH import stitching
from pysmFISH import preprocessing
from pysmFISH import configuration_files
from pysmFISH import utils
from pysmFISH import microscopy_file_parsers
from pysmFISH import data_models
from pysmFISH.logger_utils import selected_logger


def combine_steps(*args):
    pass


def single_fov_round_processing_eel(fov_subdataset: pd.Series,
                                   analysis_parameters: dict,
                                   running_functions: dict,
                                   dark_img: np.ndarray,
                                   experiment_fpath: str,
                                   preprocessed_zarr_fpath: str,
                                   save_steps_output:bool=False,
                                   start_from_preprocessed_imgs:bool=False)-&gt; Tuple[pd.DataFrame,Tuple]:
    
    &#34;&#34;&#34;Function to run eel processing and counting on a single fov

    Args:
        fov_subdataset (pd.Series): Contains all the metadata relative to a fov.
        analysis_parameters (dict): Processing parameters.
        running_functions (dict): Preprocessing and counting function to run on
            the selected fov.
        dark_img (np.ndarray): Image for the correction of dark signal of the
            camera.
        experiment_fpath (str): Path to the experiment to process
        preprocessed_zarr_fpath (str): Path to the zarr container where the preprocessed
            images will be saved
        save_steps_output (bool, optional): Determine if to save the intermediate
            processing steps. Defaults to False.

    Returns:
        Tuple[pd.DataFrame,Tuple]: counts, filt_out
    &#34;&#34;&#34;

    logger = selected_logger()
    experiment_fpath = Path(experiment_fpath)
    
    experiment_name = fov_subdataset.experiment_name
    pipeline = fov_subdataset.pipeline
    processing_type = fov_subdataset.processing_type
    zarr_grp_name = fov_subdataset.grp_name
    
    raw_data_location = Path(fov_subdataset.raw_data_location)
    parsed_raw_data_fpath = raw_data_location.parent

    if processing_type == &#39;fish&#39;:
        processing_parameters = analysis_parameters[&#39;fish&#39;]
        filtering_fun = running_functions[&#39;fish_channels_preprocessing&#39;]
        counting_fun = running_functions[&#39;fish_channels_dots_calling&#39;]
    
    elif &#39;beads&#39; in processing_type:
        processing_parameters = analysis_parameters[processing_type]
        filtering_fun = running_functions[&#39;reference_channels_preprocessing&#39;]
        counting_fun = running_functions[&#39;reference_channels_dots_calling&#39;]

    elif processing_type != &#39;staining&#39;:
        processing_parameters = analysis_parameters[processing_type]
        filtering_fun = running_functions[&#39;reference_channels_preprocessing&#39;]
        counting_fun = running_functions[&#39;reference_channels_dots_calling&#39;]


    if start_from_preprocessed_imgs:
        # Load already filtered data
        filt_out = io.load_general_zarr(fov_subdataset,preprocessed_zarr_fpath,tag=&#39;preprocessed_data&#39;)
        filt_out = ((filt_out[0],),filt_out[1])

    else:

        filt_out = getattr(pysmFISH.preprocessing,filtering_fun)(
                                                        zarr_grp_name,
                                                        parsed_raw_data_fpath,
                                                        processing_parameters,
                                                        dark_img)
  
    counts = getattr(pysmFISH.dots_calling,counting_fun)(
                                                        filt_out[0][0],
                                                        fov_subdataset,
                                                        processing_parameters)                                              

    if save_steps_output:

        # Save the file as zarr
        store = zarr.DirectoryStore(preprocessed_zarr_fpath)
        root = zarr.group(store=store,overwrite=False)
        tag_name = experiment_name + &#39;_&#39; + fov_subdataset.channel + &#39;_round_&#39; + str(fov_subdataset.round_num) + &#39;_fov_&#39; + str(fov_subdataset.fov_num)
        dgrp = root.create_group(tag_name,overwrite=True)
        for k, v in filt_out[1].items():
            dgrp.attrs[k] = v
        fov_name = &#39;preprocessed_data_fov_&#39; + str(fov_subdataset.fov_num)
        dgrp.attrs[&#39;fov_name&#39;] = fov_name
        img = utils.convert_to_uint16(filt_out[0][-1]) # Must change to zero to save final processed image 
        dset = dgrp.create_dataset(fov_name, data=img, shape=img.shape, chunks=None,overwrite=True)

        # counts.to_parquet(raw_counts_path / (fname + &#39;.parquet&#39;),index=False)

    # return counts, (fov_subdataset.channel,fov_subdataset.round_num,img)
    return counts, filt_out


def single_fov_round_processing_serial_nuclei(fov_subdataset: pd.Series,
                                   analysis_parameters: dict,
                                   running_functions: dict,
                                   dark_img: np.ndarray,
                                   experiment_fpath: str,
                                   preprocessed_zarr_fpath: str,
                                   save_steps_output=False)-&gt; Tuple[np.ndarray,pd.Series]:

    &#34;&#34;&#34;Function to run serial processing of nuclei
    Some of the input variable are not used but I wanted to keep the same type of input
    for all the single fov processing functions.

    Args:
        fov_subdataset (pd.Series): Contains all the metadata relative to a fov.
        analysis_parameters (dict): Processing parameters.
        running_functions (dict): Preprocessing and counting function to run on
            the selected fov.
        dark_img (np.ndarray): Image for the correction of dark signal of the
            camera.
        experiment_fpath (str): Path to the experiment to process
        preprocessed_zarr_fpath (str): Path to the zarr container where the preprocessed
            images will be saved
        save_steps_output (bool, optional): Determine if to save the intermediate
            processing steps. Defaults to False.

    Returns:
        Tuple[np.ndarray,pd.Series]: (img,fov_subdataset)
    &#34;&#34;&#34;
    logger = selected_logger()
    experiment_fpath = Path(experiment_fpath)

    # Path of directory where to save the intermediate results
    filtered_img_path = experiment_fpath / &#39;results&#39;
    raw_counts_path = experiment_fpath / &#39;results&#39;
    
    experiment_name = fov_subdataset.experiment_name
    pipeline = fov_subdataset.pipeline
    processing_type = fov_subdataset.processing_type
    zarr_grp_name = fov_subdataset.grp_name
    
    raw_data_location = Path(fov_subdataset.raw_data_location)
    parsed_raw_data_fpath = raw_data_location.parent

    processing_parameters = analysis_parameters[processing_type]

    filt_out = getattr(pysmFISH.preprocessing,running_functions[&#39;reference_channels_preprocessing&#39;])(
                                                                        zarr_grp_name,
                                                                        parsed_raw_data_fpath,
                                                                        processing_parameters)

    if save_steps_output:

        # Save the file as zarr
        store = zarr.DirectoryStore(preprocessed_zarr_fpath)
        root = zarr.group(store=store,overwrite=False)
        tag_name = experiment_name + &#39;_&#39; + fov_subdataset.channel + &#39;_round_&#39; + str(fov_subdataset.round_num) + &#39;_fov_&#39; + str(fov_subdataset.fov_num)
        dgrp = root.create_group(tag_name,overwrite=True)
        for k, v in filt_out[1].items():
            dgrp.attrs[k] = v
        fov_name = &#39;preprocessed_data_fov_&#39; + str(fov_subdataset.fov_num)
        dgrp.attrs[&#39;fov_name&#39;] = fov_name
        img = utils.convert_to_uint16(filt_out[0][-1])
        dset = dgrp.create_dataset(fov_name, data=img, shape=img.shape, chunks=None,overwrite=True)

    return (img,fov_subdataset)


def processing_barcoded_eel_fov_graph(experiment_fpath: str,
                                    analysis_parameters: dict,
                                    running_functions: dict, 
                                    tiles_org,
                                    metadata: dict,
                                    grpd_fovs: pd.DataFrame,
                                    save_intermediate_steps: bool, 
                                    preprocessed_image_tag: str, 
                                    client, 
                                    chunks_size: int, 
                                    save_bits_int: int,
                                    start_from_preprocessed_imgs: False):
    
    &#34;&#34;&#34;Processing graph for eel type of experiments. Run all the
    steps that can be applied to a single FOV.
    1) Filtering and counting
    2) Register all imaging rounds
    3) Identification of the barcodes (decoding)
    4) Stitching using the stage coords
    5) Generate an output file with the counts for visualisation

    IMPORTANT:
    Because some of the processing steps take quite a bit of time it is necessary
    to process the FOV in chunks to avoid that the processes will fail (workers get
    lost and not comunicate with the scheduler).

    Args:
        experiment_fpath (str): Path to the experiment to process
        analysis_parameters (dict): Parameters to use for the processing
        running_functions (dict): Function to run for preprocessing and counting
        tiles_org (tile_org): Organization of the tiles in the large image
        metadata (dict): Metadata describing the experiment
        grpd_fovs (pd.DataFrame): Database of the experiment grouped by fov
        save_intermediate_steps (bool): Save preprocessed images and raw counts
        preprocessed_image_tag (str): Tag to label the preprocessed images zarr container
        client (distributed.Client): Dask Client that take care of the graph processing
        chunks_size (int): Number of FOVs to process in one go
        save_bits_int (int): Save the intensity of the barcodes (also negative barcodes)
                        and the position of the bits that are flipped
        start_from_preprocessed_imgs (bool): Run the processing starting from the counting
                using preprocessed images. default: False 
    &#34;&#34;&#34;
        
    experiment_fpath = Path(experiment_fpath)
    io.create_empty_zarr_file(experiment_fpath.as_posix(), preprocessed_image_tag)
    preprocessed_zarr_fpath = experiment_fpath / (experiment_fpath.stem + &#39;_&#39; + preprocessed_image_tag + &#39;.zarr&#39;)

    microscopy_file_parsers.create_dark_img(experiment_fpath,metadata)

    dark_img = preprocessing.load_dark_image(experiment_fpath)
    
    # did this conversion to avoid to pass self to dask
    # analysis_parameters = analysis_parameters
    # running_functions = running_functions
    # tile_corners_coords_pxl = tile_corners_coords_pxl
    
    
    dark_img = delayed(dark_img)
    analysis_parameters = delayed(analysis_parameters)
    running_functions = delayed(running_functions)
    tile_corners_coords_pxl = delayed(tiles_org.tile_corners_coords_pxl)

    list_all_channels = metadata[&#39;list_all_channels&#39;]
    stitching_channel = metadata[&#39;stitching_channel&#39;]
    fish_channels = set(list_all_channels)^set([stitching_channel])

    codebook_dict = configuration_files.load_codebook(experiment_fpath,metadata)
    codebook_dict = delayed(codebook_dict)
    
    all_processing = []
    all_filtered_images = []
    all_fovs = list(grpd_fovs.groups.keys())
    chunks = [all_fovs[x:x+chunks_size] for x in range(0, len(all_fovs), chunks_size)]
    for chunk in chunks:
        all_processing = []
        all_counts_fov = {}
        for fov_num in chunk:
            all_filtered_images = {}
            all_counts_fov = {}
            all_counts_fov_concat = {}
            
            fov_group = grpd_fovs.get_group(fov_num)
            channel_grpd = fov_group.groupby(&#39;channel&#39;)

            all_filtered_imges = {}
            for channel_proc in list_all_channels:
                all_filtered_images[channel_proc] = {}
                all_counts_fov[channel_proc] = []
                group = channel_grpd.get_group(channel_proc)
                for index_value, fov_subdataset in group.iterrows():
                    round_num = fov_subdataset.round_num
                    channel = fov_subdataset.channel
                    
                    fov = fov_subdataset.fov_num
                    experiment_name = fov_subdataset.experiment_name
                    dask_delayed_name = &#39;filt_count_&#39; +experiment_name + &#39;_&#39; + channel + \
                                    &#39;_round_&#39; + str(round_num) + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()
                    fov_out = delayed(single_fov_round_processing_eel, name=dask_delayed_name,nout=2)(fov_subdataset,
                                                analysis_parameters,
                                                running_functions,
                                                dark_img,
                                                experiment_fpath,
                                                preprocessed_zarr_fpath,
                                                save_steps_output=save_intermediate_steps,
                                                start_from_preprocessed_imgs=start_from_preprocessed_imgs,
                                                dask_key_name=dask_delayed_name)
                    counts, filt_out = fov_out[0], fov_out[1]
                    
                    all_counts_fov[channel_proc].append(counts) 
                        
                    if save_bits_int:
                        if channel_proc != fov_subdataset.stitching_channel:
                            all_filtered_images[channel_proc][round_num] = filt_out # store it if it gets too big
            
                name = &#39;concat_&#39; +experiment_name + &#39;_&#39; + channel_proc + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()
                all_counts_fov_concat[channel_proc] = delayed(pd.concat,name=name)(all_counts_fov[channel_proc],axis=0,ignore_index=True)
            

            
            if save_intermediate_steps:
                
                for channel in list_all_channels:
                    name = &#39;save_raw_counts_&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()

                    
                    saved_raw_counts = delayed(all_counts_fov_concat[channel].to_parquet,name=name)(Path(experiment_fpath) / &#39;results&#39;/ (experiment_name + \
                            &#39;_raw_counts_channel_&#39;+ channel + &#39;_fov_&#39; + str(fov) + &#39;.parquet&#39;),index=False)

                    all_processing.append(saved_raw_counts)


            # name = &#39;register_&#39; +experiment_name + &#39;_&#39; + stitching_channel + &#39;_&#39; \
            #                     + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()
            # registered_counts = delayed(fovs_registration.beads_based_registration,name=name)(all_counts_fov_concat[stitching_channel],
            #                                     analysis_parameters)

            
            registration_stitching_channel_output = delayed(fovs_registration.beads_based_registration_stitching_channel,name=name)(all_counts_fov_concat[stitching_channel],
                                                    analysis_parameters,metadata)

            stitching_channel_df, all_rounds_shifts, all_rounds_matching_dots = registration_stitching_channel_output[0], \
                                                                                registration_stitching_channel_output[1], \
                                                                                registration_stitching_channel_output[2]


            stitched_coords_reference_df = delayed(stitching.stitch_using_coords_general,name=name)(stitching_channel_df,
                                                                tile_corners_coords_pxl,tiles_org.reference_corner_fov_position,
                                                                metadata,tag=&#39;microscope_stitched&#39;)
            all_stitched_coords = []
            all_stitched_coords.append(stitched_coords_reference_df)

            for processing_channel in fish_channels:
                
                # Register fish
                name = &#39;register_fish_channels_&#39; +experiment_name + &#39;_&#39; + processing_channel + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()

                registered_counts = delayed(fovs_registration.beads_based_registration_fish,name=name)(all_counts_fov_concat[processing_channel],
                                                    all_rounds_shifts, all_rounds_matching_dots, analysis_parameters)

                # Decoded fish
                name = &#39;decode_&#39; +experiment_name + &#39;_&#39; + processing_channel + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()
                decoded = delayed(barcodes_analysis.extract_barcodes_NN_fast_multicolor,name=name)(registered_counts, 
                                                                        analysis_parameters,codebook_dict[processing_channel],
                                                                        metadata)                                                        
            
                if save_bits_int:

                    # all_filtered_images = {}
                    # group_bits = channel_grpd.get_group(processing_channel)
                    # for index_value, fov_subdataset in group_bits.iterrows():
                    #     round_num = fov_subdataset.round_num
                    #     name = &#39;load_filtered_image_&#39; +experiment_name + &#39;_&#39; \
                    #             + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
                    #     filt_out = delayed(io.load_general_zarr,name=name)(fov_subdataset,preprocessed_zarr_fpath,tag=&#39;preprocessed_data&#39;)
                        # all_filtered_images[round_num] = filt_out
                    
                    name = &#39;combine_shifted_images_&#39; +experiment_name + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize() 

                    combined_shift_images = delayed(fovs_registration.combine_register_filtered_image_single_channel,name=name)(all_filtered_images[processing_channel],
                                                metadata,all_rounds_shifts)
                    
                    name = &#39;extract_dots_intensities_&#39; +experiment_name + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
                    extracted_intensities = delayed(barcodes_analysis.extract_dots_images,name=name)(decoded[1],
                                            combined_shift_images,experiment_fpath,metadata)

                    # Stitch to the microscope reference coords
                    name = &#39;stitch_to_mic_coords_&#39; +experiment_name + &#39;_&#39; + processing_channel + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()  
                    stitched_coords = delayed(stitching.stitch_using_coords_general,name=name)(extracted_intensities,
                                                                tile_corners_coords_pxl,tiles_org.reference_corner_fov_position,
                                                                metadata,tag=&#39;microscope_stitched&#39;)    

                else:
                    stitched_coords = delayed(stitching.stitch_using_coords_general,name=name)(decoded[1],
                                                                tile_corners_coords_pxl,tiles_org.reference_corner_fov_position,
                                                                metadata,tag=&#39;microscope_stitched&#39;)    

                    
                all_stitched_coords.append(stitched_coords)

            
            name = &#39;concat_&#39; +experiment_name + \
                                    &#39;_fov_&#39; + str(fov) + &#39;-&#39; + tokenize()
            all_stitched_coords = delayed(pd.concat,name=name)(all_stitched_coords,axis=0,ignore_index=True) 
                
                
            name = &#39;save_df_&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize() 
            saved_file = delayed(all_stitched_coords.to_parquet,name=name)(Path(experiment_fpath) / &#39;results&#39;/ (experiment_name + \
                            &#39;_decoded_fov_&#39; + str(fov) + &#39;.parquet&#39;),index=False)
                        
            
            all_processing.append(saved_file)


        _ = dask.compute(*all_processing)
        client.run(gc.collect)

    io.consolidate_zarr_metadata(preprocessed_zarr_fpath)


#TODO: Needs to be adjusted
def processing_barcoded_eel_fov_graph_from_decoding(experiment_fpath: str,
                                    analysis_parameters: dict,
                                    tiles_org,
                                    metadata: dict,
                                    grpd_fovs: pd.DataFrame,
                                    client, 
                                    chunks_size: int):
    
    &#34;&#34;&#34;Processing graph for eel type of experiments. Runs the decoding of
    a preprocessed experiment

    3) Identification of the barcodes (decoding)
    4) Stitching using the stage coords
    5) Generate an output file with the counts for visualisation

    IMPORTANT:
    Because some of the processing steps take quite a bit of time it is necessary
    to process the FOV in chunks to avoid that the processes will fail (workers get
    lost and not comunicate with the scheduler).

    Args:
        experiment_fpath (str): Path to the experiment to process
        analysis_parameters (dict): Parameters to use for the processing
        tiles_org (tile_org): Organization of the tiles in the large image
        metadata (dict): Metadata describing the experiment
        grpd_fovs (pd.DataFrame): Database of the experiment grouped by fov
        client (distributed.Client): Dask Client that take care of the graph processing
        chunks_size (int): Number of FOVs to process in one go

    &#34;&#34;&#34;
        
    experiment_fpath = Path(experiment_fpath)
    
    analysis_parameters = delayed(analysis_parameters)
    tile_corners_coords_pxl = delayed(tiles_org.tile_corners_coords_pxl)

    list_all_channels = metadata[&#39;list_all_channels&#39;]
    stitching_channel = metadata[&#39;stitching_channel&#39;]
    fish_channels = set(list_all_channels)^set([stitching_channel])

    codebook_dict = configuration_files.load_codebook(experiment_fpath,metadata)
    codebook_dict = delayed(codebook_dict)
    
    all_processing = []
    all_fovs = list(grpd_fovs.groups.keys())
    chunks = [all_fovs[x:x+chunks_size] for x in range(0, len(all_fovs), chunks_size)]
    for chunk in chunks:
        all_processing = []
        all_counts_fov = {}
        for fov_num in chunk:

            counts_fpath = list((experiment_fpath / &#39;results&#39;).glob(&#39;*_decoded_fov_&#39;+str(fov_num)+&#39;.parquet&#39;))[0]
            experiment_name = experiment_fpath.stem

            name = &#39;load_counts_&#39; +experiment_name + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
            counts_fov = delayed(pd.read_parquet,name=name)(counts_fpath)

            # all_stitched_coords = []
            # for processing_channel in fish_channels:

            #     # Decoded fish
            #     name = &#39;decode_&#39; +experiment_name + &#39;_&#39; + processing_channel + &#39;_&#39; \
            #                         + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
            #     decoded = delayed(barcodes_analysis.extract_barcodes_NN_fast_multicolor,name=name)(counts_fov, 
            #                                                             analysis_parameters,codebook_dict[processing_channel],
            #                                                             metadata)


            #     # Stitch to the microscope reference coords
            #     name = &#39;stitch_to_mic_coords_&#39; +experiment_name + &#39;_&#39; + processing_channel + &#39;_&#39; \
            #                         + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()  
            #     stitched_coords = delayed(stitching.stitch_using_coords_general,name=name)(decoded[1],
            #                                                     tile_corners_coords_pxl,tiles_org.reference_corner_fov_position,
            #                                                     metadata,tag=&#39;microscope_stitched&#39;)
            

            #     all_stitched_coords.append(stitched_coords)

            
            # name = &#39;concat_&#39; +experiment_name + \
            #                         &#39;_fov_&#39; + str(fov_num) + &#39;-&#39; + tokenize()
            # all_stitched_coords = delayed(pd.concat,name=name)(all_stitched_coords,axis=0,ignore_index=True) 
                
                
            # name = &#39;save_df_&#39; +experiment_name + &#39;_&#39; \
            #                     + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize() 
            # saved_file = delayed(all_stitched_coords.to_parquet,name=name)(Path(experiment_fpath) / &#39;results&#39;/ (experiment_name + \
            #                 &#39;_decoded_fov_&#39; + str(fov_num) + &#39;.parquet&#39;),index=False)
                        
            
            # all_processing.append(saved_file)
            all_processing.append(counts_fov)


        _ = dask.compute(*all_processing)

       

def processing_barcoded_eel_fov_starting_from_registration_graph(experiment_fpath: str,
                                    analysis_parameters: dict,
                                    running_functions: dict, 
                                    tiles_org,
                                    metadata: dict,
                                    grpd_fovs: pd.DataFrame,
                                    preprocessed_image_tag: str, 
                                    client, 
                                    chunk_size: int, 
                                    save_bits_int: int,):
    &#34;&#34;&#34;Processing graph for runnning analysis of eel type experiments
    skipping the preprocessing and counting. It is useful when there
    are issue with the registration of the different rounds. The
    processing restart with the registration of the differen rounds.
    1) Register all imaging rounds
    2) Identification of the barcodes (decoding)
    3) Stitching using the stage coords
    4) Generate an output file with the counts for visualisation

    IMPORTANT:
    Because some of the processing steps take quite a bit of time it is necessary
    to process the FOV in chunks to avoid that the processes will fail (workers get
    lost and not comunicate with the scheduler).

    Args:
        experiment_fpath (str): Path to the experiment to process
        analysis_parameters (dict): Parameters to use for the processing
        running_functions (dict): Function to run for preprocessing and counting
        tiles_org (tile_org): Organization of the tiles in the large image
        metadata (dict): Metadata describing the experiment
        grpd_fovs (pd.DataFrame): Database of the experiment grouped by fov
        preprocessed_image_tag (str): Tag to label the preprocessed images zarr container
        client (distributed.Client): Dask Client that take care of the graph processing
        chunks_size (int): Number of FOVs to process in one go
        save_bits_int (int): Save the intensity of the barcodes (also negative barcodes)
                        and the position of the bits that are flipped
    &#34;&#34;&#34;
        


    experiment_fpath = Path(experiment_fpath)
    experiment_name = experiment_fpath.stem
    preprocessed_zarr_fpath = experiment_fpath / (experiment_fpath.stem + &#39;_&#39; + preprocessed_image_tag + &#39;.zarr&#39;)
    
    list_all_channels = metadata[&#39;list_all_channels&#39;]
    stitching_channel = metadata[&#39;stitching_channel&#39;]
    fish_channels = set(list_all_channels)^set([stitching_channel])
    total_rounds = metadata[&#39;total_rounds&#39;]
    all_processing = []

    analysis_parameters = delayed(analysis_parameters)
    tile_corners_coords_pxl = delayed(tiles_org.tile_corners_coords_pxl)
    codebook_dict = configuration_files.load_codebook(experiment_fpath,metadata)
    codebook_dict = delayed(codebook_dict)



    all_fovs = list(grpd_fovs.groups.keys())
    chunks = [all_fovs[x:x+chunk_size] for x in range(0, len(all_fovs), chunk_size)]
        
    for chunk in chunks:
        all_processing = []
        for fov_num in chunk:

            fov_group = grpd_fovs.get_group(fov_num)
            channel_grpd = fov_group.groupby(&#39;channel&#39;)

            stitching_channel_fpath = list((experiment_fpath / &#39;results&#39;).glob(&#39;*_raw_counts_channel_&#39;+stitching_channel + &#39;_fov_&#39;+str(fov_num)+&#39;.parquet&#39;))[0]
            
            name = &#39;load_counts_&#39; +experiment_name + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
            all_counts_fov = delayed(pd.read_parquet,name=name)(stitching_channel_fpath)

            
            name = &#39;regitration_stitching_&#39; +experiment_name + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
            registration_stitching_channel_output = delayed(fovs_registration.beads_based_registration_stitching_channel,name=name)(all_counts_fov,
                                                    analysis_parameters,metadata)

            stitching_channel_df, all_rounds_shifts, all_rounds_matching_dots = registration_stitching_channel_output[0], \
                                                                                registration_stitching_channel_output[1], \
                                                                                registration_stitching_channel_output[2]


            name = &#39;stitching_to_microscope_&#39; +experiment_name + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
            stitched_coords_reference_df = delayed(stitching.stitch_using_coords_general,name=name)(stitching_channel_df,
                                                                tile_corners_coords_pxl,tiles_org.reference_corner_fov_position,
                                                                metadata,tag=&#39;microscope_stitched&#39;)
            all_stitched_coords = []
            all_stitched_coords.append(stitched_coords_reference_df)

            for processing_channel in fish_channels:
                
                # Register fish
                name = &#39;load_fish_channels_&#39; +experiment_name + &#39;_&#39; + processing_channel + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()

                channel_fpath = list((experiment_fpath / &#39;results&#39;).glob(&#39;*_raw_counts_channel_&#39;+processing_channel + &#39;_fov_&#39;+str(fov_num)+&#39;.parquet&#39;))[0]
            
                name = &#39;load_counts_&#39; +experiment_name + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
                fish_counts_fov = delayed(pd.read_parquet,name=name)(channel_fpath)
                

                registered_counts = delayed(fovs_registration.beads_based_registration_fish,name=name)(fish_counts_fov,
                                                    all_rounds_shifts, all_rounds_matching_dots, analysis_parameters)

                # Decoded fish
                name = &#39;decode_&#39; +experiment_name + &#39;_&#39; + processing_channel + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
                decoded = delayed(barcodes_analysis.extract_barcodes_NN_fast_multicolor,name=name)(registered_counts, 
                                                                        analysis_parameters,codebook_dict[processing_channel],
                                                                        metadata)                                                        
            
                if save_bits_int:

                    # all_filtered_images = {}
                    # group_bits = channel_grpd.get_group(processing_channel)
                    # for index_value, fov_subdataset in group_bits.iterrows():
                    #     round_num = fov_subdataset.round_num
                    #     name = &#39;load_filtered_image_&#39; +experiment_name + &#39;_&#39; \
                    #             + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
                    #     filt_out = delayed(io.load_general_zarr,name=name)(fov_subdataset,preprocessed_zarr_fpath,tag=&#39;preprocessed_data&#39;)
                        # all_filtered_images[round_num] = filt_out
                    
                    name = &#39;combine_shifted_images_&#39; +experiment_name + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize() 

                    combined_shift_images = delayed(fovs_registration.combine_register_filtered_image_single_channel,name=name)(all_filtered_images[processing_channel],
                                                metadata,all_rounds_shifts)
                    
                    name = &#39;extract_dots_intensities_&#39; +experiment_name + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
                    extracted_intensities = delayed(barcodes_analysis.extract_dots_images,name=name)(decoded[1],
                                            combined_shift_images,experiment_fpath,metadata)

                    # Stitch to the microscope reference coords
                    name = &#39;stitch_to_mic_coords_&#39; +experiment_name + &#39;_&#39; + processing_channel + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()  
                    stitched_coords = delayed(stitching.stitch_using_coords_general,name=name)(extracted_intensities,
                                                                tile_corners_coords_pxl,tiles_org.reference_corner_fov_position,
                                                                metadata,tag=&#39;microscope_stitched&#39;)    

                else:
                    stitched_coords = delayed(stitching.stitch_using_coords_general,name=name)(decoded[1],
                                                                tile_corners_coords_pxl,tiles_org.reference_corner_fov_position,
                                                                metadata,tag=&#39;microscope_stitched&#39;)    

                    
                all_stitched_coords.append(stitched_coords)

            
            name = &#39;concat_&#39; +experiment_name + \
                                    &#39;_fov_&#39; + str(fov_num) + &#39;-&#39; + tokenize()
            all_stitched_coords = delayed(pd.concat,name=name)(all_stitched_coords,axis=0,ignore_index=True) 
                
                
            name = &#39;save_df_&#39; +experiment_name + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize() 
            saved_file = delayed(all_stitched_coords.to_parquet,name=name)(Path(experiment_fpath) / &#39;results&#39;/ (experiment_name + \
                            &#39;_decoded_fov_&#39; + str(fov_num) + &#39;.parquet&#39;),index=False)
                        
            
            all_processing.append(saved_file)
                

        _ = dask.compute(*all_processing)






def combine_filtered_images(output_list: list,experiment_fpath: str,
                            metadata: pd.DataFrame, save:bool=False):
    &#34;&#34;&#34;Function used to combine all the filtered images for a fov/channel in a single
        image stack
    Args:
        output_list (list): list containing the output of preprocessing 
        experiment_fpath (str): path to the experiment to process
        metadata (pd.DataFrame): dataframe containing the metadata
        save (bool, optional): Determine if the filtered images should be stored Defaults to False.
    Returns:
        img_stack (np.ndarray): image stack of all the images for a fov. The position in the
                stack correspond to round_num-1
    &#34;&#34;&#34;
    experiment_fpath = Path(experiment_fpath)
     
    img_stack = np.zeros([metadata[&#39;total_rounds&#39;],metadata[&#39;img_width&#39;],metadata[&#39;img_height&#39;]])

    for img, img_meta in output_list:
        round_num = img_meta.round_num
        img_stack[round_num-1,:,:] = img

    if save:
        # Add conversion to more compress ftype
        img_meta = output_list[0][1]
        channel = img_meta.channel
        fov = img_meta.fov_num
        fpath = experiment_fpath / &#39;results&#39; / (experiment_fpath.stem + &#39;_&#39; + channel + &#39;_combined_img_fov_&#39; + fov + &#39;.npy&#39;)
        np.save(fpath, img_stack)
    
    return img_stack



def processing_serial_fish_fov_graph(experiment_fpath: str,
                                    analysis_parameters: dict,
                                    running_functions: dict, 
                                    tiles_org,
                                    metadata: dict,
                                    grpd_fovs: pd.DataFrame,
                                    save_intermediate_steps: bool, 
                                    preprocessed_image_tag: str, 
                                    client,
                                    chunks_size: int):
    &#34;&#34;&#34;Processing graph for serial type of experiments.

    Args:
    
        experiment_fpath (str): Path to the experiment to process
        analysis_parameters (dict): Parameters to use for the processing
        running_functions (dict): Function to run for preprocessing and counting
        tiles_org (tile_org): Organization of the tiles in the large image
        metadata (dict): Metadata describing the experiment
        grpd_fovs (pd.DataFrame): Database of the experiment grouped by fov
        save_intermediate_steps (bool): Save preprocessed images and raw counts
        preprocessed_image_tag (str): Tag to label the preprocessed images zarr container
        client (distributed.Client): Dask Client that take care of the graph processing
        chunks_size (int): Number of FOVs to process in one go
    
    &#34;&#34;&#34;

    experiment_fpath = Path(experiment_fpath)
    io.create_empty_zarr_file(experiment_fpath, preprocessed_image_tag)
    preprocessed_zarr_fpath = experiment_fpath / (experiment_fpath.stem + &#39;_&#39; + preprocessed_image_tag + &#39;.zarr&#39;)

    microscopy_file_parsers.create_dark_img(experiment_fpath,metadata)


    dark_img = preprocessing.load_dark_image(experiment_fpath)
    
    # did this conversion to avoid to pass self to dask
    analysis_parameters = analysis_parameters
    running_functions = running_functions
    tile_corners_coords_pxl = tiles_org.tile_corners_coords_pxl
    
    dark_img = delayed(dark_img)
    analysis_parameters = delayed(analysis_parameters)
    running_functions = delayed(running_functions)
    tile_corners_coords_pxl = delayed(tile_corners_coords_pxl)

    all_processing = []
    all_filtered_images = []
    all_fovs = list(grpd_fovs.groups.keys())
    chunks = [all_fovs[x:x+chunks_size] for x in range(0, len(all_fovs), chunks_size)]
    for chunk in chunks:
        all_processing = []
        all_filtered_images = []
        for fov_num in chunk:
            group = grpd_fovs.get_group(fov_num)
    # for fov_num, group in grpd_fovs:
            all_counts_fov = []
            all_nuclei_fov = []
            for index_value, fov_subdataset in group.iterrows():
                round_num = fov_subdataset.round_num
                channel = fov_subdataset.channel
                fov = fov_subdataset.fov_num
                stitching_type = fov_subdataset.stitching_type
                experiment_name = fov_subdataset.experiment_name
                processing_type = fov_subdataset.processing_type

                if processing_type == &#39;nuclei&#39;:
                    dask_delayed_name = &#39;filt_&#39; +experiment_name + &#39;_&#39; + channel + \
                                    &#39;_round_&#39; + str(round_num) + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()

                    out_nuclei = delayed(single_fov_round_processing_serial_nuclei,name=dask_delayed_name)(fov_subdataset,
                                            analysis_parameters,
                                            running_functions,
                                            dark_img,
                                            experiment_fpath,
                                            preprocessed_image_tag,
                                            preprocessed_zarr_fpath,
                                            save_steps_output=save_intermediate_steps,
                                            dask_key_name=dask_delayed_name)
                    all_nuclei_fov.append(out_nuclei)


                else:
                    dask_delayed_name = &#39;filt_count_&#39; +experiment_name + &#39;_&#39; + channel + \
                                    &#39;_round_&#39; + str(round_num) + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()
                    fov_out = delayed(single_fov_round_processing_eel,name=dask_delayed_name)(fov_subdataset,
                                                analysis_parameters,
                                                running_functions,
                                                dark_img,
                                                experiment_fpath,
                                                preprocessed_zarr_fpath,
                                                save_steps_output=save_intermediate_steps,
                                                dask_key_name=dask_delayed_name)
                    
                    counts, filt_out = fov_out[0], fov_out[1]
                    all_counts_fov.append(counts)
                    
                    # if channel != fov_subdataset.stitching_channel:
                    #     all_filtered_images.append(filt_out)
                    

            name = &#39;concat_fish_&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()
            all_counts_fov = delayed(pd.concat,name=name)(all_counts_fov,axis=0,ignore_index=True)
            
            if stitching_type == &#39;nuclei&#39;:

                name = &#39;create_nuclei_stack&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()
                filtered_nuclei_stack = delayed(combine_filtered_images,name=name)(all_nuclei_fov,experiment_fpath,metadata)

                name = &#39;register_&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()
                registered_counts = delayed(fovs_registration.nuclei_based_registration,name=name)(all_counts_fov,
                                                    filtered_nuclei_stack,
                                                    analysis_parameters)

            else:

                name = &#39;register_&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()
                registered_counts = delayed(fovs_registration.beads_based_registration,name=name)(all_counts_fov,
                                                    analysis_parameters)
                                                                                                
            name = &#39;stitch_to_mic_coords_&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()  

            stitched_coords = delayed(stitching.stitch_using_coords_general,name=name)(registered_counts,
                                                            tile_corners_coords_pxl,tiles_org.reference_corner_fov_position,
                                                            metadata,tag=&#39;microscope_stitched&#39;)
            
            name = &#39;register_and_combine_filt_imgs&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize() 
            
            # combined_images = delayed(fovs_registration.combine_register_filtered_images,name=name)(all_filtered_images,stitched_coords,
            #                                                                                 fov_subdataset.stitching_channel)

            name = &#39;save_df_&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize() 
            saved_file = delayed(stitched_coords.to_parquet,name=name)(Path(experiment_fpath) / &#39;results&#39;/ (experiment_name + \
                            &#39;_decoded_fov_&#39; + str(fov) + &#39;.parquet&#39;),index=False)
        
            all_processing.append(saved_file) 
        
        _ = dask.compute(*all_processing)

    io.consolidate_zarr_metadata(preprocessed_zarr_fpath)

    

def single_fov_fresh_tissue_beads(processing_tag: str,
                                   fov_subdataset: pd.Series,
                                   analysis_parameters: dict,
                                   running_functions: dict,
                                   dark_img: np.ndarray,
                                   experiment_fpath: str,
                                   preprocessed_zarr_fpath: str,
                                   save_steps_output: bool=True):
    &#34;&#34;&#34;[summary]

    Args:
        processing_tag (str): name describing the processing
        fov_subdataset (pd.Series): metadata corresponding to the specific fov
        analysis_parameters (dict): paramters used for processing
        running_functions (dict): functions to run preprocessing and detection of the beads
        dark_img (np.ndarray): background of the camera
        experiment_fpath (str): path to the experiment to process.
        preprocessed_zarr_fpath (str): path to the zarr container with the preprocessed images
        save_steps_output (bool, optional): Determine if to save preprocessing data. Defaults to True.

    Returns:
        [Tuple[pd.DataFrame, Tuple]]: counts, filt_out if processing_tag == &#39;beads&#39;
        [Tuple]: filt_out if processing_tag == &#39;nuclei&#39;
    &#34;&#34;&#34;

    logger = selected_logger()
    experiment_fpath = Path(experiment_fpath)

    experiment_name = fov_subdataset.experiment_name
    zarr_grp_name = fov_subdataset.grp_name

    parsed_raw_data_fpath = experiment_fpath / &#39;fresh_tissue&#39;/ (experiment_name +&#39;_img_data.zarr&#39;)
    
    processing_parameters = analysis_parameters[&#39;fresh-tissue&#39;][processing_tag]

    if processing_tag == &#39;beads&#39;:
        filtering_fun = running_functions[&#39;fresh_sample_reference_preprocessing&#39;]
        counting_fun = running_functions[&#39;fresh_sample_reference_dots_calling&#39;]


        filt_out = getattr(pysmFISH.preprocessing,filtering_fun)(
                                                        zarr_grp_name,
                                                        parsed_raw_data_fpath,
                                                        processing_parameters,
                                                        dark_img)

        counts = getattr(pysmFISH.dots_calling,counting_fun)(
                                                            filt_out[0][0],
                                                            fov_subdataset,
                                                            processing_parameters)       

        if save_steps_output:

            # Save the file as zarr
            store = zarr.DirectoryStore(preprocessed_zarr_fpath)
            root = zarr.group(store=store,overwrite=False)
            tag_name = experiment_name + &#39;_fresh_tissue_&#39; + processing_tag + &#39;_fov_&#39; + str(fov_subdataset.fov_num)
            dgrp = root.create_group(tag_name,overwrite=True)
            for k, v in filt_out[1].items():
                dgrp.attrs[k] = v
            fov_name = &#39;preprocessed_data_fov_&#39; + str(fov_subdataset.fov_num)
            dgrp.attrs[&#39;fov_name&#39;] = fov_name
            img = utils.convert_to_uint16(filt_out[0][-1])
            dset = dgrp.create_dataset(fov_name, data=img, shape=img.shape, chunks=None,overwrite=True)                                       

    elif processing_tag == &#39;nuclei&#39;:
        filtering_fun = running_functions[&#39;fresh_sample_nuclei_preprocessing&#39;]
        filt_out = getattr(pysmFISH.preprocessing,filtering_fun)(
                                                        zarr_grp_name,
                                                        parsed_raw_data_fpath,
                                                        processing_parameters)

        if save_steps_output:

            # Save the file as zarr
            store = zarr.DirectoryStore(preprocessed_zarr_fpath)
            root = zarr.group(store=store,overwrite=False)
            tag_name = experiment_name + &#39;_fresh_tissue_&#39; + processing_tag + &#39;_fov_&#39; + str(fov_subdataset.fov_num)
            dgrp = root.create_group(tag_name,overwrite=True)
            for k, v in filt_out[1].items():
                dgrp.attrs[k] = v
            fov_name = &#39;preprocessed_data_fov_&#39; + str(fov_subdataset.fov_num)
            dgrp.attrs[&#39;fov_name&#39;] = fov_name
            img = img_as_uint(filt_out[0][-1])
            dset = dgrp.create_dataset(fov_name, data=img, shape=img.shape, chunks=None,overwrite=True)


    if processing_tag == &#39;beads&#39;:
        return counts, filt_out

    elif processing_tag == &#39;nuclei&#39;:
        return filt_out



def make_fresh_beads_count_like_eel(data,eel_metadata):
    data[&#39;r_px_registered&#39;] = data[&#39;r_px_original&#39;]
    data[&#39;c_px_registered&#39;] = data[&#39;c_px_original&#39;]
    data[&#39;hamming_distance&#39;] = 0
    data[&#39;decoded_genes&#39;] = &#39;beads&#39;
    data[&#39;machine&#39;] = eel_metadata[&#39;machine&#39;]
    return data


def process_fresh_sample_graph(experiment_fpath: str, 
                            running_functions:dict, 
                            analysis_parameters: dict, 
                            client, 
                            chunks_size: int,
                            tag_ref_beads: str, 
                            tag_nuclei: str,
                            eel_metadata: dict,
                            parsing: bool=True,
                            save_steps_output:bool=True):
    &#34;&#34;&#34;Processing graph for the low magnification images of the 
    tissues nuclei acquired before eel and used for the
    segmentation and identification of the cells

    1) Parsing of the raw images (if required)
    2) Create the fresh nuclei images dataset
    3) Preprocessing and counting (beads) or
       preprocessing (nuclei) 

    Args:
        experiment_fpath (str): path to the experiment to process
        running_functions (dict): function used to run preprocessing and counting
        analysis_parameters (dict): parameters used to run the analysis
        client (distributed.Client): dask client coordinating the processing 
        chunks_size (int): processing in chunks
        tag_ref_beads (str): str in the files name used to identify the images of the beads
        tag_nuclei (str): str in the files name used to identify the images of the nuclei
        eel_metadata (dict): overall experiment info
        parsing (bool, optional): Determine if the images need to be parsed. Defaults to True.
        save_steps_output (bool): save the processed data
    &#34;&#34;&#34;
    logger = selected_logger()
    all_parsing = []
    
    if parsing:
        presence_nuclei = 0
        presence_beads = 0
        all_fresh_tissue_fpath = list((Path(experiment_fpath) / &#39;fresh_tissue&#39;).glob(&#39;*.nd2&#39;))
        if all_fresh_tissue_fpath:
            for fpath in all_fresh_tissue_fpath:
                if tag_ref_beads in fpath.stem:
                    parsed_beads_fpath = experiment_fpath / &#39;fresh_tissue&#39;/ (fpath.stem +&#39;_img_data.zarr&#39;)
                    parsing_future = client.submit(microscopy_file_parsers.nikon_nd2_parser_simple_mfov,fpath)
                    all_parsing.append(parsing_future)
                    presence_beads = 1
                elif tag_nuclei in fpath.stem:
                    parsed_nuclei_fpath = experiment_fpath / &#39;fresh_tissue&#39;/ (fpath.stem +&#39;_img_data.zarr&#39;)
                    parsing_future = client.submit(microscopy_file_parsers.nikon_nd2_parser_simple_mfov,fpath)
                    all_parsing.append(parsing_future)
                    presence_nuclei = 1

            if presence_beads and presence_nuclei:
                _ = client.gather(all_parsing)
                io.consolidate_zarr_metadata(parsed_beads_fpath)
                io.consolidate_zarr_metadata(parsed_nuclei_fpath)
            else:
                if not presence_beads:
                    logger.error(f&#39;missing fresh-tissue beads file&#39;)
                    sys.exit(f&#39;missing fresh-tissue beads file&#39;)
                elif not presence_nuclei:
                    logger.error(f&#39;missing fresh-tissue nuclei file&#39;)
                    sys.exit(f&#39;missing fresh-tissue nuclei file&#39;)
                else:
                    logger.error(f&#39;missing fresh-tissue beads and nuclei files&#39;)
                    sys.exit(f&#39;missing fresh-tissue beads and nuclei files&#39;)

    else:
        all_fresh_tissue_fpath = list((Path(experiment_fpath) / &#39;fresh_tissue&#39;).glob(&#39;*.zarr&#39;))
        if all_fresh_tissue_fpath:
            for fpath in all_fresh_tissue_fpath:
                if tag_ref_beads in fpath.stem:
                    parsed_beads_fpath = fpath
                    presence_beads = 1
                elif tag_nuclei in fpath.stem:
                    parsed_nuclei_fpath = fpath
                    presence_nuclei = 1
              
        if not presence_beads:
            logger.error(f&#39;missing fresh-tissue beads parsed file&#39;)
            sys.exit(f&#39;missing fresh-tissue beads parsed file&#39;)
        elif not presence_nuclei:
            logger.error(f&#39;missing fresh-tissue nuclei parsed file&#39;)
            sys.exit(f&#39;missing fresh-tissue nuclei parsed file&#39;)
        elif (not presence_nuclei) &amp; (not presence_beads    ):
            logger.error(f&#39;missing fresh-tissue beads and nuclei parsed files&#39;)
            sys.exit(f&#39;missing fresh-tissue beads and nuclei parsed files&#39;)  

  
    # Create dataset
    
    ds_beads = data_models.Dataset()
    ds_nuclei = data_models.Dataset()
    ds_beads.create_full_dataset_from_zmetadata(parsed_beads_fpath)
    ds_nuclei.create_full_dataset_from_zmetadata(parsed_nuclei_fpath)

    beads_grpd_fovs = ds_beads.dataset.groupby(&#39;fov_num&#39;)
    nuclei_grpd_fovs = ds_nuclei.dataset.groupby(&#39;fov_num&#39;)
    
    # In this case I fake a dark image. It must be collected from the 
    # robofish system
    img_width = ds_nuclei.dataset.iloc[0].img_width
    img_height = ds_nuclei.dataset.iloc[0].img_height
    dark_img = np.zeros([img_width,img_height])

    base_path = experiment_fpath / &#39;fresh_tissue&#39;
    utils.create_dir(base_path / &#39;results&#39;)
    # nuclei_base = parsed_nuclei_fpath.stem.split(&#39;_img_data.zarr&#39;)[0]
    # beads_base = parsed_beads_fpath.stem.split(&#39;_img_data.zarr&#39;)[0]
    nuclei_filtered_fpath = base_path /  (base_path.stem + &#39;_nuclei_preprocessed_img_data.zarr&#39;)
    io.create_empty_zarr_file(base_path.as_posix(), tag=&#39;nuclei_preprocessed_img_data&#39;)
    beads_filtered_fpath = base_path /  (base_path.stem + &#39;_beads_preprocessed_img_data.zarr&#39;)
    io.create_empty_zarr_file(base_path.as_posix(), tag=&#39;beads_preprocessed_img_data&#39;)
    
    client.run(gc.collect)

    processing_tag = &#39;beads&#39;

    ds_beads.dataset[&#39;processing_type&#39;] = &#39;undefined&#39;
    ds_beads.dataset[&#39;overlapping_percentage&#39;] = 5 / 100
    ds_beads.dataset[&#39;machine&#39;] = eel_metadata[&#39;machine&#39;]
    ds_beads.dataset[&#39;round_num&#39;] = 1
    metadata = ds_beads.collect_metadata(ds_beads.dataset)

    round_num = 1
    stitching_channel = &#39;Europium&#39;
    tiles_org = stitching.organize_square_tiles(base_path,ds_beads.dataset,metadata,round_num)
    tiles_org.run_tiles_organization()

    all_fovs = list(beads_grpd_fovs.groups.keys())
    chunks = [all_fovs[x:x+chunks_size] for x in range(0, len(all_fovs), chunks_size)]
    for chunk in chunks:
        all_processing = []
        all_counts_beads = []
        for fov_num in chunk:
            fov_subdataset = beads_grpd_fovs.get_group(fov_num).iloc[0] # Olny one round of imaging
            
            round_num = fov_subdataset.round_num
            channel = fov_subdataset.channel
            fov = fov_subdataset.fov_num
            experiment_name = fov_subdataset.experiment_name
            dask_delayed_name = &#39;filt_count_beads_fov&#39;+ str(fov) + &#39;_&#39; + tokenize()
            fov_out = delayed(single_fov_fresh_tissue_beads, name=dask_delayed_name)(
                                            processing_tag,
                                            fov_subdataset,
                                            analysis_parameters,
                                            running_functions,
                                            dark_img,
                                            experiment_fpath,
                                            preprocessed_zarr_fpath=beads_filtered_fpath,
                                            save_steps_output=save_steps_output,
                                            dask_key_name=dask_delayed_name)
            counts, filt_out = fov_out[0], fov_out[1]
        
        

            # name = &#39;concat_all_counts_beads_fresh_tissue&#39;+ &#39;-&#39; + tokenize()
            # all_counts_fov = delayed(pd.concat,name=name)(all_counts_beads,axis=0,ignore_index=True)

            name = &#39;add missing fields&#39;+ &#39;-&#39; + tokenize()
            counts_adj = delayed(make_fresh_beads_count_like_eel,name=name)(counts,eel_metadata)


            # Stitch to the microscope reference coords
            name = &#39;stitch_to_mic_coords_&#39; +experiment_name + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()  
            stitched_coords = delayed(stitching.stitch_using_coords_general,name=name)(counts_adj,
                                                            tiles_org.tile_corners_coords_pxl,tiles_org.reference_corner_fov_position,
                                                            metadata,tag=&#39;microscope_stitched&#39;)

            # Add registration and recalculation of all the coords
            name = &#39;save_df_beads_fresh_tissue&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize() 
            saved_file = delayed(stitched_coords.to_parquet,name=name)(base_path / &#39;results&#39;/ (experiment_name + \
                        &#39;_counts_beads_fresh_tissue_decoded_fov_&#39;+ str(fov_num) +&#39;.parquet&#39;),index=False)

            all_processing.append(saved_file)
        _ = dask.compute(all_processing)
        client.run(gc.collect)

    processing_tag=&#39;nuclei&#39;

    all_fovs = list(nuclei_grpd_fovs.groups.keys())
    chunks = [all_fovs[x:x+chunks_size] for x in range(0, len(all_fovs), chunks_size)]
    for chunk in chunks:
        all_processing_nuclei = []
        for fov_num in chunk:
            fov_subdataset = nuclei_grpd_fovs.get_group(fov_num).iloc[0] # Olny one round of imaging
            round_num = fov_subdataset.round_num
            channel = fov_subdataset.channel
            fov = fov_subdataset.fov_num
            experiment_name = fov_subdataset.experiment_name
            dask_delayed_name = &#39;filt_nuclei_fov&#39;+ str(fov) + &#39;_&#39; + tokenize()
            fov_out = delayed(single_fov_fresh_tissue_beads, name=dask_delayed_name)(
                                            processing_tag,
                                            fov_subdataset,
                                            analysis_parameters,
                                            running_functions,
                                            dark_img,
                                            experiment_fpath,
                                            preprocessed_zarr_fpath=nuclei_filtered_fpath,
                                            save_steps_output=save_steps_output,
                                            dask_key_name=dask_delayed_name)
                
            all_processing_nuclei.append(fov_out)

 
        # end = delayed(combine_steps)(saved_file,all_processing_nuclei)
      
        _ = dask.compute(all_processing_nuclei)
        client.run(gc.collect)
    





# TODO Remove functions



# def collect_bits_intensity_graph(dataset:pd.Dataframe, experiment_fpath:str, 
#                             grpd_fovs,metadata:Dict,chunks_size,codebooks,client):

#     # Write to add stitching reference to the dataset to make in easy to run the
#     # bits analysis
    

#     # Need to run for fov

#     bit_channels = list(set(metadata[&#39;list_all_channels&#39;]).difference(metadata[&#39;stitching_channel&#39;])))
#     experiment_fpath = Path(experiment_fpath)
#     experiment_name = metadata[&#39;experiment_name&#39;]
#     filtered_images_path =  Path(experiment_fpath) / (metadata[&#39;experiment_name&#39;] + &#39;preprocessed_img_data.zarr&#39;)

#     all_fovs = list(grpd_fovs.groups.keys())
#     chunks = [all_fovs[x:x+chunks_size] for x in range(0, len(all_fovs), chunks_size)]
#     for chunk in chunks:
#         all_processing = []
#         all_filtered_images = []
#         for fov_num in chunk:
#             group = grpd_fovs.get_group(fov_num)
#             grpd_channel = group.groupby(&#39;channel&#39;)

#             # Load counts
#             name = &#39;Load_counts&#39; +experiment_name + &#39;_&#39; + \
#                                         + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize() 
                    
#             counts_fpath = experiment_fpath / &#39;results&#39; / (experiment_name + &#39;_decoded_fov_&#39; +str(fov_num) + &#39;.parquet&#39;)
#             counts_df = delayed(pd.read_parquet,name=name)(counts_fpath)


#             for channel, channel_grp in grpd_channel:
#                 all_filtered_images = []
#                 for index_value, fov_subdataset in channel_grp.iterrows():
#                     # Create ((img,), metadata) list to match the one used in the eel graph in order
#                     # to used the same set of functions

#                     name =  &#39;load_processed_images_&#39; + fov_subdataset.grp_name+ &#39;-&#39; + tokenize()

#                     img = delayed(io.load_general_zarr,name=name)(fov_subdataset,filtered_images_path)
#                     filt_out = ((img,), metadata)
#                     all_filtered_images.append(filt_out)

                
#                 name = &#39;register_and_combine_filt_imgs&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
#                                         + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize() 
                    
#                 combined_images = delayed(fovs_registration.combine_register_filtered_images,name=name)(all_filtered_images,counts_df,
#                                                                                                 fov_subdataset.stitching_channel)


#                 name = &#39;extract_barcodes_int&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
#                                     + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
#                 barcodes_max = delayed(barcodes_analysis.extract_dots_images,name=name)(counts_df,combined_images,
#                                                                                         experiment_fpath)


#                 name = &#39;extract_bit_flip_direction&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
#                                     + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()
#                 flip_direction = delayed(barcodes_analysis.define_flip_direction,name=name)(codebook,
#                                                                                         experiment_fpath,
#                                                                                         stitched_coords)



    # &#34;&#34;&#34;Collected the intensity of the 1 and 0 bits and the flipping direction.
    #     This is an extra function to run after the data are collected to avoid
    #     to slow down the initial dots counting.

    # Args:
    #     dataset ([type]): [description]
    # &#34;&#34;&#34;</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pysmFISH.fov_processing.combine_filtered_images"><code class="name flex">
<span>def <span class="ident">combine_filtered_images</span></span>(<span>output_list: list, experiment_fpath: str, metadata: pandas.core.frame.DataFrame, save: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to combine all the filtered images for a fov/channel in a single
image stack</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>output_list</code></strong> :&ensp;<code>list</code></dt>
<dd>list containing the output of preprocessing </dd>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>path to the experiment to process</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>dataframe containing the metadata</dd>
<dt><strong><code>save</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Determine if the filtered images should be stored Defaults to False.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>img_stack (np.ndarray): image stack of all the images for a fov. The position in the
stack correspond to round_num-1</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def combine_filtered_images(output_list: list,experiment_fpath: str,
                            metadata: pd.DataFrame, save:bool=False):
    &#34;&#34;&#34;Function used to combine all the filtered images for a fov/channel in a single
        image stack
    Args:
        output_list (list): list containing the output of preprocessing 
        experiment_fpath (str): path to the experiment to process
        metadata (pd.DataFrame): dataframe containing the metadata
        save (bool, optional): Determine if the filtered images should be stored Defaults to False.
    Returns:
        img_stack (np.ndarray): image stack of all the images for a fov. The position in the
                stack correspond to round_num-1
    &#34;&#34;&#34;
    experiment_fpath = Path(experiment_fpath)
     
    img_stack = np.zeros([metadata[&#39;total_rounds&#39;],metadata[&#39;img_width&#39;],metadata[&#39;img_height&#39;]])

    for img, img_meta in output_list:
        round_num = img_meta.round_num
        img_stack[round_num-1,:,:] = img

    if save:
        # Add conversion to more compress ftype
        img_meta = output_list[0][1]
        channel = img_meta.channel
        fov = img_meta.fov_num
        fpath = experiment_fpath / &#39;results&#39; / (experiment_fpath.stem + &#39;_&#39; + channel + &#39;_combined_img_fov_&#39; + fov + &#39;.npy&#39;)
        np.save(fpath, img_stack)
    
    return img_stack</code></pre>
</details>
</dd>
<dt id="pysmFISH.fov_processing.combine_steps"><code class="name flex">
<span>def <span class="ident">combine_steps</span></span>(<span>*args)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def combine_steps(*args):
    pass</code></pre>
</details>
</dd>
<dt id="pysmFISH.fov_processing.make_fresh_beads_count_like_eel"><code class="name flex">
<span>def <span class="ident">make_fresh_beads_count_like_eel</span></span>(<span>data, eel_metadata)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_fresh_beads_count_like_eel(data,eel_metadata):
    data[&#39;r_px_registered&#39;] = data[&#39;r_px_original&#39;]
    data[&#39;c_px_registered&#39;] = data[&#39;c_px_original&#39;]
    data[&#39;hamming_distance&#39;] = 0
    data[&#39;decoded_genes&#39;] = &#39;beads&#39;
    data[&#39;machine&#39;] = eel_metadata[&#39;machine&#39;]
    return data</code></pre>
</details>
</dd>
<dt id="pysmFISH.fov_processing.process_fresh_sample_graph"><code class="name flex">
<span>def <span class="ident">process_fresh_sample_graph</span></span>(<span>experiment_fpath: str, running_functions: dict, analysis_parameters: dict, client, chunks_size: int, tag_ref_beads: str, tag_nuclei: str, eel_metadata: dict, parsing: bool = True, save_steps_output: bool = True)</span>
</code></dt>
<dd>
<div class="desc"><p>Processing graph for the low magnification images of the
tissues nuclei acquired before eel and used for the
segmentation and identification of the cells</p>
<p>1) Parsing of the raw images (if required)
2) Create the fresh nuclei images dataset
3) Preprocessing and counting (beads) or
preprocessing (nuclei) </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>path to the experiment to process</dd>
<dt><strong><code>running_functions</code></strong> :&ensp;<code>dict</code></dt>
<dd>function used to run preprocessing and counting</dd>
<dt><strong><code>analysis_parameters</code></strong> :&ensp;<code>dict</code></dt>
<dd>parameters used to run the analysis</dd>
<dt><strong><code>client</code></strong> :&ensp;<code>distributed.Client</code></dt>
<dd>dask client coordinating the processing </dd>
<dt><strong><code>chunks_size</code></strong> :&ensp;<code>int</code></dt>
<dd>processing in chunks</dd>
<dt><strong><code>tag_ref_beads</code></strong> :&ensp;<code>str</code></dt>
<dd>str in the files name used to identify the images of the beads</dd>
<dt><strong><code>tag_nuclei</code></strong> :&ensp;<code>str</code></dt>
<dd>str in the files name used to identify the images of the nuclei</dd>
<dt><strong><code>eel_metadata</code></strong> :&ensp;<code>dict</code></dt>
<dd>overall experiment info</dd>
<dt><strong><code>parsing</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Determine if the images need to be parsed. Defaults to True.</dd>
<dt><strong><code>save_steps_output</code></strong> :&ensp;<code>bool</code></dt>
<dd>save the processed data</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process_fresh_sample_graph(experiment_fpath: str, 
                            running_functions:dict, 
                            analysis_parameters: dict, 
                            client, 
                            chunks_size: int,
                            tag_ref_beads: str, 
                            tag_nuclei: str,
                            eel_metadata: dict,
                            parsing: bool=True,
                            save_steps_output:bool=True):
    &#34;&#34;&#34;Processing graph for the low magnification images of the 
    tissues nuclei acquired before eel and used for the
    segmentation and identification of the cells

    1) Parsing of the raw images (if required)
    2) Create the fresh nuclei images dataset
    3) Preprocessing and counting (beads) or
       preprocessing (nuclei) 

    Args:
        experiment_fpath (str): path to the experiment to process
        running_functions (dict): function used to run preprocessing and counting
        analysis_parameters (dict): parameters used to run the analysis
        client (distributed.Client): dask client coordinating the processing 
        chunks_size (int): processing in chunks
        tag_ref_beads (str): str in the files name used to identify the images of the beads
        tag_nuclei (str): str in the files name used to identify the images of the nuclei
        eel_metadata (dict): overall experiment info
        parsing (bool, optional): Determine if the images need to be parsed. Defaults to True.
        save_steps_output (bool): save the processed data
    &#34;&#34;&#34;
    logger = selected_logger()
    all_parsing = []
    
    if parsing:
        presence_nuclei = 0
        presence_beads = 0
        all_fresh_tissue_fpath = list((Path(experiment_fpath) / &#39;fresh_tissue&#39;).glob(&#39;*.nd2&#39;))
        if all_fresh_tissue_fpath:
            for fpath in all_fresh_tissue_fpath:
                if tag_ref_beads in fpath.stem:
                    parsed_beads_fpath = experiment_fpath / &#39;fresh_tissue&#39;/ (fpath.stem +&#39;_img_data.zarr&#39;)
                    parsing_future = client.submit(microscopy_file_parsers.nikon_nd2_parser_simple_mfov,fpath)
                    all_parsing.append(parsing_future)
                    presence_beads = 1
                elif tag_nuclei in fpath.stem:
                    parsed_nuclei_fpath = experiment_fpath / &#39;fresh_tissue&#39;/ (fpath.stem +&#39;_img_data.zarr&#39;)
                    parsing_future = client.submit(microscopy_file_parsers.nikon_nd2_parser_simple_mfov,fpath)
                    all_parsing.append(parsing_future)
                    presence_nuclei = 1

            if presence_beads and presence_nuclei:
                _ = client.gather(all_parsing)
                io.consolidate_zarr_metadata(parsed_beads_fpath)
                io.consolidate_zarr_metadata(parsed_nuclei_fpath)
            else:
                if not presence_beads:
                    logger.error(f&#39;missing fresh-tissue beads file&#39;)
                    sys.exit(f&#39;missing fresh-tissue beads file&#39;)
                elif not presence_nuclei:
                    logger.error(f&#39;missing fresh-tissue nuclei file&#39;)
                    sys.exit(f&#39;missing fresh-tissue nuclei file&#39;)
                else:
                    logger.error(f&#39;missing fresh-tissue beads and nuclei files&#39;)
                    sys.exit(f&#39;missing fresh-tissue beads and nuclei files&#39;)

    else:
        all_fresh_tissue_fpath = list((Path(experiment_fpath) / &#39;fresh_tissue&#39;).glob(&#39;*.zarr&#39;))
        if all_fresh_tissue_fpath:
            for fpath in all_fresh_tissue_fpath:
                if tag_ref_beads in fpath.stem:
                    parsed_beads_fpath = fpath
                    presence_beads = 1
                elif tag_nuclei in fpath.stem:
                    parsed_nuclei_fpath = fpath
                    presence_nuclei = 1
              
        if not presence_beads:
            logger.error(f&#39;missing fresh-tissue beads parsed file&#39;)
            sys.exit(f&#39;missing fresh-tissue beads parsed file&#39;)
        elif not presence_nuclei:
            logger.error(f&#39;missing fresh-tissue nuclei parsed file&#39;)
            sys.exit(f&#39;missing fresh-tissue nuclei parsed file&#39;)
        elif (not presence_nuclei) &amp; (not presence_beads    ):
            logger.error(f&#39;missing fresh-tissue beads and nuclei parsed files&#39;)
            sys.exit(f&#39;missing fresh-tissue beads and nuclei parsed files&#39;)  

  
    # Create dataset
    
    ds_beads = data_models.Dataset()
    ds_nuclei = data_models.Dataset()
    ds_beads.create_full_dataset_from_zmetadata(parsed_beads_fpath)
    ds_nuclei.create_full_dataset_from_zmetadata(parsed_nuclei_fpath)

    beads_grpd_fovs = ds_beads.dataset.groupby(&#39;fov_num&#39;)
    nuclei_grpd_fovs = ds_nuclei.dataset.groupby(&#39;fov_num&#39;)
    
    # In this case I fake a dark image. It must be collected from the 
    # robofish system
    img_width = ds_nuclei.dataset.iloc[0].img_width
    img_height = ds_nuclei.dataset.iloc[0].img_height
    dark_img = np.zeros([img_width,img_height])

    base_path = experiment_fpath / &#39;fresh_tissue&#39;
    utils.create_dir(base_path / &#39;results&#39;)
    # nuclei_base = parsed_nuclei_fpath.stem.split(&#39;_img_data.zarr&#39;)[0]
    # beads_base = parsed_beads_fpath.stem.split(&#39;_img_data.zarr&#39;)[0]
    nuclei_filtered_fpath = base_path /  (base_path.stem + &#39;_nuclei_preprocessed_img_data.zarr&#39;)
    io.create_empty_zarr_file(base_path.as_posix(), tag=&#39;nuclei_preprocessed_img_data&#39;)
    beads_filtered_fpath = base_path /  (base_path.stem + &#39;_beads_preprocessed_img_data.zarr&#39;)
    io.create_empty_zarr_file(base_path.as_posix(), tag=&#39;beads_preprocessed_img_data&#39;)
    
    client.run(gc.collect)

    processing_tag = &#39;beads&#39;

    ds_beads.dataset[&#39;processing_type&#39;] = &#39;undefined&#39;
    ds_beads.dataset[&#39;overlapping_percentage&#39;] = 5 / 100
    ds_beads.dataset[&#39;machine&#39;] = eel_metadata[&#39;machine&#39;]
    ds_beads.dataset[&#39;round_num&#39;] = 1
    metadata = ds_beads.collect_metadata(ds_beads.dataset)

    round_num = 1
    stitching_channel = &#39;Europium&#39;
    tiles_org = stitching.organize_square_tiles(base_path,ds_beads.dataset,metadata,round_num)
    tiles_org.run_tiles_organization()

    all_fovs = list(beads_grpd_fovs.groups.keys())
    chunks = [all_fovs[x:x+chunks_size] for x in range(0, len(all_fovs), chunks_size)]
    for chunk in chunks:
        all_processing = []
        all_counts_beads = []
        for fov_num in chunk:
            fov_subdataset = beads_grpd_fovs.get_group(fov_num).iloc[0] # Olny one round of imaging
            
            round_num = fov_subdataset.round_num
            channel = fov_subdataset.channel
            fov = fov_subdataset.fov_num
            experiment_name = fov_subdataset.experiment_name
            dask_delayed_name = &#39;filt_count_beads_fov&#39;+ str(fov) + &#39;_&#39; + tokenize()
            fov_out = delayed(single_fov_fresh_tissue_beads, name=dask_delayed_name)(
                                            processing_tag,
                                            fov_subdataset,
                                            analysis_parameters,
                                            running_functions,
                                            dark_img,
                                            experiment_fpath,
                                            preprocessed_zarr_fpath=beads_filtered_fpath,
                                            save_steps_output=save_steps_output,
                                            dask_key_name=dask_delayed_name)
            counts, filt_out = fov_out[0], fov_out[1]
        
        

            # name = &#39;concat_all_counts_beads_fresh_tissue&#39;+ &#39;-&#39; + tokenize()
            # all_counts_fov = delayed(pd.concat,name=name)(all_counts_beads,axis=0,ignore_index=True)

            name = &#39;add missing fields&#39;+ &#39;-&#39; + tokenize()
            counts_adj = delayed(make_fresh_beads_count_like_eel,name=name)(counts,eel_metadata)


            # Stitch to the microscope reference coords
            name = &#39;stitch_to_mic_coords_&#39; +experiment_name + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()  
            stitched_coords = delayed(stitching.stitch_using_coords_general,name=name)(counts_adj,
                                                            tiles_org.tile_corners_coords_pxl,tiles_org.reference_corner_fov_position,
                                                            metadata,tag=&#39;microscope_stitched&#39;)

            # Add registration and recalculation of all the coords
            name = &#39;save_df_beads_fresh_tissue&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize() 
            saved_file = delayed(stitched_coords.to_parquet,name=name)(base_path / &#39;results&#39;/ (experiment_name + \
                        &#39;_counts_beads_fresh_tissue_decoded_fov_&#39;+ str(fov_num) +&#39;.parquet&#39;),index=False)

            all_processing.append(saved_file)
        _ = dask.compute(all_processing)
        client.run(gc.collect)

    processing_tag=&#39;nuclei&#39;

    all_fovs = list(nuclei_grpd_fovs.groups.keys())
    chunks = [all_fovs[x:x+chunks_size] for x in range(0, len(all_fovs), chunks_size)]
    for chunk in chunks:
        all_processing_nuclei = []
        for fov_num in chunk:
            fov_subdataset = nuclei_grpd_fovs.get_group(fov_num).iloc[0] # Olny one round of imaging
            round_num = fov_subdataset.round_num
            channel = fov_subdataset.channel
            fov = fov_subdataset.fov_num
            experiment_name = fov_subdataset.experiment_name
            dask_delayed_name = &#39;filt_nuclei_fov&#39;+ str(fov) + &#39;_&#39; + tokenize()
            fov_out = delayed(single_fov_fresh_tissue_beads, name=dask_delayed_name)(
                                            processing_tag,
                                            fov_subdataset,
                                            analysis_parameters,
                                            running_functions,
                                            dark_img,
                                            experiment_fpath,
                                            preprocessed_zarr_fpath=nuclei_filtered_fpath,
                                            save_steps_output=save_steps_output,
                                            dask_key_name=dask_delayed_name)
                
            all_processing_nuclei.append(fov_out)

 
        # end = delayed(combine_steps)(saved_file,all_processing_nuclei)
      
        _ = dask.compute(all_processing_nuclei)
        client.run(gc.collect)</code></pre>
</details>
</dd>
<dt id="pysmFISH.fov_processing.processing_barcoded_eel_fov_graph"><code class="name flex">
<span>def <span class="ident">processing_barcoded_eel_fov_graph</span></span>(<span>experiment_fpath: str, analysis_parameters: dict, running_functions: dict, tiles_org, metadata: dict, grpd_fovs: pandas.core.frame.DataFrame, save_intermediate_steps: bool, preprocessed_image_tag: str, client, chunks_size: int, save_bits_int: int, start_from_preprocessed_imgs: False)</span>
</code></dt>
<dd>
<div class="desc"><p>Processing graph for eel type of experiments. Run all the
steps that can be applied to a single FOV.
1) Filtering and counting
2) Register all imaging rounds
3) Identification of the barcodes (decoding)
4) Stitching using the stage coords
5) Generate an output file with the counts for visualisation</p>
<p>IMPORTANT:
Because some of the processing steps take quite a bit of time it is necessary
to process the FOV in chunks to avoid that the processes will fail (workers get
lost and not comunicate with the scheduler).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the experiment to process</dd>
<dt><strong><code>analysis_parameters</code></strong> :&ensp;<code>dict</code></dt>
<dd>Parameters to use for the processing</dd>
<dt><strong><code>running_functions</code></strong> :&ensp;<code>dict</code></dt>
<dd>Function to run for preprocessing and counting</dd>
<dt><strong><code>tiles_org</code></strong> :&ensp;<code>tile_org</code></dt>
<dd>Organization of the tiles in the large image</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>dict</code></dt>
<dd>Metadata describing the experiment</dd>
<dt><strong><code>grpd_fovs</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Database of the experiment grouped by fov</dd>
<dt><strong><code>save_intermediate_steps</code></strong> :&ensp;<code>bool</code></dt>
<dd>Save preprocessed images and raw counts</dd>
<dt><strong><code>preprocessed_image_tag</code></strong> :&ensp;<code>str</code></dt>
<dd>Tag to label the preprocessed images zarr container</dd>
<dt><strong><code>client</code></strong> :&ensp;<code>distributed.Client</code></dt>
<dd>Dask Client that take care of the graph processing</dd>
<dt><strong><code>chunks_size</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of FOVs to process in one go</dd>
<dt><strong><code>save_bits_int</code></strong> :&ensp;<code>int</code></dt>
<dd>Save the intensity of the barcodes (also negative barcodes)
and the position of the bits that are flipped</dd>
<dt><strong><code>start_from_preprocessed_imgs</code></strong> :&ensp;<code>bool</code></dt>
<dd>Run the processing starting from the counting
using preprocessed images. default: False</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def processing_barcoded_eel_fov_graph(experiment_fpath: str,
                                    analysis_parameters: dict,
                                    running_functions: dict, 
                                    tiles_org,
                                    metadata: dict,
                                    grpd_fovs: pd.DataFrame,
                                    save_intermediate_steps: bool, 
                                    preprocessed_image_tag: str, 
                                    client, 
                                    chunks_size: int, 
                                    save_bits_int: int,
                                    start_from_preprocessed_imgs: False):
    
    &#34;&#34;&#34;Processing graph for eel type of experiments. Run all the
    steps that can be applied to a single FOV.
    1) Filtering and counting
    2) Register all imaging rounds
    3) Identification of the barcodes (decoding)
    4) Stitching using the stage coords
    5) Generate an output file with the counts for visualisation

    IMPORTANT:
    Because some of the processing steps take quite a bit of time it is necessary
    to process the FOV in chunks to avoid that the processes will fail (workers get
    lost and not comunicate with the scheduler).

    Args:
        experiment_fpath (str): Path to the experiment to process
        analysis_parameters (dict): Parameters to use for the processing
        running_functions (dict): Function to run for preprocessing and counting
        tiles_org (tile_org): Organization of the tiles in the large image
        metadata (dict): Metadata describing the experiment
        grpd_fovs (pd.DataFrame): Database of the experiment grouped by fov
        save_intermediate_steps (bool): Save preprocessed images and raw counts
        preprocessed_image_tag (str): Tag to label the preprocessed images zarr container
        client (distributed.Client): Dask Client that take care of the graph processing
        chunks_size (int): Number of FOVs to process in one go
        save_bits_int (int): Save the intensity of the barcodes (also negative barcodes)
                        and the position of the bits that are flipped
        start_from_preprocessed_imgs (bool): Run the processing starting from the counting
                using preprocessed images. default: False 
    &#34;&#34;&#34;
        
    experiment_fpath = Path(experiment_fpath)
    io.create_empty_zarr_file(experiment_fpath.as_posix(), preprocessed_image_tag)
    preprocessed_zarr_fpath = experiment_fpath / (experiment_fpath.stem + &#39;_&#39; + preprocessed_image_tag + &#39;.zarr&#39;)

    microscopy_file_parsers.create_dark_img(experiment_fpath,metadata)

    dark_img = preprocessing.load_dark_image(experiment_fpath)
    
    # did this conversion to avoid to pass self to dask
    # analysis_parameters = analysis_parameters
    # running_functions = running_functions
    # tile_corners_coords_pxl = tile_corners_coords_pxl
    
    
    dark_img = delayed(dark_img)
    analysis_parameters = delayed(analysis_parameters)
    running_functions = delayed(running_functions)
    tile_corners_coords_pxl = delayed(tiles_org.tile_corners_coords_pxl)

    list_all_channels = metadata[&#39;list_all_channels&#39;]
    stitching_channel = metadata[&#39;stitching_channel&#39;]
    fish_channels = set(list_all_channels)^set([stitching_channel])

    codebook_dict = configuration_files.load_codebook(experiment_fpath,metadata)
    codebook_dict = delayed(codebook_dict)
    
    all_processing = []
    all_filtered_images = []
    all_fovs = list(grpd_fovs.groups.keys())
    chunks = [all_fovs[x:x+chunks_size] for x in range(0, len(all_fovs), chunks_size)]
    for chunk in chunks:
        all_processing = []
        all_counts_fov = {}
        for fov_num in chunk:
            all_filtered_images = {}
            all_counts_fov = {}
            all_counts_fov_concat = {}
            
            fov_group = grpd_fovs.get_group(fov_num)
            channel_grpd = fov_group.groupby(&#39;channel&#39;)

            all_filtered_imges = {}
            for channel_proc in list_all_channels:
                all_filtered_images[channel_proc] = {}
                all_counts_fov[channel_proc] = []
                group = channel_grpd.get_group(channel_proc)
                for index_value, fov_subdataset in group.iterrows():
                    round_num = fov_subdataset.round_num
                    channel = fov_subdataset.channel
                    
                    fov = fov_subdataset.fov_num
                    experiment_name = fov_subdataset.experiment_name
                    dask_delayed_name = &#39;filt_count_&#39; +experiment_name + &#39;_&#39; + channel + \
                                    &#39;_round_&#39; + str(round_num) + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()
                    fov_out = delayed(single_fov_round_processing_eel, name=dask_delayed_name,nout=2)(fov_subdataset,
                                                analysis_parameters,
                                                running_functions,
                                                dark_img,
                                                experiment_fpath,
                                                preprocessed_zarr_fpath,
                                                save_steps_output=save_intermediate_steps,
                                                start_from_preprocessed_imgs=start_from_preprocessed_imgs,
                                                dask_key_name=dask_delayed_name)
                    counts, filt_out = fov_out[0], fov_out[1]
                    
                    all_counts_fov[channel_proc].append(counts) 
                        
                    if save_bits_int:
                        if channel_proc != fov_subdataset.stitching_channel:
                            all_filtered_images[channel_proc][round_num] = filt_out # store it if it gets too big
            
                name = &#39;concat_&#39; +experiment_name + &#39;_&#39; + channel_proc + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()
                all_counts_fov_concat[channel_proc] = delayed(pd.concat,name=name)(all_counts_fov[channel_proc],axis=0,ignore_index=True)
            

            
            if save_intermediate_steps:
                
                for channel in list_all_channels:
                    name = &#39;save_raw_counts_&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()

                    
                    saved_raw_counts = delayed(all_counts_fov_concat[channel].to_parquet,name=name)(Path(experiment_fpath) / &#39;results&#39;/ (experiment_name + \
                            &#39;_raw_counts_channel_&#39;+ channel + &#39;_fov_&#39; + str(fov) + &#39;.parquet&#39;),index=False)

                    all_processing.append(saved_raw_counts)


            # name = &#39;register_&#39; +experiment_name + &#39;_&#39; + stitching_channel + &#39;_&#39; \
            #                     + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()
            # registered_counts = delayed(fovs_registration.beads_based_registration,name=name)(all_counts_fov_concat[stitching_channel],
            #                                     analysis_parameters)

            
            registration_stitching_channel_output = delayed(fovs_registration.beads_based_registration_stitching_channel,name=name)(all_counts_fov_concat[stitching_channel],
                                                    analysis_parameters,metadata)

            stitching_channel_df, all_rounds_shifts, all_rounds_matching_dots = registration_stitching_channel_output[0], \
                                                                                registration_stitching_channel_output[1], \
                                                                                registration_stitching_channel_output[2]


            stitched_coords_reference_df = delayed(stitching.stitch_using_coords_general,name=name)(stitching_channel_df,
                                                                tile_corners_coords_pxl,tiles_org.reference_corner_fov_position,
                                                                metadata,tag=&#39;microscope_stitched&#39;)
            all_stitched_coords = []
            all_stitched_coords.append(stitched_coords_reference_df)

            for processing_channel in fish_channels:
                
                # Register fish
                name = &#39;register_fish_channels_&#39; +experiment_name + &#39;_&#39; + processing_channel + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()

                registered_counts = delayed(fovs_registration.beads_based_registration_fish,name=name)(all_counts_fov_concat[processing_channel],
                                                    all_rounds_shifts, all_rounds_matching_dots, analysis_parameters)

                # Decoded fish
                name = &#39;decode_&#39; +experiment_name + &#39;_&#39; + processing_channel + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()
                decoded = delayed(barcodes_analysis.extract_barcodes_NN_fast_multicolor,name=name)(registered_counts, 
                                                                        analysis_parameters,codebook_dict[processing_channel],
                                                                        metadata)                                                        
            
                if save_bits_int:

                    # all_filtered_images = {}
                    # group_bits = channel_grpd.get_group(processing_channel)
                    # for index_value, fov_subdataset in group_bits.iterrows():
                    #     round_num = fov_subdataset.round_num
                    #     name = &#39;load_filtered_image_&#39; +experiment_name + &#39;_&#39; \
                    #             + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
                    #     filt_out = delayed(io.load_general_zarr,name=name)(fov_subdataset,preprocessed_zarr_fpath,tag=&#39;preprocessed_data&#39;)
                        # all_filtered_images[round_num] = filt_out
                    
                    name = &#39;combine_shifted_images_&#39; +experiment_name + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize() 

                    combined_shift_images = delayed(fovs_registration.combine_register_filtered_image_single_channel,name=name)(all_filtered_images[processing_channel],
                                                metadata,all_rounds_shifts)
                    
                    name = &#39;extract_dots_intensities_&#39; +experiment_name + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
                    extracted_intensities = delayed(barcodes_analysis.extract_dots_images,name=name)(decoded[1],
                                            combined_shift_images,experiment_fpath,metadata)

                    # Stitch to the microscope reference coords
                    name = &#39;stitch_to_mic_coords_&#39; +experiment_name + &#39;_&#39; + processing_channel + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()  
                    stitched_coords = delayed(stitching.stitch_using_coords_general,name=name)(extracted_intensities,
                                                                tile_corners_coords_pxl,tiles_org.reference_corner_fov_position,
                                                                metadata,tag=&#39;microscope_stitched&#39;)    

                else:
                    stitched_coords = delayed(stitching.stitch_using_coords_general,name=name)(decoded[1],
                                                                tile_corners_coords_pxl,tiles_org.reference_corner_fov_position,
                                                                metadata,tag=&#39;microscope_stitched&#39;)    

                    
                all_stitched_coords.append(stitched_coords)

            
            name = &#39;concat_&#39; +experiment_name + \
                                    &#39;_fov_&#39; + str(fov) + &#39;-&#39; + tokenize()
            all_stitched_coords = delayed(pd.concat,name=name)(all_stitched_coords,axis=0,ignore_index=True) 
                
                
            name = &#39;save_df_&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize() 
            saved_file = delayed(all_stitched_coords.to_parquet,name=name)(Path(experiment_fpath) / &#39;results&#39;/ (experiment_name + \
                            &#39;_decoded_fov_&#39; + str(fov) + &#39;.parquet&#39;),index=False)
                        
            
            all_processing.append(saved_file)


        _ = dask.compute(*all_processing)
        client.run(gc.collect)

    io.consolidate_zarr_metadata(preprocessed_zarr_fpath)</code></pre>
</details>
</dd>
<dt id="pysmFISH.fov_processing.processing_barcoded_eel_fov_graph_from_decoding"><code class="name flex">
<span>def <span class="ident">processing_barcoded_eel_fov_graph_from_decoding</span></span>(<span>experiment_fpath: str, analysis_parameters: dict, tiles_org, metadata: dict, grpd_fovs: pandas.core.frame.DataFrame, client, chunks_size: int)</span>
</code></dt>
<dd>
<div class="desc"><p>Processing graph for eel type of experiments. Runs the decoding of
a preprocessed experiment</p>
<p>3) Identification of the barcodes (decoding)
4) Stitching using the stage coords
5) Generate an output file with the counts for visualisation</p>
<p>IMPORTANT:
Because some of the processing steps take quite a bit of time it is necessary
to process the FOV in chunks to avoid that the processes will fail (workers get
lost and not comunicate with the scheduler).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the experiment to process</dd>
<dt><strong><code>analysis_parameters</code></strong> :&ensp;<code>dict</code></dt>
<dd>Parameters to use for the processing</dd>
<dt><strong><code>tiles_org</code></strong> :&ensp;<code>tile_org</code></dt>
<dd>Organization of the tiles in the large image</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>dict</code></dt>
<dd>Metadata describing the experiment</dd>
<dt><strong><code>grpd_fovs</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Database of the experiment grouped by fov</dd>
<dt><strong><code>client</code></strong> :&ensp;<code>distributed.Client</code></dt>
<dd>Dask Client that take care of the graph processing</dd>
<dt><strong><code>chunks_size</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of FOVs to process in one go</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def processing_barcoded_eel_fov_graph_from_decoding(experiment_fpath: str,
                                    analysis_parameters: dict,
                                    tiles_org,
                                    metadata: dict,
                                    grpd_fovs: pd.DataFrame,
                                    client, 
                                    chunks_size: int):
    
    &#34;&#34;&#34;Processing graph for eel type of experiments. Runs the decoding of
    a preprocessed experiment

    3) Identification of the barcodes (decoding)
    4) Stitching using the stage coords
    5) Generate an output file with the counts for visualisation

    IMPORTANT:
    Because some of the processing steps take quite a bit of time it is necessary
    to process the FOV in chunks to avoid that the processes will fail (workers get
    lost and not comunicate with the scheduler).

    Args:
        experiment_fpath (str): Path to the experiment to process
        analysis_parameters (dict): Parameters to use for the processing
        tiles_org (tile_org): Organization of the tiles in the large image
        metadata (dict): Metadata describing the experiment
        grpd_fovs (pd.DataFrame): Database of the experiment grouped by fov
        client (distributed.Client): Dask Client that take care of the graph processing
        chunks_size (int): Number of FOVs to process in one go

    &#34;&#34;&#34;
        
    experiment_fpath = Path(experiment_fpath)
    
    analysis_parameters = delayed(analysis_parameters)
    tile_corners_coords_pxl = delayed(tiles_org.tile_corners_coords_pxl)

    list_all_channels = metadata[&#39;list_all_channels&#39;]
    stitching_channel = metadata[&#39;stitching_channel&#39;]
    fish_channels = set(list_all_channels)^set([stitching_channel])

    codebook_dict = configuration_files.load_codebook(experiment_fpath,metadata)
    codebook_dict = delayed(codebook_dict)
    
    all_processing = []
    all_fovs = list(grpd_fovs.groups.keys())
    chunks = [all_fovs[x:x+chunks_size] for x in range(0, len(all_fovs), chunks_size)]
    for chunk in chunks:
        all_processing = []
        all_counts_fov = {}
        for fov_num in chunk:

            counts_fpath = list((experiment_fpath / &#39;results&#39;).glob(&#39;*_decoded_fov_&#39;+str(fov_num)+&#39;.parquet&#39;))[0]
            experiment_name = experiment_fpath.stem

            name = &#39;load_counts_&#39; +experiment_name + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
            counts_fov = delayed(pd.read_parquet,name=name)(counts_fpath)

            # all_stitched_coords = []
            # for processing_channel in fish_channels:

            #     # Decoded fish
            #     name = &#39;decode_&#39; +experiment_name + &#39;_&#39; + processing_channel + &#39;_&#39; \
            #                         + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
            #     decoded = delayed(barcodes_analysis.extract_barcodes_NN_fast_multicolor,name=name)(counts_fov, 
            #                                                             analysis_parameters,codebook_dict[processing_channel],
            #                                                             metadata)


            #     # Stitch to the microscope reference coords
            #     name = &#39;stitch_to_mic_coords_&#39; +experiment_name + &#39;_&#39; + processing_channel + &#39;_&#39; \
            #                         + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()  
            #     stitched_coords = delayed(stitching.stitch_using_coords_general,name=name)(decoded[1],
            #                                                     tile_corners_coords_pxl,tiles_org.reference_corner_fov_position,
            #                                                     metadata,tag=&#39;microscope_stitched&#39;)
            

            #     all_stitched_coords.append(stitched_coords)

            
            # name = &#39;concat_&#39; +experiment_name + \
            #                         &#39;_fov_&#39; + str(fov_num) + &#39;-&#39; + tokenize()
            # all_stitched_coords = delayed(pd.concat,name=name)(all_stitched_coords,axis=0,ignore_index=True) 
                
                
            # name = &#39;save_df_&#39; +experiment_name + &#39;_&#39; \
            #                     + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize() 
            # saved_file = delayed(all_stitched_coords.to_parquet,name=name)(Path(experiment_fpath) / &#39;results&#39;/ (experiment_name + \
            #                 &#39;_decoded_fov_&#39; + str(fov_num) + &#39;.parquet&#39;),index=False)
                        
            
            # all_processing.append(saved_file)
            all_processing.append(counts_fov)


        _ = dask.compute(*all_processing)</code></pre>
</details>
</dd>
<dt id="pysmFISH.fov_processing.processing_barcoded_eel_fov_starting_from_registration_graph"><code class="name flex">
<span>def <span class="ident">processing_barcoded_eel_fov_starting_from_registration_graph</span></span>(<span>experiment_fpath: str, analysis_parameters: dict, running_functions: dict, tiles_org, metadata: dict, grpd_fovs: pandas.core.frame.DataFrame, preprocessed_image_tag: str, client, chunk_size: int, save_bits_int: int)</span>
</code></dt>
<dd>
<div class="desc"><p>Processing graph for runnning analysis of eel type experiments
skipping the preprocessing and counting. It is useful when there
are issue with the registration of the different rounds. The
processing restart with the registration of the differen rounds.
1) Register all imaging rounds
2) Identification of the barcodes (decoding)
3) Stitching using the stage coords
4) Generate an output file with the counts for visualisation</p>
<p>IMPORTANT:
Because some of the processing steps take quite a bit of time it is necessary
to process the FOV in chunks to avoid that the processes will fail (workers get
lost and not comunicate with the scheduler).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the experiment to process</dd>
<dt><strong><code>analysis_parameters</code></strong> :&ensp;<code>dict</code></dt>
<dd>Parameters to use for the processing</dd>
<dt><strong><code>running_functions</code></strong> :&ensp;<code>dict</code></dt>
<dd>Function to run for preprocessing and counting</dd>
<dt><strong><code>tiles_org</code></strong> :&ensp;<code>tile_org</code></dt>
<dd>Organization of the tiles in the large image</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>dict</code></dt>
<dd>Metadata describing the experiment</dd>
<dt><strong><code>grpd_fovs</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Database of the experiment grouped by fov</dd>
<dt><strong><code>preprocessed_image_tag</code></strong> :&ensp;<code>str</code></dt>
<dd>Tag to label the preprocessed images zarr container</dd>
<dt><strong><code>client</code></strong> :&ensp;<code>distributed.Client</code></dt>
<dd>Dask Client that take care of the graph processing</dd>
<dt><strong><code>chunks_size</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of FOVs to process in one go</dd>
<dt><strong><code>save_bits_int</code></strong> :&ensp;<code>int</code></dt>
<dd>Save the intensity of the barcodes (also negative barcodes)
and the position of the bits that are flipped</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def processing_barcoded_eel_fov_starting_from_registration_graph(experiment_fpath: str,
                                    analysis_parameters: dict,
                                    running_functions: dict, 
                                    tiles_org,
                                    metadata: dict,
                                    grpd_fovs: pd.DataFrame,
                                    preprocessed_image_tag: str, 
                                    client, 
                                    chunk_size: int, 
                                    save_bits_int: int,):
    &#34;&#34;&#34;Processing graph for runnning analysis of eel type experiments
    skipping the preprocessing and counting. It is useful when there
    are issue with the registration of the different rounds. The
    processing restart with the registration of the differen rounds.
    1) Register all imaging rounds
    2) Identification of the barcodes (decoding)
    3) Stitching using the stage coords
    4) Generate an output file with the counts for visualisation

    IMPORTANT:
    Because some of the processing steps take quite a bit of time it is necessary
    to process the FOV in chunks to avoid that the processes will fail (workers get
    lost and not comunicate with the scheduler).

    Args:
        experiment_fpath (str): Path to the experiment to process
        analysis_parameters (dict): Parameters to use for the processing
        running_functions (dict): Function to run for preprocessing and counting
        tiles_org (tile_org): Organization of the tiles in the large image
        metadata (dict): Metadata describing the experiment
        grpd_fovs (pd.DataFrame): Database of the experiment grouped by fov
        preprocessed_image_tag (str): Tag to label the preprocessed images zarr container
        client (distributed.Client): Dask Client that take care of the graph processing
        chunks_size (int): Number of FOVs to process in one go
        save_bits_int (int): Save the intensity of the barcodes (also negative barcodes)
                        and the position of the bits that are flipped
    &#34;&#34;&#34;
        


    experiment_fpath = Path(experiment_fpath)
    experiment_name = experiment_fpath.stem
    preprocessed_zarr_fpath = experiment_fpath / (experiment_fpath.stem + &#39;_&#39; + preprocessed_image_tag + &#39;.zarr&#39;)
    
    list_all_channels = metadata[&#39;list_all_channels&#39;]
    stitching_channel = metadata[&#39;stitching_channel&#39;]
    fish_channels = set(list_all_channels)^set([stitching_channel])
    total_rounds = metadata[&#39;total_rounds&#39;]
    all_processing = []

    analysis_parameters = delayed(analysis_parameters)
    tile_corners_coords_pxl = delayed(tiles_org.tile_corners_coords_pxl)
    codebook_dict = configuration_files.load_codebook(experiment_fpath,metadata)
    codebook_dict = delayed(codebook_dict)



    all_fovs = list(grpd_fovs.groups.keys())
    chunks = [all_fovs[x:x+chunk_size] for x in range(0, len(all_fovs), chunk_size)]
        
    for chunk in chunks:
        all_processing = []
        for fov_num in chunk:

            fov_group = grpd_fovs.get_group(fov_num)
            channel_grpd = fov_group.groupby(&#39;channel&#39;)

            stitching_channel_fpath = list((experiment_fpath / &#39;results&#39;).glob(&#39;*_raw_counts_channel_&#39;+stitching_channel + &#39;_fov_&#39;+str(fov_num)+&#39;.parquet&#39;))[0]
            
            name = &#39;load_counts_&#39; +experiment_name + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
            all_counts_fov = delayed(pd.read_parquet,name=name)(stitching_channel_fpath)

            
            name = &#39;regitration_stitching_&#39; +experiment_name + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
            registration_stitching_channel_output = delayed(fovs_registration.beads_based_registration_stitching_channel,name=name)(all_counts_fov,
                                                    analysis_parameters,metadata)

            stitching_channel_df, all_rounds_shifts, all_rounds_matching_dots = registration_stitching_channel_output[0], \
                                                                                registration_stitching_channel_output[1], \
                                                                                registration_stitching_channel_output[2]


            name = &#39;stitching_to_microscope_&#39; +experiment_name + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
            stitched_coords_reference_df = delayed(stitching.stitch_using_coords_general,name=name)(stitching_channel_df,
                                                                tile_corners_coords_pxl,tiles_org.reference_corner_fov_position,
                                                                metadata,tag=&#39;microscope_stitched&#39;)
            all_stitched_coords = []
            all_stitched_coords.append(stitched_coords_reference_df)

            for processing_channel in fish_channels:
                
                # Register fish
                name = &#39;load_fish_channels_&#39; +experiment_name + &#39;_&#39; + processing_channel + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()

                channel_fpath = list((experiment_fpath / &#39;results&#39;).glob(&#39;*_raw_counts_channel_&#39;+processing_channel + &#39;_fov_&#39;+str(fov_num)+&#39;.parquet&#39;))[0]
            
                name = &#39;load_counts_&#39; +experiment_name + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
                fish_counts_fov = delayed(pd.read_parquet,name=name)(channel_fpath)
                

                registered_counts = delayed(fovs_registration.beads_based_registration_fish,name=name)(fish_counts_fov,
                                                    all_rounds_shifts, all_rounds_matching_dots, analysis_parameters)

                # Decoded fish
                name = &#39;decode_&#39; +experiment_name + &#39;_&#39; + processing_channel + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
                decoded = delayed(barcodes_analysis.extract_barcodes_NN_fast_multicolor,name=name)(registered_counts, 
                                                                        analysis_parameters,codebook_dict[processing_channel],
                                                                        metadata)                                                        
            
                if save_bits_int:

                    # all_filtered_images = {}
                    # group_bits = channel_grpd.get_group(processing_channel)
                    # for index_value, fov_subdataset in group_bits.iterrows():
                    #     round_num = fov_subdataset.round_num
                    #     name = &#39;load_filtered_image_&#39; +experiment_name + &#39;_&#39; \
                    #             + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
                    #     filt_out = delayed(io.load_general_zarr,name=name)(fov_subdataset,preprocessed_zarr_fpath,tag=&#39;preprocessed_data&#39;)
                        # all_filtered_images[round_num] = filt_out
                    
                    name = &#39;combine_shifted_images_&#39; +experiment_name + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize() 

                    combined_shift_images = delayed(fovs_registration.combine_register_filtered_image_single_channel,name=name)(all_filtered_images[processing_channel],
                                                metadata,all_rounds_shifts)
                    
                    name = &#39;extract_dots_intensities_&#39; +experiment_name + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()
                    extracted_intensities = delayed(barcodes_analysis.extract_dots_images,name=name)(decoded[1],
                                            combined_shift_images,experiment_fpath,metadata)

                    # Stitch to the microscope reference coords
                    name = &#39;stitch_to_mic_coords_&#39; +experiment_name + &#39;_&#39; + processing_channel + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize()  
                    stitched_coords = delayed(stitching.stitch_using_coords_general,name=name)(extracted_intensities,
                                                                tile_corners_coords_pxl,tiles_org.reference_corner_fov_position,
                                                                metadata,tag=&#39;microscope_stitched&#39;)    

                else:
                    stitched_coords = delayed(stitching.stitch_using_coords_general,name=name)(decoded[1],
                                                                tile_corners_coords_pxl,tiles_org.reference_corner_fov_position,
                                                                metadata,tag=&#39;microscope_stitched&#39;)    

                    
                all_stitched_coords.append(stitched_coords)

            
            name = &#39;concat_&#39; +experiment_name + \
                                    &#39;_fov_&#39; + str(fov_num) + &#39;-&#39; + tokenize()
            all_stitched_coords = delayed(pd.concat,name=name)(all_stitched_coords,axis=0,ignore_index=True) 
                
                
            name = &#39;save_df_&#39; +experiment_name + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov_num) + &#39;-&#39; + tokenize() 
            saved_file = delayed(all_stitched_coords.to_parquet,name=name)(Path(experiment_fpath) / &#39;results&#39;/ (experiment_name + \
                            &#39;_decoded_fov_&#39; + str(fov_num) + &#39;.parquet&#39;),index=False)
                        
            
            all_processing.append(saved_file)
                

        _ = dask.compute(*all_processing)</code></pre>
</details>
</dd>
<dt id="pysmFISH.fov_processing.processing_serial_fish_fov_graph"><code class="name flex">
<span>def <span class="ident">processing_serial_fish_fov_graph</span></span>(<span>experiment_fpath: str, analysis_parameters: dict, running_functions: dict, tiles_org, metadata: dict, grpd_fovs: pandas.core.frame.DataFrame, save_intermediate_steps: bool, preprocessed_image_tag: str, client, chunks_size: int)</span>
</code></dt>
<dd>
<div class="desc"><p>Processing graph for serial type of experiments.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the experiment to process</dd>
<dt><strong><code>analysis_parameters</code></strong> :&ensp;<code>dict</code></dt>
<dd>Parameters to use for the processing</dd>
<dt><strong><code>running_functions</code></strong> :&ensp;<code>dict</code></dt>
<dd>Function to run for preprocessing and counting</dd>
<dt><strong><code>tiles_org</code></strong> :&ensp;<code>tile_org</code></dt>
<dd>Organization of the tiles in the large image</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>dict</code></dt>
<dd>Metadata describing the experiment</dd>
<dt><strong><code>grpd_fovs</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Database of the experiment grouped by fov</dd>
<dt><strong><code>save_intermediate_steps</code></strong> :&ensp;<code>bool</code></dt>
<dd>Save preprocessed images and raw counts</dd>
<dt><strong><code>preprocessed_image_tag</code></strong> :&ensp;<code>str</code></dt>
<dd>Tag to label the preprocessed images zarr container</dd>
<dt><strong><code>client</code></strong> :&ensp;<code>distributed.Client</code></dt>
<dd>Dask Client that take care of the graph processing</dd>
<dt><strong><code>chunks_size</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of FOVs to process in one go</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def processing_serial_fish_fov_graph(experiment_fpath: str,
                                    analysis_parameters: dict,
                                    running_functions: dict, 
                                    tiles_org,
                                    metadata: dict,
                                    grpd_fovs: pd.DataFrame,
                                    save_intermediate_steps: bool, 
                                    preprocessed_image_tag: str, 
                                    client,
                                    chunks_size: int):
    &#34;&#34;&#34;Processing graph for serial type of experiments.

    Args:
    
        experiment_fpath (str): Path to the experiment to process
        analysis_parameters (dict): Parameters to use for the processing
        running_functions (dict): Function to run for preprocessing and counting
        tiles_org (tile_org): Organization of the tiles in the large image
        metadata (dict): Metadata describing the experiment
        grpd_fovs (pd.DataFrame): Database of the experiment grouped by fov
        save_intermediate_steps (bool): Save preprocessed images and raw counts
        preprocessed_image_tag (str): Tag to label the preprocessed images zarr container
        client (distributed.Client): Dask Client that take care of the graph processing
        chunks_size (int): Number of FOVs to process in one go
    
    &#34;&#34;&#34;

    experiment_fpath = Path(experiment_fpath)
    io.create_empty_zarr_file(experiment_fpath, preprocessed_image_tag)
    preprocessed_zarr_fpath = experiment_fpath / (experiment_fpath.stem + &#39;_&#39; + preprocessed_image_tag + &#39;.zarr&#39;)

    microscopy_file_parsers.create_dark_img(experiment_fpath,metadata)


    dark_img = preprocessing.load_dark_image(experiment_fpath)
    
    # did this conversion to avoid to pass self to dask
    analysis_parameters = analysis_parameters
    running_functions = running_functions
    tile_corners_coords_pxl = tiles_org.tile_corners_coords_pxl
    
    dark_img = delayed(dark_img)
    analysis_parameters = delayed(analysis_parameters)
    running_functions = delayed(running_functions)
    tile_corners_coords_pxl = delayed(tile_corners_coords_pxl)

    all_processing = []
    all_filtered_images = []
    all_fovs = list(grpd_fovs.groups.keys())
    chunks = [all_fovs[x:x+chunks_size] for x in range(0, len(all_fovs), chunks_size)]
    for chunk in chunks:
        all_processing = []
        all_filtered_images = []
        for fov_num in chunk:
            group = grpd_fovs.get_group(fov_num)
    # for fov_num, group in grpd_fovs:
            all_counts_fov = []
            all_nuclei_fov = []
            for index_value, fov_subdataset in group.iterrows():
                round_num = fov_subdataset.round_num
                channel = fov_subdataset.channel
                fov = fov_subdataset.fov_num
                stitching_type = fov_subdataset.stitching_type
                experiment_name = fov_subdataset.experiment_name
                processing_type = fov_subdataset.processing_type

                if processing_type == &#39;nuclei&#39;:
                    dask_delayed_name = &#39;filt_&#39; +experiment_name + &#39;_&#39; + channel + \
                                    &#39;_round_&#39; + str(round_num) + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()

                    out_nuclei = delayed(single_fov_round_processing_serial_nuclei,name=dask_delayed_name)(fov_subdataset,
                                            analysis_parameters,
                                            running_functions,
                                            dark_img,
                                            experiment_fpath,
                                            preprocessed_image_tag,
                                            preprocessed_zarr_fpath,
                                            save_steps_output=save_intermediate_steps,
                                            dask_key_name=dask_delayed_name)
                    all_nuclei_fov.append(out_nuclei)


                else:
                    dask_delayed_name = &#39;filt_count_&#39; +experiment_name + &#39;_&#39; + channel + \
                                    &#39;_round_&#39; + str(round_num) + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()
                    fov_out = delayed(single_fov_round_processing_eel,name=dask_delayed_name)(fov_subdataset,
                                                analysis_parameters,
                                                running_functions,
                                                dark_img,
                                                experiment_fpath,
                                                preprocessed_zarr_fpath,
                                                save_steps_output=save_intermediate_steps,
                                                dask_key_name=dask_delayed_name)
                    
                    counts, filt_out = fov_out[0], fov_out[1]
                    all_counts_fov.append(counts)
                    
                    # if channel != fov_subdataset.stitching_channel:
                    #     all_filtered_images.append(filt_out)
                    

            name = &#39;concat_fish_&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()
            all_counts_fov = delayed(pd.concat,name=name)(all_counts_fov,axis=0,ignore_index=True)
            
            if stitching_type == &#39;nuclei&#39;:

                name = &#39;create_nuclei_stack&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()
                filtered_nuclei_stack = delayed(combine_filtered_images,name=name)(all_nuclei_fov,experiment_fpath,metadata)

                name = &#39;register_&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()
                registered_counts = delayed(fovs_registration.nuclei_based_registration,name=name)(all_counts_fov,
                                                    filtered_nuclei_stack,
                                                    analysis_parameters)

            else:

                name = &#39;register_&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
                                    + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()
                registered_counts = delayed(fovs_registration.beads_based_registration,name=name)(all_counts_fov,
                                                    analysis_parameters)
                                                                                                
            name = &#39;stitch_to_mic_coords_&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize()  

            stitched_coords = delayed(stitching.stitch_using_coords_general,name=name)(registered_counts,
                                                            tile_corners_coords_pxl,tiles_org.reference_corner_fov_position,
                                                            metadata,tag=&#39;microscope_stitched&#39;)
            
            name = &#39;register_and_combine_filt_imgs&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize() 
            
            # combined_images = delayed(fovs_registration.combine_register_filtered_images,name=name)(all_filtered_images,stitched_coords,
            #                                                                                 fov_subdataset.stitching_channel)

            name = &#39;save_df_&#39; +experiment_name + &#39;_&#39; + channel + &#39;_&#39; \
                                + &#39;_fov_&#39; +str(fov) + &#39;-&#39; + tokenize() 
            saved_file = delayed(stitched_coords.to_parquet,name=name)(Path(experiment_fpath) / &#39;results&#39;/ (experiment_name + \
                            &#39;_decoded_fov_&#39; + str(fov) + &#39;.parquet&#39;),index=False)
        
            all_processing.append(saved_file) 
        
        _ = dask.compute(*all_processing)

    io.consolidate_zarr_metadata(preprocessed_zarr_fpath)</code></pre>
</details>
</dd>
<dt id="pysmFISH.fov_processing.single_fov_fresh_tissue_beads"><code class="name flex">
<span>def <span class="ident">single_fov_fresh_tissue_beads</span></span>(<span>processing_tag: str, fov_subdataset: pandas.core.series.Series, analysis_parameters: dict, running_functions: dict, dark_img: numpy.ndarray, experiment_fpath: str, preprocessed_zarr_fpath: str, save_steps_output: bool = True)</span>
</code></dt>
<dd>
<div class="desc"><p>[summary]</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>processing_tag</code></strong> :&ensp;<code>str</code></dt>
<dd>name describing the processing</dd>
<dt><strong><code>fov_subdataset</code></strong> :&ensp;<code>pd.Series</code></dt>
<dd>metadata corresponding to the specific fov</dd>
<dt><strong><code>analysis_parameters</code></strong> :&ensp;<code>dict</code></dt>
<dd>paramters used for processing</dd>
<dt><strong><code>running_functions</code></strong> :&ensp;<code>dict</code></dt>
<dd>functions to run preprocessing and detection of the beads</dd>
<dt><strong><code>dark_img</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>background of the camera</dd>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>path to the experiment to process.</dd>
<dt><strong><code>preprocessed_zarr_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>path to the zarr container with the preprocessed images</dd>
<dt><strong><code>save_steps_output</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Determine if to save preprocessing data. Defaults to True.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>[Tuple[pd.DataFrame, Tuple]]</code></dt>
<dd>counts, filt_out if processing_tag == 'beads'</dd>
<dt><code>[Tuple]</code></dt>
<dd>filt_out if processing_tag == 'nuclei'</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def single_fov_fresh_tissue_beads(processing_tag: str,
                                   fov_subdataset: pd.Series,
                                   analysis_parameters: dict,
                                   running_functions: dict,
                                   dark_img: np.ndarray,
                                   experiment_fpath: str,
                                   preprocessed_zarr_fpath: str,
                                   save_steps_output: bool=True):
    &#34;&#34;&#34;[summary]

    Args:
        processing_tag (str): name describing the processing
        fov_subdataset (pd.Series): metadata corresponding to the specific fov
        analysis_parameters (dict): paramters used for processing
        running_functions (dict): functions to run preprocessing and detection of the beads
        dark_img (np.ndarray): background of the camera
        experiment_fpath (str): path to the experiment to process.
        preprocessed_zarr_fpath (str): path to the zarr container with the preprocessed images
        save_steps_output (bool, optional): Determine if to save preprocessing data. Defaults to True.

    Returns:
        [Tuple[pd.DataFrame, Tuple]]: counts, filt_out if processing_tag == &#39;beads&#39;
        [Tuple]: filt_out if processing_tag == &#39;nuclei&#39;
    &#34;&#34;&#34;

    logger = selected_logger()
    experiment_fpath = Path(experiment_fpath)

    experiment_name = fov_subdataset.experiment_name
    zarr_grp_name = fov_subdataset.grp_name

    parsed_raw_data_fpath = experiment_fpath / &#39;fresh_tissue&#39;/ (experiment_name +&#39;_img_data.zarr&#39;)
    
    processing_parameters = analysis_parameters[&#39;fresh-tissue&#39;][processing_tag]

    if processing_tag == &#39;beads&#39;:
        filtering_fun = running_functions[&#39;fresh_sample_reference_preprocessing&#39;]
        counting_fun = running_functions[&#39;fresh_sample_reference_dots_calling&#39;]


        filt_out = getattr(pysmFISH.preprocessing,filtering_fun)(
                                                        zarr_grp_name,
                                                        parsed_raw_data_fpath,
                                                        processing_parameters,
                                                        dark_img)

        counts = getattr(pysmFISH.dots_calling,counting_fun)(
                                                            filt_out[0][0],
                                                            fov_subdataset,
                                                            processing_parameters)       

        if save_steps_output:

            # Save the file as zarr
            store = zarr.DirectoryStore(preprocessed_zarr_fpath)
            root = zarr.group(store=store,overwrite=False)
            tag_name = experiment_name + &#39;_fresh_tissue_&#39; + processing_tag + &#39;_fov_&#39; + str(fov_subdataset.fov_num)
            dgrp = root.create_group(tag_name,overwrite=True)
            for k, v in filt_out[1].items():
                dgrp.attrs[k] = v
            fov_name = &#39;preprocessed_data_fov_&#39; + str(fov_subdataset.fov_num)
            dgrp.attrs[&#39;fov_name&#39;] = fov_name
            img = utils.convert_to_uint16(filt_out[0][-1])
            dset = dgrp.create_dataset(fov_name, data=img, shape=img.shape, chunks=None,overwrite=True)                                       

    elif processing_tag == &#39;nuclei&#39;:
        filtering_fun = running_functions[&#39;fresh_sample_nuclei_preprocessing&#39;]
        filt_out = getattr(pysmFISH.preprocessing,filtering_fun)(
                                                        zarr_grp_name,
                                                        parsed_raw_data_fpath,
                                                        processing_parameters)

        if save_steps_output:

            # Save the file as zarr
            store = zarr.DirectoryStore(preprocessed_zarr_fpath)
            root = zarr.group(store=store,overwrite=False)
            tag_name = experiment_name + &#39;_fresh_tissue_&#39; + processing_tag + &#39;_fov_&#39; + str(fov_subdataset.fov_num)
            dgrp = root.create_group(tag_name,overwrite=True)
            for k, v in filt_out[1].items():
                dgrp.attrs[k] = v
            fov_name = &#39;preprocessed_data_fov_&#39; + str(fov_subdataset.fov_num)
            dgrp.attrs[&#39;fov_name&#39;] = fov_name
            img = img_as_uint(filt_out[0][-1])
            dset = dgrp.create_dataset(fov_name, data=img, shape=img.shape, chunks=None,overwrite=True)


    if processing_tag == &#39;beads&#39;:
        return counts, filt_out

    elif processing_tag == &#39;nuclei&#39;:
        return filt_out</code></pre>
</details>
</dd>
<dt id="pysmFISH.fov_processing.single_fov_round_processing_eel"><code class="name flex">
<span>def <span class="ident">single_fov_round_processing_eel</span></span>(<span>fov_subdataset: pandas.core.series.Series, analysis_parameters: dict, running_functions: dict, dark_img: numpy.ndarray, experiment_fpath: str, preprocessed_zarr_fpath: str, save_steps_output: bool = False, start_from_preprocessed_imgs: bool = False) ‑> Tuple[pandas.core.frame.DataFrame, Tuple]</span>
</code></dt>
<dd>
<div class="desc"><p>Function to run eel processing and counting on a single fov</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>fov_subdataset</code></strong> :&ensp;<code>pd.Series</code></dt>
<dd>Contains all the metadata relative to a fov.</dd>
<dt><strong><code>analysis_parameters</code></strong> :&ensp;<code>dict</code></dt>
<dd>Processing parameters.</dd>
<dt><strong><code>running_functions</code></strong> :&ensp;<code>dict</code></dt>
<dd>Preprocessing and counting function to run on
the selected fov.</dd>
<dt><strong><code>dark_img</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Image for the correction of dark signal of the
camera.</dd>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the experiment to process</dd>
<dt><strong><code>preprocessed_zarr_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the zarr container where the preprocessed
images will be saved</dd>
<dt><strong><code>save_steps_output</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Determine if to save the intermediate
processing steps. Defaults to False.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[pd.DataFrame,Tuple]</code></dt>
<dd>counts, filt_out</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def single_fov_round_processing_eel(fov_subdataset: pd.Series,
                                   analysis_parameters: dict,
                                   running_functions: dict,
                                   dark_img: np.ndarray,
                                   experiment_fpath: str,
                                   preprocessed_zarr_fpath: str,
                                   save_steps_output:bool=False,
                                   start_from_preprocessed_imgs:bool=False)-&gt; Tuple[pd.DataFrame,Tuple]:
    
    &#34;&#34;&#34;Function to run eel processing and counting on a single fov

    Args:
        fov_subdataset (pd.Series): Contains all the metadata relative to a fov.
        analysis_parameters (dict): Processing parameters.
        running_functions (dict): Preprocessing and counting function to run on
            the selected fov.
        dark_img (np.ndarray): Image for the correction of dark signal of the
            camera.
        experiment_fpath (str): Path to the experiment to process
        preprocessed_zarr_fpath (str): Path to the zarr container where the preprocessed
            images will be saved
        save_steps_output (bool, optional): Determine if to save the intermediate
            processing steps. Defaults to False.

    Returns:
        Tuple[pd.DataFrame,Tuple]: counts, filt_out
    &#34;&#34;&#34;

    logger = selected_logger()
    experiment_fpath = Path(experiment_fpath)
    
    experiment_name = fov_subdataset.experiment_name
    pipeline = fov_subdataset.pipeline
    processing_type = fov_subdataset.processing_type
    zarr_grp_name = fov_subdataset.grp_name
    
    raw_data_location = Path(fov_subdataset.raw_data_location)
    parsed_raw_data_fpath = raw_data_location.parent

    if processing_type == &#39;fish&#39;:
        processing_parameters = analysis_parameters[&#39;fish&#39;]
        filtering_fun = running_functions[&#39;fish_channels_preprocessing&#39;]
        counting_fun = running_functions[&#39;fish_channels_dots_calling&#39;]
    
    elif &#39;beads&#39; in processing_type:
        processing_parameters = analysis_parameters[processing_type]
        filtering_fun = running_functions[&#39;reference_channels_preprocessing&#39;]
        counting_fun = running_functions[&#39;reference_channels_dots_calling&#39;]

    elif processing_type != &#39;staining&#39;:
        processing_parameters = analysis_parameters[processing_type]
        filtering_fun = running_functions[&#39;reference_channels_preprocessing&#39;]
        counting_fun = running_functions[&#39;reference_channels_dots_calling&#39;]


    if start_from_preprocessed_imgs:
        # Load already filtered data
        filt_out = io.load_general_zarr(fov_subdataset,preprocessed_zarr_fpath,tag=&#39;preprocessed_data&#39;)
        filt_out = ((filt_out[0],),filt_out[1])

    else:

        filt_out = getattr(pysmFISH.preprocessing,filtering_fun)(
                                                        zarr_grp_name,
                                                        parsed_raw_data_fpath,
                                                        processing_parameters,
                                                        dark_img)
  
    counts = getattr(pysmFISH.dots_calling,counting_fun)(
                                                        filt_out[0][0],
                                                        fov_subdataset,
                                                        processing_parameters)                                              

    if save_steps_output:

        # Save the file as zarr
        store = zarr.DirectoryStore(preprocessed_zarr_fpath)
        root = zarr.group(store=store,overwrite=False)
        tag_name = experiment_name + &#39;_&#39; + fov_subdataset.channel + &#39;_round_&#39; + str(fov_subdataset.round_num) + &#39;_fov_&#39; + str(fov_subdataset.fov_num)
        dgrp = root.create_group(tag_name,overwrite=True)
        for k, v in filt_out[1].items():
            dgrp.attrs[k] = v
        fov_name = &#39;preprocessed_data_fov_&#39; + str(fov_subdataset.fov_num)
        dgrp.attrs[&#39;fov_name&#39;] = fov_name
        img = utils.convert_to_uint16(filt_out[0][-1]) # Must change to zero to save final processed image 
        dset = dgrp.create_dataset(fov_name, data=img, shape=img.shape, chunks=None,overwrite=True)

        # counts.to_parquet(raw_counts_path / (fname + &#39;.parquet&#39;),index=False)

    # return counts, (fov_subdataset.channel,fov_subdataset.round_num,img)
    return counts, filt_out</code></pre>
</details>
</dd>
<dt id="pysmFISH.fov_processing.single_fov_round_processing_serial_nuclei"><code class="name flex">
<span>def <span class="ident">single_fov_round_processing_serial_nuclei</span></span>(<span>fov_subdataset: pandas.core.series.Series, analysis_parameters: dict, running_functions: dict, dark_img: numpy.ndarray, experiment_fpath: str, preprocessed_zarr_fpath: str, save_steps_output=False) ‑> Tuple[numpy.ndarray, pandas.core.series.Series]</span>
</code></dt>
<dd>
<div class="desc"><p>Function to run serial processing of nuclei
Some of the input variable are not used but I wanted to keep the same type of input
for all the single fov processing functions.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>fov_subdataset</code></strong> :&ensp;<code>pd.Series</code></dt>
<dd>Contains all the metadata relative to a fov.</dd>
<dt><strong><code>analysis_parameters</code></strong> :&ensp;<code>dict</code></dt>
<dd>Processing parameters.</dd>
<dt><strong><code>running_functions</code></strong> :&ensp;<code>dict</code></dt>
<dd>Preprocessing and counting function to run on
the selected fov.</dd>
<dt><strong><code>dark_img</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Image for the correction of dark signal of the
camera.</dd>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the experiment to process</dd>
<dt><strong><code>preprocessed_zarr_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the zarr container where the preprocessed
images will be saved</dd>
<dt><strong><code>save_steps_output</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Determine if to save the intermediate
processing steps. Defaults to False.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[np.ndarray,pd.Series]</code></dt>
<dd>(img,fov_subdataset)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def single_fov_round_processing_serial_nuclei(fov_subdataset: pd.Series,
                                   analysis_parameters: dict,
                                   running_functions: dict,
                                   dark_img: np.ndarray,
                                   experiment_fpath: str,
                                   preprocessed_zarr_fpath: str,
                                   save_steps_output=False)-&gt; Tuple[np.ndarray,pd.Series]:

    &#34;&#34;&#34;Function to run serial processing of nuclei
    Some of the input variable are not used but I wanted to keep the same type of input
    for all the single fov processing functions.

    Args:
        fov_subdataset (pd.Series): Contains all the metadata relative to a fov.
        analysis_parameters (dict): Processing parameters.
        running_functions (dict): Preprocessing and counting function to run on
            the selected fov.
        dark_img (np.ndarray): Image for the correction of dark signal of the
            camera.
        experiment_fpath (str): Path to the experiment to process
        preprocessed_zarr_fpath (str): Path to the zarr container where the preprocessed
            images will be saved
        save_steps_output (bool, optional): Determine if to save the intermediate
            processing steps. Defaults to False.

    Returns:
        Tuple[np.ndarray,pd.Series]: (img,fov_subdataset)
    &#34;&#34;&#34;
    logger = selected_logger()
    experiment_fpath = Path(experiment_fpath)

    # Path of directory where to save the intermediate results
    filtered_img_path = experiment_fpath / &#39;results&#39;
    raw_counts_path = experiment_fpath / &#39;results&#39;
    
    experiment_name = fov_subdataset.experiment_name
    pipeline = fov_subdataset.pipeline
    processing_type = fov_subdataset.processing_type
    zarr_grp_name = fov_subdataset.grp_name
    
    raw_data_location = Path(fov_subdataset.raw_data_location)
    parsed_raw_data_fpath = raw_data_location.parent

    processing_parameters = analysis_parameters[processing_type]

    filt_out = getattr(pysmFISH.preprocessing,running_functions[&#39;reference_channels_preprocessing&#39;])(
                                                                        zarr_grp_name,
                                                                        parsed_raw_data_fpath,
                                                                        processing_parameters)

    if save_steps_output:

        # Save the file as zarr
        store = zarr.DirectoryStore(preprocessed_zarr_fpath)
        root = zarr.group(store=store,overwrite=False)
        tag_name = experiment_name + &#39;_&#39; + fov_subdataset.channel + &#39;_round_&#39; + str(fov_subdataset.round_num) + &#39;_fov_&#39; + str(fov_subdataset.fov_num)
        dgrp = root.create_group(tag_name,overwrite=True)
        for k, v in filt_out[1].items():
            dgrp.attrs[k] = v
        fov_name = &#39;preprocessed_data_fov_&#39; + str(fov_subdataset.fov_num)
        dgrp.attrs[&#39;fov_name&#39;] = fov_name
        img = utils.convert_to_uint16(filt_out[0][-1])
        dset = dgrp.create_dataset(fov_name, data=img, shape=img.shape, chunks=None,overwrite=True)

    return (img,fov_subdataset)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pysmFISH" href="index.html">pysmFISH</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pysmFISH.fov_processing.combine_filtered_images" href="#pysmFISH.fov_processing.combine_filtered_images">combine_filtered_images</a></code></li>
<li><code><a title="pysmFISH.fov_processing.combine_steps" href="#pysmFISH.fov_processing.combine_steps">combine_steps</a></code></li>
<li><code><a title="pysmFISH.fov_processing.make_fresh_beads_count_like_eel" href="#pysmFISH.fov_processing.make_fresh_beads_count_like_eel">make_fresh_beads_count_like_eel</a></code></li>
<li><code><a title="pysmFISH.fov_processing.process_fresh_sample_graph" href="#pysmFISH.fov_processing.process_fresh_sample_graph">process_fresh_sample_graph</a></code></li>
<li><code><a title="pysmFISH.fov_processing.processing_barcoded_eel_fov_graph" href="#pysmFISH.fov_processing.processing_barcoded_eel_fov_graph">processing_barcoded_eel_fov_graph</a></code></li>
<li><code><a title="pysmFISH.fov_processing.processing_barcoded_eel_fov_graph_from_decoding" href="#pysmFISH.fov_processing.processing_barcoded_eel_fov_graph_from_decoding">processing_barcoded_eel_fov_graph_from_decoding</a></code></li>
<li><code><a title="pysmFISH.fov_processing.processing_barcoded_eel_fov_starting_from_registration_graph" href="#pysmFISH.fov_processing.processing_barcoded_eel_fov_starting_from_registration_graph">processing_barcoded_eel_fov_starting_from_registration_graph</a></code></li>
<li><code><a title="pysmFISH.fov_processing.processing_serial_fish_fov_graph" href="#pysmFISH.fov_processing.processing_serial_fish_fov_graph">processing_serial_fish_fov_graph</a></code></li>
<li><code><a title="pysmFISH.fov_processing.single_fov_fresh_tissue_beads" href="#pysmFISH.fov_processing.single_fov_fresh_tissue_beads">single_fov_fresh_tissue_beads</a></code></li>
<li><code><a title="pysmFISH.fov_processing.single_fov_round_processing_eel" href="#pysmFISH.fov_processing.single_fov_round_processing_eel">single_fov_round_processing_eel</a></code></li>
<li><code><a title="pysmFISH.fov_processing.single_fov_round_processing_serial_nuclei" href="#pysmFISH.fov_processing.single_fov_round_processing_serial_nuclei">single_fov_round_processing_serial_nuclei</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>