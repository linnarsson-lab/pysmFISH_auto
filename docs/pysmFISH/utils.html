<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>pysmFISH.utils API documentation</title>
<meta name="description" content="Set of utility functions that do not belong to any
specific module." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pysmFISH.utils</code></h1>
</header>
<section id="section-intro">
<p>Set of utility functions that do not belong to any
specific module.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Set of utility functions that do not belong to any
specific module.
&#34;&#34;&#34;


from typing import *
import shutil
import sys
import git
import os
import click
import ctypes
import numpy as np
from skimage import img_as_float64
from pathlib import Path
from datetime import datetime


from pysmFISH.logger_utils import selected_logger
from pysmFISH.configuration_files import create_general_analysis_config_file


def create_dir(dir_path: str):
    &#34;&#34;&#34;Create a directory

    The directory is created only if it is not present in the folder.
    If the directory is already present it is not overwritten

    Args:
        dir_path (str): Create a directory and change it access to 777.
    &#34;&#34;&#34;
    try:
        os.stat(dir_path)
    except:
        os.mkdir(dir_path)
        os.chmod(dir_path,0o777)


def get_git_hash() -&gt; str:
    &#34;&#34;&#34;Function used to get the hash of the current commit used for the 
    processing of the data

    Returns:
        version (str): hash of the commit used for processing the data
    &#34;&#34;&#34;
    logger = selected_logger()
    repo = git.Repo(search_parent_directories=True)
    version = repo.head.object.hexsha
    logger.debug(f&#34;current code version: {version}&#34;)
    return version


def create_processing_env(processing_folder_path:str):
    logger = selected_logger()
    
    processing_folder_path = Path(processing_folder_path)
    config_path = processing_folder_path / &#39;config_db&#39;
    codebooks_path = processing_folder_path / &#39;codebooks&#39;
    probes_path = processing_folder_path / &#39;probes_sets&#39;
    
    # Create the directories that will contain the files required for the processing
    create_dir(config_path)
    create_dir(codebooks_path)
    create_dir(probes_path)

    # Create the analysis master files
    create_general_analysis_config_file(config_path)


def nice_deltastring(delta) -&gt; str:
    &#34;&#34;&#34;Function that provide a nice visualization of execution time

    From Sten Linnarsson lab
    https://github.com/linnarsson-lab/cytograph-shoji/blob/6389e8864c755f056ab7c9b51892650e5ed4f040/cytograph/pipeline/workflow.py#L12
    
    Args:
        delta (datetime.timedelta): execution time. Ex. End time - start time

    Returns:
        str: time difference in ms
    &#34;&#34;&#34;

    result = []
    s = delta.total_seconds()
    h = s // 60 // 60
    if h &gt;= 1:
        result.append(f&#34;{int(h)}h&#34;)
        s -= h * 60 * 60
    m = s // 60
    if m &gt;= 1:
        result.append(f&#34;{int(m)}m&#34;)
        s -= m * 60
    if s &gt;= 1:
        result.append(f&#34;{int(s)}s&#34;)
    if len(result) &gt; 0:
        return &#34; &#34;.join(result)
    else:
        return f&#34;{delta.microseconds // 1000} ms&#34;


def free_space(hd_path:str, min_free_space:int) -&gt; bool:
    &#34;&#34;&#34;Function used to determine if there is enough space in the
        HD where the experiment will be processed
    Args:
        hd_path (str): pathway of the target HD where the processing will be run
        min_free_space (int): minimum space required for processing in Gb (ex: 1000)

    Returns:
        bool: True if there is enough free space to process the experiment
    &#34;&#34;&#34;

    logger = selected_logger()
    total, used, free = shutil.disk_usage(hd_path)
    free_space_giga = free // (2**30)
    if free_space_giga &lt;= min_free_space:
        logger.info(f&#39;Free space in the HD: {free_space_giga} Gb data cannot be transferred,\
                        not enough space on the HD&#39;)
        return False
    else:
        logger.info(f&#39;Free space in the HD: {free_space_giga} Gb data can be transferred&#39;)
        return True


def end_processing_file(path_destination:str, completion_pattern:str=&#39;processing_completed.txt&#39;):
    &#34;&#34;&#34;Function used to create the file that signal that the
    analysis is completed

    Args:
        path_destination (str): Path where to save the file
        completion_pattern (str, optional): Tag indicating the completion. Defaults to &#39;processing_completed.txt&#39;.
    &#34;&#34;&#34;
    
    logger = selected_logger()
    
    fname = Path(path_destination) / completion_pattern
    try:
        open(fname, &#39;a&#39;).close()
    except OSError:
        logger.error(&#39;Failed to create the processing termination file&#39;)
    else:
        logger.info(&#39;processing termination files created&#39;)






def create_folder_structure(experiment_fpath:str,run_type:str):
    &#34;&#34;&#34;Create the folder structure where to sort the files generated by ROBOFISH

    FOLDER STRUCTURE
    - original_robofish_logs: contains all the original robofish logs.
    - extra_files: contains the extra files acquired during imaging.
    - extra_processing_data: contains extra files used in the analysis 
            like the dark images for flat field correction.
    - pipeline_config: contains all the configuration files.
    - raw_data: contains the renamed .nd2 files and the corresponding 
            pickle configuration files.
    - output_figures: contains the reports and visualizations
    - probes: contains the fasta file with the probes used in the experiment

    Args:
        experiment_fpath (str): path to the experiment to process
        run_type (str): type of processing run. It can be:
                - original: if processing a new experiment
                - re-run: if it is a reprocessing
    &#34;&#34;&#34;

    logger = selected_logger()
    experiment_fpath = Path(experiment_fpath)

    if run_type == &#39;new&#39;:

        folders_list = [&#39;raw_data&#39;,
                        &#39;original_robofish_logs&#39;,
                        &#39;extra_processing_data&#39;,
                        &#39;extra_files&#39;,
                        &#39;pipeline_config&#39;,
                        &#39;output_figures&#39;,
                        &#39;probes&#39;,
                        &#39;logs&#39;,
                        &#39;results&#39;,
                        &#39;microscope_tiles_coords&#39;,
                        &#39;notebooks&#39;]
    else:
        folders_list = [&#39;extra_processing_data&#39;,
                    &#39;pipeline_config&#39;,
                    &#39;output_figures&#39;,
                    &#39;probes&#39;,
                    &#39;logs&#39;,
                    &#39;results&#39;,
                    &#39;microscope_tiles_coords&#39;,
                    &#39;notebooks&#39;]
    
    for folder_name in folders_list:
        try:
            os.stat(experiment_fpath / folder_name )
            logger.info(f&#39;{folder_name} already exist&#39;)
        except FileNotFoundError:
            os.mkdir(experiment_fpath / folder_name)
            os.chmod(experiment_fpath / folder_name,0o777)


def collect_processing_files(experiment_fpath:str, experiment_info:Dict):
    &#34;&#34;&#34;Gather codebooks and probes from the storage folders

    Args:
        experiment_fpath (str): path to the experiment to process
        experiment_info (Dict): content of the configuration file (experiment_name_config.yaml)
            present in the experiment folder
    Todo:
        Modify the selection and the loading of multiple codebooks / probes
    &#34;&#34;&#34;
    logger = selected_logger()

    experiment_fpath = Path(experiment_fpath)

    try:
        machine = experiment_info[&#39;Machine&#39;]
    except NameError:
        machine = &#39;NOT_DEFINED&#39;


    for idx, probes in experiment_info[&#39;Probes_FASTA&#39;].items():
        if probes != &#39;None&#39;:
            probes_fpath = experiment_fpath.parent / &#39;probes_sets&#39; / probes
            try:
                shutil.copy(probes_fpath, (experiment_fpath / &#39;probes&#39;/ probes))
            except FileNotFoundError:
                logger.error(&#39;missing probes set file&#39;)
                sys.exit(&#39;missing probes set file&#39;)
        else:
            
            if &#39;barcoded&#39; in experiment_info[&#39;Experiment_type&#39;]:
                codebooks_folder = experiment_fpath.parent / &#39;codebooks&#39;
                
                for idx, codebook in experiment_info[&#39;Codebooks&#39;].items():
                    if codebook != &#39;None&#39;:
                        codebook_fpath = codebooks_folder / codebook
                        
                        # Create codebook folder in the experiment folder
                        try:
                            os.stat(experiment_fpath / &#39;codebook&#39; )
                            logger.info(f&#39;codebook folder already exist&#39;)
                        except FileNotFoundError:
                            os.mkdir(experiment_fpath / &#39;codebook&#39;)
                            os.chmod(experiment_fpath / &#39;codebook&#39;,0o777)
                        try:
                            shutil.copy(codebook_fpath, (experiment_fpath / &#39;codebook&#39;))
                        except FileNotFoundError:
                            logger.error(&#39;codebook is missing&#39;)
                            sys.exit(&#39;codebook is missing&#39;)


def sort_data_into_folders(experiment_fpath:str,experiment_info:Dict):
    &#34;&#34;&#34;Sort the files created by ROBOFISH in subfolders

    Args:
        experiment_fpath (str): path to the experiment to process
        experiment_info (Dict): content of the configuration file (experiment_name_config.yaml)
            present in the experiment folder
    &#34;&#34;&#34;
    
    logger = selected_logger()
    experiment_fpath = Path(experiment_fpath)

    # Move the robofish generated logs
    robofish_logs = list(experiment_fpath.glob(&#39;*.log&#39;))
    if len(robofish_logs):
        for log in robofish_logs:
            shutil.move(log.as_posix(), (experiment_fpath / &#39;original_robofish_logs&#39;).as_posix())
            logger.debug(f&#39;moved {log.stem} into original_robofish_logs&#39;)
    else:
        logger.debug(f&#39;there are no original robofish logs in the experiment folder&#39;)

    # Move the crosses images
    crosses_files = list(experiment_fpath.glob(&#39;*_cross.nd2&#39;))
    if len(crosses_files):
        for cross in crosses_files:
            shutil.move(cross.as_posix(), (experiment_fpath / &#39;extra_files&#39;).as_posix())
            logger.debug(f&#39;moved {cross.stem} into extra_files&#39;)
    else:
        logger.debug(f&#39;there are no crosses images in the experiment folders&#39;)
    
    # Move the coords files
    coords_files = list(experiment_fpath.glob(&#39;*.xml&#39;))
    if len(coords_files):
        for coord in coords_files:
            shutil.move(coord.as_posix(), (experiment_fpath / &#39;extra_files&#39;).as_posix())
            logger.debug(f&#39;moved {coord.stem} into extra_files&#39;)
    else:
        logger.debug(f&#39;there are no coords files in the experiment folders&#39;)
    
    # Move the fresh nuclei file for eel
    if &#39;eel&#39; in experiment_info[&#39;Experiment_type&#39;]:
        beads_files = list(experiment_fpath.glob(&#39;*ChannelEuropium_Cy3*&#39;))
        nuclei_files = list(experiment_fpath.glob(&#39;*ChannelCy3_Nuclei_*&#39;))
        
        if len(nuclei_files) or (len(beads_files)):
            try:
                os.stat(experiment_fpath / &#39;fresh_tissue&#39; )
                logger.debug(f&#39;fresh_tissue already exist&#39;)
            except FileNotFoundError:
                os.mkdir(experiment_fpath / &#39;fresh_tissue&#39;)
                os.chmod(experiment_fpath / &#39;fresh_tissue&#39;,0o777)

                os.mkdir(experiment_fpath / &#39;fresh_tissue&#39; / &#39;results&#39;)
                os.chmod(experiment_fpath / &#39;fresh_tissue&#39; / &#39;results&#39;,0o777)

                os.mkdir(experiment_fpath / &#39;fresh_tissue&#39; / &#39;output_figures&#39;)
                os.chmod(experiment_fpath / &#39;fresh_tissue&#39; / &#39;output_figures&#39;,0o777)
            
            for nuclei in nuclei_files:
                shutil.move(nuclei.as_posix(), (experiment_fpath / &#39;fresh_tissue&#39;).as_posix())
                logger.debug(f&#39;moved {nuclei.stem} into fresh tissue&#39;)

            for beads in beads_files:
                shutil.move(beads.as_posix(), (experiment_fpath / &#39;fresh_tissue&#39;).as_posix())
                logger.debug(f&#39;moved {beads.stem} into fresh tissue&#39;)
        
        large_views = list(experiment_fpath.glob(&#39;*ChannelDAPI*&#39;))
        if len(large_views):
            for large_view in large_views:
                shutil.move(large_view.as_posix(), (experiment_fpath / &#39;extra_files&#39;).as_posix())
                logger.debug(f&#39;moved {large_view.stem} into extra_files&#39;)
        else:
            logger.debug(f&#39;The experiment does not have large view images of fresh nuclei&#39;)

    # move remaining .nd2 files
    all_nd2 = list(experiment_fpath.glob(&#39;*.nd2&#39;))
    remaining = [el for el in all_nd2 if &#39;Count&#39; not in el.stem]
    if len(remaining):
        for fremaining in remaining:
            shutil.move(fremaining.as_posix(), (experiment_fpath / &#39;extra_files&#39;).as_posix())
            logger.debug(f&#39;moved {fremaining.stem} into extra_files&#39;)
    else:
        logger.debug(f&#39;There are no extra files to be moved&#39;)




def copytree(src:str, dst:str, symlinks:bool=False, ignore:str=None):
    &#34;&#34;&#34; Function used to copy an entire directory tree into another directory

    Code copied from:
    https://stackoverflow.com/questions/1868714/how-do-i-copy-an-entire-directory-of-files-into-an-existing-directory-using-pyth

    Args:
        src (str): path of the directory to copy
        dst (str): path of the destination
        symlinks (bool, optional): Set to true if you want to copy symlinks as well. Defaults to False.
        ignore (str, optional): Files to ignore. Defaults to None.
    &#34;&#34;&#34;
    if not os.path.exists(dst):
        os.makedirs(dst)
    for item in os.listdir(src):
        s = os.path.join(src, item)
        d = os.path.join(dst, item)
        if os.path.isdir(s):
            copytree(s, d, symlinks, ignore)
        else:
            if not os.path.exists(d) or os.stat(s).st_mtime - os.stat(d).st_mtime &gt; 1:
                shutil.copy2(s, d)



def convert_to_uint16_full_float64_range(image: np.ndarray)-&gt;np.ndarray:
    &#34;&#34;&#34;Utility function to convert images to full range float64
    Args:
        image (np.ndarray): Image as numpy array

    Returns:
        image (np.ndarray): Image as float64 numpy array
    &#34;&#34;&#34;
    # Clip the values above 1
    image = image / np.finfo(np.float64).max
    # image[image &gt; 1] = 1
    # in the current processing step the images are float
    # but not anymore between (0,1)
    # Scale to the max of the uint16
    image *= np.iinfo(np.uint16).max
    # Round and convert to integer
    image = np.uint16(np.rint(image))
    return image


def convert_from_uint16_to_float64(image: np.ndarray)-&gt;np.ndarray:
    &#34;&#34;&#34;Utility function to convert images to float64
    Now a similar function is included in scikit-image but was not
    there when I started the developing

    Args:
        image (np.ndarray): Image as numpy array

    Returns:
        image (np.ndarray): Image as float64 numpy array
    &#34;&#34;&#34;
    image = image / np.iinfo(np.uint16).max
    image = img_as_float64(image)
    return image


def convert_to_uint16(image:np.ndarray)-&gt; np.ndarray:
    &#34;&#34;&#34; Utility function to convert images to uint16
    
    Consider that the original images were uint16
    that is why i normalize for np.iinfo(np.uint16).max*1.0
    otherwise the values will be to small

    Args:
        image (np.ndarray): Image as numpy array, probably float64 after
        processing

    Returns:
        image: (np.ndarray): Image as numpy array converted to uint16
    &#34;&#34;&#34;
    
 
    image = image / (np.iinfo(np.uint16).max*1.0)
    image *= np.iinfo(np.uint16).max
    # Round and convert to integer
    image = image.astype(np.uint16)
    return image



class OptionEatAll(click.Option):
    &#34;&#34;&#34; Option class to ingest undefined number of options.

    Code copied from:
    https://stackoverflow.com/questions/48391777/nargs-equivalent-for-options-in-click

    &#34;&#34;&#34;

    def __init__(self, *args, **kwargs):
        self.save_other_options = kwargs.pop(&#39;save_other_options&#39;, True)
        nargs = kwargs.pop(&#39;nargs&#39;, -1)
        assert nargs == -1, &#39;nargs, if set, must be -1 not {}&#39;.format(nargs)
        super(OptionEatAll, self).__init__(*args, **kwargs)
        self._previous_parser_process = None
        self._eat_all_parser = None

    def add_to_parser(self, parser, ctx):

        def parser_process(value, state):
            # method to hook to the parser.process
            done = False
            value = [value]
            if self.save_other_options:
                # grab everything up to the next option
                while state.rargs and not done:
                    for prefix in self._eat_all_parser.prefixes:
                        if state.rargs[0].startswith(prefix):
                            done = True
                    if not done:
                        value.append(state.rargs.pop(0))
            else:
                # grab everything remaining
                value += state.rargs
                state.rargs[:] = []
            value = tuple(value)

            # call the actual process
            self._previous_parser_process(value, state)

        retval = super(OptionEatAll, self).add_to_parser(parser, ctx)
        for name in self.opts:
            our_parser = parser._long_opt.get(name) or parser._short_opt.get(name)
            if our_parser:
                self._eat_all_parser = our_parser
                self._previous_parser_process = our_parser.process
                our_parser.process = parser_process
                break
        return retval


def trim_memory() -&gt; int:
     libc = ctypes.CDLL(&#34;libc.so.6&#34;)
     return libc.malloc_trim(0)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pysmFISH.utils.collect_processing_files"><code class="name flex">
<span>def <span class="ident">collect_processing_files</span></span>(<span>experiment_fpath: str, experiment_info: Dict)</span>
</code></dt>
<dd>
<div class="desc"><p>Gather codebooks and probes from the storage folders</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>path to the experiment to process</dd>
<dt><strong><code>experiment_info</code></strong> :&ensp;<code>Dict</code></dt>
<dd>content of the configuration file (experiment_name_config.yaml)
present in the experiment folder</dd>
</dl>
<h2 id="todo">Todo</h2>
<p>Modify the selection and the loading of multiple codebooks / probes</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def collect_processing_files(experiment_fpath:str, experiment_info:Dict):
    &#34;&#34;&#34;Gather codebooks and probes from the storage folders

    Args:
        experiment_fpath (str): path to the experiment to process
        experiment_info (Dict): content of the configuration file (experiment_name_config.yaml)
            present in the experiment folder
    Todo:
        Modify the selection and the loading of multiple codebooks / probes
    &#34;&#34;&#34;
    logger = selected_logger()

    experiment_fpath = Path(experiment_fpath)

    try:
        machine = experiment_info[&#39;Machine&#39;]
    except NameError:
        machine = &#39;NOT_DEFINED&#39;


    for idx, probes in experiment_info[&#39;Probes_FASTA&#39;].items():
        if probes != &#39;None&#39;:
            probes_fpath = experiment_fpath.parent / &#39;probes_sets&#39; / probes
            try:
                shutil.copy(probes_fpath, (experiment_fpath / &#39;probes&#39;/ probes))
            except FileNotFoundError:
                logger.error(&#39;missing probes set file&#39;)
                sys.exit(&#39;missing probes set file&#39;)
        else:
            
            if &#39;barcoded&#39; in experiment_info[&#39;Experiment_type&#39;]:
                codebooks_folder = experiment_fpath.parent / &#39;codebooks&#39;
                
                for idx, codebook in experiment_info[&#39;Codebooks&#39;].items():
                    if codebook != &#39;None&#39;:
                        codebook_fpath = codebooks_folder / codebook
                        
                        # Create codebook folder in the experiment folder
                        try:
                            os.stat(experiment_fpath / &#39;codebook&#39; )
                            logger.info(f&#39;codebook folder already exist&#39;)
                        except FileNotFoundError:
                            os.mkdir(experiment_fpath / &#39;codebook&#39;)
                            os.chmod(experiment_fpath / &#39;codebook&#39;,0o777)
                        try:
                            shutil.copy(codebook_fpath, (experiment_fpath / &#39;codebook&#39;))
                        except FileNotFoundError:
                            logger.error(&#39;codebook is missing&#39;)
                            sys.exit(&#39;codebook is missing&#39;)</code></pre>
</details>
</dd>
<dt id="pysmFISH.utils.convert_from_uint16_to_float64"><code class="name flex">
<span>def <span class="ident">convert_from_uint16_to_float64</span></span>(<span>image: numpy.ndarray) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Utility function to convert images to float64
Now a similar function is included in scikit-image but was not
there when I started the developing</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Image as numpy array</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>image (np.ndarray): Image as float64 numpy array</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convert_from_uint16_to_float64(image: np.ndarray)-&gt;np.ndarray:
    &#34;&#34;&#34;Utility function to convert images to float64
    Now a similar function is included in scikit-image but was not
    there when I started the developing

    Args:
        image (np.ndarray): Image as numpy array

    Returns:
        image (np.ndarray): Image as float64 numpy array
    &#34;&#34;&#34;
    image = image / np.iinfo(np.uint16).max
    image = img_as_float64(image)
    return image</code></pre>
</details>
</dd>
<dt id="pysmFISH.utils.convert_to_uint16"><code class="name flex">
<span>def <span class="ident">convert_to_uint16</span></span>(<span>image: numpy.ndarray) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Utility function to convert images to uint16</p>
<p>Consider that the original images were uint16
that is why i normalize for np.iinfo(np.uint16).max*1.0
otherwise the values will be to small</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Image as numpy array, probably float64 after</dd>
</dl>
<p>processing</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>image</code></dt>
<dd>(np.ndarray): Image as numpy array converted to uint16</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convert_to_uint16(image:np.ndarray)-&gt; np.ndarray:
    &#34;&#34;&#34; Utility function to convert images to uint16
    
    Consider that the original images were uint16
    that is why i normalize for np.iinfo(np.uint16).max*1.0
    otherwise the values will be to small

    Args:
        image (np.ndarray): Image as numpy array, probably float64 after
        processing

    Returns:
        image: (np.ndarray): Image as numpy array converted to uint16
    &#34;&#34;&#34;
    
 
    image = image / (np.iinfo(np.uint16).max*1.0)
    image *= np.iinfo(np.uint16).max
    # Round and convert to integer
    image = image.astype(np.uint16)
    return image</code></pre>
</details>
</dd>
<dt id="pysmFISH.utils.convert_to_uint16_full_float64_range"><code class="name flex">
<span>def <span class="ident">convert_to_uint16_full_float64_range</span></span>(<span>image: numpy.ndarray) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Utility function to convert images to full range float64</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Image as numpy array</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>image (np.ndarray): Image as float64 numpy array</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convert_to_uint16_full_float64_range(image: np.ndarray)-&gt;np.ndarray:
    &#34;&#34;&#34;Utility function to convert images to full range float64
    Args:
        image (np.ndarray): Image as numpy array

    Returns:
        image (np.ndarray): Image as float64 numpy array
    &#34;&#34;&#34;
    # Clip the values above 1
    image = image / np.finfo(np.float64).max
    # image[image &gt; 1] = 1
    # in the current processing step the images are float
    # but not anymore between (0,1)
    # Scale to the max of the uint16
    image *= np.iinfo(np.uint16).max
    # Round and convert to integer
    image = np.uint16(np.rint(image))
    return image</code></pre>
</details>
</dd>
<dt id="pysmFISH.utils.copytree"><code class="name flex">
<span>def <span class="ident">copytree</span></span>(<span>src: str, dst: str, symlinks: bool = False, ignore: str = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to copy an entire directory tree into another directory</p>
<p>Code copied from:
<a href="https://stackoverflow.com/questions/1868714/how-do-i-copy-an-entire-directory-of-files-into-an-existing-directory-using-pyth">https://stackoverflow.com/questions/1868714/how-do-i-copy-an-entire-directory-of-files-into-an-existing-directory-using-pyth</a></p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>src</code></strong> :&ensp;<code>str</code></dt>
<dd>path of the directory to copy</dd>
<dt><strong><code>dst</code></strong> :&ensp;<code>str</code></dt>
<dd>path of the destination</dd>
<dt><strong><code>symlinks</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Set to true if you want to copy symlinks as well. Defaults to False.</dd>
<dt><strong><code>ignore</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Files to ignore. Defaults to None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def copytree(src:str, dst:str, symlinks:bool=False, ignore:str=None):
    &#34;&#34;&#34; Function used to copy an entire directory tree into another directory

    Code copied from:
    https://stackoverflow.com/questions/1868714/how-do-i-copy-an-entire-directory-of-files-into-an-existing-directory-using-pyth

    Args:
        src (str): path of the directory to copy
        dst (str): path of the destination
        symlinks (bool, optional): Set to true if you want to copy symlinks as well. Defaults to False.
        ignore (str, optional): Files to ignore. Defaults to None.
    &#34;&#34;&#34;
    if not os.path.exists(dst):
        os.makedirs(dst)
    for item in os.listdir(src):
        s = os.path.join(src, item)
        d = os.path.join(dst, item)
        if os.path.isdir(s):
            copytree(s, d, symlinks, ignore)
        else:
            if not os.path.exists(d) or os.stat(s).st_mtime - os.stat(d).st_mtime &gt; 1:
                shutil.copy2(s, d)</code></pre>
</details>
</dd>
<dt id="pysmFISH.utils.create_dir"><code class="name flex">
<span>def <span class="ident">create_dir</span></span>(<span>dir_path: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a directory</p>
<p>The directory is created only if it is not present in the folder.
If the directory is already present it is not overwritten</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dir_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Create a directory and change it access to 777.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_dir(dir_path: str):
    &#34;&#34;&#34;Create a directory

    The directory is created only if it is not present in the folder.
    If the directory is already present it is not overwritten

    Args:
        dir_path (str): Create a directory and change it access to 777.
    &#34;&#34;&#34;
    try:
        os.stat(dir_path)
    except:
        os.mkdir(dir_path)
        os.chmod(dir_path,0o777)</code></pre>
</details>
</dd>
<dt id="pysmFISH.utils.create_folder_structure"><code class="name flex">
<span>def <span class="ident">create_folder_structure</span></span>(<span>experiment_fpath: str, run_type: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Create the folder structure where to sort the files generated by ROBOFISH</p>
<p>FOLDER STRUCTURE
- original_robofish_logs: contains all the original robofish logs.
- extra_files: contains the extra files acquired during imaging.
- extra_processing_data: contains extra files used in the analysis
like the dark images for flat field correction.
- pipeline_config: contains all the configuration files.
- raw_data: contains the renamed .nd2 files and the corresponding
pickle configuration files.
- output_figures: contains the reports and visualizations
- probes: contains the fasta file with the probes used in the experiment</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>path to the experiment to process</dd>
<dt><strong><code>run_type</code></strong> :&ensp;<code>str</code></dt>
<dd>type of processing run. It can be:
- original: if processing a new experiment
- re-run: if it is a reprocessing</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_folder_structure(experiment_fpath:str,run_type:str):
    &#34;&#34;&#34;Create the folder structure where to sort the files generated by ROBOFISH

    FOLDER STRUCTURE
    - original_robofish_logs: contains all the original robofish logs.
    - extra_files: contains the extra files acquired during imaging.
    - extra_processing_data: contains extra files used in the analysis 
            like the dark images for flat field correction.
    - pipeline_config: contains all the configuration files.
    - raw_data: contains the renamed .nd2 files and the corresponding 
            pickle configuration files.
    - output_figures: contains the reports and visualizations
    - probes: contains the fasta file with the probes used in the experiment

    Args:
        experiment_fpath (str): path to the experiment to process
        run_type (str): type of processing run. It can be:
                - original: if processing a new experiment
                - re-run: if it is a reprocessing
    &#34;&#34;&#34;

    logger = selected_logger()
    experiment_fpath = Path(experiment_fpath)

    if run_type == &#39;new&#39;:

        folders_list = [&#39;raw_data&#39;,
                        &#39;original_robofish_logs&#39;,
                        &#39;extra_processing_data&#39;,
                        &#39;extra_files&#39;,
                        &#39;pipeline_config&#39;,
                        &#39;output_figures&#39;,
                        &#39;probes&#39;,
                        &#39;logs&#39;,
                        &#39;results&#39;,
                        &#39;microscope_tiles_coords&#39;,
                        &#39;notebooks&#39;]
    else:
        folders_list = [&#39;extra_processing_data&#39;,
                    &#39;pipeline_config&#39;,
                    &#39;output_figures&#39;,
                    &#39;probes&#39;,
                    &#39;logs&#39;,
                    &#39;results&#39;,
                    &#39;microscope_tiles_coords&#39;,
                    &#39;notebooks&#39;]
    
    for folder_name in folders_list:
        try:
            os.stat(experiment_fpath / folder_name )
            logger.info(f&#39;{folder_name} already exist&#39;)
        except FileNotFoundError:
            os.mkdir(experiment_fpath / folder_name)
            os.chmod(experiment_fpath / folder_name,0o777)</code></pre>
</details>
</dd>
<dt id="pysmFISH.utils.create_processing_env"><code class="name flex">
<span>def <span class="ident">create_processing_env</span></span>(<span>processing_folder_path: str)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_processing_env(processing_folder_path:str):
    logger = selected_logger()
    
    processing_folder_path = Path(processing_folder_path)
    config_path = processing_folder_path / &#39;config_db&#39;
    codebooks_path = processing_folder_path / &#39;codebooks&#39;
    probes_path = processing_folder_path / &#39;probes_sets&#39;
    
    # Create the directories that will contain the files required for the processing
    create_dir(config_path)
    create_dir(codebooks_path)
    create_dir(probes_path)

    # Create the analysis master files
    create_general_analysis_config_file(config_path)</code></pre>
</details>
</dd>
<dt id="pysmFISH.utils.end_processing_file"><code class="name flex">
<span>def <span class="ident">end_processing_file</span></span>(<span>path_destination: str, completion_pattern: str = 'processing_completed.txt')</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to create the file that signal that the
analysis is completed</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>path_destination</code></strong> :&ensp;<code>str</code></dt>
<dd>Path where to save the file</dd>
<dt><strong><code>completion_pattern</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Tag indicating the completion. Defaults to 'processing_completed.txt'.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def end_processing_file(path_destination:str, completion_pattern:str=&#39;processing_completed.txt&#39;):
    &#34;&#34;&#34;Function used to create the file that signal that the
    analysis is completed

    Args:
        path_destination (str): Path where to save the file
        completion_pattern (str, optional): Tag indicating the completion. Defaults to &#39;processing_completed.txt&#39;.
    &#34;&#34;&#34;
    
    logger = selected_logger()
    
    fname = Path(path_destination) / completion_pattern
    try:
        open(fname, &#39;a&#39;).close()
    except OSError:
        logger.error(&#39;Failed to create the processing termination file&#39;)
    else:
        logger.info(&#39;processing termination files created&#39;)</code></pre>
</details>
</dd>
<dt id="pysmFISH.utils.free_space"><code class="name flex">
<span>def <span class="ident">free_space</span></span>(<span>hd_path: str, min_free_space: int) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to determine if there is enough space in the
HD where the experiment will be processed</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>hd_path</code></strong> :&ensp;<code>str</code></dt>
<dd>pathway of the target HD where the processing will be run</dd>
<dt><strong><code>min_free_space</code></strong> :&ensp;<code>int</code></dt>
<dd>minimum space required for processing in Gb (ex: 1000)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if there is enough free space to process the experiment</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def free_space(hd_path:str, min_free_space:int) -&gt; bool:
    &#34;&#34;&#34;Function used to determine if there is enough space in the
        HD where the experiment will be processed
    Args:
        hd_path (str): pathway of the target HD where the processing will be run
        min_free_space (int): minimum space required for processing in Gb (ex: 1000)

    Returns:
        bool: True if there is enough free space to process the experiment
    &#34;&#34;&#34;

    logger = selected_logger()
    total, used, free = shutil.disk_usage(hd_path)
    free_space_giga = free // (2**30)
    if free_space_giga &lt;= min_free_space:
        logger.info(f&#39;Free space in the HD: {free_space_giga} Gb data cannot be transferred,\
                        not enough space on the HD&#39;)
        return False
    else:
        logger.info(f&#39;Free space in the HD: {free_space_giga} Gb data can be transferred&#39;)
        return True</code></pre>
</details>
</dd>
<dt id="pysmFISH.utils.get_git_hash"><code class="name flex">
<span>def <span class="ident">get_git_hash</span></span>(<span>) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to get the hash of the current commit used for the
processing of the data</p>
<h2 id="returns">Returns</h2>
<p>version (str): hash of the commit used for processing the data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_git_hash() -&gt; str:
    &#34;&#34;&#34;Function used to get the hash of the current commit used for the 
    processing of the data

    Returns:
        version (str): hash of the commit used for processing the data
    &#34;&#34;&#34;
    logger = selected_logger()
    repo = git.Repo(search_parent_directories=True)
    version = repo.head.object.hexsha
    logger.debug(f&#34;current code version: {version}&#34;)
    return version</code></pre>
</details>
</dd>
<dt id="pysmFISH.utils.nice_deltastring"><code class="name flex">
<span>def <span class="ident">nice_deltastring</span></span>(<span>delta) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Function that provide a nice visualization of execution time</p>
<p>From Sten Linnarsson lab
<a href="https://github.com/linnarsson-lab/cytograph-shoji/blob/6389e8864c755f056ab7c9b51892650e5ed4f040/cytograph/pipeline/workflow.py#L12">https://github.com/linnarsson-lab/cytograph-shoji/blob/6389e8864c755f056ab7c9b51892650e5ed4f040/cytograph/pipeline/workflow.py#L12</a></p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>delta</code></strong> :&ensp;<code>datetime.timedelta</code></dt>
<dd>execution time. Ex. End time - start time</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>time difference in ms</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nice_deltastring(delta) -&gt; str:
    &#34;&#34;&#34;Function that provide a nice visualization of execution time

    From Sten Linnarsson lab
    https://github.com/linnarsson-lab/cytograph-shoji/blob/6389e8864c755f056ab7c9b51892650e5ed4f040/cytograph/pipeline/workflow.py#L12
    
    Args:
        delta (datetime.timedelta): execution time. Ex. End time - start time

    Returns:
        str: time difference in ms
    &#34;&#34;&#34;

    result = []
    s = delta.total_seconds()
    h = s // 60 // 60
    if h &gt;= 1:
        result.append(f&#34;{int(h)}h&#34;)
        s -= h * 60 * 60
    m = s // 60
    if m &gt;= 1:
        result.append(f&#34;{int(m)}m&#34;)
        s -= m * 60
    if s &gt;= 1:
        result.append(f&#34;{int(s)}s&#34;)
    if len(result) &gt; 0:
        return &#34; &#34;.join(result)
    else:
        return f&#34;{delta.microseconds // 1000} ms&#34;</code></pre>
</details>
</dd>
<dt id="pysmFISH.utils.sort_data_into_folders"><code class="name flex">
<span>def <span class="ident">sort_data_into_folders</span></span>(<span>experiment_fpath: str, experiment_info: Dict)</span>
</code></dt>
<dd>
<div class="desc"><p>Sort the files created by ROBOFISH in subfolders</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>path to the experiment to process</dd>
<dt><strong><code>experiment_info</code></strong> :&ensp;<code>Dict</code></dt>
<dd>content of the configuration file (experiment_name_config.yaml)
present in the experiment folder</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sort_data_into_folders(experiment_fpath:str,experiment_info:Dict):
    &#34;&#34;&#34;Sort the files created by ROBOFISH in subfolders

    Args:
        experiment_fpath (str): path to the experiment to process
        experiment_info (Dict): content of the configuration file (experiment_name_config.yaml)
            present in the experiment folder
    &#34;&#34;&#34;
    
    logger = selected_logger()
    experiment_fpath = Path(experiment_fpath)

    # Move the robofish generated logs
    robofish_logs = list(experiment_fpath.glob(&#39;*.log&#39;))
    if len(robofish_logs):
        for log in robofish_logs:
            shutil.move(log.as_posix(), (experiment_fpath / &#39;original_robofish_logs&#39;).as_posix())
            logger.debug(f&#39;moved {log.stem} into original_robofish_logs&#39;)
    else:
        logger.debug(f&#39;there are no original robofish logs in the experiment folder&#39;)

    # Move the crosses images
    crosses_files = list(experiment_fpath.glob(&#39;*_cross.nd2&#39;))
    if len(crosses_files):
        for cross in crosses_files:
            shutil.move(cross.as_posix(), (experiment_fpath / &#39;extra_files&#39;).as_posix())
            logger.debug(f&#39;moved {cross.stem} into extra_files&#39;)
    else:
        logger.debug(f&#39;there are no crosses images in the experiment folders&#39;)
    
    # Move the coords files
    coords_files = list(experiment_fpath.glob(&#39;*.xml&#39;))
    if len(coords_files):
        for coord in coords_files:
            shutil.move(coord.as_posix(), (experiment_fpath / &#39;extra_files&#39;).as_posix())
            logger.debug(f&#39;moved {coord.stem} into extra_files&#39;)
    else:
        logger.debug(f&#39;there are no coords files in the experiment folders&#39;)
    
    # Move the fresh nuclei file for eel
    if &#39;eel&#39; in experiment_info[&#39;Experiment_type&#39;]:
        beads_files = list(experiment_fpath.glob(&#39;*ChannelEuropium_Cy3*&#39;))
        nuclei_files = list(experiment_fpath.glob(&#39;*ChannelCy3_Nuclei_*&#39;))
        
        if len(nuclei_files) or (len(beads_files)):
            try:
                os.stat(experiment_fpath / &#39;fresh_tissue&#39; )
                logger.debug(f&#39;fresh_tissue already exist&#39;)
            except FileNotFoundError:
                os.mkdir(experiment_fpath / &#39;fresh_tissue&#39;)
                os.chmod(experiment_fpath / &#39;fresh_tissue&#39;,0o777)

                os.mkdir(experiment_fpath / &#39;fresh_tissue&#39; / &#39;results&#39;)
                os.chmod(experiment_fpath / &#39;fresh_tissue&#39; / &#39;results&#39;,0o777)

                os.mkdir(experiment_fpath / &#39;fresh_tissue&#39; / &#39;output_figures&#39;)
                os.chmod(experiment_fpath / &#39;fresh_tissue&#39; / &#39;output_figures&#39;,0o777)
            
            for nuclei in nuclei_files:
                shutil.move(nuclei.as_posix(), (experiment_fpath / &#39;fresh_tissue&#39;).as_posix())
                logger.debug(f&#39;moved {nuclei.stem} into fresh tissue&#39;)

            for beads in beads_files:
                shutil.move(beads.as_posix(), (experiment_fpath / &#39;fresh_tissue&#39;).as_posix())
                logger.debug(f&#39;moved {beads.stem} into fresh tissue&#39;)
        
        large_views = list(experiment_fpath.glob(&#39;*ChannelDAPI*&#39;))
        if len(large_views):
            for large_view in large_views:
                shutil.move(large_view.as_posix(), (experiment_fpath / &#39;extra_files&#39;).as_posix())
                logger.debug(f&#39;moved {large_view.stem} into extra_files&#39;)
        else:
            logger.debug(f&#39;The experiment does not have large view images of fresh nuclei&#39;)

    # move remaining .nd2 files
    all_nd2 = list(experiment_fpath.glob(&#39;*.nd2&#39;))
    remaining = [el for el in all_nd2 if &#39;Count&#39; not in el.stem]
    if len(remaining):
        for fremaining in remaining:
            shutil.move(fremaining.as_posix(), (experiment_fpath / &#39;extra_files&#39;).as_posix())
            logger.debug(f&#39;moved {fremaining.stem} into extra_files&#39;)
    else:
        logger.debug(f&#39;There are no extra files to be moved&#39;)</code></pre>
</details>
</dd>
<dt id="pysmFISH.utils.trim_memory"><code class="name flex">
<span>def <span class="ident">trim_memory</span></span>(<span>) ‑> int</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def trim_memory() -&gt; int:
     libc = ctypes.CDLL(&#34;libc.so.6&#34;)
     return libc.malloc_trim(0)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pysmFISH.utils.OptionEatAll"><code class="flex name class">
<span>class <span class="ident">OptionEatAll</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Option class to ingest undefined number of options.</p>
<p>Code copied from:
<a href="https://stackoverflow.com/questions/48391777/nargs-equivalent-for-options-in-click">https://stackoverflow.com/questions/48391777/nargs-equivalent-for-options-in-click</a></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class OptionEatAll(click.Option):
    &#34;&#34;&#34; Option class to ingest undefined number of options.

    Code copied from:
    https://stackoverflow.com/questions/48391777/nargs-equivalent-for-options-in-click

    &#34;&#34;&#34;

    def __init__(self, *args, **kwargs):
        self.save_other_options = kwargs.pop(&#39;save_other_options&#39;, True)
        nargs = kwargs.pop(&#39;nargs&#39;, -1)
        assert nargs == -1, &#39;nargs, if set, must be -1 not {}&#39;.format(nargs)
        super(OptionEatAll, self).__init__(*args, **kwargs)
        self._previous_parser_process = None
        self._eat_all_parser = None

    def add_to_parser(self, parser, ctx):

        def parser_process(value, state):
            # method to hook to the parser.process
            done = False
            value = [value]
            if self.save_other_options:
                # grab everything up to the next option
                while state.rargs and not done:
                    for prefix in self._eat_all_parser.prefixes:
                        if state.rargs[0].startswith(prefix):
                            done = True
                    if not done:
                        value.append(state.rargs.pop(0))
            else:
                # grab everything remaining
                value += state.rargs
                state.rargs[:] = []
            value = tuple(value)

            # call the actual process
            self._previous_parser_process(value, state)

        retval = super(OptionEatAll, self).add_to_parser(parser, ctx)
        for name in self.opts:
            our_parser = parser._long_opt.get(name) or parser._short_opt.get(name)
            if our_parser:
                self._eat_all_parser = our_parser
                self._previous_parser_process = our_parser.process
                our_parser.process = parser_process
                break
        return retval</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>click.core.Option</li>
<li>click.core.Parameter</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="pysmFISH.utils.OptionEatAll.add_to_parser"><code class="name flex">
<span>def <span class="ident">add_to_parser</span></span>(<span>self, parser, ctx)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_to_parser(self, parser, ctx):

    def parser_process(value, state):
        # method to hook to the parser.process
        done = False
        value = [value]
        if self.save_other_options:
            # grab everything up to the next option
            while state.rargs and not done:
                for prefix in self._eat_all_parser.prefixes:
                    if state.rargs[0].startswith(prefix):
                        done = True
                if not done:
                    value.append(state.rargs.pop(0))
        else:
            # grab everything remaining
            value += state.rargs
            state.rargs[:] = []
        value = tuple(value)

        # call the actual process
        self._previous_parser_process(value, state)

    retval = super(OptionEatAll, self).add_to_parser(parser, ctx)
    for name in self.opts:
        our_parser = parser._long_opt.get(name) or parser._short_opt.get(name)
        if our_parser:
            self._eat_all_parser = our_parser
            self._previous_parser_process = our_parser.process
            our_parser.process = parser_process
            break
    return retval</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pysmFISH" href="index.html">pysmFISH</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pysmFISH.utils.collect_processing_files" href="#pysmFISH.utils.collect_processing_files">collect_processing_files</a></code></li>
<li><code><a title="pysmFISH.utils.convert_from_uint16_to_float64" href="#pysmFISH.utils.convert_from_uint16_to_float64">convert_from_uint16_to_float64</a></code></li>
<li><code><a title="pysmFISH.utils.convert_to_uint16" href="#pysmFISH.utils.convert_to_uint16">convert_to_uint16</a></code></li>
<li><code><a title="pysmFISH.utils.convert_to_uint16_full_float64_range" href="#pysmFISH.utils.convert_to_uint16_full_float64_range">convert_to_uint16_full_float64_range</a></code></li>
<li><code><a title="pysmFISH.utils.copytree" href="#pysmFISH.utils.copytree">copytree</a></code></li>
<li><code><a title="pysmFISH.utils.create_dir" href="#pysmFISH.utils.create_dir">create_dir</a></code></li>
<li><code><a title="pysmFISH.utils.create_folder_structure" href="#pysmFISH.utils.create_folder_structure">create_folder_structure</a></code></li>
<li><code><a title="pysmFISH.utils.create_processing_env" href="#pysmFISH.utils.create_processing_env">create_processing_env</a></code></li>
<li><code><a title="pysmFISH.utils.end_processing_file" href="#pysmFISH.utils.end_processing_file">end_processing_file</a></code></li>
<li><code><a title="pysmFISH.utils.free_space" href="#pysmFISH.utils.free_space">free_space</a></code></li>
<li><code><a title="pysmFISH.utils.get_git_hash" href="#pysmFISH.utils.get_git_hash">get_git_hash</a></code></li>
<li><code><a title="pysmFISH.utils.nice_deltastring" href="#pysmFISH.utils.nice_deltastring">nice_deltastring</a></code></li>
<li><code><a title="pysmFISH.utils.sort_data_into_folders" href="#pysmFISH.utils.sort_data_into_folders">sort_data_into_folders</a></code></li>
<li><code><a title="pysmFISH.utils.trim_memory" href="#pysmFISH.utils.trim_memory">trim_memory</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pysmFISH.utils.OptionEatAll" href="#pysmFISH.utils.OptionEatAll">OptionEatAll</a></code></h4>
<ul class="">
<li><code><a title="pysmFISH.utils.OptionEatAll.add_to_parser" href="#pysmFISH.utils.OptionEatAll.add_to_parser">add_to_parser</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>