<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>pysmFISH.fovs_registration API documentation</title>
<meta name="description" content="group of class or functions use to register the fov between
different rounds." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pysmFISH.fovs_registration</code></h1>
</header>
<section id="section-intro">
<p>group of class or functions use to register the fov between
different rounds.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
group of class or functions use to register the fov between
different rounds.
&#34;&#34;&#34;
from typing import *
import logging
import zarr
import pickle
import pandas as pd
import numpy as np
import sys
from pathlib import Path
from sklearn.neighbors import NearestNeighbors
from skimage import transform
from skimage.measure import ransac
from scipy.spatial import distance
from scipy.ndimage import fourier_shift

from skimage.feature import register_translation
# from skimage.registration import phase_cross_correlation UPDATE SKIMAGEN
from skimage import filters
from skimage.registration import phase_cross_correlation


from sklearn.neighbors import NearestNeighbors

import itertools
import math
import operator
from scipy.optimize import minimize

import gc


from pysmFISH.logger_utils import selected_logger
from pysmFISH.errors import Registration_errors

from pysmFISH.data_models import Output_models
from pysmFISH import utils

def create_fake_image(img_shape: np.ndarray,coords: np.ndarray)-&gt;np.ndarray:
    &#34;&#34;&#34;Function used to create an image from dots counts. The image
    will be used for FFT based registration. The dots are mapped in
    the image and the signal is enhanced using a gaussian. This
    increase the features that can be used in the FFT based
    registration.

    Args:
        img_shape (np.ndarray): Shape of the image to create. It matches
            the shape of the images to process.
        coords (np.ndarray): Coordinates of the peaks detected.

    Returns:
        np.ndarray: synthetic image used for registration
    &#34;&#34;&#34;
    gaussian_sigma = 1 # original is 5 
    img = np.zeros(img_shape,dtype=np.float64)
    img[coords[:,0].astype(int),coords[:,1].astype(int)] = 1000
    img = filters.gaussian(img,sigma=gaussian_sigma)
    return img


def register_images(img: np.ndarray, shift: np.ndarray)-&gt;np.ndarray:
    &#34;&#34;&#34;Function to create a new image shifted according
    a predefined shift.

    Args:
        img (np.ndarray): Image to shift
        shift (np.ndarray): Shift

    Returns:
        np.ndarray: Shifted image
    &#34;&#34;&#34;
    offset_image = fourier_shift(np.fft.fftn(img), shift)
    offset_image = np.fft.ifftn(offset_image).real
    return offset_image


def combine_register_filtered_images(output_dict: dict, metadata: dict, 
                                    all_rounds_shifts:dict)-&gt;np.ndarray:
    &#34;&#34;&#34;Function used to register the image throughout all rounds.

    Args:
        output_dict (dict): dict containg output of the filtering ((img,),metadata) organised
                            by channe and round.
        metadata (dict): Metadata that characterize the acquired images
        registered_counts (pd.DataFrame): Counts after registration.

    Returns:
        np.ndarray: Image stack with all the rounds registered.
    &#34;&#34;&#34;
    registered_img_stack = {}
    if isinstance(all_rounds_shifts, dict) and (output_dict):
        for channel, all_rounds_data in output_dict.items():
            img_stack = np.zeros([int(metadata[&#39;total_rounds&#39;]),int(metadata[&#39;img_width&#39;]),int(metadata[&#39;img_height&#39;])])
            for round_num, filt_out in all_rounds_data.items():
                img = filt_out[0][0]
                shift = all_rounds_shifts[int(round_num)]
                if isinstance(shift,np.ndarray):
                    shifted_img = register_images(img,shift)
                    img_stack[round_num-1,:,:] = shifted_img
            registered_img_stack[channel] = img_stack
        return registered_img_stack
    else:
        registered_img_stack = np.nan


def combine_register_filtered_image_single_channel(output_dict: dict, metadata: dict, 
                                    all_rounds_shifts:dict)-&gt;np.ndarray:
    &#34;&#34;&#34;Function used to register the image throughout all rounds.

    Args:
        output_dict (dict): dict containg output of the filtering ((img,),metadata) organised
                            by channe and round.
        metadata (dict): Metadata that characterize the acquired images
        registered_counts (pd.DataFrame): Counts after registration.
        channel (str): processing channel

    Returns:
        np.ndarray: Image stack with all the rounds registered.
    &#34;&#34;&#34;
    if isinstance(all_rounds_shifts, dict) and isinstance(output_dict,dict):
        img_stack = np.zeros([int(metadata[&#39;total_rounds&#39;]),int(metadata[&#39;img_width&#39;]),int(metadata[&#39;img_height&#39;])])
        for round_num, filt_out in output_dict.items():
            img = filt_out[0][0]
            shift = all_rounds_shifts[int(round_num)]
            if isinstance(shift,np.ndarray):
                shifted_img = register_images(img,shift)
                img_stack[round_num-1,:,:] = shifted_img
        return img_stack
    else:
        img_stack = np.nan




def identify_matching_register_dots_NN(ref_dots_coords_fov,tran_registered_coords,registration_tollerance_pxl):
    # put in the wrapping function
    #if (ref_dots_coords_fov.shape[0] &gt;0) and (tran_registered_coords.shape[0] &gt;0):
            
    # initialize network
    nn = NearestNeighbors(1, metric=&#34;euclidean&#34;)
    nn.fit(ref_dots_coords_fov)

    # Get the nn
    dists, indices = nn.kneighbors(tran_registered_coords, return_distance=True)

    # select only the nn that are below pxl distance
    idx_selected_coords_compare = np.where(dists &lt;= registration_tollerance_pxl)[0]

    number_matching_dots = idx_selected_coords_compare.shape[0]
    
    return number_matching_dots




def beads_based_registration(all_counts_fov: pd.DataFrame,
                            analysis_parameters: Dict)-&gt;pd.DataFrame:
    &#34;&#34;&#34;[summary]

    Args:
        all_counts_fov (pd.DataFrame): [description]
        analysis_parameters (Dict): [description]

    Returns:
        pd.DataFrame: [description]
    &#34;&#34;&#34;
    
    # Used index to avoid to remake the output dataframe
    
    stitching_channel = all_counts_fov[&#39;stitching_channel&#39;].iloc[0]
    
    stitching_channel_df = all_counts_fov.loc[(all_counts_fov.channel == stitching_channel) &amp;
                                              (all_counts_fov.mapped_beads_type == &#39;large&#39;)  , :]
    
    if stitching_channel_df.shape[0] &lt; 2:
        stitching_channel_df = all_counts_fov.loc[(all_counts_fov.channel == stitching_channel) , :]

    
    fish_df = all_counts_fov.loc[all_counts_fov.channel != stitching_channel,:]
    
    reference_round_num = analysis_parameters[&#39;RegistrationReferenceHybridization&#39;]
    registration_tollerance_pxl = analysis_parameters[&#39;RegistrationTollerancePxl&#39;]
    
    registration_errors = Registration_errors()
    
    
    # Determine if there are any round with missing counts in the registration
    if stitching_channel_df[stitching_channel_df[&#39;dot_id&#39;].isnull()].empty :
    
        all_counts_fov[&#39;r_px_registered&#39;] = np.nan
        all_counts_fov[&#39;c_px_registered&#39;] = np.nan
        all_counts_fov[&#39;r_shift_px&#39;] = np.nan
        all_counts_fov[&#39;c_shift_px&#39;] = np.nan
        all_counts_fov[&#39;min_number_matching_dots_registration&#39;] = np.nan

        # Register stitching channel
        ref_counts_df = stitching_channel_df.loc[stitching_channel_df.round_num == reference_round_num,:]

        all_counts_fov.loc[ref_counts_df.index,&#39;r_px_registered&#39;] =  \
                ref_counts_df.loc[ref_counts_df.round_num == reference_round_num,&#39;r_px_original&#39;]
        all_counts_fov.loc[ref_counts_df.index,&#39;c_px_registered&#39;] =  \
                ref_counts_df.loc[ref_counts_df.round_num == reference_round_num,&#39;c_px_original&#39;]
        all_counts_fov.loc[ref_counts_df.index,&#39;r_shift_px&#39;] =  0
        all_counts_fov.loc[ref_counts_df.index,&#39;c_shift_px&#39;] =  0
        all_counts_fov.loc[ref_counts_df.index,&#39;min_number_matching_dots_registration&#39;] =  1000

        # Register fish
        fish_ref_round = fish_df.loc[fish_df.round_num == reference_round_num,:]
        
        all_counts_fov.loc[fish_ref_round.index,&#39;r_px_registered&#39;] =  \
                fish_ref_round.loc[fish_ref_round.index,&#39;r_px_original&#39;]
        all_counts_fov.loc[fish_ref_round.index,&#39;c_px_registered&#39;] =  \
                fish_ref_round.loc[fish_ref_round.index,&#39;c_px_original&#39;]
        all_counts_fov.loc[fish_ref_round.index,&#39;r_shift_px&#39;] =  0
        all_counts_fov.loc[fish_ref_round.index,&#39;c_shift_px&#39;] =  0
        all_counts_fov.loc[fish_ref_round.index,&#39;min_number_matching_dots_registration&#39;] =  1000
        
        # Create reference fake image for registration
        img_width = ref_counts_df.iloc[0][&#39;img_width&#39;]
        img_height = ref_counts_df.iloc[0][&#39;img_height&#39;]
        ref_coords = ref_counts_df.loc[:,[&#39;r_px_original&#39;, &#39;c_px_original&#39;]].to_numpy()
        img_ref = create_fake_image((img_width, img_height),ref_coords)

        all_rounds = all_counts_fov.round_num.unique()
        all_rounds = all_rounds[all_rounds != reference_round_num]
        for tran_round_num in all_rounds:

           
            tran_counts_df = stitching_channel_df.loc[stitching_channel_df.round_num == tran_round_num,:]
            img_width = tran_counts_df.iloc[0][&#39;img_width&#39;]
            img_height = tran_counts_df.iloc[0][&#39;img_height&#39;]
            tran_coords = tran_counts_df.loc[:,[&#39;r_px_original&#39;, &#39;c_px_original&#39;]].to_numpy()
            img_tran = create_fake_image((img_width, img_height),tran_coords)


            shift, error, diffphase = register_translation(img_ref, img_tran)
            registered_tran_coords = tran_coords + shift
            min_num_matching_dots = identify_matching_register_dots_NN(ref_coords,
                                                        registered_tran_coords,
                                                        registration_tollerance_pxl)


            # Register stitching channel
            all_counts_fov.loc[tran_counts_df.index,&#39;r_px_registered&#39;] =  registered_tran_coords[:,0]
            all_counts_fov.loc[tran_counts_df.index,&#39;c_px_registered&#39;] =  registered_tran_coords[:,1]
            all_counts_fov.loc[tran_counts_df.index,&#39;r_shift_px&#39;] =  shift[0]
            all_counts_fov.loc[tran_counts_df.index,&#39;c_shift_px&#39;] =  shift[1]
            all_counts_fov.loc[tran_counts_df.index,
                        &#39;min_number_matching_dots_registration&#39;] =  min_num_matching_dots
            
            
            # Register fish
            fish_ref_round = fish_df.loc[fish_df.round_num == tran_round_num,:]
            all_counts_fov.loc[fish_ref_round.index,&#39;r_px_registered&#39;] =  fish_ref_round[&#39;r_px_original&#39;] + shift[0] 
            all_counts_fov.loc[fish_ref_round.index,&#39;c_px_registered&#39;] =  fish_ref_round[&#39;c_px_original&#39;] + shift[1]
            all_counts_fov.loc[fish_ref_round.index,&#39;r_shift_px&#39;] =  shift[0] 
            all_counts_fov.loc[fish_ref_round.index,&#39;c_shift_px&#39;] =  shift[1]
            all_counts_fov.loc[fish_ref_round.index,
                        &#39;min_number_matching_dots_registration&#39;] =  min_num_matching_dots
            
            
    else:
        
        all_counts_fov[&#39;r_px_registered&#39;] = np.nan
        all_counts_fov[&#39;c_px_registered&#39;] = np.nan
        all_counts_fov[&#39;r_shift_px&#39;] = np.nan
        all_counts_fov[&#39;c_shift_px&#39;] = np.nan
        all_counts_fov[&#39;min_number_matching_dots_registration&#39;] = registration_errors.missing_counts_reg_channel
     
    return all_counts_fov


def beads_based_registration_stitching_channel(stitching_channel_df: pd.DataFrame,
                analysis_parameters: Dict, metadata: Dict)-&gt; Tuple[pd.DataFrame, np.ndarray, pd.DataFrame]:
    &#34;&#34;&#34;Registration of the reference channel that contained reference beads.

    Args:
        stitching_channel_df (pd.DataFrame): Coordinates of the beads
        analysis_parameters (Dict): Processing parameters
        metadata (Dict): Overall experiment info parameters

    Returns:
        Tuple[pd.DataFrame, np.ndarray, pd.DataFrame]: (stitching_channel_df, 
                        all_rounds_shifts, all_rounds_matching_dots)
    
    &#34;&#34;&#34;
                
    # Used index to avoid to remake the output dataframe
    # REMEMBER that you can miss one of the types of beads when dual beads
    #          are used for the registration

    reference_round_num = analysis_parameters[&#39;RegistrationReferenceHybridization&#39;]
    registration_tollerance_pxl = analysis_parameters[&#39;RegistrationTollerancePxl&#39;]
    registration_tollerance_counts = analysis_parameters[&#39;RegistrationMinMatchingBeads&#39;]
    


    registration_errors = Registration_errors()
    
    all_rounds_shifts = {}
    all_rounds_matching_dots = {}
    # Determine if there are any round with missing counts in the registration

    # Dropna to determine if the dataframe is empty or not. Also will remove the
    # rounds without counts
    stitching_channel_df = stitching_channel_df.dropna()
    if stitching_channel_df.shape[0]:
    
        stitching_channel_df[&#39;r_px_registered&#39;] = np.nan
        stitching_channel_df[&#39;c_px_registered&#39;] = np.nan
        stitching_channel_df[&#39;r_shift_px&#39;] = np.nan
        stitching_channel_df[&#39;c_shift_px&#39;] = np.nan
        stitching_channel_df[&#39;min_number_matching_dots_registration&#39;] = np.nan

        # Register stitching channel
        ref_counts_df = stitching_channel_df.loc[stitching_channel_df.round_num == reference_round_num,:]

        while True:
            if not ref_counts_df.shape[0]:

                stitching_channel_df = stitching_channel_df.append({&#39;round_num&#39;:reference_round_num}, ignore_index=True)
                
                all_rounds_shifts[reference_round_num] = np.nan

                if  reference_round_num == analysis_parameters[&#39;RegistrationReferenceHybridization&#39;]:
                    stitching_channel_df.loc[stitching_channel_df.round_num == reference_round_num,
                                &#39;min_number_matching_dots_registration&#39;] = registration_errors.missing_counts_reference_round

                    all_rounds_matching_dots[reference_round_num] = registration_errors.missing_counts_reference_round
                else:
                    stitching_channel_df.loc[stitching_channel_df.round_num == reference_round_num,
                                &#39;min_number_matching_dots_registration&#39;] = registration_errors.missing_counts_in_round

                    all_rounds_matching_dots[reference_round_num] = registration_errors.missing_counts_in_round

                reference_round_num += 1 # Valid only if the reference round is one if it is different you need to find
                                        # another logic for the processing
                
                if reference_round_num &gt; metadata[&#39;total_rounds&#39;]:
                    break
                else:
                    ref_counts_df = stitching_channel_df.loc[stitching_channel_df.round_num == reference_round_num,:]

            else:
                break
                
        if reference_round_num &gt; metadata[&#39;total_rounds&#39;]:
            stitching_channel_df[&#39;r_px_registered&#39;] = np.nan
            stitching_channel_df[&#39;c_px_registered&#39;] = np.nan
            stitching_channel_df[&#39;r_shift_px&#39;] = np.nan
            stitching_channel_df[&#39;c_shift_px&#39;] = np.nan
            stitching_channel_df[&#39;min_number_matching_dots_registration&#39;] = registration_errors.missing_counts_reg_channel
            all_rounds_shifts = np.nan

        else:

            # ref_counts_df = stitching_channel_df.loc[stitching_channel_df.round_num == reference_round_num,:]
            stitching_channel_df.loc[ref_counts_df.index,&#39;r_px_registered&#39;] =  \
                    ref_counts_df.loc[ref_counts_df.round_num == reference_round_num,&#39;r_px_original&#39;]
            stitching_channel_df.loc[ref_counts_df.index,&#39;c_px_registered&#39;] =  \
                    ref_counts_df.loc[ref_counts_df.round_num == reference_round_num,&#39;c_px_original&#39;]
            stitching_channel_df.loc[ref_counts_df.index,&#39;r_shift_px&#39;] =  0
            stitching_channel_df.loc[ref_counts_df.index,&#39;c_shift_px&#39;] =  0
            stitching_channel_df.loc[ref_counts_df.index,&#39;min_number_matching_dots_registration&#39;] =  1000

            all_rounds_shifts[reference_round_num] = np.array([0,0])
            all_rounds_matching_dots[reference_round_num] = 1000


            # Create reference fake image for registration
            img_width = metadata[&#39;img_width&#39;]
            img_height = metadata[&#39;img_height&#39;]
            ref_coords = ref_counts_df.loc[:,[&#39;r_px_original&#39;, &#39;c_px_original&#39;]].to_numpy()

            img_ref = create_fake_image((img_width, img_height),ref_coords)

            all_rounds = np.arange(1,metadata[&#39;total_rounds&#39;]+1)
            all_rounds = all_rounds[all_rounds &gt; reference_round_num]

            for tran_round_num in all_rounds:
            
                tran_counts_df = stitching_channel_df.loc[stitching_channel_df.round_num == tran_round_num,:]
                
                if tran_counts_df.shape[0]:
    
                    tran_coords = tran_counts_df.loc[:,[&#39;r_px_original&#39;, &#39;c_px_original&#39;]].to_numpy()
                    img_tran = create_fake_image((img_width, img_height),tran_coords)


                    shift, error, diffphase = register_translation(img_ref, img_tran)
                    registered_tran_coords = tran_coords + shift
                    min_num_matching_dots = identify_matching_register_dots_NN(ref_coords,
                                                                registered_tran_coords,
                                                                registration_tollerance_pxl)

                    all_rounds_shifts[tran_round_num] = shift
                    all_rounds_matching_dots[tran_round_num] = min_num_matching_dots
                    

                    # Register stitching channel
                    stitching_channel_df.loc[tran_counts_df.index,&#39;r_px_registered&#39;] =  registered_tran_coords[:,0]
                    stitching_channel_df.loc[tran_counts_df.index,&#39;c_px_registered&#39;] =  registered_tran_coords[:,1]
                    stitching_channel_df.loc[tran_counts_df.index,&#39;r_shift_px&#39;] =  shift[0]
                    stitching_channel_df.loc[tran_counts_df.index,&#39;c_shift_px&#39;] =  shift[1]
                    if min_num_matching_dots &gt;=registration_tollerance_counts:
                        stitching_channel_df.loc[tran_counts_df.index,
                                &#39;min_number_matching_dots_registration&#39;] =  min_num_matching_dots
                    else:
                        stitching_channel_df.loc[tran_counts_df.index,
                                &#39;min_number_matching_dots_registration&#39;] =  registration_errors.number_beads_below_tolerance_counts

                else:

                    stitching_channel_df = stitching_channel_df.append({&#39;round_num&#39;:tran_round_num}, ignore_index=True)
                    stitching_channel_df.loc[stitching_channel_df.round_num == tran_round_num,
                                &#39;min_number_matching_dots_registration&#39;] = registration_errors.missing_counts_in_round

                    all_rounds_shifts[tran_round_num] = np.nan
                    all_rounds_matching_dots[tran_round_num] = registration_errors.missing_counts_in_round
            
    else:
        
        stitching_channel_df[&#39;r_px_registered&#39;] = np.nan
        stitching_channel_df[&#39;c_px_registered&#39;] = np.nan
        stitching_channel_df[&#39;r_shift_px&#39;] = np.nan
        stitching_channel_df[&#39;c_shift_px&#39;] = np.nan
        stitching_channel_df[&#39;min_number_matching_dots_registration&#39;] = registration_errors.missing_counts_reg_channel
        all_rounds_shifts = np.nan
     
    return stitching_channel_df, all_rounds_shifts, all_rounds_matching_dots




def beads_based_registration_fish(all_counts_fov: pd.DataFrame,
                                        all_rounds_shifts: np.ndarray,
                                        all_rounds_matching_dots: pd.DataFrame,
                                        analysis_parameters: Dict)-&gt;pd.DataFrame:
    &#34;&#34;&#34;Adjust the coords of the fish dots using the shift calculated in the 
    reference channel.

    Args:
        all_counts_fov (pd.DataFrame): Coords of all peaks
        all_rounds_shifts (np.ndarray): Calculated shift from the registration 
                                of the reference channel
        all_rounds_matching_dots (pd.DataFrame): Marching dots between rounds
        analysis_parameters (Dict): Processing parameters

    Returns:
        pd.DataFrame: All registered counts
    &#34;&#34;&#34;
    
    registration_errors = Registration_errors()
    
    # Determine if there are counts in the fish channel
    all_counts_fov = all_counts_fov.dropna()
    
    if not all_counts_fov.shape[0]:    
        all_counts_fov = all_counts_fov.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.missing_counts_fish_channel}, 
                                                                                                                    ignore_index=True)

    elif isinstance(all_rounds_shifts,dict):

        for round_num, shift in all_rounds_shifts.items():
            if isinstance(shift,np.ndarray):
                all_counts_fov.loc[all_counts_fov.round_num == round_num,&#39;r_px_registered&#39;] =  all_counts_fov[&#39;r_px_original&#39;] + shift[0] 
                all_counts_fov.loc[all_counts_fov.round_num == round_num,&#39;c_px_registered&#39;] =  all_counts_fov[&#39;c_px_original&#39;] + shift[1]
                all_counts_fov.loc[all_counts_fov.round_num == round_num,&#39;r_shift_px&#39;] =  shift[0] 
                all_counts_fov.loc[all_counts_fov.round_num == round_num,&#39;c_shift_px&#39;] =  shift[1]
                all_counts_fov.loc[all_counts_fov.round_num == round_num,
                            &#39;min_number_matching_dots_registration&#39;] =  all_rounds_matching_dots[round_num]
            else:
                all_counts_fov.loc[all_counts_fov.round_num == round_num,&#39;r_px_registered&#39;] =  np.nan
                all_counts_fov.loc[all_counts_fov.round_num == round_num,&#39;c_px_registered&#39;] =  np.nan
                all_counts_fov.loc[all_counts_fov.round_num == round_num,&#39;r_shift_px&#39;] = np.nan
                all_counts_fov.loc[all_counts_fov.round_num == round_num,&#39;c_shift_px&#39;] =  np.nan
                all_counts_fov.loc[all_counts_fov.round_num == round_num,
                            &#39;min_number_matching_dots_registration&#39;] =  all_rounds_matching_dots[round_num]

    else:

        all_counts_fov[&#39;r_px_registered&#39;] = np.nan
        all_counts_fov[&#39;c_px_registered&#39;] = np.nan
        all_counts_fov[&#39;r_shift_px&#39;] = np.nan
        all_counts_fov[&#39;c_shift_px&#39;] = np.nan
        all_counts_fov[&#39;min_number_matching_dots_registration&#39;] = registration_errors.missing_counts_reg_channel
                 
     
    return all_counts_fov


# TODO MUST ADD THE CONSIDERATION OF POTENTIAL ERRORS
def nuclei_based_registration(all_counts_fov: pd.DataFrame,
                            img_stack: np.ndarray,
                            analysis_parameters: Dict)-&gt;pd.DataFrame:
    &#34;&#34;&#34;Function used to run the registration of a single fov
    through all hybridization. The registration is done using the dots
    coords determined in each image

    Args:
        all_counts_fov (pd.DataFrame): Coords of all peaks
        img_stack (np.ndarray): Image stack of the nuclei from different rounds
        analysis_parameters (Dict): Processing parameters

    Returns:
        pd.DataFrame: All registered counts
    &#34;&#34;&#34;
   
    
    logger = selected_logger()
    
    # Used index to avoid to remake the output dataframe
    
    stitching_channel = all_counts_fov[&#39;stitching_channel&#39;].iloc[0]
    stitching_channel_df = all_counts_fov.loc[all_counts_fov.channel == stitching_channel, :]
    fish_df = all_counts_fov.loc[all_counts_fov.channel != stitching_channel,:]
    
    reference_round_num = analysis_parameters[&#39;RegistrationReferenceHybridization&#39;]
    ref_round_num_img = reference_round_num -1
    registration_tollerance_pxl = analysis_parameters[&#39;RegistrationTollerancePxl&#39;]
    
    registration_errors = Registration_errors()
    
    
    # Determine if there are any round with missing counts in the registration
    if stitching_channel_df[stitching_channel_df[&#39;dot_id&#39;].isnull()].empty :
    
        all_counts_fov[&#39;r_px_registered&#39;] = np.nan
        all_counts_fov[&#39;c_px_registered&#39;] = np.nan
        all_counts_fov[&#39;r_shift_px&#39;] = np.nan
        all_counts_fov[&#39;c_shift_px&#39;] = np.nan
        all_counts_fov[&#39;min_number_matching_dots_registration&#39;] = np.nan
        all_counts_fov[&#39;RMS&#39;] = np.nan


        # Register fish and enter ref round info
        fish_ref_round = fish_df.loc[fish_df.round_num == reference_round_num,:]

        all_counts_fov.loc[fish_ref_round.index,&#39;r_px_registered&#39;] =  \
                fish_ref_round.loc[fish_ref_round.index,&#39;r_px_original&#39;]
        all_counts_fov.loc[fish_ref_round.index,&#39;c_px_registered&#39;] =  \
                fish_ref_round.loc[fish_ref_round.index,&#39;c_px_original&#39;]
        all_counts_fov.loc[fish_ref_round.index,&#39;r_shift_px&#39;] =  0
        all_counts_fov.loc[fish_ref_round.index,&#39;c_shift_px&#39;] =  0
        all_counts_fov.loc[fish_ref_round.index,&#39;min_number_matching_dots_registration&#39;] =  1000
        all_counts_fov.loc[fish_ref_round.index,&#39;RMS&#39;] =  0

        all_rounds = np.arange(img_stack.shape[0])
        all_rounds = all_rounds[all_rounds != ref_round_num_img]

        ref_img = img_stack[ref_round_num_img,:,:]
    
        for r_num in all_rounds:
            # Register fish
            fish_ref_round = fish_df.loc[fish_df.round_num == (r_num+1),:]

            shift, error, diffphase = phase_cross_correlation(ref_img, img_stack[r_num,:,:],return_error=True)    
            
            all_counts_fov.loc[fish_ref_round.index,&#39;r_px_registered&#39;] =  fish_ref_round[&#39;r_px_original&#39;] + shift[0] 
            all_counts_fov.loc[fish_ref_round.index,&#39;c_px_registered&#39;] =  fish_ref_round[&#39;c_px_original&#39;] + shift[1]
            all_counts_fov.loc[fish_ref_round.index,&#39;r_shift_px&#39;] =  shift[0] 
            all_counts_fov.loc[fish_ref_round.index,&#39;c_shift_px&#39;] =  shift[1]
            all_counts_fov.loc[fish_ref_round.index,
                        &#39;min_number_matching_dots_registration&#39;] =  error
            all_counts_fov.loc[fish_ref_round.index,&#39;RMS&#39;] =  0

    else:
        
        all_counts_fov[&#39;r_px_registered&#39;] = np.nan
        all_counts_fov[&#39;c_px_registered&#39;] = np.nan
        all_counts_fov[&#39;r_shift_px&#39;] = np.nan
        all_counts_fov[&#39;c_shift_px&#39;] = np.nan
        all_counts_fov[&#39;min_number_matching_dots_registration&#39;] = registration_errors.missing_counts_reg_channel
        all_counts_fov[&#39;RMS&#39;] = np.nan
     
    return all_counts_fov






# TODO Adjust and port this function in case of triangulation
# class triangles_based_registration():
#     &#34;&#34;&#34;
#     Class used to register the different rounds by searaching and
#     matching all possible triangles formed by the dots in the reference
#     and translated image. This function run only a registration to the reference
#     round
    
#     The calculation of the triangle is based on list processing and may 
#     be improved in ported to numpy.
#     https://stackoverflow.com/questions/43126580/match-set-of-x-y-points-to-another-set-that-is-scaled-rotated-translated-and

#     &#34;&#34;&#34;

#     def __init__(self, counts, experiment_fpath, channel_name, roi_number, fov_name):
#         self.counts = counts
#         self.experiment_fpath = Path(experiment_fpath)
#         self.channel_name = channel_name
#         self.roi_number = roi_number
#         self.fov_name = fov_name
        
#         self.logger = logging.getLogger(__name__)
        
#         self.pipeline_config_fpath = self.experiment_fpath / &#39;pipeline_config&#39;
#         self.experiment_config_fpath =  self.pipeline_config_fpath / &#39;experiment.yaml&#39;
#         self.experiment_config = load_pipeline_config_file(self.experiment_config_fpath)
        
#         searching_key = &#39;*roi_&#39; +str(self.roi_number) + &#39;_&#39; + self.channel_name + &#39;_images_config.yaml&#39;        
        
#         try:
#             self.image_config_fpath = list(self.pipeline_config_fpath.glob(searching_key))[0]
#         except:
#             self.logger.error(f&#39;the reference beads image_config file is missing {searching_key}&#39;)
#             sys.exit(f&#39;the reference beads image_config file&#39;)

        
#         # Load registration parameters
#         self.image_config = load_pipeline_config_file(self.image_config_fpath)
#         self.registration_parameters = self.image_config[fov_name][&#39;fov_analysis_parameters&#39;][&#39;rounds_registration&#39;]
#         self.chunk_size = self.registration_parameters[&#39;chunk_size&#39;]
#         self.min_dots_chunk = self.registration_parameters[&#39;min_dots_chunk&#39;]
#         self.min_error_triangles = self.registration_parameters[&#39;min_error_triangles&#39;]
#         self.percent_padding = self.registration_parameters[&#39;percent_padding&#39;]
#         self.reference_round = self.registration_parameters[&#39;reference_round&#39;]
#         self.collect_all_chunks = self.registration_parameters[&#39;collect_all_chunks&#39;]
#         self.reference_round_name = &#39;round_&#39; + str(self.reference_round)
       
#         # The top lef coords are 0,0 because we are using relative coords
#         self.tl_coords = (0,0)

#         self.img_dimensions = (self.image_config[fov_name][&#39;rounds&#39;][self.reference_round_name][&#39;shape&#39;][&#39;height&#39;],
#                                self.image_config[fov_name][&#39;rounds&#39;][self.reference_round_name][&#39;shape&#39;][&#39;width&#39;])    
                    

#     @staticmethod
#     def combine_coords(counts, round_num):
#         data_reference = counts.loc[counts[&#39;round_num&#39;] == round_num]
#         r_px = data_reference.r_px_original.to_list()
#         c_px = data_reference.c_px_original.to_list()
#         coords = np.array(list(zip(r_px,c_px)))
#         position_idx = data_reference.index
#         return coords, position_idx


#     @staticmethod
#     def obj_fun(pars,x,src):
#         tx, ty = pars
#         H = np.array([[1, 0, tx],\
#             [0, 1, ty]])
#         src1 = np.c_[src,np.ones(src.shape[0])]
#         return np.sum( (x - src1.dot(H.T)[:,:2])**2 )

#     @staticmethod
#     def apply_transform(pars, src):
#         tx, ty = pars
#         H = np.array([[1, 0, tx],\
#             [0, 1, ty]])
#         src1 = np.c_[src,np.ones(src.shape[0])]
#         return src1.dot(H.T)[:,:2]

#     @staticmethod
#     def distance(x1,y1,x2,y2):
#         return math.sqrt((x2 - x1)**2 + (y2 - y1)**2 )

#     @staticmethod
#     def list_subtract(list1,list2):
#         return np.absolute(np.array(list1)-np.array(list2))

#     def tri_sides(self,set_x, set_x_tri):

#         triangles = []
#         for i in range(len(set_x_tri)):

#             point1 = set_x_tri[i][0]
#             point2 = set_x_tri[i][1]
#             point3 = set_x_tri[i][2]

#             point1x, point1y = set_x[point1][0], set_x[point1][1]
#             point2x, point2y = set_x[point2][0], set_x[point2][1]
#             point3x, point3y = set_x[point3][0], set_x[point3][1] 

#             len1 = self.distance(point1x,point1y,point2x,point2y)
#             len2 = self.distance(point1x,point1y,point3x,point3y)
#             len3 = self.distance(point2x,point2y,point3x,point3y)

#             # you need to normalize in case the ref and the tran
#             # are warped
#             #min_side = min(len1,len2,len3)
#             #len1/=min_side
#             #len2/=min_side
#             #len3/=min_side
#             t=[len1,len2,len3]
#             t.sort()
#             triangles.append(t)

#         return triangles


#     def identify_matching_coords(self,set_A, set_B, threshold):
#         match_A_pts = []
#         match_B_pts = []
#         set_A_tri = list(itertools.combinations(range(len(set_A)), 3))
#         set_B_tri = list(itertools.combinations(range(len(set_B)), 3))
#         A_triangles = self.tri_sides(set_A, set_A_tri)
#         B_triangles = self.tri_sides(set_B, set_B_tri)
#         sums = []
#         for i in range(len(A_triangles)):
#             for j in range(len(B_triangles)):
#                 k = sum(self.list_subtract(A_triangles[i], B_triangles[j]))
#                 if k &lt; threshold:
#                     sums.append([i,j,k])
#         # sort by smallest sum
#         sums = sorted(sums, key=operator.itemgetter(2))
#         if len(sums):
#             match_A = set_A_tri[sums[0][0]]
#             match_B = set_B_tri[sums[0][1]]
#             for i in range(3):
#                 match_A_pts.append(set_A[match_A[i]])
#                 match_B_pts.append(set_B[match_B[i]])
#         return (match_A_pts,match_B_pts)



#     def calculate_chunks(self):
#         self.chunks = chunking(self.img_dimensions,self.chunk_size,
#                           self.registration_parameters[&#39;percent_padding&#39;],self.tl_coords)   
#         self.chunks.block_chunking()
#         self.Coords_Padded_Chunks_list = self.chunks.Coords_Padded_Chunks_list
        
#     def calculate_dots_chunks(self,coords,chunk_coords):  
#         r_tl = chunk_coords[0]
#         r_br = chunk_coords[1]
#         c_tl = chunk_coords[2]
#         c_br = chunk_coords[3]

#         # Select only the coords in the trimmed region
#         coords_in_chunk = coords[((r_tl &lt; coords[:,0]) &amp; (coords[:,0]&lt;r_br)\
#                     &amp; (c_tl &lt;coords[:,1]) &amp;(coords[:,1]&lt;c_br)),: ]
#         return coords_in_chunk


#     def optimize_chunking(self,ref_coords, tran_coords):       
#         self.enough_dots = False
#         chunk_size = self.chunk_size
#         while chunk_size &lt; min(self.img_dimensions):
#             chunks = chunking(self.img_dimensions, chunk_size, self.percent_padding, self.tl_coords)
#             chunks.block_chunking()
#             Coords_Padded_Chunks_list = chunks.Coords_Padded_Chunks_list
#             ref_max_number_dots = []
#             tran_max_number_dots = []
#             ref_total = []
#             tran_total = []
#             for chunk_coords in Coords_Padded_Chunks_list:
#                 ref_coords_in_chunk = self.calculate_dots_chunks(ref_coords,chunk_coords)
#                 tran_coords_in_chunk = self.calculate_dots_chunks(tran_coords,chunk_coords)
#                 if ref_coords_in_chunk.shape[0] &gt; self.min_dots_chunk and tran_coords_in_chunk.shape[0] &gt; self.min_dots_chunk:
#                         self.enough_dots = True
#                         break
#             if self.enough_dots:
#                 break
#             else:
#                 self.enough_dots = False
#                 chunk_size += 200

#         if self.enough_dots:
#             # Collect the ref and tran coords from the chunks with enough dots
#             self.ref_tran_screening_list = []
#             for chunk_coords in Coords_Padded_Chunks_list:
#                 ref_coords_in_chunk = self.calculate_dots_chunks(ref_coords,chunk_coords)
#                 tran_coords_in_chunk = self.calculate_dots_chunks(tran_coords,chunk_coords)
#                 if ref_coords_in_chunk.shape[0] &gt; self.min_dots_chunk and tran_coords_in_chunk.shape[0] &gt; self.min_dots_chunk:
#                     self.ref_tran_screening_list.append((ref_coords_in_chunk,tran_coords_in_chunk,chunk_coords))
#             self.chunk_size = chunk_size


#     def rounds_to_register(self):
#         # remember that round_num is not pythonic
#         self.rounds_list = list(self.counts[&#39;round_num&#39;].unique())
#         if self.reference_round == False:
#             logger.error(f&#39;missing reference round&#39;)
#             sys.exit(f&#39;missing reference round&#39;)
#         elif self.reference_round &lt;0 or self.reference_round &gt; max(self.rounds_list):
#             logger.error(f&#39;selected reference round {self.reference_round} is out of range&#39;)
#             sys.exit(f&#39;selected reference round {self.reference_round} is out of range&#39;)
#         else:
#             self.rounds_list = list(self.counts[&#39;round_num&#39;].unique()) 
#             self.processing_combinations = []
#             self.rounds_list.remove(self.reference_round)
#             for el in self.rounds_list:
#                 self.processing_combinations.append((self.reference_round,el))

#     def cpl_registration(self,ref_coords,tran_coords,cpl):
#         self.optimize_chunking(ref_coords, tran_coords)
#         self.completed_registration = False
#         if self.enough_dots:
#             match_ref_pts_all = []
#             match_tran_pts_all = []
#             if self.collect_all_chunks:
#             # Collect all matching dots in all chunked regions with number of dots above threshold
#                 for ref_coords_in_chunk,tran_coords_in_chunk, chunk_coords in self.ref_tran_screening_list:
#                         match_ref_pts, match_tran_pts = self.identify_matching_coords(ref_coords_in_chunk,tran_coords_in_chunk,self.min_error_triangles)
#                         if len(match_ref_pts) and len(match_tran_pts):
#                             match_ref_pts_all.append(match_ref_pts)
#                             match_tran_pts_all.append(match_tran_pts)
#                 match_ref_pts_all = [pts for grp in match_ref_pts_all for pts in grp]
#                 match_tran_pts_all = [pts for grp in match_tran_pts_all for pts in grp]
#             else:
#                 ref_coords_in_chunk,tran_coords_in_chunk, chunk_coords = self.ref_tran_screening_list[0]
#                 match_ref_pts_all, match_tran_pts_all = self.identify_matching_coords(ref_coords_in_chunk,tran_coords_in_chunk,self.min_error_triangles)

#             if len(match_ref_pts_all):
#                 match_ref_pts_all = np.vstack(match_ref_pts_all)
#                 match_tran_pts_all = np.vstack(match_tran_pts_all)
#                 minimization_output = minimize(self.obj_fun,[0,0],args=(match_ref_pts_all,match_tran_pts_all), method=&#39;Nelder-Mead&#39;)
#                 if minimization_output.success:
#                     self.tran_registered_coords = self.apply_transform(minimization_output.x, tran_coords)
#                     self.transformation_matrix = minimization_output.x
#                     self.completed_registration = True
#                 else:
#                     self.logger.info(f&#39;chunk {chunk_coords} of {cpl} failed minimization of distances&#39;)
#             else:
#                 self.logger.info(f&#39;chunk {chunk_coords} of {cpl} did not find matching triangles&#39;)

#         else:
#             self.logger.info(f&#39;cannot register rounds {cpl} not enough dots&#39;)
#             self.tran_registered_coords = tran_coords
#             self.transformation_matrix = np.empty([1,2])
#             self.transformation_matrix[:] = np.nan

#         if not self.completed_registration:
#             self.logger.info(f&#39;was not possible to register {cpl} &#39;)
#             self.tran_registered_coords = tran_coords
#             self.transformation_matrix = np.empty([1,2])
#             self.transformation_matrix[:] = np.nan


#     def register(self):
#         all_registration_matrix = {}
#         r_px_col_name = &#39;r_px_registered&#39;
#         c_px_col_name = &#39;c_px_registered&#39;
#         self.counts[r_px_col_name] = np.nan
#         self.counts[c_px_col_name] = np.nan
#         self.counts[&#39;r_transformation_registration&#39;] = np.nan
#         self.counts[&#39;c_transformation_registration&#39;] = np.nan
#         self.rounds_to_register()
#         for cpl in self.processing_combinations:
#             ref_round, tran_round = cpl
#             ref_coords, ref_position_idx = self.combine_coords(self.counts,ref_round)
#             tran_coords, tran_position_idx = self.combine_coords(self.counts,tran_round)
#             self.cpl_registration(ref_coords,tran_coords,cpl)
#             all_registration_matrix[cpl] = self.transformation_matrix
#             self.ref_registered_coords = ref_coords
#             self.counts.loc[ref_position_idx, r_px_col_name] = self.ref_registered_coords[:,0]
#             self.counts.loc[ref_position_idx, c_px_col_name] = self.ref_registered_coords[:,1]
#             self.counts.loc[ref_position_idx, &#39;r_transformation_registration&#39;] = np.ones(self.ref_registered_coords.shape[0])
#             self.counts.loc[ref_position_idx, &#39;c_transformation_registration&#39;] = np.ones(self.ref_registered_coords.shape[0])
#             self.counts.loc[tran_position_idx, r_px_col_name] = self.tran_registered_coords[:,0]
#             self.counts.loc[tran_position_idx, c_px_col_name] = self.tran_registered_coords[:,1]
#             all_transf = np.tile(self.transformation_matrix,(self.tran_registered_coords.shape[0],1))
#             self.counts.loc[tran_position_idx, &#39;r_transformation_registration&#39;] = all_transf[:,0]
#             self.counts.loc[tran_position_idx, &#39;c_transformation_registration&#39;] = all_transf[:,1]
       
#         return self.counts, all_registration_matrix




# TODO Remove not used functions
########## ----------------------------------------





# @task(name=&#39;fft_registration_beads&#39;)# ADD LOGGER
def fft_registration_beads(reference_coords:np.ndarray, translated_coords:np.ndarray,
                       img_shape: np.ndarray, fov_num:int,
                       hybridization_num_translated:int):

    # CHECK THE VALUES AND CATCH THE ERROR TO BLOCK FOV FOR REGISTRATION     
    if np.any(np.isnan(reference_coords)):
        logger.error(f&#39;missing reference round for registration for fov {fov_num}&#39;) 
        signals.SKIP(f&#39;missing reference round for registration for fov {fov_num}&#39;)
        shift = np.array([np.nan,np.nan])
        error = 0
        tran_registered_coords = translated_coords
        
        # RETURN VALUES TO WRITE ON DB
    elif np.any(np.isnan(translated_coords)):
        logger.error(f&#39;missing registration round {hybridization_num_translated} for registration for fov {fov_num}&#39;)   
        shift = np.array([np.nan,np.nan])
        error = 0
        tran_registered_coords = translated_coords
        
    else:
        img_ref = create_fake_image(img_shape,reference_coords)    
        img_tran = create_fake_image(img_shape,translated_coords)
        shift, error, diffphase = register_translation(img_ref, img_tran)
        tran_registered_coords = translated_coords + shift
        tran_registered_coords = tran_registered_coords.astype(int)

    return tran_registered_coords, shift, error, fov_num, hybridization_num_translated 


def identify_matching_register_dots_NN(ref_dots_coords_fov,tran_registered_coords,registration_tollerance_pxl):
    # put in the wrapping function
    #if (ref_dots_coords_fov.shape[0] &gt;0) and (tran_registered_coords.shape[0] &gt;0):
            
    # initialize network
    nn = NearestNeighbors(n_neighbors=1, metric=&#34;euclidean&#34;)
    nn.fit(ref_dots_coords_fov)

    # Get the nn
    dists, indices = nn.kneighbors(tran_registered_coords, return_distance=True)

    # select only the nn that are below pxl distance
    idx_selected_coords_compare = np.where(dists &lt;= registration_tollerance_pxl)[0]

    number_matching_dots = idx_selected_coords_compare.shape[0]
    
    return number_matching_dots


def calculate_shift_hybridization_fov(processing_files:List,analysis_parameters:dict, save=True):
    &#34;&#34;&#34;
    Function used to run the registration of a single fov
    through all hybridization. The registration is done using the dots
    coords determined in each image

    Args:
        processing_files: List
            list of the files with the counts to register
        analysis_parameters: Dict
            dict that contains the settings for the analysis 
    &#34;&#34;&#34;
    
    logger = selected_logger()
    all_rounds_shifts = {}
    
    registration_errors = Registration_errors()
    data_models = Output_models()
    output_registration_df = data_models.output_registration_df
    status = &#39;SUCCESS&#39;

    reference_hybridization = analysis_parameters[&#39;RegistrationReferenceHybridization&#39;]
    round_num = reference_hybridization
    reference_hybridization_str = &#39;Hybridization&#39; + str(reference_hybridization).zfill(2)
    registration_tollerance_pxl = analysis_parameters[&#39;RegistrationTollerancePxl&#39;]

    # collect info used to generate fname when files are corrupted   
    experiment_fpath = processing_files[0].parent.parent.parent
    channel = (processing_files[0].stem).split(&#39;_&#39;)[-4]
    experiment_name = experiment_fpath.stem
    fov = (processing_files[0].stem).split(&#39;_&#39;)[-2]
    file_tags = {&#39;experiment_fpath&#39;:experiment_fpath,
                &#39;experiment_name&#39;:experiment_name,
                &#39;channel&#39;:channel,
                &#39;fov&#39;:fov}

    fname = experiment_fpath / &#39;tmp&#39; / &#39;registered_counts&#39; / (experiment_name + &#39;_&#39; + channel + &#39;_registered_fov_&#39; + fov + &#39;.parquet&#39;)
    shift_fname = experiment_fpath / &#39;tmp&#39; / &#39;registered_counts&#39; / (experiment_name + &#39;_&#39; + channel + &#39;_all_rounds_shifts_fov_&#39; + fov + &#39;.pkl&#39;)
    # Load reference hybridization data
    try:
        ref_fpath = [fpath for fpath in processing_files if reference_hybridization_str in fpath.as_posix()][0]
    except:
        logger.error(f&#39;missing reference hyb file for fov {fov}&#39;)
        output_registration_df = output_registration_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.missing_file_reg_channel, 
                                            &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num)},ignore_index=True)
        status = &#39;FAILED&#39;
        all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
    else:
        try:
            ref_counts,ref_img_metadata = pickle.load(open(ref_fpath, &#39;rb&#39;))
        except:
            logger.error(f&#39;cannot open the reference hyb file for fov {fov}&#39;)
            output_registration_df = output_registration_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.cannot_load_file_reg_channel,
                                            &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num) },ignore_index=True)
            status = &#39;FAILED&#39;
            all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
        else:
            # Check if there are dots detected in the reference round
            if np.any(np.isnan(ref_counts[&#39;r_px_original&#39;])) or (ref_counts[&#39;r_px_original&#39;].shape[0]&lt;registration_tollerance_pxl):
                logger.error(f&#39;There are no dots in there reference hyb for fov {fov} &#39;)
                output_registration_df = output_registration_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.missing_counts_reg_channel,
                                            &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num) },ignore_index=True)
                status = &#39;FAILED&#39;
                all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
            else:
                ref_counts_df = pd.DataFrame(ref_counts)
                ref_counts_df[&#39;r_px_registered&#39;] = ref_counts_df[&#39;r_px_original&#39;]
                ref_counts_df[&#39;c_px_registered&#39;] = ref_counts_df[&#39;c_px_original&#39;]
                ref_counts_df[&#39;r_shift_px&#39;] = 0
                ref_counts_df[&#39;c_shift_px&#39;] = 0
                ref_counts_df[&#39;min_number_matching_dots_registration&#39;] = 1000
                all_rounds_shifts[round_num] = np.array([0,0])

                output_registration_df = pd.concat([output_registration_df,ref_counts_df],axis=0,ignore_index=True)
                
                tran_processing_files =processing_files.copy()
                tran_processing_files.remove(ref_fpath)
                img_width = ref_img_metadata[&#39;img_width&#39;]
                img_height = ref_img_metadata[&#39;img_height&#39;]

                img_shape = (img_width, img_height)
                ref_coords = ref_counts_df.loc[:,[&#39;r_px_original&#39;, &#39;c_px_original&#39;]].to_numpy()
                img_ref = create_fake_image(img_shape,ref_coords)
        

                for fpath in tran_processing_files:
                    try:
                        tran_counts, tran_img_metadata = pickle.load(open(fpath, &#39;rb&#39;))
                    except:
                        logger.error(f&#39;cannot open {fpath.stem} file for fov {fov}&#39;)
                        # If there is an error in the opening reset the df
                        round_num = int((fpath.stem).split(&#39;_&#39;)[-5].split(&#39;Hybridization&#39;)[-1])
                        output_registration_df = data_models.output_registration_df
                        output_registration_df = output_registration_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.cannot_load_file_reg_channel,
                                            &#39;fov_num&#39;:int(fov) ,&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num)},ignore_index=True)
                        status = &#39;FAILED&#39;
                        all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
                        break
                    else:
                        tran_counts_df = pd.DataFrame(tran_counts)
                        tran_coords = tran_counts_df.loc[:,[&#39;r_px_original&#39;, &#39;c_px_original&#39;]].to_numpy()
                        if np.any(np.isnan(tran_coords)) or tran_coords.shape[0]&lt;registration_tollerance_pxl:
                            round_num = int((fpath.stem).split(&#39;_&#39;)[-5].split(&#39;Hybridization&#39;)[-1])
                            # If dots are missing, reset the df
                            output_registration_df = data_models.output_registration_df
                            output_registration_df = output_registration_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.missing_counts_reg_channel,
                                            &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num) },ignore_index=True)
                            status = &#39;FAILED&#39;
                            all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
                            logger.error(f&#39; {fpath.stem} file for fov {fov} has no counts&#39;)
                            break
                        else:
                            
                            round_num = tran_counts[&#39;round_num&#39;][0]
                            ref_img_metadata[&#39;reference_hyb&#39;] = str(reference_hybridization)
                            img_tran = create_fake_image(img_shape,tran_coords)
                            shift, error, diffphase = register_translation(img_ref, img_tran)
                            all_rounds_shifts[round_num] = shift
                            registered_tran_coords = tran_coords + shift
                            min_num_matching_dots = identify_matching_register_dots_NN(ref_coords,
                                                                                    registered_tran_coords,
                                                                                    registration_tollerance_pxl)
                            
                            tran_counts_df[&#39;r_px_registered&#39;] = registered_tran_coords[:,0]
                            tran_counts_df[&#39;c_px_registered&#39;] = registered_tran_coords[:,1]
                            tran_counts_df[&#39;r_shift_px&#39;] = shift[0]
                            tran_counts_df[&#39;c_shift_px&#39;] = shift[1]
                            tran_counts_df[&#39;min_number_matching_dots_registration&#39;] = min_num_matching_dots

                            output_registration_df = pd.concat([output_registration_df,tran_counts_df],axis=0,ignore_index=True)
                            output_registration_df.attrs[fov] = ref_img_metadata

                # Save the dataframe
                
                output_registration_df[&#39;reference_hyb&#39;] = reference_hybridization
                output_registration_df[&#39;experiment_type&#39;] = ref_img_metadata[&#39;experiment_type&#39;]
                output_registration_df[&#39;experiment_name&#39;] = ref_img_metadata[&#39;experiment_name&#39;]
                output_registration_df[&#39;pxl_um&#39;] = ref_img_metadata[&#39;pixel_microns&#39;]
                output_registration_df[&#39;stitching_type&#39;] = ref_img_metadata[&#39;stitching_type&#39;]
                output_registration_df[&#39;img_width_px&#39;] = ref_img_metadata[&#39;img_width&#39;]
                output_registration_df[&#39;img_height_px&#39;] = ref_img_metadata[&#39;img_height&#39;]
                output_registration_df[&#39;fov_acquisition_coords_x&#39;] = ref_img_metadata[&#39;fov_acquisition_coords_x&#39;]
                output_registration_df[&#39;fov_acquisition_coords_y&#39;] = ref_img_metadata[&#39;fov_acquisition_coords_y&#39;]
                output_registration_df[&#39;fov_acquisition_coords_z&#39;] = ref_img_metadata[&#39;fov_acquisition_coords_z&#39;]
        
        # Save extra metadata in the
        if save:
            output_registration_df.to_parquet(fname,index=False)
            pickle.dump(all_rounds_shifts,open(shift_fname,&#39;wb&#39;))
        return output_registration_df, all_rounds_shifts, file_tags, status



def calculate_shift_hybridization_fov_test(fov:int,
                                            counts_output:Dict,
                                            analysis_parameters:Dict, 
                                            experiment_info:Dict):
    &#34;&#34;&#34;
    Function used to run the registration of a single fov
    through all hybridization. The registration is done using the dots
    coords determined in each image

    Args:
        processing_files: List
            list of the files with the counts to register
        analysis_parameters: Dict
            dict that contains the settings for the analysis 
    &#34;&#34;&#34;
    
    logger = selected_logger()
    all_rounds_shifts = {}
    
    registration_errors = Registration_errors()
    data_models = Output_models()
    output_registration_df = data_models.output_registration_df
    status = &#39;SUCCESS&#39;

    reference_hybridization = analysis_parameters[&#39;RegistrationReferenceHybridization&#39;]
    round_num = reference_hybridization
    reference_hybridization_str = &#39;Hybridization&#39; + str(reference_hybridization).zfill(2)
    channel = experiment_info[&#39;StitchingChannel&#39;]
    registration_tollerance_pxl = analysis_parameters[&#39;RegistrationTollerancePxl&#39;]
    counts_zarr_names = list(counts_output[&#39;registration&#39;][channel].keys())

    try:
        ref_zarr_name = [el for el in counts_zarr_names if reference_hybridization_str in el][0]
    except:
        logger.error(f&#39;missing registration counts fov {fov}&#39;)
        output_registration_df = output_registration_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.missing_file_reg_channel, 
                                            &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num)},ignore_index=True)
        status = &#39;FAILED&#39;
        all_rounds_shifts[round_num] = np.array([np.nan,np.nan])

    else:
        ref_counts, ref_img_metadata = counts_output[&#39;registration&#39;][channel][ref_zarr_name]
        # Check if there are dots detected in the reference round
        if np.any(np.isnan(ref_counts[&#39;r_px_original&#39;])) or (ref_counts[&#39;r_px_original&#39;].shape[0]&lt;registration_tollerance_pxl):
            logger.error(f&#39;There are no dots in there reference hyb for fov {fov} &#39;)
            output_registration_df = output_registration_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.missing_counts_reg_channel,
                                        &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num) },ignore_index=True)
            status = &#39;FAILED&#39;
            all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
        else:
            ref_counts_df = pd.DataFrame(ref_counts)
            ref_counts_df[&#39;r_px_registered&#39;] = ref_counts_df[&#39;r_px_original&#39;]
            ref_counts_df[&#39;c_px_registered&#39;] = ref_counts_df[&#39;c_px_original&#39;]
            ref_counts_df[&#39;r_shift_px&#39;] = 0
            ref_counts_df[&#39;c_shift_px&#39;] = 0
            ref_counts_df[&#39;min_number_matching_dots_registration&#39;] = 1000
            all_rounds_shifts[round_num] = np.array([0,0])

            output_registration_df = pd.concat([output_registration_df,ref_counts_df],axis=0,ignore_index=True)
            
            tran_processing_files = counts_zarr_names.copy()
            tran_processing_files.remove(ref_zarr_name)
            img_width = ref_img_metadata[&#39;img_width&#39;]
            img_height = ref_img_metadata[&#39;img_height&#39;]

            img_shape = (img_width, img_height)
            ref_coords = ref_counts_df.loc[:,[&#39;r_px_original&#39;, &#39;c_px_original&#39;]].to_numpy()
            img_ref = create_fake_image(img_shape,ref_coords)
    

            for zarr_name in tran_processing_files:
                round_num = int(zarr_name.split(&#39;_&#39;)[-4].split(&#39;Hybridization&#39;)[-1])
                try:
                    tran_counts, tran_img_metadata = counts_output[&#39;registration&#39;][channel][zarr_name]
                except:
                    logger.error(f&#39;cannot open {zarr_name} file for fov {fov}&#39;)
                    # If there is an error in the opening reset the df
                    output_registration_df = data_models.output_registration_df
                    output_registration_df = output_registration_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.cannot_load_file_reg_channel,
                                        &#39;fov_num&#39;:int(fov) ,&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num)},ignore_index=True)
                    status = &#39;FAILED&#39;
                    all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
                    break
                else:
                    tran_counts_df = pd.DataFrame(tran_counts)
                    tran_coords = tran_counts_df.loc[:,[&#39;r_px_original&#39;, &#39;c_px_original&#39;]].to_numpy()
                    if np.any(np.isnan(tran_coords)) or tran_coords.shape[0]&lt;registration_tollerance_pxl:
                        # If dots are missing, reset the df
                        output_registration_df = data_models.output_registration_df
                        output_registration_df = output_registration_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.missing_counts_reg_channel,
                                        &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num) },ignore_index=True)
                        status = &#39;FAILED&#39;
                        all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
                        logger.error(f&#39; {zarr_name} file for fov {fov} has no counts&#39;)
                        break
                    else:
                        
                        round_num = tran_counts[&#39;round_num&#39;][0]
                        ref_img_metadata[&#39;reference_hyb&#39;] = str(reference_hybridization)
                        img_tran = create_fake_image(img_shape,tran_coords)
                        shift, error, diffphase = register_translation(img_ref, img_tran)
                        all_rounds_shifts[round_num] = shift
                        registered_tran_coords = tran_coords + shift
                        min_num_matching_dots = identify_matching_register_dots_NN(ref_coords,
                                                                                registered_tran_coords,
                                                                                registration_tollerance_pxl)
                        
                        tran_counts_df[&#39;r_px_registered&#39;] = registered_tran_coords[:,0]
                        tran_counts_df[&#39;c_px_registered&#39;] = registered_tran_coords[:,1]
                        tran_counts_df[&#39;r_shift_px&#39;] = shift[0]
                        tran_counts_df[&#39;c_shift_px&#39;] = shift[1]
                        tran_counts_df[&#39;min_number_matching_dots_registration&#39;] = min_num_matching_dots

                        output_registration_df = pd.concat([output_registration_df,tran_counts_df],axis=0,ignore_index=True)

            # Save the dataframe
            
            output_registration_df[&#39;reference_hyb&#39;] = reference_hybridization
            output_registration_df[&#39;experiment_type&#39;] = ref_img_metadata[&#39;experiment_type&#39;]
            output_registration_df[&#39;experiment_name&#39;] = ref_img_metadata[&#39;experiment_name&#39;]
            output_registration_df[&#39;pxl_um&#39;] = ref_img_metadata[&#39;pixel_microns&#39;]
            output_registration_df[&#39;stitching_type&#39;] = ref_img_metadata[&#39;stitching_type&#39;]
            output_registration_df[&#39;img_width_px&#39;] = ref_img_metadata[&#39;img_width&#39;]
            output_registration_df[&#39;img_height_px&#39;] = ref_img_metadata[&#39;img_height&#39;]
            output_registration_df[&#39;fov_acquisition_coords_x&#39;] = ref_img_metadata[&#39;fov_acquisition_coords_x&#39;]
            output_registration_df[&#39;fov_acquisition_coords_y&#39;] = ref_img_metadata[&#39;fov_acquisition_coords_y&#39;]
            output_registration_df[&#39;fov_acquisition_coords_z&#39;] = ref_img_metadata[&#39;fov_acquisition_coords_z&#39;]
    
    
    return output_registration_df, all_rounds_shifts, status


def register_fish(processing_files:List,analysis_parameters:Dict,
                        registered_reference_channel_df,all_rounds_shifts:Dict,file_tags:Dict,status:str,
                        save=True):

    logger = selected_logger()
    registration_errors = Registration_errors()
    data_models = Output_models()
    fov = file_tags[&#39;fov&#39;]
    channel = (processing_files[0].stem).split(&#39;_&#39;)[-4]
    file_tags[&#39;channel&#39;] = channel
    registered_fish_df = data_models.output_registration_df

    if status == &#39;FAILED&#39;:
        error = registered_reference_channel_df[&#39;min_number_matching_dots_registration&#39;].values[0]
        round_num = registered_reference_channel_df[&#39;round_num&#39;].values[0]
        registered_fish_df = registered_fish_df.append({&#39;min_number_matching_dots_registration&#39;:error,
                                                           &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num) },ignore_index=True)
    elif status == &#39;SUCCESS&#39;:
        reference_hybridization = registered_reference_channel_df.attrs[fov][&#39;reference_hyb&#39;]
        reference_hybridization_str = &#39;Hybridization&#39; + str(reference_hybridization).zfill(2)
        for fpath in processing_files:
            round_num = int((fpath.stem).split(&#39;_&#39;)[-5].split(&#39;Hybridization&#39;)[-1])
            try:
                fish_counts, fish_img_metadata = pickle.load(open(fpath,&#39;rb&#39;))
            except:
                logger.error(f&#39;cannot open the processing files&#39;)
                
                registered_fish_df = registered_fish_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.cannot_load_file_fish_channel,
                                                &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:round_num },ignore_index=True)
                status = &#39;FAILED&#39;
                break
            else:                
                if np.any(np.isnan(fish_counts[&#39;r_px_original&#39;])):
                    logger.error(f&#39;There are no dots in there reference hyb for fov {fov} &#39;)
                    registered_fish_df = registered_fish_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.missing_counts_fish_channel,
                                                &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:round_num },ignore_index=True)
                    status = &#39;FAILED&#39;
                    break

                else:
                    if reference_hybridization_str in fpath.as_posix():
                        fish_img_metadata[&#39;reference_hyb&#39;] = reference_hybridization
                        registered_fish_df.attrs[fov] = fish_img_metadata
                    fish_counts_df = pd.DataFrame(fish_counts)
                    
                    subset_df = registered_reference_channel_df.loc[registered_reference_channel_df[&#39;round_num&#39;] == round_num, :]
                    subset_df = subset_df.reset_index()
                        
                    shift = all_rounds_shifts[round_num]
                    fish_counts_df[&#39;r_px_registered&#39;] = fish_counts[&#39;r_px_original&#39;] + shift[0]
                    fish_counts_df[&#39;c_px_registered&#39;] = fish_counts[&#39;c_px_original&#39;] + shift[1]
                    fish_counts_df[&#39;r_shift_px&#39;] = shift[0]
                    fish_counts_df[&#39;c_shift_px&#39;] = shift[1]
                    fish_counts_df[&#39;min_number_matching_dots_registration&#39;] = subset_df.loc[0,&#39;min_number_matching_dots_registration&#39;] 
                    # fish_counts_df[&#39;reference_hyb&#39;] = reference_hybridization
                    # fish_counts_df[&#39;experiment_type&#39;] = subset_df.loc[0,&#39;experiment_type&#39;]
                    # fish_counts_df[&#39;experiment_name&#39;] = subset_df.loc[0,&#39;experiment_name&#39;]
                    # fish_counts_df[&#39;pxl_um&#39;] = subset_df.loc[0,&#39;pxl_um&#39;]
                    # fish_counts_df[&#39;stitching_type&#39;] = subset_df.loc[0,&#39;stitching_type&#39;]
                    # fish_counts_df[&#39;fov_acquisition_coords_x&#39;] = subset_df.loc[0,&#39;fov_acquisition_coords_x&#39;]
                    # fish_counts_df[&#39;fov_acquisition_coords_y&#39;] = subset_df.loc[0,&#39;fov_acquisition_coords_y&#39;]
                    # fish_counts_df[&#39;fov_acquisition_coords_z&#39;] = subset_df.loc[0,&#39;fov_acquisition_coords_z&#39;]

                    registered_fish_df = pd.concat([registered_fish_df,fish_counts_df],axis=0,ignore_index=True)
                    status = &#39;SUCCESS&#39;

    if save:
        fname = file_tags[&#39;experiment_fpath&#39;] / &#39;tmp&#39; / &#39;registered_counts&#39; / (file_tags[&#39;experiment_name&#39;] + &#39;_&#39; + file_tags[&#39;channel&#39;] + &#39;_registered_fov_&#39; + file_tags[&#39;fov&#39;] + &#39;.parquet&#39;)
        registered_fish_df.to_parquet(fname,index=False)
    return registered_fish_df, file_tags, status


def register_fish_test(fov:int,
                        channel:str,
                        counts_output:Dict,
                        registered_reference_channel_df,
                        all_rounds_shifts:Dict,
                        analysis_parameters:Dict,
                        status:str):

    logger = selected_logger()
    registration_errors = Registration_errors()
    data_models = Output_models()

    registered_fish_df = data_models.output_registration_df

    counts_zarr_names = list(counts_output[&#39;fish&#39;][channel].keys())

    if status == &#39;FAILED&#39;:
        error = registered_reference_channel_df[&#39;min_number_matching_dots_registration&#39;].values[0]
        round_num = registered_reference_channel_df[&#39;round_num&#39;].values[0]
        registered_fish_df = registered_fish_df.append({&#39;min_number_matching_dots_registration&#39;:error,
                                                           &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num) },ignore_index=True)
    elif status == &#39;SUCCESS&#39;:
        reference_hybridization = analysis_parameters[&#39;RegistrationReferenceHybridization&#39;]
        reference_hybridization_str = &#39;Hybridization&#39; + str(reference_hybridization).zfill(2)
        
        for zarr_name in counts_zarr_names:
            round_num = int(zarr_name.split(&#39;_&#39;)[-4].split(&#39;Hybridization&#39;)[-1])
            try:
                fish_counts, fish_img_metadata = counts_output[&#39;fish&#39;][channel][zarr_name]
            except:
                logger.error(f&#39;missing the counts in {zarr_name}&#39;)
                
                registered_fish_df = registered_fish_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.cannot_load_file_fish_channel,
                                                &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:round_num },ignore_index=True)
                status = &#39;FAILED&#39;
                break
            else:                
                if np.any(np.isnan(fish_counts[&#39;r_px_original&#39;])):
                    logger.error(f&#39;There are no dots in there reference hyb for fov {fov} &#39;)
                    registered_fish_df = registered_fish_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.missing_counts_fish_channel,
                                                &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:round_num },ignore_index=True)
                    status = &#39;FAILED&#39;
                    break

                else:
                    if reference_hybridization_str in zarr_name:
                        fish_img_metadata[&#39;reference_hyb&#39;] = reference_hybridization
                        registered_fish_df.attrs[fov] = fish_img_metadata
                    fish_counts_df = pd.DataFrame(fish_counts)
                    
                    subset_df = registered_reference_channel_df.loc[registered_reference_channel_df[&#39;round_num&#39;] == round_num, :]
                    subset_df = subset_df.reset_index()
                        
                    shift = all_rounds_shifts[round_num]
                    fish_counts_df[&#39;r_px_registered&#39;] = fish_counts[&#39;r_px_original&#39;] + shift[0]
                    fish_counts_df[&#39;c_px_registered&#39;] = fish_counts[&#39;c_px_original&#39;] + shift[1]
                    fish_counts_df[&#39;r_shift_px&#39;] = shift[0]
                    fish_counts_df[&#39;c_shift_px&#39;] = shift[1]
                    fish_counts_df[&#39;min_number_matching_dots_registration&#39;] = subset_df.loc[0,&#39;min_number_matching_dots_registration&#39;] 
                    fish_counts_df[&#39;reference_hyb&#39;] = reference_hybridization
                    fish_counts_df[&#39;experiment_type&#39;] = subset_df.loc[0,&#39;experiment_type&#39;]
                    fish_counts_df[&#39;experiment_name&#39;] = subset_df.loc[0,&#39;experiment_name&#39;]
                    fish_counts_df[&#39;pxl_um&#39;] = subset_df.loc[0,&#39;pxl_um&#39;]
                    fish_counts_df[&#39;stitching_type&#39;] = subset_df.loc[0,&#39;stitching_type&#39;]
                    fish_counts_df[&#39;fov_acquisition_coords_x&#39;] = subset_df.loc[0,&#39;fov_acquisition_coords_x&#39;]
                    fish_counts_df[&#39;fov_acquisition_coords_y&#39;] = subset_df.loc[0,&#39;fov_acquisition_coords_y&#39;]
                    fish_counts_df[&#39;fov_acquisition_coords_z&#39;] = subset_df.loc[0,&#39;fov_acquisition_coords_z&#39;]
                    fish_counts_df[&#39;img_width_px&#39;] = fish_img_metadata[&#39;img_width&#39;]
                    fish_counts_df[&#39;img_height_px&#39;] = fish_img_metadata[&#39;img_height&#39;]




                    registered_fish_df = pd.concat([registered_fish_df,fish_counts_df],axis=0,ignore_index=True)
                    status = &#39;SUCCESS&#39;

    return registered_fish_df, status






def calculate_shift_hybridization_fov_nuclei(processing_files:List,analysis_parameters:dict, save=True):
    &#34;&#34;&#34;
    Function used to run the registration of a single fov
    through all hybridization. The registration is done using the dots
    coords determined in each image

    Args:
        processing_files: List
            list of the files with the filtered images of the nuclei
        analysis_parameters: Dict
            dict that contains the settings for the analysis 
    &#34;&#34;&#34;
    
    logger = selected_logger()
    all_rounds_shifts = {}
    all_rounds_shifts_RMS = {}
    registration_errors = Registration_errors()
    data_models = Output_models()
    output_registration_df = data_models.output_registration_df
    status = &#39;SUCCESS&#39;

    reference_hybridization = analysis_parameters[&#39;RegistrationReferenceHybridization&#39;]
    round_num = reference_hybridization
    reference_hybridization_str = &#39;Hybridization&#39; + str(reference_hybridization).zfill(2)
    registration_tollerance_pxl = analysis_parameters[&#39;RegistrationTollerancePxl&#39;]

    # collect info used to generate fname when files are corrupted   
    experiment_fpath = processing_files[0].parent.parent.parent
    channel = (processing_files[0].stem).split(&#39;_&#39;)[-4]
    experiment_name = experiment_fpath.stem
    fov = (processing_files[0].stem).split(&#39;_&#39;)[-2]
    file_tags = {&#39;experiment_fpath&#39;:experiment_fpath,
                &#39;experiment_name&#39;:experiment_name,
                &#39;channel&#39;:channel,
                &#39;fov&#39;:fov}

    shift_fname = experiment_fpath / &#39;tmp&#39; / &#39;registered_counts&#39; / (experiment_name + &#39;_&#39; + channel + &#39;_nuclei_all_rounds_shifts_fov_&#39; + fov + &#39;.pkl&#39;)
    shift_error_fname = experiment_fpath / &#39;tmp&#39; / &#39;registered_counts&#39; / (experiment_name + &#39;_&#39; + channel + &#39;_nuclei_all_rounds_shifts_errors_fov_&#39; + fov + &#39;.pkl&#39;)
    
    # Load reference hybridization data
    try:
        ref_fpath = [fpath for fpath in processing_files if reference_hybridization_str in fpath.as_posix()][0]
    except:
        logger.error(f&#39;missing reference hyb file for fov {fov}&#39;)
        status = &#39;FAILED&#39;
        all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
        all_rounds_shifts_RMS[round_num] = 1
    else:
        try:
            ref_img,ref_img_metadata = pickle.load(open(ref_fpath, &#39;rb&#39;))
        except:
            logger.error(f&#39;cannot open the reference hyb file for fov {fov}&#39;)
            status = &#39;FAILED&#39;
            all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
            all_rounds_shifts_RMS[round_num] = 1
        else:   
                tran_processing_files =processing_files.copy()
                tran_processing_files.remove(ref_fpath)
                
                for fpath in tran_processing_files:
                    try:
                        tran_img, tran_img_metadata = pickle.load(open(fpath, &#39;rb&#39;))
                    except:
                        logger.error(f&#39;cannot open {fpath.stem} file for fov {fov}&#39;)
                        # If there is an error in the opening reset the df
                        round_num = int((fpath.stem).split(&#39;_&#39;)[-5].split(&#39;Hybridization&#39;)[-1])
                        status = &#39;FAILED&#39;
                        all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
                        all_rounds_shifts_RMS[round_num] = 1
                        break
                    else:                    
                            round_num = int((fpath.stem).split(&#39;_&#39;)[-5].split(&#39;Hybridization&#39;)[-1])
                            ref_img_metadata[&#39;reference_hyb&#39;] = str(reference_hybridization)
                            
                            shift, error, diffphase = phase_cross_correlation(ref_img, tran_img,return_error=True,)
                            all_rounds_shifts[round_num] = shift
                            all_rounds_shifts_RMS[round_num] = error
        
        # Save extra metadata in the
        if save:
            pickle.dump(all_rounds_shifts,open(shift_fname,&#39;wb&#39;))
            pickle.dump(all_rounds_shifts_RMS,open(shift_error_fname,&#39;wb&#39;))

        return all_rounds_shifts, all_rounds_shifts_RMS, file_tags, status






def calculate_shift_hybridization_fov_nuclei_test(
                                            img_stack:np.ndarray,
                                            analysis_parameters:Dict):
    &#34;&#34;&#34;
    Function used to run the registration of a single fov
    through all hybridization. The registration is done using the dots
    coords determined in each image

    Args:
        processing_files: List
            list of the files with the counts to register
        analysis_parameters: Dict
            dict that contains the settings for the analysis 


    MUST ADD THE CONSIDERATION OF POTENTIAL ERRORS
    &#34;&#34;&#34;
    
    logger = selected_logger()
    
    registration_errors = Registration_errors()
  
    ref_round_num = analysis_parameters[&#39;RegistrationReferenceHybridization&#39;] - 1
    registration_tollerance_pxl = analysis_parameters[&#39;RegistrationTollerancePxl&#39;]

    all_rounds = np.arange(img_stack.shape[0])
    all_rounds = all_rounds[all_rounds != ref_round_num]

    ref_img = img_stack[ref_round_num,:,:]

    all_rounds_reg = []
    ref_df = pd.DataFrame({&#39;round_num&#39;:ref_round_num + 1,
                                            &#39;r_shift_px&#39;: 0,
                                            &#39;c_shift_px&#39;:0,
                                            &#39;min_number_matching_dots_registration&#39;:1000,
                                            &#39;RMS&#39;:0})

    all_rounds_reg.append(ref_df)
    for r_num in all_rounds:
        shift, error, diffphase = phase_cross_correlation(ref_img, img_stack[r_num,:,:],return_error=True)    
        tran_df = pd.DataFrame({&#39;round_num&#39;:[r_num + 1],
                                        &#39;r_shift_px&#39;: [shift[0]],
                                        &#39;c_shift_px&#39;:[shift[1]],
                                        &#39;min_number_matching_dots_registration&#39;:error,
                                        &#39;RMS&#39;:error})

        all_rounds_reg.append(tran_df)

    output_registration_df = pd.concat([all_rounds_reg],axis=0,ignore_index=True)


    return output_registration_df





def register_fish_on_nuclei_test(fov:int,
                        counts_output:Dict,
                        registered_reference_channel_df,
                        all_rounds_shifts:Dict,
                        analysis_parameters:Dict,
                        status:str):

    logger = selected_logger()
    registration_errors = Registration_errors()
    data_models = Output_models()

    registered_fish_df = data_models.output_registration_df

    if status == &#39;FAILED&#39;:
        error = registered_reference_channel_df[&#39;min_number_matching_dots_registration&#39;].values[0]
        round_num = registered_reference_channel_df[&#39;round_num&#39;].values[0]
        registered_fish_df = registered_fish_df.append({&#39;min_number_matching_dots_registration&#39;:error,
                                                           &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num) },ignore_index=True)
    elif status == &#39;SUCCESS&#39;:
        reference_hybridization = analysis_parameters[&#39;RegistrationReferenceHybridization&#39;]
        reference_hybridization_str = &#39;Hybridization&#39; + str(reference_hybridization).zfill(2)
        
        for channel, all_counts_dict in counts_output[&#39;fish&#39;].items():
            for zarr_name, fish_counts_tpl in all_counts_dict.items():
                round_num = int(zarr_name.split(&#39;_&#39;)[-4].split(&#39;Hybridization&#39;)[-1])
                
                fish_counts, fish_img_metadata = fish_counts_tpl

                fish_counts_df = pd.DataFrame(fish_counts)
                shift = all_rounds_shifts[round_num]
                fish_counts_df[&#39;r_px_registered&#39;] = fish_counts[&#39;r_px_original&#39;] + shift[0]
                fish_counts_df[&#39;c_px_registered&#39;] = fish_counts[&#39;c_px_original&#39;] + shift[1]
                fish_counts_df[&#39;r_shift_px&#39;] = shift[0]
                fish_counts_df[&#39;c_shift_px&#39;] = shift[1]
                # fish_counts_df[&#39;min_number_matching_dots_registration&#39;] = fish_counts[&#39;min_number_matching_dots_registration&#39;]
                fish_counts_df[&#39;reference_hyb&#39;] = reference_hybridization
                # fish_counts_df[&#39;experiment_type&#39;] = fish_counts[&#39;experiment_type&#39;]
                # fish_counts_df[&#39;experiment_name&#39;] = fish_counts[&#39;experiment_name&#39;]
                # fish_counts_df[&#39;pxl_um&#39;] = fish_counts[&#39;pxl_um&#39;]
                # fish_counts_df[&#39;stitching_type&#39;] = fish_counts[&#39;stitching_type&#39;]
                # fish_counts_df[&#39;fov_acquisition_coords_x&#39;] = fish_counts[&#39;fov_acquisition_coords_x&#39;]
                # fish_counts_df[&#39;fov_acquisition_coords_y&#39;] = fish_counts[&#39;fov_acquisition_coords_y&#39;]
                # fish_counts_df[&#39;fov_acquisition_coords_z&#39;] = fish_counts[&#39;fov_acquisition_coords_z&#39;]
                # fish_counts_df[&#39;img_width_px&#39;] = fish_img_metadata[&#39;img_width&#39;]
                # fish_counts_df[&#39;img_height_px&#39;] = fish_img_metadata[&#39;img_height&#39;]
                
                registered_fish_df = pd.concat([registered_fish_df,fish_counts_df],axis=0,ignore_index=True)
        status = &#39;SUCCESS&#39;

    return registered_fish_df, status


def register_fish_on_nuclei(processing_files:List,analysis_parameters:Dict,
                        registered_reference_channel_df,all_rounds_shifts:Dict,file_tags:Dict,status:str,
                        save=True):
    &#34;&#34;&#34;
    The only difference to the other function is the channel name definition
    &#34;&#34;&#34;
    logger = selected_logger()
    registration_errors = Registration_errors()
    data_models = Output_models()
    fov = file_tags[&#39;fov&#39;]
    channel = &#39;all_channels&#39;
    file_tags[&#39;channel&#39;] = channel
    registered_fish_df = data_models.output_registration_df

    if status == &#39;FAILED&#39;:
        error = registered_reference_channel_df[&#39;min_number_matching_dots_registration&#39;].values[0]
        round_num = registered_reference_channel_df[&#39;round_num&#39;].values[0]
        registered_fish_df = registered_fish_df.append({&#39;min_number_matching_dots_registration&#39;:error,
                                                           &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num) },ignore_index=True)
    elif status == &#39;SUCCESS&#39;:
        reference_hybridization = registered_reference_channel_df.attrs[fov][&#39;reference_hyb&#39;]
        reference_hybridization_str = &#39;Hybridization&#39; + str(reference_hybridization).zfill(2)
        for fpath in processing_files:
            round_num = int((fpath.stem).split(&#39;_&#39;)[-5].split(&#39;Hybridization&#39;)[-1])
            try:
                fish_counts, fish_img_metadata = pickle.load(open(fpath,&#39;rb&#39;))
            except:
                logger.error(f&#39;cannot open the processing files&#39;)
                
                registered_fish_df = registered_fish_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.cannot_load_file_fish_channel,
                                                &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:round_num },ignore_index=True)
                status = &#39;FAILED&#39;
                break
            else:                
                if np.any(np.isnan(fish_counts[&#39;r_px_original&#39;])):
                    logger.error(f&#39;There are no dots in there reference hyb for fov {fov} &#39;)
                    registered_fish_df = registered_fish_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.missing_counts_fish_channel,
                                                &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:round_num },ignore_index=True)
                    status = &#39;FAILED&#39;
                    break

                else:
                    if reference_hybridization_str in fpath.as_posix():
                        fish_img_metadata[&#39;reference_hyb&#39;] = reference_hybridization
                        registered_fish_df.attrs[fov] = fish_img_metadata
                    fish_counts_df = pd.DataFrame(fish_counts)
                    
                    subset_df = registered_reference_channel_df.loc[registered_reference_channel_df[&#39;round_num&#39;] == round_num, :]
                    subset_df = subset_df.reset_index()
                        
                    shift = all_rounds_shifts[round_num]
                    fish_counts_df[&#39;r_px_registered&#39;] = fish_counts[&#39;r_px_original&#39;] + shift[0]
                    fish_counts_df[&#39;c_px_registered&#39;] = fish_counts[&#39;c_px_original&#39;] + shift[1]
                    fish_counts_df[&#39;r_shift_px&#39;] = shift[0]
                    fish_counts_df[&#39;c_shift_px&#39;] = shift[1]
                    fish_counts_df[&#39;min_number_matching_dots_registration&#39;] = subset_df.loc[0,&#39;min_number_matching_dots_registration&#39;] 
                    registered_fish_df = pd.concat([registered_fish_df,fish_counts_df],axis=0,ignore_index=True)
                    status = &#39;SUCCESS&#39;

    if save:
        fname = file_tags[&#39;experiment_fpath&#39;] / &#39;tmp&#39; / &#39;registered_counts&#39; / (file_tags[&#39;experiment_name&#39;] + &#39;_&#39; + file_tags[&#39;channel&#39;] +&#39;_registered_fov_&#39; + file_tags[&#39;fov&#39;] + &#39;.parquet&#39;)
        registered_fish_df.to_parquet(fname,index=False)
    return registered_fish_df, file_tags, status

def create_registration_grps(experiment_fpath:str,registration_channel:str, fovs:List, save=True):
    &#34;&#34;&#34;
    Function to create groups of files that need to be registered together
    Args:
        experiment_fpath: str
            Path to the exp directory 
        registration_channel : str
            Name of the channel used for registration of the fovs
        fovs: List
            List of the keys used for grouping
    Returns:
        all_grps: List
            List of tuples containing the file names of reference
            channel and fish grouped by fov
    &#34;&#34;&#34;
    logger = selected_logger()
    tmp_fpath = Path(experiment_fpath) / &#39;tmp/raw_counts&#39;
    all_files = set(tmp_fpath.glob(&#39;*&#39;))
    registration_files = list(tmp_fpath.glob(&#39;*&#39; + registration_channel + &#39;*&#39;))
    fish_files = all_files.difference(registration_files)

    all_grps = []
    for fov in fovs:
        search_key_reg = registration_channel + &#39;_fov_&#39; + str(fov) + &#39;_dots.pkl&#39;
        search_key_fish =  &#39;_fov_&#39; + str(fov) + &#39;_dots.pkl&#39;
        grp_reg = [reg_f for reg_f in registration_files if search_key_reg in reg_f.as_posix()]
        grp_fish = [fish_f for fish_f in fish_files if search_key_fish in fish_f.as_posix()]
        logger.debug(f&#39;fov {fov} for registration on {registration_channel} has {len(grp_reg)} counts files&#39;)
        all_grps.append((grp_reg, grp_fish))
    if save:
        fname = Path(experiment_fpath) / &#39;tmp&#39; / &#39;registration_groups.pkl&#39;
        pickle.dump(all_grps, open(fname,&#39;wb&#39;))
    return all_grps



































#         counts_df = data[0]




# def registration_fish_hybridization(reference_coords:np.ndarray,shift:np.ndarray,
#                                     fov_num:int, hybridization_num_translated:int):
#     &#34;&#34;&#34;
#     Function for the registration of the fish counts using
#     the shift calculated by aligning the registration channel

#     Parameters:
#     -----------

#     all_rounds_shifts: dict
#         dictionary containing the round number as key and 
#         shift as item
#     counts: pandas dataframe
#         pandas dataframe containing the fish counting 
#         output

#     &#34;&#34;&#34;
#     logger = prefect.utilities.logging.get_logger(&#34;registration_fish&#34;)

#     if len(reference_coords):
#         if np.any(np.isnan(shift)):
#             registered_coords = reference_coords
#             logger.info(f&#39;registration of {fov_num} of hybridization {hybridization_num_translated} failed&#39;)
#         else:
#             registered_coords = reference_coords + shift
#     else:
#         logger.info(f&#39;no counts in fov {fov_num} of hybridization {hybridization_num_translated}&#39;)
#         registered_coords=np.array([np.nan,np.nan])
    
#     return registered_coords, shift



# @task(name=&#39;create-combinations-registration-fov&#39;)
# def hybridizations_registration_grps(experiment_info):

#     logger = prefect_logging_setup(&#34;create-combination-registration-fov&#34;)

#     experiment_name = experiment_info[&#39;EXP_number&#39;]
#     reference_hybridization_number = 1
#     reference_fov = 355
   
#     dots_ws, images_properties_ws, experiment_properties_ws, analysis_parameters_ws = connect_to_shoji_smfish_experiment(experiment_name)

#     stitching_channel = experiment_properties_ws[:].StitchingChannel
#     fields_of_view = images_properties_ws.FieldsOfView[(images_properties_ws.FovNumber == reference_fov) &amp;
#                                                 (images_properties_ws.AcquistionChannel == stitching_channel) &amp;
#                                                 (images_properties_ws.HybridizationNumber == reference_hybridization_number)]


#     fields_of_view = fields_of_view.reshape(fields_of_view.shape[1],)
    
#     fields_of_view = [355,73,122]
    
#     number_hybridizations = np.unique( images_properties_ws.HybridizationNumber[(images_properties_ws.AcquistionChannel == stitching_channel) &amp; 
#                                                                             (images_properties_ws.FovNumber == reference_fov)])
    
#     # I will keep registration also for the reference hyb with itself to avoid extra function to rewrite the coords of
#     # unprocessed hyb
#     # number_hybridizations = number_hybridizations[number_hybridizations &gt; reference_hybridization_number]
    
#     processing_combinations = list(itertools.product([stitching_channel],fields_of_view,[reference_hybridization_number],number_hybridizations))
    
#     return processing_combinations


# @task(name=&#39;calculate-shift-fov&#39;)
# def calculate_shift_hybridization_fov(processing_combination,experiment_info):
#     logger = prefect_logging_setup(&#34;calculate-shift-fov&#34;)
#     # Add try exect for determine if the ws are there
#     experiment_name = experiment_info[&#39;EXP_number&#39;]
    
#     dots_ws, images_properties_ws, experiment_properties_ws, analysis_parameters_ws = connect_to_shoji_smfish_experiment(experiment_name)
    
#     img_shape = images_properties_ws.ImageShape[(images_properties_ws.AcquistionChannel == processing_combination[0]) &amp; 
#                                             (images_properties_ws.FovNumber == processing_combination[1]) &amp; 
#                                             (images_properties_ws.HybridizationNumber == processing_combination[2])]
#     img_shape = img_shape.reshape(2,)
    

#     ref_dots_coords_fov = dots_ws.DotCoordsFOV[(dots_ws.FovNumber == processing_combination[1]) &amp;
#                                 (dots_ws.DotChannel == processing_combination[0]) &amp;
#                                 (dots_ws.HybridizationNumber == processing_combination[2])]
#     ref_dots_coords_fov = ref_dots_coords_fov.reshape(ref_dots_coords_fov.shape[0],2)
    

#     tran_dots_coords_fov = dots_ws.DotCoordsFOV[(dots_ws.FovNumber == processing_combination[1]) &amp;
#                                     (dots_ws.DotChannel == processing_combination[0]) &amp;
#                                     (dots_ws.HybridizationNumber == processing_combination[3])]
#     tran_dots_coords_fov = tran_dots_coords_fov.reshape(tran_dots_coords_fov.shape[0],2)
    
#     tran_registered_coords, shift, error, fov_num, hybridization_num_translated = \
#                             fft_registration_beads(ref_dots_coords_fov, tran_dots_coords_fov,
#                         img_shape=img_shape, fov_num=processing_combination[1],
#                         hybridization_num_translated=processing_combination[3])
    
    
#     # Write out the registration shift on shoji
#     shift = shift.reshape(1,1,1,2)
#     stitching_channel = experiment_properties_ws[:].StitchingChannel
#     images_properties_ws.RegistrationShift[(images_properties_ws.FovNumber == processing_combination[1]) &amp; 
#                 (images_properties_ws.HybridizationNumber == processing_combination[3]) &amp;
#                 (images_properties_ws.AcquistionChannel == stitching_channel)] = shift
    
#     # Translate the coords of all the dots for all channels and save data in shoji
#     dots_ws.DotsCoordsRegisteredFOV[(dots_ws.FovNumber == processing_combination[1]) &amp;
#             (dots_ws.HybridizationNumber == processing_combination[3])] =  dots_ws.DotCoordsFOV[(dots_ws.FovNumber == processing_combination[1]) &amp;
#             (dots_ws.HybridizationNumber == processing_combination[3])] + shift


#     # Calculate error shift and write it out on shoji
#     if (ref_dots_coords_fov.shape[0] &gt;0) and (tran_registered_coords.shape[0] &gt;0):
#         pxl = analysis_parameters_ws.BarcodesExtractionResolution[:]
#         number_matching_dots = identify_matching_register_dots_NN(ref_dots_coords_fov,tran_registered_coords,pxl)
#         number_matching_dots = np.array(number_matching_dots, dtype=np.float64).reshape(1,1,1)
#         all_errors = images_properties_ws.RegistrationError[(images_properties_ws.FovNumber == processing_combination[1]) &amp; 
#                 (images_properties_ws.HybridizationNumber == processing_combination[3])] 
#         number_matching_dots =np.repeat(number_matching_dots,all_errors.shape[0]).reshape(all_errors.shape[0],1,1)
#         images_properties_ws.RegistrationError[(images_properties_ws.FovNumber == processing_combination[1]) &amp; 
#                 (images_properties_ws.HybridizationNumber == processing_combination[3])] = number_matching_dots
#     else:
#         all_errors = images_properties_ws.RegistrationError[(images_properties_ws.FovNumber == processing_combination[1]) &amp; 
#                 (images_properties_ws.HybridizationNumber == processing_combination[3])] 
#         number_matching_dots =np.repeat(0,all_errors.shape[0]).reshape(all_errors.shape[0],1,1)
#         images_properties_ws.RegistrationError[(images_properties_ws.FovNumber == processing_combination[1]) &amp; 
#                 (images_properties_ws.HybridizationNumber == processing_combination[3])] = number_matching_dots




# @task(name=&#39;registration-fish-round&#39;)
# def registration_fish_hybridization(reference_coords:np.ndarray,shift:np.ndarray,
#                                     fov_num:int, hybridization_num_translated:int):
#     &#34;&#34;&#34;
#     Function for the registration of the fish counts using
#     the shift calculated by aligning the registration channel

#     Parameters:
#     -----------

#     all_rounds_shifts: dict
#         dictionary containing the round number as key and 
#         shift as item
#     counts: pandas dataframe
#         pandas dataframe containing the fish counting 
#         output

#     &#34;&#34;&#34;
#     logger = prefect.utilities.logging.get_logger(&#34;registration_fish&#34;)

#     if len(reference_coords):
#         if np.any(np.isnan(shift)):
#             registered_coords = reference_coords
#             logger.info(f&#39;registration of {fov_num} of hybridization {hybridization_num_translated} failed&#39;)
#         else:
#             registered_coords = reference_coords + shift
#     else:
#         logger.info(f&#39;no counts in fov {fov_num} of hybridization {hybridization_num_translated}&#39;)
#         registered_coords=np.array([np.nan,np.nan])
    
#     return registered_coords, shift























############
# utility function to use in stitching
def determine_overlap_region(self):
        &#34;&#34;&#34;Determine the overlap between two neighbouring tiles

        Parameters:
        -----------

        ind1: int
            Index (flattened) of tile 1
        ind2: int
            Index (flattened) of tile 2

        micData: object
            MicroscopeData object containing coordinates

        Returns:
        --------

        overlap1: np.array
            Overlapping part of tile_1
        overlap2: np.array
            Overlapping part of tile_2
        plot_order: np.array
            Numpy array of ones. The shape of this array is
            used for plotting the overlaps in well fitting
            subplots.
        &#34;&#34;&#34;
        
        
        if np.ma.is_masked(self.micData.tile_set.flat[:][self.ind1]):
            tile_1 = False
        else:
            tile_1 = True
            fnum_tile_1 = self.micData.tile_set.flat[:][self.ind1] + self.micData.tile_nr.min()
            
        
        if np.ma.is_masked(self.micData.tile_set.flat[:][self.ind2]):
            tile_2 = False
        else:
            tile_2 = True
            fnum_tile_2 = self.micData.tile_set.flat[:][self.ind2] + self.micData.tile_nr.min()
            

        if (tile_1 and tile_2):
            self.tiles_num = (fnum_tile_1, fnum_tile_2)
            self.tile1_x_coords = self.micData.x_coords[self.micData.tile_set.flat[:][self.ind1]]
            self.tile2_x_coords = self.micData.x_coords[self.micData.tile_set.flat[:][self.ind2]]
            self.tile1_y_coords = self.micData.y_coords[self.micData.tile_set.flat[:][self.ind1]]
            self.tile2_y_coords = self.micData.y_coords[self.micData.tile_set.flat[:][self.ind2]]

            tile_1_fpath = [fpath for fpath in self.counting_files_list if &#39;pos_&#39;+str(fnum_tile_1)+&#39;.&#39; in str(fpath)][0]
            self.tile_1_store = zarr.DirectoryStore(tile_1_fpath)
            self.tile_1_root = zarr.group(store=self.tile_1_store, overwrite=False)
            self.tile_1_counts = self.tile_1_root[&#39;stringency_raw_counts&#39;][&#39;coords_original&#39;][...]
            tile_1_ref_coords = np.array([self.tile1_y_coords,self.tile1_x_coords])
            tile_1_ref_coords = tile_1_ref_coords[:,np.newaxis]
            self.tile_1_adj_coords = self.tile_1_counts + tile_1_ref_coords


            tile_2_fpath = [fpath for fpath in self.counting_files_list if &#39;pos_&#39;+str(fnum_tile_2)+&#39;.&#39; in str(fpath)][0]
            self.tile_2_store = zarr.DirectoryStore(tile_2_fpath)
            self.tile_2_root = zarr.group(store=self.tile_2_store, overwrite=False)
            self.tile_2_counts = self.tile_2_root[&#39;stringency_raw_counts&#39;][&#39;coords_original&#39;][...]
            tile_2_ref_coords = np.array([self.tile2_y_coords,self.tile2_x_coords])
            tile_2_ref_coords = tile_2_ref_coords[:,np.newaxis]
            self.tile_2_adj_coords = self.tile_2_counts + tile_2_ref_coords


            
            if self.tile1_y_coords &gt; self.tile2_y_coords:
                r_tl = self.tile1_y_coords
                r_br = self.tile2_y_coords + self.img_size

                r_bl = self.tile2_y_coords + self.img_size
                r_tr = self.tile1_y_coords
                
            else:
                r_tl = self.tile2_y_coords
                r_br = self.tile1_y_coords + self.img_size
                
                r_bl = self.tile1_y_coords + self.img_size
                r_tr = self.tile2_y_coords

            if self.tile1_x_coords &gt; self.tile2_x_coords:
                c_tl = self.tile1_x_coords
                c_br = self.tile2_x_coords + self.img_size
                
                c_tr = self.tile2_x_coords + self.img_size
                c_bl = self.tile1_x_coords
                
            else:
                c_tl = self.tile2_x_coords
                c_br = self.tile1_x_coords + self.img_size
                
                c_bl = self.tile2_x_coords
                c_tr = self.tile1_x_coords + self.img_size


            self.tl_coords = np.array([r_tl,c_tl])
            self.br_coords = np.array([r_br,c_br])
            self.tr_coords = np.array([r_tr,c_tr])
            self.bl_coords = np.array([r_bl,c_bl])
            num_r = np.abs(self.tl_coords[1] - self.tr_coords[1])
            num_c = np.abs(self.tr_coords[0] - self.bl_coords[0])
            self.region_dimensions = (num_c,num_r)


        else:
            self.tl_coords = self.br_coords = self.tr_coords = self.bl_coords = None
            
###################################




class chunking():
    &#34;&#34;&#34;
    utility class to create processing chunks
    &#34;&#34;&#34;

    def __init__(self, region_dimensions, chunk_size, percent_padding, tl_coords):
        self.region_dimensions = region_dimensions
        self.chunk_size = chunk_size
        self.percent_padding = percent_padding
        self.tl_coords = tl_coords
    

    @staticmethod
    def block_chunks_calculator(dimension,chunk_size):
        &#34;&#34;&#34;
        Helper function to calculate the size of the chunks created according
        the length of the vector and the chunk size.

        Parameters:
        -----------

        dimension: int
            Length of the vector to Chunk
        chunkSize: int 
            Dimension of the Chunks

        Returns:
        -----------

        chunks_sizes: np.array 
            Array of the sizes of the created chunks. It deals with conditions 
            when the expected chunks size do not fit an even number of times in the 
            dimension
        &#34;&#34;&#34;
        number_even_chunks=int(dimension//chunk_size)
        total_size_even_chunks=number_even_chunks*chunk_size
        odd_tile_size=dimension-total_size_even_chunks
        chunk_sizes=[]
        chunks_sizes=list(np.repeat(chunk_size,number_even_chunks-1))
        if odd_tile_size &lt; chunk_size:
            chunks_sizes.append(chunk_size+odd_tile_size)
        else:
            chunks_sizes.append(odd_tile_size)
        return tuple(chunks_sizes)
    
    def block_chunking(self):
        &#34;&#34;&#34;
        Function used to generate the coords of the images according to the
        chunking 

        Parameters:
        -----------

        PercentPadding: float 
            Percent of overlapping between the different images (Ex. 0.2).
        ChunkSize: int 
            Dimension of the Chunks.

        Returns:
        -----------

        Coords_Chunks_list: list 
            List of np.array with the coords of the images without padding
        Coords_Padded_Chunks_list: list 
            List of np.array with the coords of the images with padding

        Notes:
        ------

        For both lists each np.array contains the coords in the following order:
        [row_tl,row_br,col_tl,col_br]

        &#34;&#34;&#34;
        num_r,num_c = self.region_dimensions
        pixel_padding = int(self.chunk_size*self.percent_padding)
        self.starting_position = self.tl_coords

        # Calculate the size of the chunks
        r_chunks_size = self.block_chunks_calculator(num_r,self.chunk_size)
        
        c_chunks_size = self.block_chunks_calculator(num_c,self.chunk_size)
        
        # Calculate the total numbers of chunks
        nr_chunks = len(r_chunks_size)
        
        nc_chunks = len(c_chunks_size)
       


        # Coords top left corner (tl)
        if nr_chunks == 1:
            r_coords_tl = self.starting_position[0]
        else:  
            r_coords_tl = np.arange(self.starting_position[0],(self.starting_position[0]+self.chunk_size*(nr_chunks)),self.chunk_size)
        
        
        if nc_chunks == 1:
            c_coords_tl = self.starting_position[1]
        else:
            c_coords_tl = np.arange(self.starting_position[1],(self.starting_position[1]+self.chunk_size*(nc_chunks)),self.chunk_size)

        
        # Coords of all the tl in the image
        r_coords_tl_all,c_coords_tl_all = np.meshgrid(r_coords_tl,c_coords_tl,indexing=&#39;ij&#39;)
        self.coords_all_to_test = [r_coords_tl_all,c_coords_tl_all]
        # Calculate all the br coords
        r_coords_br_all = r_coords_tl_all.copy()
        c_coords_br_all = c_coords_tl_all.copy()

        for c in np.arange(0,r_coords_tl_all.shape[1]):
            r_coords_br_all[:,c] = r_coords_br_all[:,c]+r_chunks_size

        for r in np.arange(0,r_coords_tl_all.shape[0]):
             c_coords_br_all[r,:] = c_coords_br_all[r,:]+c_chunks_size

        # Calculate the padded coords
        r_coords_tl_all_padded = r_coords_tl_all-pixel_padding
        c_coords_tl_all_padded = c_coords_tl_all-pixel_padding
        r_coords_br_all_padded = r_coords_br_all+pixel_padding
        c_coords_br_all_padded = c_coords_br_all+pixel_padding

        # Correct for coords out of the image (where tl&lt;0,br&gt;Img.shape)
        r_coords_tl_all_padded[r_coords_tl_all_padded&lt;0] = r_coords_tl_all[r_coords_tl_all_padded&lt;0]
        c_coords_tl_all_padded[c_coords_tl_all_padded&lt;0] = c_coords_tl_all[c_coords_tl_all_padded&lt;0]
        r_coords_br_all_padded[r_coords_br_all_padded&gt;num_r] = r_coords_br_all[r_coords_br_all_padded&gt;num_r]
        c_coords_br_all_padded[c_coords_br_all_padded&gt;num_c] = c_coords_br_all[c_coords_br_all_padded&gt;num_c]

        # The coords list are generated as:
        # row_tl,row_br,col_tl,col_br


        # Create a list for the padded coords
        self.Coords_Padded_Chunks_list = list()
        for r in np.arange(0,r_coords_tl_all_padded.shape[0]):
            for c in np.arange(0,r_coords_tl_all_padded.shape[1]):
                self.Coords_Padded_Chunks_list.append(np.array([r_coords_tl_all_padded[r][c],\
                                                           r_coords_br_all_padded[r][c],\
                                                           c_coords_tl_all_padded[r][c],\
                                                           c_coords_br_all_padded[r][c]])) 
    


class reference_beads_registration():

    def __init__(self,ref_hyb_coords, comp_hyb_coords, Coords_Padded_Chunks_list, n_neighbors,
                min_acceptable_distance, min_samples, residual_threshold, max_trials, matching_radius):

        self.ref_hyb_coords = ref_hyb_coords
        self.comp_hyb_coords = comp_hyb_coords
        self.Coords_Padded_Chunks_list = Coords_Padded_Chunks_list

        self.n_neighbors = n_neighbors
        self.min_acceptable_distance = min_acceptable_distance
        self.min_samples = min_samples
        self.residual_threshold = residual_threshold
        self.max_trials = max_trials
        self.matching_radius = matching_radius

        self.logger = logging.getLogger(__name__)

    @staticmethod
    def calculate_min_distances(selected_ref):
        ref_dist = distance.cdist(selected_ref.T, selected_ref.T)
        ref_dist = np.triu(ref_dist)
        ref_dist = ref_dist[:-1,:]
        mref = np.ma.masked_where(ref_dist==0,ref_dist)
        mref_min = mref.min(axis=1)
        return np.sort(mref_min.data)
    
    @staticmethod
    # CALCULATE ERROR OVER THE DIAGONAL
    def errors(transformed_coords, ref_good):
        diagonals = np.sqrt((ref_good[:,0]- transformed_coords[:,0])**2 + (ref_good[:,1]- transformed_coords[:,1])**2)
        diagonal_mean = np.mean(diagonals,axis=0)
        diagonal_median = np.median(diagonals,axis=0)
        err1 = np.sum((diagonals-diagonal_mean),axis=0)/len(diagonals)
        err2 = np.sum((diagonals-diagonal_mean)**2,axis=0)/len(diagonals)
        diag_std = np.std(diagonals)
        diag_sem = diag_std/len(diagonals)
        
        # delta = np.abs(ref_good - transformed_coords)
        # delta_mean = np.mean(delta,axis=0)
        # err1 = np.sum((delta-delta_mean),axis=0)/len(transformed_coords)
        # err2 = np.sum((delta-delta_mean)**2,axis=0)/len(transformed_coords)
        return err1,err2, diagonal_mean, diagonal_median, diag_std, diag_sem

    def calculate_NN_roi(self,chunk_coords):    
        r_tl = chunk_coords[0]
        r_br = chunk_coords[1]
        c_tl = chunk_coords[2]
        c_br = chunk_coords[3]

        # Select only the coords in the trimmed region
        ref_trimmed = self.ref_hyb_coords[:,((r_tl &lt; self.ref_hyb_coords[0,:]) &amp; (self.ref_hyb_coords[0,:]&lt;r_br)\
                                      &amp; (c_tl &lt;self.ref_hyb_coords[1,:]) &amp;(self.ref_hyb_coords[1,:]&lt;c_br)) ]
        tran_trimmed = self.comp_hyb_coords[:,((r_tl &lt; self.comp_hyb_coords[0,:]) &amp; (self.comp_hyb_coords[0,:]&lt;r_br)\
                                          &amp; (c_tl &lt;self.comp_hyb_coords[1,:]) &amp;(self.comp_hyb_coords[1,:]&lt;c_br)) ]
        
        # Add check if there are dots in the timmed region
        if ref_trimmed.size &gt;= 2*self.n_neighbors and tran_trimmed.size &gt;= 2*self.n_neighbors:
            nbrs_ref = NearestNeighbors(n_neighbors=self.n_neighbors, algorithm=&#39;ball_tree&#39;,radius=self.matching_radius).fit(ref_trimmed.T)
            nbrs_tr = NearestNeighbors(n_neighbors=self.n_neighbors, algorithm=&#39;ball_tree&#39;,radius=self.matching_radius).fit(tran_trimmed.T)
        else:
            nbrs_ref = nbrs_tr = np.nan
            
        return ref_trimmed, tran_trimmed, nbrs_ref, nbrs_tr
   

    def calculate_NN_overlapping_region(self, coords_overlapping_region):
        
        # Add check if there are dots in the timmed region
        if coords_overlapping_region.size &gt;= 2*self.n_neighbors and coords_overlapping_region.size &gt;= 2*self.n_neighbors:
            nbrs = NearestNeighbors(n_neighbors=self.n_neighbors, algorithm=&#39;ball_tree&#39;,radius=self.matching_radius).fit(coords_overlapping_region.T)
        else:
            nbrs = np.nan
            
        return nbrs

    
    def calculate_registration(self):
        
        self.c = []
        passing_num = 0
        matching_points = False
        if self.ref_hyb_coords.size and self.comp_hyb_coords.size:
            for chunk_coords in self.Coords_Padded_Chunks_list:
                ref_trimmed, tran_trimmed, nbrs_ref, nbrs_tr= self.calculate_NN_roi(chunk_coords)
                if ref_trimmed.size &gt;= 2*self.n_neighbors and tran_trimmed.size &gt;= 2*self.n_neighbors:
                    if nbrs_ref != np.nan and nbrs_tr != np.nan:
                        # create dots id list
                        trans_dot_id_list = np.arange(tran_trimmed.shape[1])
                        for tran_dot_id in trans_dot_id_list:
                            searching=tran_trimmed[:,tran_dot_id]
                            searching = searching[np.newaxis,:]
                            dist, idx  = nbrs_tr.kneighbors(searching,n_neighbors=self.n_neighbors)
                            selected_tran = tran_trimmed[:,idx[0]]
                            tran_dist = self.calculate_min_distances(selected_tran)
                            for id_r in np.arange(ref_trimmed.shape[1]):
                                searching_r=ref_trimmed[:,id_r]
                                searching_r = searching_r[np.newaxis,:]
                                dist_r, idx_r  = nbrs_ref.kneighbors(searching_r,n_neighbors=self.n_neighbors)
                                if idx_r[0].shape[0] == idx[0].shape[0]: 
                                    selected_ref = ref_trimmed[:,idx_r[0]]
                                    ref_dist = self.calculate_min_distances(selected_ref)
                                    if np.all(np.abs(ref_dist - tran_dist)&lt;self.min_acceptable_distance):
                                        ref = ref_trimmed[:,idx_r[0]]
                                        ref_srt = ref[:,ref[0,:].argsort()]
                                        tran = tran_trimmed[:,idx[0]]
                                        tran_srt = tran[:,tran[0,:].argsort()]
                                        cpls = np.concatenate((ref_srt.T,tran_srt.T),axis=1)
                                        self.c.append(cpls)
                                        if passing_num == 0:
                                            matching_points = cpls
                                            passing_num += 1
                                        else:
                                            matching_points = np.concatenate((matching_points,cpls),axis=0)
            if isinstance(matching_points,np.ndarray):
                matching_points = np.unique(matching_points,axis=0)
                self.ref = matching_points[:,0:2]
                self.tran = matching_points[:,2:]
                if (self.min_samples &lt; self.ref.shape[0]) and (self.min_samples &lt; self.tran.shape[0]):
                    self.model, self.inliers = ransac((self.tran, self.ref), transform.SimilarityTransform, min_samples=self.min_samples,
                                    residual_threshold=self.residual_threshold, max_trials=self.max_trials)
    #                 self.model = transform.estimate_transform(&#39;Affine&#39;,self.tran, self.ref)
                    self.missing_pos = False
                else:
                    self.missing_pos = True 
            else:
                self.missing_pos = True 
        else: 
            self.missing_pos = True
        
        if not self.missing_pos:
            if self.model:
                self.tr_good = self.tran[self.inliers]
                self.ref_good = self.ref[self.inliers]
                self.transformed_coords = transform.matrix_transform(self.tr_good, self.model.params)
                self.transformed_all_coords = transform.matrix_transform(self.comp_hyb_coords.T, self.model.params)
                self.delta = self.ref_good - self.tr_good
                self.translation_mean = np.mean(self.delta,axis=0)
                self.translation_median = np.median(self.delta,axis=0)
                self.translation_diagonal = np.sqrt((self.ref_good[:,0] - self.tr_good[:,0])**2 + (self.ref_good[:,1] - self.tr_good[:,1])**2)
                self.translational_diagonal_mean = np.mean(self.translation_diagonal)
                self.translational_diagonal_median = np.median(self.translation_diagonal)
                self.translation_diagonal_std = np.std(self.translation_diagonal)
                self.translation_diagonal_sem = np.std(self.translation_diagonal)/ len(self.translation_diagonal)
                self.err1,self.err2, self.diagonal_mean, self.diagonal_median, self.diag_std, self.diag_sem = self.errors(self.transformed_coords, self.ref_good)
                self.used_points = [self.ref_good,self.tr_good]
            else:
                self.missing_pos = True


    def deploy(self):
        self.registration_data = {}
        if self.ref_hyb_coords.size &gt;= 2*self.n_neighbors:
            self.ref_nbrs = self.calculate_NN_overlapping_region(self.ref_hyb_coords)
            if self.comp_hyb_coords.size &gt;= 2*self.n_neighbors:
                self.comp_nbrs = self.calculate_NN_overlapping_region(self.comp_hyb_coords)
                if (self.ref_nbrs != np.nan) and (self.comp_nbrs != np.nan):
                    self.calculate_registration()
                else:
                    self.logger.info(f&#39;no neighbors identified&#39;)
                    self.missing_pos = True
            else:
                self.logger.info(f&#39;comp region \
                        does not contain enough dots for registration&#39;)
                self.missing_pos = True
                
                # ADJUST WHEN SAVING THE DATA
                self.registration_data = {&#39;missing_pos&#39;:self.missing_pos}
        else:
            self.logger.info(f&#39;reference region\
                            does not contain enough dots for registration&#39;)
            self.missing_pos = True
            
        if self.missing_pos:
            self.registration_data = {&#39;missing_pos&#39;:self.missing_pos}
        else:
            self.registration_data = {&#39;translation_diagonal_mean&#39;:self.translational_diagonal_mean, 
                                    &#39;translation_diagonal_median&#39;: self.translational_diagonal_median, 
                                    &#39;translation_diagonal_std&#39;: self.translation_diagonal_std,
                                    &#39;translation_diagonal_sem&#39;:self.translation_diagonal_sem,
                                    &#39;used_points&#39;: self.used_points,
                                    &#39;model_params&#39;:self.model.params, 
                                    &#39;err1&#39;:self.err1, 
                                    &#39;err2&#39;:self.err2, 
                                    &#39;diagonal_mean&#39;:self.diagonal_mean,
                                    &#39;diagonal_median&#39;:self.translational_diagonal_median,
                                    &#39;diag_std&#39;:self.diag_std, 
                                    &#39;diag_sem&#39;:self.diag_sem,
                                    &#39;transformed_coords&#39;:self.transformed_coords,
                                    &#39;transformed_all_coords&#39;:self.transformed_all_coords,
                                    &#39;missing_pos&#39;:self.missing_pos}



class reference_beads_registration_couple():

    &#34;&#34;&#34;
    class used to register a couple of rounds. It is used to monitor the outcome
    because it saves a lot of information useful for troubleshooting. Once the
    parameters are well define the corresponding non test function is used in the
    data processing
    &#34;&#34;&#34;

    def __init__(self,ref_hyb_coords, comp_hyb_coords, Coords_Padded_Chunks_list, n_neighbors,
                min_acceptable_distance, min_samples, residual_threshold, max_trials, matching_radius):

        self.ref_hyb_coords = ref_hyb_coords
        self.comp_hyb_coords = comp_hyb_coords
        self.Coords_Padded_Chunks_list = Coords_Padded_Chunks_list

        self.n_neighbors = n_neighbors
        self.min_acceptable_distance = min_acceptable_distance
        self.min_samples = min_samples
        self.residual_threshold = residual_threshold
        self.max_trials = max_trials
        self.matching_radius = matching_radius

        self.logger = logging.getLogger(__name__)

    @staticmethod
    def calculate_min_distances(selected_ref):
        ref_dist = distance.cdist(selected_ref, selected_ref)
        ref_dist = np.triu(ref_dist)
        ref_dist = ref_dist[:-1,:]
        mref = np.ma.masked_where(ref_dist==0,ref_dist)
        mref_min = mref.min(axis=1)
        return np.sort(mref_min.data)
    
    @staticmethod
    # CALCULATE ERROR OVER THE DIAGONAL
    def errors(transformed_coords, ref_good):
        diagonals = np.sqrt((ref_good[:,0]- transformed_coords[:,0])**2 + (ref_good[:,1]- transformed_coords[:,1])**2)
        diagonal_mean = np.mean(diagonals,axis=0)
        diagonal_median = np.median(diagonals,axis=0)
        err1 = np.sum((diagonals-diagonal_mean),axis=0)/len(diagonals)
        err2 = np.sum((diagonals-diagonal_mean)**2,axis=0)/len(diagonals)
        diag_std = np.std(diagonals)
        diag_sem = diag_std/len(diagonals)
        
        # delta = np.abs(ref_good - transformed_coords)
        # delta_mean = np.mean(delta,axis=0)
        # err1 = np.sum((delta-delta_mean),axis=0)/len(transformed_coords)
        # err2 = np.sum((delta-delta_mean)**2,axis=0)/len(transformed_coords)
        return err1,err2, diagonal_mean, diagonal_median, diag_std, diag_sem

    def calculate_NN_roi(self,chunk_coords):    
        r_tl = chunk_coords[0]
        r_br = chunk_coords[1]
        c_tl = chunk_coords[2]
        c_br = chunk_coords[3]

        # Select only the coords in the trimmed region
        ref_trimmed = self.ref_hyb_coords[((r_tl &lt; self.ref_hyb_coords[:,0]) &amp; (self.ref_hyb_coords[:,0]&lt;r_br)\
                                      &amp; (c_tl &lt;self.ref_hyb_coords[:,1]) &amp;(self.ref_hyb_coords[:,1]&lt;c_br)),:]
        tran_trimmed = self.comp_hyb_coords[((r_tl &lt; self.comp_hyb_coords[:,0]) &amp; (self.comp_hyb_coords[:,0]&lt;r_br)\
                                          &amp; (c_tl &lt;self.comp_hyb_coords[:,1]) &amp;(self.comp_hyb_coords[:,1]&lt;c_br)),:]
        
        # Add check if there are dots in the timmed region
        if ref_trimmed.size &gt;= 2*self.n_neighbors and tran_trimmed.size &gt;= 2*self.n_neighbors:
            nbrs_ref = NearestNeighbors(n_neighbors=self.n_neighbors, algorithm=&#39;ball_tree&#39;,radius=self.matching_radius).fit(ref_trimmed)
            nbrs_tr = NearestNeighbors(n_neighbors=self.n_neighbors, algorithm=&#39;ball_tree&#39;,radius=self.matching_radius).fit(tran_trimmed)
        else:
            nbrs_ref = nbrs_tr = np.nan
            
        return ref_trimmed, tran_trimmed, nbrs_ref, nbrs_tr
   

    def calculate_NN_overlapping_region(self, coords_overlapping_region):
        
        # Add check if there are dots in the timmed region
        if coords_overlapping_region.size &gt;= 2*self.n_neighbors and coords_overlapping_region.size &gt;= 2*self.n_neighbors:
            nbrs = NearestNeighbors(n_neighbors=self.n_neighbors, algorithm=&#39;ball_tree&#39;,radius=self.matching_radius).fit(coords_overlapping_region)
        else:
            nbrs = np.nan
            
        return nbrs

    
    def calculate_registration(self):
        self.monitor = []
        self.c = []
        passing_num = 0
        self.matching_points = False
        if self.ref_hyb_coords.size and self.comp_hyb_coords.size:
            for chunk_coords in self.Coords_Padded_Chunks_list:
                ref_trimmed, tran_trimmed, nbrs_ref, nbrs_tr= self.calculate_NN_roi(chunk_coords)
                #if ref_trimmed.shape[0] &gt;= 2*self.n_neighbors and tran_trimmed.shape[0] &gt;= 2*self.n_neighbors:
                if ref_trimmed.shape[0] &gt;= 20 and tran_trimmed.shape[0] &gt;= 20: 
                    self.monitor.append((ref_trimmed,tran_trimmed))
                    if nbrs_ref != np.nan and nbrs_tr != np.nan:
                        # create dots id list
                        trans_dot_id_list = np.arange(tran_trimmed.shape[0])
                        for tran_dot_id in trans_dot_id_list:
                            searching=tran_trimmed[tran_dot_id,:]
                            searching = searching[np.newaxis,:]
                            dist, idx  = nbrs_tr.kneighbors(searching,n_neighbors=self.n_neighbors)
                            selected_tran = tran_trimmed[idx[0],:]
                            tran_dist = self.calculate_min_distances(selected_tran)
                            for id_r in np.arange(ref_trimmed.shape[0]):
                                self.searching_r=ref_trimmed[id_r,:]
                                self.searching_r = self.searching_r[np.newaxis,:]
                                dist_r, self.idx_r  = nbrs_ref.kneighbors(self.searching_r,n_neighbors=self.n_neighbors)
                                if self.idx_r[0].shape[0] == idx[0].shape[0]: 
                                    selected_ref = ref_trimmed[self.idx_r[0],:]
                                    ref_dist = self.calculate_min_distances(selected_ref)
                                    if np.all(np.abs(ref_dist - tran_dist)&lt;self.min_acceptable_distance):
                                        ref = ref_trimmed[self.idx_r[0],:]
                                        ref_srt = ref[ref[0,:].argsort(),:]
                                        tran = tran_trimmed[idx[0],:]
                                        tran_srt = tran[tran[0,:].argsort(),:]
                                        cpls = np.concatenate((ref_srt,tran_srt),axis=1)
                                        self.c.append(cpls)
                                        if passing_num == 0:
                                            self.matching_points = cpls
                                            passing_num += 1
                                        else:
                                            self.matching_points = np.concatenate((self.matching_points,cpls),axis=0)
            if isinstance(self.matching_points,np.ndarray):
                self.matching_points = np.unique(self.matching_points,axis=0)
                self.ref = self.matching_points[:,0:2]
                self.tran = self.matching_points[:,2:]
                if (self.min_samples &lt; self.ref.shape[0]) and (self.min_samples &lt; self.tran.shape[0]):
                    self.model, self.inliers = ransac((self.tran, self.ref), transform.SimilarityTransform, min_samples=self.min_samples,
                                    residual_threshold=self.residual_threshold, max_trials=self.max_trials)
    #                 self.model = transform.estimate_transform(&#39;Affine&#39;,self.tran, self.ref)
                    self.missing_pos = False
                else:
                    self.missing_pos = True 
            else:
                self.missing_pos = True 
        else: 
            self.missing_pos = True
        
        if not self.missing_pos:
            if self.model:
                self.tr_good = self.tran[self.inliers]
                self.ref_good = self.ref[self.inliers]
                self.transformed_coords = transform.matrix_transform(self.tr_good, self.model.params)
                self.transformed_all_coords = transform.matrix_transform(self.comp_hyb_coords, self.model.params)
                self.delta = self.ref_good - self.tr_good
                self.translation_mean = np.mean(self.delta,axis=0)
                self.translation_median = np.median(self.delta,axis=0)
                self.translation_diagonal = np.sqrt((self.ref_good[:,0] - self.tr_good[:,0])**2 + (self.ref_good[:,1] - self.tr_good[:,1])**2)
                self.translational_diagonal_mean = np.mean(self.translation_diagonal)
                self.translational_diagonal_median = np.median(self.translation_diagonal)
                self.translation_diagonal_std = np.std(self.translation_diagonal)
                self.translation_diagonal_sem = np.std(self.translation_diagonal)/ len(self.translation_diagonal)
                self.err1,self.err2, self.diagonal_mean, self.diagonal_median, self.diag_std, self.diag_sem = self.errors(self.transformed_coords, self.ref_good)
                self.used_points = [self.ref_good,self.tr_good]
            else:
                self.missing_pos = True


    def deploy(self):
        self.registration_data = {}
        if self.ref_hyb_coords.size &gt;= 2*self.n_neighbors:
            self.ref_nbrs = self.calculate_NN_overlapping_region(self.ref_hyb_coords)
            if self.comp_hyb_coords.size &gt;= 2*self.n_neighbors:
                self.comp_nbrs = self.calculate_NN_overlapping_region(self.comp_hyb_coords)
                if (self.ref_nbrs != np.nan) and (self.comp_nbrs != np.nan):
                    self.calculate_registration()
                else:
                    self.logger.info(f&#39;no neighbors identified&#39;)
                    self.missing_pos = True
            else:
                self.logger.info(f&#39;comp region \
                        does not contain enough dots for registration&#39;)
                self.missing_pos = True
                
                # ADJUST WHEN SAVING THE DATA
                self.registration_data = {&#39;missing_pos&#39;:self.missing_pos}
        else:
            self.logger.info(f&#39;reference region\
                            does not contain enough dots for registration&#39;)
            self.missing_pos = True
            
        if self.missing_pos:
            self.registration_data = {&#39;missing_pos&#39;:self.missing_pos}
        else:
            self.registration_data = {&#39;translation_diagonal_mean&#39;:self.translational_diagonal_mean, 
                                    &#39;translation_diagonal_median&#39;: self.translational_diagonal_median, 
                                    &#39;translation_diagonal_std&#39;: self.translation_diagonal_std,
                                    &#39;translation_diagonal_sem&#39;:self.translation_diagonal_sem,
                                    &#39;used_points&#39;: self.used_points,
                                    &#39;model_params&#39;:self.model.params, 
                                    &#39;err1&#39;:self.err1, 
                                    &#39;err2&#39;:self.err2, 
                                    &#39;diagonal_mean&#39;:self.diagonal_mean,
                                    &#39;diagonal_median&#39;:self.translational_diagonal_median,
                                    &#39;diag_std&#39;:self.diag_std, 
                                    &#39;diag_sem&#39;:self.diag_sem,
                                    &#39;transformed_coords&#39;:self.transformed_coords,
                                    &#39;transformed_all_coords&#39;:self.transformed_all_coords,
                                    &#39;missing_pos&#39;:self.missing_pos}</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pysmFISH.fovs_registration.beads_based_registration"><code class="name flex">
<span>def <span class="ident">beads_based_registration</span></span>(<span>all_counts_fov:pandas.core.frame.DataFrame, analysis_parameters:Dict) >pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>[summary]</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>all_counts_fov</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>[description]</dd>
<dt><strong><code>analysis_parameters</code></strong> :&ensp;<code>Dict</code></dt>
<dd>[description]</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>[description]</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def beads_based_registration(all_counts_fov: pd.DataFrame,
                            analysis_parameters: Dict)-&gt;pd.DataFrame:
    &#34;&#34;&#34;[summary]

    Args:
        all_counts_fov (pd.DataFrame): [description]
        analysis_parameters (Dict): [description]

    Returns:
        pd.DataFrame: [description]
    &#34;&#34;&#34;
    
    # Used index to avoid to remake the output dataframe
    
    stitching_channel = all_counts_fov[&#39;stitching_channel&#39;].iloc[0]
    
    stitching_channel_df = all_counts_fov.loc[(all_counts_fov.channel == stitching_channel) &amp;
                                              (all_counts_fov.mapped_beads_type == &#39;large&#39;)  , :]
    
    if stitching_channel_df.shape[0] &lt; 2:
        stitching_channel_df = all_counts_fov.loc[(all_counts_fov.channel == stitching_channel) , :]

    
    fish_df = all_counts_fov.loc[all_counts_fov.channel != stitching_channel,:]
    
    reference_round_num = analysis_parameters[&#39;RegistrationReferenceHybridization&#39;]
    registration_tollerance_pxl = analysis_parameters[&#39;RegistrationTollerancePxl&#39;]
    
    registration_errors = Registration_errors()
    
    
    # Determine if there are any round with missing counts in the registration
    if stitching_channel_df[stitching_channel_df[&#39;dot_id&#39;].isnull()].empty :
    
        all_counts_fov[&#39;r_px_registered&#39;] = np.nan
        all_counts_fov[&#39;c_px_registered&#39;] = np.nan
        all_counts_fov[&#39;r_shift_px&#39;] = np.nan
        all_counts_fov[&#39;c_shift_px&#39;] = np.nan
        all_counts_fov[&#39;min_number_matching_dots_registration&#39;] = np.nan

        # Register stitching channel
        ref_counts_df = stitching_channel_df.loc[stitching_channel_df.round_num == reference_round_num,:]

        all_counts_fov.loc[ref_counts_df.index,&#39;r_px_registered&#39;] =  \
                ref_counts_df.loc[ref_counts_df.round_num == reference_round_num,&#39;r_px_original&#39;]
        all_counts_fov.loc[ref_counts_df.index,&#39;c_px_registered&#39;] =  \
                ref_counts_df.loc[ref_counts_df.round_num == reference_round_num,&#39;c_px_original&#39;]
        all_counts_fov.loc[ref_counts_df.index,&#39;r_shift_px&#39;] =  0
        all_counts_fov.loc[ref_counts_df.index,&#39;c_shift_px&#39;] =  0
        all_counts_fov.loc[ref_counts_df.index,&#39;min_number_matching_dots_registration&#39;] =  1000

        # Register fish
        fish_ref_round = fish_df.loc[fish_df.round_num == reference_round_num,:]
        
        all_counts_fov.loc[fish_ref_round.index,&#39;r_px_registered&#39;] =  \
                fish_ref_round.loc[fish_ref_round.index,&#39;r_px_original&#39;]
        all_counts_fov.loc[fish_ref_round.index,&#39;c_px_registered&#39;] =  \
                fish_ref_round.loc[fish_ref_round.index,&#39;c_px_original&#39;]
        all_counts_fov.loc[fish_ref_round.index,&#39;r_shift_px&#39;] =  0
        all_counts_fov.loc[fish_ref_round.index,&#39;c_shift_px&#39;] =  0
        all_counts_fov.loc[fish_ref_round.index,&#39;min_number_matching_dots_registration&#39;] =  1000
        
        # Create reference fake image for registration
        img_width = ref_counts_df.iloc[0][&#39;img_width&#39;]
        img_height = ref_counts_df.iloc[0][&#39;img_height&#39;]
        ref_coords = ref_counts_df.loc[:,[&#39;r_px_original&#39;, &#39;c_px_original&#39;]].to_numpy()
        img_ref = create_fake_image((img_width, img_height),ref_coords)

        all_rounds = all_counts_fov.round_num.unique()
        all_rounds = all_rounds[all_rounds != reference_round_num]
        for tran_round_num in all_rounds:

           
            tran_counts_df = stitching_channel_df.loc[stitching_channel_df.round_num == tran_round_num,:]
            img_width = tran_counts_df.iloc[0][&#39;img_width&#39;]
            img_height = tran_counts_df.iloc[0][&#39;img_height&#39;]
            tran_coords = tran_counts_df.loc[:,[&#39;r_px_original&#39;, &#39;c_px_original&#39;]].to_numpy()
            img_tran = create_fake_image((img_width, img_height),tran_coords)


            shift, error, diffphase = register_translation(img_ref, img_tran)
            registered_tran_coords = tran_coords + shift
            min_num_matching_dots = identify_matching_register_dots_NN(ref_coords,
                                                        registered_tran_coords,
                                                        registration_tollerance_pxl)


            # Register stitching channel
            all_counts_fov.loc[tran_counts_df.index,&#39;r_px_registered&#39;] =  registered_tran_coords[:,0]
            all_counts_fov.loc[tran_counts_df.index,&#39;c_px_registered&#39;] =  registered_tran_coords[:,1]
            all_counts_fov.loc[tran_counts_df.index,&#39;r_shift_px&#39;] =  shift[0]
            all_counts_fov.loc[tran_counts_df.index,&#39;c_shift_px&#39;] =  shift[1]
            all_counts_fov.loc[tran_counts_df.index,
                        &#39;min_number_matching_dots_registration&#39;] =  min_num_matching_dots
            
            
            # Register fish
            fish_ref_round = fish_df.loc[fish_df.round_num == tran_round_num,:]
            all_counts_fov.loc[fish_ref_round.index,&#39;r_px_registered&#39;] =  fish_ref_round[&#39;r_px_original&#39;] + shift[0] 
            all_counts_fov.loc[fish_ref_round.index,&#39;c_px_registered&#39;] =  fish_ref_round[&#39;c_px_original&#39;] + shift[1]
            all_counts_fov.loc[fish_ref_round.index,&#39;r_shift_px&#39;] =  shift[0] 
            all_counts_fov.loc[fish_ref_round.index,&#39;c_shift_px&#39;] =  shift[1]
            all_counts_fov.loc[fish_ref_round.index,
                        &#39;min_number_matching_dots_registration&#39;] =  min_num_matching_dots
            
            
    else:
        
        all_counts_fov[&#39;r_px_registered&#39;] = np.nan
        all_counts_fov[&#39;c_px_registered&#39;] = np.nan
        all_counts_fov[&#39;r_shift_px&#39;] = np.nan
        all_counts_fov[&#39;c_shift_px&#39;] = np.nan
        all_counts_fov[&#39;min_number_matching_dots_registration&#39;] = registration_errors.missing_counts_reg_channel
     
    return all_counts_fov</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.beads_based_registration_fish"><code class="name flex">
<span>def <span class="ident">beads_based_registration_fish</span></span>(<span>all_counts_fov:pandas.core.frame.DataFrame, all_rounds_shifts:numpy.ndarray, all_rounds_matching_dots:pandas.core.frame.DataFrame, analysis_parameters:Dict) >pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Adjust the coords of the fish dots using the shift calculated in the
reference channel.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>all_counts_fov</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Coords of all peaks</dd>
<dt><strong><code>all_rounds_shifts</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Calculated shift from the registration
of the reference channel</dd>
<dt><strong><code>all_rounds_matching_dots</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Marching dots between rounds</dd>
<dt><strong><code>analysis_parameters</code></strong> :&ensp;<code>Dict</code></dt>
<dd>Processing parameters</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>All registered counts</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def beads_based_registration_fish(all_counts_fov: pd.DataFrame,
                                        all_rounds_shifts: np.ndarray,
                                        all_rounds_matching_dots: pd.DataFrame,
                                        analysis_parameters: Dict)-&gt;pd.DataFrame:
    &#34;&#34;&#34;Adjust the coords of the fish dots using the shift calculated in the 
    reference channel.

    Args:
        all_counts_fov (pd.DataFrame): Coords of all peaks
        all_rounds_shifts (np.ndarray): Calculated shift from the registration 
                                of the reference channel
        all_rounds_matching_dots (pd.DataFrame): Marching dots between rounds
        analysis_parameters (Dict): Processing parameters

    Returns:
        pd.DataFrame: All registered counts
    &#34;&#34;&#34;
    
    registration_errors = Registration_errors()
    
    # Determine if there are counts in the fish channel
    all_counts_fov = all_counts_fov.dropna()
    
    if not all_counts_fov.shape[0]:    
        all_counts_fov = all_counts_fov.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.missing_counts_fish_channel}, 
                                                                                                                    ignore_index=True)

    elif isinstance(all_rounds_shifts,dict):

        for round_num, shift in all_rounds_shifts.items():
            if isinstance(shift,np.ndarray):
                all_counts_fov.loc[all_counts_fov.round_num == round_num,&#39;r_px_registered&#39;] =  all_counts_fov[&#39;r_px_original&#39;] + shift[0] 
                all_counts_fov.loc[all_counts_fov.round_num == round_num,&#39;c_px_registered&#39;] =  all_counts_fov[&#39;c_px_original&#39;] + shift[1]
                all_counts_fov.loc[all_counts_fov.round_num == round_num,&#39;r_shift_px&#39;] =  shift[0] 
                all_counts_fov.loc[all_counts_fov.round_num == round_num,&#39;c_shift_px&#39;] =  shift[1]
                all_counts_fov.loc[all_counts_fov.round_num == round_num,
                            &#39;min_number_matching_dots_registration&#39;] =  all_rounds_matching_dots[round_num]
            else:
                all_counts_fov.loc[all_counts_fov.round_num == round_num,&#39;r_px_registered&#39;] =  np.nan
                all_counts_fov.loc[all_counts_fov.round_num == round_num,&#39;c_px_registered&#39;] =  np.nan
                all_counts_fov.loc[all_counts_fov.round_num == round_num,&#39;r_shift_px&#39;] = np.nan
                all_counts_fov.loc[all_counts_fov.round_num == round_num,&#39;c_shift_px&#39;] =  np.nan
                all_counts_fov.loc[all_counts_fov.round_num == round_num,
                            &#39;min_number_matching_dots_registration&#39;] =  all_rounds_matching_dots[round_num]

    else:

        all_counts_fov[&#39;r_px_registered&#39;] = np.nan
        all_counts_fov[&#39;c_px_registered&#39;] = np.nan
        all_counts_fov[&#39;r_shift_px&#39;] = np.nan
        all_counts_fov[&#39;c_shift_px&#39;] = np.nan
        all_counts_fov[&#39;min_number_matching_dots_registration&#39;] = registration_errors.missing_counts_reg_channel
                 
     
    return all_counts_fov</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.beads_based_registration_stitching_channel"><code class="name flex">
<span>def <span class="ident">beads_based_registration_stitching_channel</span></span>(<span>stitching_channel_df:pandas.core.frame.DataFrame, analysis_parameters:Dict, metadata:Dict) >Tuple[pandas.core.frame.DataFrame,numpy.ndarray,pandas.core.frame.DataFrame]</span>
</code></dt>
<dd>
<div class="desc"><p>Registration of the reference channel that contained reference beads.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>stitching_channel_df</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Coordinates of the beads</dd>
<dt><strong><code>analysis_parameters</code></strong> :&ensp;<code>Dict</code></dt>
<dd>Processing parameters</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>Dict</code></dt>
<dd>Overall experiment info parameters</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[pd.DataFrame, np.ndarray, pd.DataFrame]</code></dt>
<dd>(stitching_channel_df,
all_rounds_shifts, all_rounds_matching_dots)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def beads_based_registration_stitching_channel(stitching_channel_df: pd.DataFrame,
                analysis_parameters: Dict, metadata: Dict)-&gt; Tuple[pd.DataFrame, np.ndarray, pd.DataFrame]:
    &#34;&#34;&#34;Registration of the reference channel that contained reference beads.

    Args:
        stitching_channel_df (pd.DataFrame): Coordinates of the beads
        analysis_parameters (Dict): Processing parameters
        metadata (Dict): Overall experiment info parameters

    Returns:
        Tuple[pd.DataFrame, np.ndarray, pd.DataFrame]: (stitching_channel_df, 
                        all_rounds_shifts, all_rounds_matching_dots)
    
    &#34;&#34;&#34;
                
    # Used index to avoid to remake the output dataframe
    # REMEMBER that you can miss one of the types of beads when dual beads
    #          are used for the registration

    reference_round_num = analysis_parameters[&#39;RegistrationReferenceHybridization&#39;]
    registration_tollerance_pxl = analysis_parameters[&#39;RegistrationTollerancePxl&#39;]
    registration_tollerance_counts = analysis_parameters[&#39;RegistrationMinMatchingBeads&#39;]
    


    registration_errors = Registration_errors()
    
    all_rounds_shifts = {}
    all_rounds_matching_dots = {}
    # Determine if there are any round with missing counts in the registration

    # Dropna to determine if the dataframe is empty or not. Also will remove the
    # rounds without counts
    stitching_channel_df = stitching_channel_df.dropna()
    if stitching_channel_df.shape[0]:
    
        stitching_channel_df[&#39;r_px_registered&#39;] = np.nan
        stitching_channel_df[&#39;c_px_registered&#39;] = np.nan
        stitching_channel_df[&#39;r_shift_px&#39;] = np.nan
        stitching_channel_df[&#39;c_shift_px&#39;] = np.nan
        stitching_channel_df[&#39;min_number_matching_dots_registration&#39;] = np.nan

        # Register stitching channel
        ref_counts_df = stitching_channel_df.loc[stitching_channel_df.round_num == reference_round_num,:]

        while True:
            if not ref_counts_df.shape[0]:

                stitching_channel_df = stitching_channel_df.append({&#39;round_num&#39;:reference_round_num}, ignore_index=True)
                
                all_rounds_shifts[reference_round_num] = np.nan

                if  reference_round_num == analysis_parameters[&#39;RegistrationReferenceHybridization&#39;]:
                    stitching_channel_df.loc[stitching_channel_df.round_num == reference_round_num,
                                &#39;min_number_matching_dots_registration&#39;] = registration_errors.missing_counts_reference_round

                    all_rounds_matching_dots[reference_round_num] = registration_errors.missing_counts_reference_round
                else:
                    stitching_channel_df.loc[stitching_channel_df.round_num == reference_round_num,
                                &#39;min_number_matching_dots_registration&#39;] = registration_errors.missing_counts_in_round

                    all_rounds_matching_dots[reference_round_num] = registration_errors.missing_counts_in_round

                reference_round_num += 1 # Valid only if the reference round is one if it is different you need to find
                                        # another logic for the processing
                
                if reference_round_num &gt; metadata[&#39;total_rounds&#39;]:
                    break
                else:
                    ref_counts_df = stitching_channel_df.loc[stitching_channel_df.round_num == reference_round_num,:]

            else:
                break
                
        if reference_round_num &gt; metadata[&#39;total_rounds&#39;]:
            stitching_channel_df[&#39;r_px_registered&#39;] = np.nan
            stitching_channel_df[&#39;c_px_registered&#39;] = np.nan
            stitching_channel_df[&#39;r_shift_px&#39;] = np.nan
            stitching_channel_df[&#39;c_shift_px&#39;] = np.nan
            stitching_channel_df[&#39;min_number_matching_dots_registration&#39;] = registration_errors.missing_counts_reg_channel
            all_rounds_shifts = np.nan

        else:

            # ref_counts_df = stitching_channel_df.loc[stitching_channel_df.round_num == reference_round_num,:]
            stitching_channel_df.loc[ref_counts_df.index,&#39;r_px_registered&#39;] =  \
                    ref_counts_df.loc[ref_counts_df.round_num == reference_round_num,&#39;r_px_original&#39;]
            stitching_channel_df.loc[ref_counts_df.index,&#39;c_px_registered&#39;] =  \
                    ref_counts_df.loc[ref_counts_df.round_num == reference_round_num,&#39;c_px_original&#39;]
            stitching_channel_df.loc[ref_counts_df.index,&#39;r_shift_px&#39;] =  0
            stitching_channel_df.loc[ref_counts_df.index,&#39;c_shift_px&#39;] =  0
            stitching_channel_df.loc[ref_counts_df.index,&#39;min_number_matching_dots_registration&#39;] =  1000

            all_rounds_shifts[reference_round_num] = np.array([0,0])
            all_rounds_matching_dots[reference_round_num] = 1000


            # Create reference fake image for registration
            img_width = metadata[&#39;img_width&#39;]
            img_height = metadata[&#39;img_height&#39;]
            ref_coords = ref_counts_df.loc[:,[&#39;r_px_original&#39;, &#39;c_px_original&#39;]].to_numpy()

            img_ref = create_fake_image((img_width, img_height),ref_coords)

            all_rounds = np.arange(1,metadata[&#39;total_rounds&#39;]+1)
            all_rounds = all_rounds[all_rounds &gt; reference_round_num]

            for tran_round_num in all_rounds:
            
                tran_counts_df = stitching_channel_df.loc[stitching_channel_df.round_num == tran_round_num,:]
                
                if tran_counts_df.shape[0]:
    
                    tran_coords = tran_counts_df.loc[:,[&#39;r_px_original&#39;, &#39;c_px_original&#39;]].to_numpy()
                    img_tran = create_fake_image((img_width, img_height),tran_coords)


                    shift, error, diffphase = register_translation(img_ref, img_tran)
                    registered_tran_coords = tran_coords + shift
                    min_num_matching_dots = identify_matching_register_dots_NN(ref_coords,
                                                                registered_tran_coords,
                                                                registration_tollerance_pxl)

                    all_rounds_shifts[tran_round_num] = shift
                    all_rounds_matching_dots[tran_round_num] = min_num_matching_dots
                    

                    # Register stitching channel
                    stitching_channel_df.loc[tran_counts_df.index,&#39;r_px_registered&#39;] =  registered_tran_coords[:,0]
                    stitching_channel_df.loc[tran_counts_df.index,&#39;c_px_registered&#39;] =  registered_tran_coords[:,1]
                    stitching_channel_df.loc[tran_counts_df.index,&#39;r_shift_px&#39;] =  shift[0]
                    stitching_channel_df.loc[tran_counts_df.index,&#39;c_shift_px&#39;] =  shift[1]
                    if min_num_matching_dots &gt;=registration_tollerance_counts:
                        stitching_channel_df.loc[tran_counts_df.index,
                                &#39;min_number_matching_dots_registration&#39;] =  min_num_matching_dots
                    else:
                        stitching_channel_df.loc[tran_counts_df.index,
                                &#39;min_number_matching_dots_registration&#39;] =  registration_errors.number_beads_below_tolerance_counts

                else:

                    stitching_channel_df = stitching_channel_df.append({&#39;round_num&#39;:tran_round_num}, ignore_index=True)
                    stitching_channel_df.loc[stitching_channel_df.round_num == tran_round_num,
                                &#39;min_number_matching_dots_registration&#39;] = registration_errors.missing_counts_in_round

                    all_rounds_shifts[tran_round_num] = np.nan
                    all_rounds_matching_dots[tran_round_num] = registration_errors.missing_counts_in_round
            
    else:
        
        stitching_channel_df[&#39;r_px_registered&#39;] = np.nan
        stitching_channel_df[&#39;c_px_registered&#39;] = np.nan
        stitching_channel_df[&#39;r_shift_px&#39;] = np.nan
        stitching_channel_df[&#39;c_shift_px&#39;] = np.nan
        stitching_channel_df[&#39;min_number_matching_dots_registration&#39;] = registration_errors.missing_counts_reg_channel
        all_rounds_shifts = np.nan
     
    return stitching_channel_df, all_rounds_shifts, all_rounds_matching_dots</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.calculate_shift_hybridization_fov"><code class="name flex">
<span>def <span class="ident">calculate_shift_hybridization_fov</span></span>(<span>processing_files:List, analysis_parameters:dict, save=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to run the registration of a single fov
through all hybridization. The registration is done using the dots
coords determined in each image</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>processing_files</code></strong></dt>
<dd>List
list of the files with the counts to register</dd>
<dt><strong><code>analysis_parameters</code></strong></dt>
<dd>Dict
dict that contains the settings for the analysis</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_shift_hybridization_fov(processing_files:List,analysis_parameters:dict, save=True):
    &#34;&#34;&#34;
    Function used to run the registration of a single fov
    through all hybridization. The registration is done using the dots
    coords determined in each image

    Args:
        processing_files: List
            list of the files with the counts to register
        analysis_parameters: Dict
            dict that contains the settings for the analysis 
    &#34;&#34;&#34;
    
    logger = selected_logger()
    all_rounds_shifts = {}
    
    registration_errors = Registration_errors()
    data_models = Output_models()
    output_registration_df = data_models.output_registration_df
    status = &#39;SUCCESS&#39;

    reference_hybridization = analysis_parameters[&#39;RegistrationReferenceHybridization&#39;]
    round_num = reference_hybridization
    reference_hybridization_str = &#39;Hybridization&#39; + str(reference_hybridization).zfill(2)
    registration_tollerance_pxl = analysis_parameters[&#39;RegistrationTollerancePxl&#39;]

    # collect info used to generate fname when files are corrupted   
    experiment_fpath = processing_files[0].parent.parent.parent
    channel = (processing_files[0].stem).split(&#39;_&#39;)[-4]
    experiment_name = experiment_fpath.stem
    fov = (processing_files[0].stem).split(&#39;_&#39;)[-2]
    file_tags = {&#39;experiment_fpath&#39;:experiment_fpath,
                &#39;experiment_name&#39;:experiment_name,
                &#39;channel&#39;:channel,
                &#39;fov&#39;:fov}

    fname = experiment_fpath / &#39;tmp&#39; / &#39;registered_counts&#39; / (experiment_name + &#39;_&#39; + channel + &#39;_registered_fov_&#39; + fov + &#39;.parquet&#39;)
    shift_fname = experiment_fpath / &#39;tmp&#39; / &#39;registered_counts&#39; / (experiment_name + &#39;_&#39; + channel + &#39;_all_rounds_shifts_fov_&#39; + fov + &#39;.pkl&#39;)
    # Load reference hybridization data
    try:
        ref_fpath = [fpath for fpath in processing_files if reference_hybridization_str in fpath.as_posix()][0]
    except:
        logger.error(f&#39;missing reference hyb file for fov {fov}&#39;)
        output_registration_df = output_registration_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.missing_file_reg_channel, 
                                            &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num)},ignore_index=True)
        status = &#39;FAILED&#39;
        all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
    else:
        try:
            ref_counts,ref_img_metadata = pickle.load(open(ref_fpath, &#39;rb&#39;))
        except:
            logger.error(f&#39;cannot open the reference hyb file for fov {fov}&#39;)
            output_registration_df = output_registration_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.cannot_load_file_reg_channel,
                                            &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num) },ignore_index=True)
            status = &#39;FAILED&#39;
            all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
        else:
            # Check if there are dots detected in the reference round
            if np.any(np.isnan(ref_counts[&#39;r_px_original&#39;])) or (ref_counts[&#39;r_px_original&#39;].shape[0]&lt;registration_tollerance_pxl):
                logger.error(f&#39;There are no dots in there reference hyb for fov {fov} &#39;)
                output_registration_df = output_registration_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.missing_counts_reg_channel,
                                            &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num) },ignore_index=True)
                status = &#39;FAILED&#39;
                all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
            else:
                ref_counts_df = pd.DataFrame(ref_counts)
                ref_counts_df[&#39;r_px_registered&#39;] = ref_counts_df[&#39;r_px_original&#39;]
                ref_counts_df[&#39;c_px_registered&#39;] = ref_counts_df[&#39;c_px_original&#39;]
                ref_counts_df[&#39;r_shift_px&#39;] = 0
                ref_counts_df[&#39;c_shift_px&#39;] = 0
                ref_counts_df[&#39;min_number_matching_dots_registration&#39;] = 1000
                all_rounds_shifts[round_num] = np.array([0,0])

                output_registration_df = pd.concat([output_registration_df,ref_counts_df],axis=0,ignore_index=True)
                
                tran_processing_files =processing_files.copy()
                tran_processing_files.remove(ref_fpath)
                img_width = ref_img_metadata[&#39;img_width&#39;]
                img_height = ref_img_metadata[&#39;img_height&#39;]

                img_shape = (img_width, img_height)
                ref_coords = ref_counts_df.loc[:,[&#39;r_px_original&#39;, &#39;c_px_original&#39;]].to_numpy()
                img_ref = create_fake_image(img_shape,ref_coords)
        

                for fpath in tran_processing_files:
                    try:
                        tran_counts, tran_img_metadata = pickle.load(open(fpath, &#39;rb&#39;))
                    except:
                        logger.error(f&#39;cannot open {fpath.stem} file for fov {fov}&#39;)
                        # If there is an error in the opening reset the df
                        round_num = int((fpath.stem).split(&#39;_&#39;)[-5].split(&#39;Hybridization&#39;)[-1])
                        output_registration_df = data_models.output_registration_df
                        output_registration_df = output_registration_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.cannot_load_file_reg_channel,
                                            &#39;fov_num&#39;:int(fov) ,&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num)},ignore_index=True)
                        status = &#39;FAILED&#39;
                        all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
                        break
                    else:
                        tran_counts_df = pd.DataFrame(tran_counts)
                        tran_coords = tran_counts_df.loc[:,[&#39;r_px_original&#39;, &#39;c_px_original&#39;]].to_numpy()
                        if np.any(np.isnan(tran_coords)) or tran_coords.shape[0]&lt;registration_tollerance_pxl:
                            round_num = int((fpath.stem).split(&#39;_&#39;)[-5].split(&#39;Hybridization&#39;)[-1])
                            # If dots are missing, reset the df
                            output_registration_df = data_models.output_registration_df
                            output_registration_df = output_registration_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.missing_counts_reg_channel,
                                            &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num) },ignore_index=True)
                            status = &#39;FAILED&#39;
                            all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
                            logger.error(f&#39; {fpath.stem} file for fov {fov} has no counts&#39;)
                            break
                        else:
                            
                            round_num = tran_counts[&#39;round_num&#39;][0]
                            ref_img_metadata[&#39;reference_hyb&#39;] = str(reference_hybridization)
                            img_tran = create_fake_image(img_shape,tran_coords)
                            shift, error, diffphase = register_translation(img_ref, img_tran)
                            all_rounds_shifts[round_num] = shift
                            registered_tran_coords = tran_coords + shift
                            min_num_matching_dots = identify_matching_register_dots_NN(ref_coords,
                                                                                    registered_tran_coords,
                                                                                    registration_tollerance_pxl)
                            
                            tran_counts_df[&#39;r_px_registered&#39;] = registered_tran_coords[:,0]
                            tran_counts_df[&#39;c_px_registered&#39;] = registered_tran_coords[:,1]
                            tran_counts_df[&#39;r_shift_px&#39;] = shift[0]
                            tran_counts_df[&#39;c_shift_px&#39;] = shift[1]
                            tran_counts_df[&#39;min_number_matching_dots_registration&#39;] = min_num_matching_dots

                            output_registration_df = pd.concat([output_registration_df,tran_counts_df],axis=0,ignore_index=True)
                            output_registration_df.attrs[fov] = ref_img_metadata

                # Save the dataframe
                
                output_registration_df[&#39;reference_hyb&#39;] = reference_hybridization
                output_registration_df[&#39;experiment_type&#39;] = ref_img_metadata[&#39;experiment_type&#39;]
                output_registration_df[&#39;experiment_name&#39;] = ref_img_metadata[&#39;experiment_name&#39;]
                output_registration_df[&#39;pxl_um&#39;] = ref_img_metadata[&#39;pixel_microns&#39;]
                output_registration_df[&#39;stitching_type&#39;] = ref_img_metadata[&#39;stitching_type&#39;]
                output_registration_df[&#39;img_width_px&#39;] = ref_img_metadata[&#39;img_width&#39;]
                output_registration_df[&#39;img_height_px&#39;] = ref_img_metadata[&#39;img_height&#39;]
                output_registration_df[&#39;fov_acquisition_coords_x&#39;] = ref_img_metadata[&#39;fov_acquisition_coords_x&#39;]
                output_registration_df[&#39;fov_acquisition_coords_y&#39;] = ref_img_metadata[&#39;fov_acquisition_coords_y&#39;]
                output_registration_df[&#39;fov_acquisition_coords_z&#39;] = ref_img_metadata[&#39;fov_acquisition_coords_z&#39;]
        
        # Save extra metadata in the
        if save:
            output_registration_df.to_parquet(fname,index=False)
            pickle.dump(all_rounds_shifts,open(shift_fname,&#39;wb&#39;))
        return output_registration_df, all_rounds_shifts, file_tags, status</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.calculate_shift_hybridization_fov_nuclei"><code class="name flex">
<span>def <span class="ident">calculate_shift_hybridization_fov_nuclei</span></span>(<span>processing_files:List, analysis_parameters:dict, save=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to run the registration of a single fov
through all hybridization. The registration is done using the dots
coords determined in each image</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>processing_files</code></strong></dt>
<dd>List
list of the files with the filtered images of the nuclei</dd>
<dt><strong><code>analysis_parameters</code></strong></dt>
<dd>Dict
dict that contains the settings for the analysis</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_shift_hybridization_fov_nuclei(processing_files:List,analysis_parameters:dict, save=True):
    &#34;&#34;&#34;
    Function used to run the registration of a single fov
    through all hybridization. The registration is done using the dots
    coords determined in each image

    Args:
        processing_files: List
            list of the files with the filtered images of the nuclei
        analysis_parameters: Dict
            dict that contains the settings for the analysis 
    &#34;&#34;&#34;
    
    logger = selected_logger()
    all_rounds_shifts = {}
    all_rounds_shifts_RMS = {}
    registration_errors = Registration_errors()
    data_models = Output_models()
    output_registration_df = data_models.output_registration_df
    status = &#39;SUCCESS&#39;

    reference_hybridization = analysis_parameters[&#39;RegistrationReferenceHybridization&#39;]
    round_num = reference_hybridization
    reference_hybridization_str = &#39;Hybridization&#39; + str(reference_hybridization).zfill(2)
    registration_tollerance_pxl = analysis_parameters[&#39;RegistrationTollerancePxl&#39;]

    # collect info used to generate fname when files are corrupted   
    experiment_fpath = processing_files[0].parent.parent.parent
    channel = (processing_files[0].stem).split(&#39;_&#39;)[-4]
    experiment_name = experiment_fpath.stem
    fov = (processing_files[0].stem).split(&#39;_&#39;)[-2]
    file_tags = {&#39;experiment_fpath&#39;:experiment_fpath,
                &#39;experiment_name&#39;:experiment_name,
                &#39;channel&#39;:channel,
                &#39;fov&#39;:fov}

    shift_fname = experiment_fpath / &#39;tmp&#39; / &#39;registered_counts&#39; / (experiment_name + &#39;_&#39; + channel + &#39;_nuclei_all_rounds_shifts_fov_&#39; + fov + &#39;.pkl&#39;)
    shift_error_fname = experiment_fpath / &#39;tmp&#39; / &#39;registered_counts&#39; / (experiment_name + &#39;_&#39; + channel + &#39;_nuclei_all_rounds_shifts_errors_fov_&#39; + fov + &#39;.pkl&#39;)
    
    # Load reference hybridization data
    try:
        ref_fpath = [fpath for fpath in processing_files if reference_hybridization_str in fpath.as_posix()][0]
    except:
        logger.error(f&#39;missing reference hyb file for fov {fov}&#39;)
        status = &#39;FAILED&#39;
        all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
        all_rounds_shifts_RMS[round_num] = 1
    else:
        try:
            ref_img,ref_img_metadata = pickle.load(open(ref_fpath, &#39;rb&#39;))
        except:
            logger.error(f&#39;cannot open the reference hyb file for fov {fov}&#39;)
            status = &#39;FAILED&#39;
            all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
            all_rounds_shifts_RMS[round_num] = 1
        else:   
                tran_processing_files =processing_files.copy()
                tran_processing_files.remove(ref_fpath)
                
                for fpath in tran_processing_files:
                    try:
                        tran_img, tran_img_metadata = pickle.load(open(fpath, &#39;rb&#39;))
                    except:
                        logger.error(f&#39;cannot open {fpath.stem} file for fov {fov}&#39;)
                        # If there is an error in the opening reset the df
                        round_num = int((fpath.stem).split(&#39;_&#39;)[-5].split(&#39;Hybridization&#39;)[-1])
                        status = &#39;FAILED&#39;
                        all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
                        all_rounds_shifts_RMS[round_num] = 1
                        break
                    else:                    
                            round_num = int((fpath.stem).split(&#39;_&#39;)[-5].split(&#39;Hybridization&#39;)[-1])
                            ref_img_metadata[&#39;reference_hyb&#39;] = str(reference_hybridization)
                            
                            shift, error, diffphase = phase_cross_correlation(ref_img, tran_img,return_error=True,)
                            all_rounds_shifts[round_num] = shift
                            all_rounds_shifts_RMS[round_num] = error
        
        # Save extra metadata in the
        if save:
            pickle.dump(all_rounds_shifts,open(shift_fname,&#39;wb&#39;))
            pickle.dump(all_rounds_shifts_RMS,open(shift_error_fname,&#39;wb&#39;))

        return all_rounds_shifts, all_rounds_shifts_RMS, file_tags, status</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.calculate_shift_hybridization_fov_nuclei_test"><code class="name flex">
<span>def <span class="ident">calculate_shift_hybridization_fov_nuclei_test</span></span>(<span>img_stack:numpy.ndarray, analysis_parameters:Dict)</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to run the registration of a single fov
through all hybridization. The registration is done using the dots
coords determined in each image</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>processing_files</code></strong></dt>
<dd>List
list of the files with the counts to register</dd>
<dt><strong><code>analysis_parameters</code></strong></dt>
<dd>Dict
dict that contains the settings for the analysis </dd>
</dl>
<p>MUST ADD THE CONSIDERATION OF POTENTIAL ERRORS</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_shift_hybridization_fov_nuclei_test(
                                            img_stack:np.ndarray,
                                            analysis_parameters:Dict):
    &#34;&#34;&#34;
    Function used to run the registration of a single fov
    through all hybridization. The registration is done using the dots
    coords determined in each image

    Args:
        processing_files: List
            list of the files with the counts to register
        analysis_parameters: Dict
            dict that contains the settings for the analysis 


    MUST ADD THE CONSIDERATION OF POTENTIAL ERRORS
    &#34;&#34;&#34;
    
    logger = selected_logger()
    
    registration_errors = Registration_errors()
  
    ref_round_num = analysis_parameters[&#39;RegistrationReferenceHybridization&#39;] - 1
    registration_tollerance_pxl = analysis_parameters[&#39;RegistrationTollerancePxl&#39;]

    all_rounds = np.arange(img_stack.shape[0])
    all_rounds = all_rounds[all_rounds != ref_round_num]

    ref_img = img_stack[ref_round_num,:,:]

    all_rounds_reg = []
    ref_df = pd.DataFrame({&#39;round_num&#39;:ref_round_num + 1,
                                            &#39;r_shift_px&#39;: 0,
                                            &#39;c_shift_px&#39;:0,
                                            &#39;min_number_matching_dots_registration&#39;:1000,
                                            &#39;RMS&#39;:0})

    all_rounds_reg.append(ref_df)
    for r_num in all_rounds:
        shift, error, diffphase = phase_cross_correlation(ref_img, img_stack[r_num,:,:],return_error=True)    
        tran_df = pd.DataFrame({&#39;round_num&#39;:[r_num + 1],
                                        &#39;r_shift_px&#39;: [shift[0]],
                                        &#39;c_shift_px&#39;:[shift[1]],
                                        &#39;min_number_matching_dots_registration&#39;:error,
                                        &#39;RMS&#39;:error})

        all_rounds_reg.append(tran_df)

    output_registration_df = pd.concat([all_rounds_reg],axis=0,ignore_index=True)


    return output_registration_df</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.calculate_shift_hybridization_fov_test"><code class="name flex">
<span>def <span class="ident">calculate_shift_hybridization_fov_test</span></span>(<span>fov:int, counts_output:Dict, analysis_parameters:Dict, experiment_info:Dict)</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to run the registration of a single fov
through all hybridization. The registration is done using the dots
coords determined in each image</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>processing_files</code></strong></dt>
<dd>List
list of the files with the counts to register</dd>
<dt><strong><code>analysis_parameters</code></strong></dt>
<dd>Dict
dict that contains the settings for the analysis</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_shift_hybridization_fov_test(fov:int,
                                            counts_output:Dict,
                                            analysis_parameters:Dict, 
                                            experiment_info:Dict):
    &#34;&#34;&#34;
    Function used to run the registration of a single fov
    through all hybridization. The registration is done using the dots
    coords determined in each image

    Args:
        processing_files: List
            list of the files with the counts to register
        analysis_parameters: Dict
            dict that contains the settings for the analysis 
    &#34;&#34;&#34;
    
    logger = selected_logger()
    all_rounds_shifts = {}
    
    registration_errors = Registration_errors()
    data_models = Output_models()
    output_registration_df = data_models.output_registration_df
    status = &#39;SUCCESS&#39;

    reference_hybridization = analysis_parameters[&#39;RegistrationReferenceHybridization&#39;]
    round_num = reference_hybridization
    reference_hybridization_str = &#39;Hybridization&#39; + str(reference_hybridization).zfill(2)
    channel = experiment_info[&#39;StitchingChannel&#39;]
    registration_tollerance_pxl = analysis_parameters[&#39;RegistrationTollerancePxl&#39;]
    counts_zarr_names = list(counts_output[&#39;registration&#39;][channel].keys())

    try:
        ref_zarr_name = [el for el in counts_zarr_names if reference_hybridization_str in el][0]
    except:
        logger.error(f&#39;missing registration counts fov {fov}&#39;)
        output_registration_df = output_registration_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.missing_file_reg_channel, 
                                            &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num)},ignore_index=True)
        status = &#39;FAILED&#39;
        all_rounds_shifts[round_num] = np.array([np.nan,np.nan])

    else:
        ref_counts, ref_img_metadata = counts_output[&#39;registration&#39;][channel][ref_zarr_name]
        # Check if there are dots detected in the reference round
        if np.any(np.isnan(ref_counts[&#39;r_px_original&#39;])) or (ref_counts[&#39;r_px_original&#39;].shape[0]&lt;registration_tollerance_pxl):
            logger.error(f&#39;There are no dots in there reference hyb for fov {fov} &#39;)
            output_registration_df = output_registration_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.missing_counts_reg_channel,
                                        &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num) },ignore_index=True)
            status = &#39;FAILED&#39;
            all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
        else:
            ref_counts_df = pd.DataFrame(ref_counts)
            ref_counts_df[&#39;r_px_registered&#39;] = ref_counts_df[&#39;r_px_original&#39;]
            ref_counts_df[&#39;c_px_registered&#39;] = ref_counts_df[&#39;c_px_original&#39;]
            ref_counts_df[&#39;r_shift_px&#39;] = 0
            ref_counts_df[&#39;c_shift_px&#39;] = 0
            ref_counts_df[&#39;min_number_matching_dots_registration&#39;] = 1000
            all_rounds_shifts[round_num] = np.array([0,0])

            output_registration_df = pd.concat([output_registration_df,ref_counts_df],axis=0,ignore_index=True)
            
            tran_processing_files = counts_zarr_names.copy()
            tran_processing_files.remove(ref_zarr_name)
            img_width = ref_img_metadata[&#39;img_width&#39;]
            img_height = ref_img_metadata[&#39;img_height&#39;]

            img_shape = (img_width, img_height)
            ref_coords = ref_counts_df.loc[:,[&#39;r_px_original&#39;, &#39;c_px_original&#39;]].to_numpy()
            img_ref = create_fake_image(img_shape,ref_coords)
    

            for zarr_name in tran_processing_files:
                round_num = int(zarr_name.split(&#39;_&#39;)[-4].split(&#39;Hybridization&#39;)[-1])
                try:
                    tran_counts, tran_img_metadata = counts_output[&#39;registration&#39;][channel][zarr_name]
                except:
                    logger.error(f&#39;cannot open {zarr_name} file for fov {fov}&#39;)
                    # If there is an error in the opening reset the df
                    output_registration_df = data_models.output_registration_df
                    output_registration_df = output_registration_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.cannot_load_file_reg_channel,
                                        &#39;fov_num&#39;:int(fov) ,&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num)},ignore_index=True)
                    status = &#39;FAILED&#39;
                    all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
                    break
                else:
                    tran_counts_df = pd.DataFrame(tran_counts)
                    tran_coords = tran_counts_df.loc[:,[&#39;r_px_original&#39;, &#39;c_px_original&#39;]].to_numpy()
                    if np.any(np.isnan(tran_coords)) or tran_coords.shape[0]&lt;registration_tollerance_pxl:
                        # If dots are missing, reset the df
                        output_registration_df = data_models.output_registration_df
                        output_registration_df = output_registration_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.missing_counts_reg_channel,
                                        &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num) },ignore_index=True)
                        status = &#39;FAILED&#39;
                        all_rounds_shifts[round_num] = np.array([np.nan,np.nan])
                        logger.error(f&#39; {zarr_name} file for fov {fov} has no counts&#39;)
                        break
                    else:
                        
                        round_num = tran_counts[&#39;round_num&#39;][0]
                        ref_img_metadata[&#39;reference_hyb&#39;] = str(reference_hybridization)
                        img_tran = create_fake_image(img_shape,tran_coords)
                        shift, error, diffphase = register_translation(img_ref, img_tran)
                        all_rounds_shifts[round_num] = shift
                        registered_tran_coords = tran_coords + shift
                        min_num_matching_dots = identify_matching_register_dots_NN(ref_coords,
                                                                                registered_tran_coords,
                                                                                registration_tollerance_pxl)
                        
                        tran_counts_df[&#39;r_px_registered&#39;] = registered_tran_coords[:,0]
                        tran_counts_df[&#39;c_px_registered&#39;] = registered_tran_coords[:,1]
                        tran_counts_df[&#39;r_shift_px&#39;] = shift[0]
                        tran_counts_df[&#39;c_shift_px&#39;] = shift[1]
                        tran_counts_df[&#39;min_number_matching_dots_registration&#39;] = min_num_matching_dots

                        output_registration_df = pd.concat([output_registration_df,tran_counts_df],axis=0,ignore_index=True)

            # Save the dataframe
            
            output_registration_df[&#39;reference_hyb&#39;] = reference_hybridization
            output_registration_df[&#39;experiment_type&#39;] = ref_img_metadata[&#39;experiment_type&#39;]
            output_registration_df[&#39;experiment_name&#39;] = ref_img_metadata[&#39;experiment_name&#39;]
            output_registration_df[&#39;pxl_um&#39;] = ref_img_metadata[&#39;pixel_microns&#39;]
            output_registration_df[&#39;stitching_type&#39;] = ref_img_metadata[&#39;stitching_type&#39;]
            output_registration_df[&#39;img_width_px&#39;] = ref_img_metadata[&#39;img_width&#39;]
            output_registration_df[&#39;img_height_px&#39;] = ref_img_metadata[&#39;img_height&#39;]
            output_registration_df[&#39;fov_acquisition_coords_x&#39;] = ref_img_metadata[&#39;fov_acquisition_coords_x&#39;]
            output_registration_df[&#39;fov_acquisition_coords_y&#39;] = ref_img_metadata[&#39;fov_acquisition_coords_y&#39;]
            output_registration_df[&#39;fov_acquisition_coords_z&#39;] = ref_img_metadata[&#39;fov_acquisition_coords_z&#39;]
    
    
    return output_registration_df, all_rounds_shifts, status</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.combine_register_filtered_image_single_channel"><code class="name flex">
<span>def <span class="ident">combine_register_filtered_image_single_channel</span></span>(<span>output_dict:dict, metadata:dict, all_rounds_shifts:dict) >numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to register the image throughout all rounds.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>output_dict</code></strong> :&ensp;<code>dict</code></dt>
<dd>dict containg output of the filtering ((img,),metadata) organised
by channe and round.</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>dict</code></dt>
<dd>Metadata that characterize the acquired images</dd>
<dt><strong><code>registered_counts</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Counts after registration.</dd>
<dt><strong><code>channel</code></strong> :&ensp;<code>str</code></dt>
<dd>processing channel</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Image stack with all the rounds registered.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def combine_register_filtered_image_single_channel(output_dict: dict, metadata: dict, 
                                    all_rounds_shifts:dict)-&gt;np.ndarray:
    &#34;&#34;&#34;Function used to register the image throughout all rounds.

    Args:
        output_dict (dict): dict containg output of the filtering ((img,),metadata) organised
                            by channe and round.
        metadata (dict): Metadata that characterize the acquired images
        registered_counts (pd.DataFrame): Counts after registration.
        channel (str): processing channel

    Returns:
        np.ndarray: Image stack with all the rounds registered.
    &#34;&#34;&#34;
    if isinstance(all_rounds_shifts, dict) and isinstance(output_dict,dict):
        img_stack = np.zeros([int(metadata[&#39;total_rounds&#39;]),int(metadata[&#39;img_width&#39;]),int(metadata[&#39;img_height&#39;])])
        for round_num, filt_out in output_dict.items():
            img = filt_out[0][0]
            shift = all_rounds_shifts[int(round_num)]
            if isinstance(shift,np.ndarray):
                shifted_img = register_images(img,shift)
                img_stack[round_num-1,:,:] = shifted_img
        return img_stack
    else:
        img_stack = np.nan</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.combine_register_filtered_images"><code class="name flex">
<span>def <span class="ident">combine_register_filtered_images</span></span>(<span>output_dict:dict, metadata:dict, all_rounds_shifts:dict) >numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to register the image throughout all rounds.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>output_dict</code></strong> :&ensp;<code>dict</code></dt>
<dd>dict containg output of the filtering ((img,),metadata) organised
by channe and round.</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>dict</code></dt>
<dd>Metadata that characterize the acquired images</dd>
<dt><strong><code>registered_counts</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Counts after registration.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Image stack with all the rounds registered.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def combine_register_filtered_images(output_dict: dict, metadata: dict, 
                                    all_rounds_shifts:dict)-&gt;np.ndarray:
    &#34;&#34;&#34;Function used to register the image throughout all rounds.

    Args:
        output_dict (dict): dict containg output of the filtering ((img,),metadata) organised
                            by channe and round.
        metadata (dict): Metadata that characterize the acquired images
        registered_counts (pd.DataFrame): Counts after registration.

    Returns:
        np.ndarray: Image stack with all the rounds registered.
    &#34;&#34;&#34;
    registered_img_stack = {}
    if isinstance(all_rounds_shifts, dict) and (output_dict):
        for channel, all_rounds_data in output_dict.items():
            img_stack = np.zeros([int(metadata[&#39;total_rounds&#39;]),int(metadata[&#39;img_width&#39;]),int(metadata[&#39;img_height&#39;])])
            for round_num, filt_out in all_rounds_data.items():
                img = filt_out[0][0]
                shift = all_rounds_shifts[int(round_num)]
                if isinstance(shift,np.ndarray):
                    shifted_img = register_images(img,shift)
                    img_stack[round_num-1,:,:] = shifted_img
            registered_img_stack[channel] = img_stack
        return registered_img_stack
    else:
        registered_img_stack = np.nan</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.create_fake_image"><code class="name flex">
<span>def <span class="ident">create_fake_image</span></span>(<span>img_shape:numpy.ndarray, coords:numpy.ndarray) >numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to create an image from dots counts. The image
will be used for FFT based registration. The dots are mapped in
the image and the signal is enhanced using a gaussian. This
increase the features that can be used in the FFT based
registration.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>img_shape</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Shape of the image to create. It matches
the shape of the images to process.</dd>
<dt><strong><code>coords</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Coordinates of the peaks detected.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>synthetic image used for registration</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_fake_image(img_shape: np.ndarray,coords: np.ndarray)-&gt;np.ndarray:
    &#34;&#34;&#34;Function used to create an image from dots counts. The image
    will be used for FFT based registration. The dots are mapped in
    the image and the signal is enhanced using a gaussian. This
    increase the features that can be used in the FFT based
    registration.

    Args:
        img_shape (np.ndarray): Shape of the image to create. It matches
            the shape of the images to process.
        coords (np.ndarray): Coordinates of the peaks detected.

    Returns:
        np.ndarray: synthetic image used for registration
    &#34;&#34;&#34;
    gaussian_sigma = 1 # original is 5 
    img = np.zeros(img_shape,dtype=np.float64)
    img[coords[:,0].astype(int),coords[:,1].astype(int)] = 1000
    img = filters.gaussian(img,sigma=gaussian_sigma)
    return img</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.create_registration_grps"><code class="name flex">
<span>def <span class="ident">create_registration_grps</span></span>(<span>experiment_fpath:str, registration_channel:str, fovs:List, save=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Function to create groups of files that need to be registered together</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>experiment_fpath</code></strong></dt>
<dd>str
Path to the exp directory </dd>
<dt>registration_channel : str</dt>
<dt>Name of the channel used for registration of the fovs</dt>
<dt><strong><code>fovs</code></strong></dt>
<dd>List
List of the keys used for grouping</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>all_grps</code></dt>
<dd>List
List of tuples containing the file names of reference
channel and fish grouped by fov</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_registration_grps(experiment_fpath:str,registration_channel:str, fovs:List, save=True):
    &#34;&#34;&#34;
    Function to create groups of files that need to be registered together
    Args:
        experiment_fpath: str
            Path to the exp directory 
        registration_channel : str
            Name of the channel used for registration of the fovs
        fovs: List
            List of the keys used for grouping
    Returns:
        all_grps: List
            List of tuples containing the file names of reference
            channel and fish grouped by fov
    &#34;&#34;&#34;
    logger = selected_logger()
    tmp_fpath = Path(experiment_fpath) / &#39;tmp/raw_counts&#39;
    all_files = set(tmp_fpath.glob(&#39;*&#39;))
    registration_files = list(tmp_fpath.glob(&#39;*&#39; + registration_channel + &#39;*&#39;))
    fish_files = all_files.difference(registration_files)

    all_grps = []
    for fov in fovs:
        search_key_reg = registration_channel + &#39;_fov_&#39; + str(fov) + &#39;_dots.pkl&#39;
        search_key_fish =  &#39;_fov_&#39; + str(fov) + &#39;_dots.pkl&#39;
        grp_reg = [reg_f for reg_f in registration_files if search_key_reg in reg_f.as_posix()]
        grp_fish = [fish_f for fish_f in fish_files if search_key_fish in fish_f.as_posix()]
        logger.debug(f&#39;fov {fov} for registration on {registration_channel} has {len(grp_reg)} counts files&#39;)
        all_grps.append((grp_reg, grp_fish))
    if save:
        fname = Path(experiment_fpath) / &#39;tmp&#39; / &#39;registration_groups.pkl&#39;
        pickle.dump(all_grps, open(fname,&#39;wb&#39;))
    return all_grps</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.determine_overlap_region"><code class="name flex">
<span>def <span class="ident">determine_overlap_region</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Determine the overlap between two neighbouring tiles</p>
<h2 id="parameters">Parameters:</h2>
<p>ind1: int
Index (flattened) of tile 1
ind2: int
Index (flattened) of tile 2</p>
<p>micData: object
MicroscopeData object containing coordinates</p>
<h2 id="returns">Returns:</h2>
<p>overlap1: np.array
Overlapping part of tile_1
overlap2: np.array
Overlapping part of tile_2
plot_order: np.array
Numpy array of ones. The shape of this array is
used for plotting the overlaps in well fitting
subplots.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def determine_overlap_region(self):
        &#34;&#34;&#34;Determine the overlap between two neighbouring tiles

        Parameters:
        -----------

        ind1: int
            Index (flattened) of tile 1
        ind2: int
            Index (flattened) of tile 2

        micData: object
            MicroscopeData object containing coordinates

        Returns:
        --------

        overlap1: np.array
            Overlapping part of tile_1
        overlap2: np.array
            Overlapping part of tile_2
        plot_order: np.array
            Numpy array of ones. The shape of this array is
            used for plotting the overlaps in well fitting
            subplots.
        &#34;&#34;&#34;
        
        
        if np.ma.is_masked(self.micData.tile_set.flat[:][self.ind1]):
            tile_1 = False
        else:
            tile_1 = True
            fnum_tile_1 = self.micData.tile_set.flat[:][self.ind1] + self.micData.tile_nr.min()
            
        
        if np.ma.is_masked(self.micData.tile_set.flat[:][self.ind2]):
            tile_2 = False
        else:
            tile_2 = True
            fnum_tile_2 = self.micData.tile_set.flat[:][self.ind2] + self.micData.tile_nr.min()
            

        if (tile_1 and tile_2):
            self.tiles_num = (fnum_tile_1, fnum_tile_2)
            self.tile1_x_coords = self.micData.x_coords[self.micData.tile_set.flat[:][self.ind1]]
            self.tile2_x_coords = self.micData.x_coords[self.micData.tile_set.flat[:][self.ind2]]
            self.tile1_y_coords = self.micData.y_coords[self.micData.tile_set.flat[:][self.ind1]]
            self.tile2_y_coords = self.micData.y_coords[self.micData.tile_set.flat[:][self.ind2]]

            tile_1_fpath = [fpath for fpath in self.counting_files_list if &#39;pos_&#39;+str(fnum_tile_1)+&#39;.&#39; in str(fpath)][0]
            self.tile_1_store = zarr.DirectoryStore(tile_1_fpath)
            self.tile_1_root = zarr.group(store=self.tile_1_store, overwrite=False)
            self.tile_1_counts = self.tile_1_root[&#39;stringency_raw_counts&#39;][&#39;coords_original&#39;][...]
            tile_1_ref_coords = np.array([self.tile1_y_coords,self.tile1_x_coords])
            tile_1_ref_coords = tile_1_ref_coords[:,np.newaxis]
            self.tile_1_adj_coords = self.tile_1_counts + tile_1_ref_coords


            tile_2_fpath = [fpath for fpath in self.counting_files_list if &#39;pos_&#39;+str(fnum_tile_2)+&#39;.&#39; in str(fpath)][0]
            self.tile_2_store = zarr.DirectoryStore(tile_2_fpath)
            self.tile_2_root = zarr.group(store=self.tile_2_store, overwrite=False)
            self.tile_2_counts = self.tile_2_root[&#39;stringency_raw_counts&#39;][&#39;coords_original&#39;][...]
            tile_2_ref_coords = np.array([self.tile2_y_coords,self.tile2_x_coords])
            tile_2_ref_coords = tile_2_ref_coords[:,np.newaxis]
            self.tile_2_adj_coords = self.tile_2_counts + tile_2_ref_coords


            
            if self.tile1_y_coords &gt; self.tile2_y_coords:
                r_tl = self.tile1_y_coords
                r_br = self.tile2_y_coords + self.img_size

                r_bl = self.tile2_y_coords + self.img_size
                r_tr = self.tile1_y_coords
                
            else:
                r_tl = self.tile2_y_coords
                r_br = self.tile1_y_coords + self.img_size
                
                r_bl = self.tile1_y_coords + self.img_size
                r_tr = self.tile2_y_coords

            if self.tile1_x_coords &gt; self.tile2_x_coords:
                c_tl = self.tile1_x_coords
                c_br = self.tile2_x_coords + self.img_size
                
                c_tr = self.tile2_x_coords + self.img_size
                c_bl = self.tile1_x_coords
                
            else:
                c_tl = self.tile2_x_coords
                c_br = self.tile1_x_coords + self.img_size
                
                c_bl = self.tile2_x_coords
                c_tr = self.tile1_x_coords + self.img_size


            self.tl_coords = np.array([r_tl,c_tl])
            self.br_coords = np.array([r_br,c_br])
            self.tr_coords = np.array([r_tr,c_tr])
            self.bl_coords = np.array([r_bl,c_bl])
            num_r = np.abs(self.tl_coords[1] - self.tr_coords[1])
            num_c = np.abs(self.tr_coords[0] - self.bl_coords[0])
            self.region_dimensions = (num_c,num_r)


        else:
            self.tl_coords = self.br_coords = self.tr_coords = self.bl_coords = None</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.fft_registration_beads"><code class="name flex">
<span>def <span class="ident">fft_registration_beads</span></span>(<span>reference_coords:numpy.ndarray, translated_coords:numpy.ndarray, img_shape:numpy.ndarray, fov_num:int, hybridization_num_translated:int)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fft_registration_beads(reference_coords:np.ndarray, translated_coords:np.ndarray,
                       img_shape: np.ndarray, fov_num:int,
                       hybridization_num_translated:int):

    # CHECK THE VALUES AND CATCH THE ERROR TO BLOCK FOV FOR REGISTRATION     
    if np.any(np.isnan(reference_coords)):
        logger.error(f&#39;missing reference round for registration for fov {fov_num}&#39;) 
        signals.SKIP(f&#39;missing reference round for registration for fov {fov_num}&#39;)
        shift = np.array([np.nan,np.nan])
        error = 0
        tran_registered_coords = translated_coords
        
        # RETURN VALUES TO WRITE ON DB
    elif np.any(np.isnan(translated_coords)):
        logger.error(f&#39;missing registration round {hybridization_num_translated} for registration for fov {fov_num}&#39;)   
        shift = np.array([np.nan,np.nan])
        error = 0
        tran_registered_coords = translated_coords
        
    else:
        img_ref = create_fake_image(img_shape,reference_coords)    
        img_tran = create_fake_image(img_shape,translated_coords)
        shift, error, diffphase = register_translation(img_ref, img_tran)
        tran_registered_coords = translated_coords + shift
        tran_registered_coords = tran_registered_coords.astype(int)

    return tran_registered_coords, shift, error, fov_num, hybridization_num_translated </code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.identify_matching_register_dots_NN"><code class="name flex">
<span>def <span class="ident">identify_matching_register_dots_NN</span></span>(<span>ref_dots_coords_fov, tran_registered_coords, registration_tollerance_pxl)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def identify_matching_register_dots_NN(ref_dots_coords_fov,tran_registered_coords,registration_tollerance_pxl):
    # put in the wrapping function
    #if (ref_dots_coords_fov.shape[0] &gt;0) and (tran_registered_coords.shape[0] &gt;0):
            
    # initialize network
    nn = NearestNeighbors(n_neighbors=1, metric=&#34;euclidean&#34;)
    nn.fit(ref_dots_coords_fov)

    # Get the nn
    dists, indices = nn.kneighbors(tran_registered_coords, return_distance=True)

    # select only the nn that are below pxl distance
    idx_selected_coords_compare = np.where(dists &lt;= registration_tollerance_pxl)[0]

    number_matching_dots = idx_selected_coords_compare.shape[0]
    
    return number_matching_dots</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.nuclei_based_registration"><code class="name flex">
<span>def <span class="ident">nuclei_based_registration</span></span>(<span>all_counts_fov:pandas.core.frame.DataFrame, img_stack:numpy.ndarray, analysis_parameters:Dict) >pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to run the registration of a single fov
through all hybridization. The registration is done using the dots
coords determined in each image</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>all_counts_fov</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Coords of all peaks</dd>
<dt><strong><code>img_stack</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Image stack of the nuclei from different rounds</dd>
<dt><strong><code>analysis_parameters</code></strong> :&ensp;<code>Dict</code></dt>
<dd>Processing parameters</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>All registered counts</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nuclei_based_registration(all_counts_fov: pd.DataFrame,
                            img_stack: np.ndarray,
                            analysis_parameters: Dict)-&gt;pd.DataFrame:
    &#34;&#34;&#34;Function used to run the registration of a single fov
    through all hybridization. The registration is done using the dots
    coords determined in each image

    Args:
        all_counts_fov (pd.DataFrame): Coords of all peaks
        img_stack (np.ndarray): Image stack of the nuclei from different rounds
        analysis_parameters (Dict): Processing parameters

    Returns:
        pd.DataFrame: All registered counts
    &#34;&#34;&#34;
   
    
    logger = selected_logger()
    
    # Used index to avoid to remake the output dataframe
    
    stitching_channel = all_counts_fov[&#39;stitching_channel&#39;].iloc[0]
    stitching_channel_df = all_counts_fov.loc[all_counts_fov.channel == stitching_channel, :]
    fish_df = all_counts_fov.loc[all_counts_fov.channel != stitching_channel,:]
    
    reference_round_num = analysis_parameters[&#39;RegistrationReferenceHybridization&#39;]
    ref_round_num_img = reference_round_num -1
    registration_tollerance_pxl = analysis_parameters[&#39;RegistrationTollerancePxl&#39;]
    
    registration_errors = Registration_errors()
    
    
    # Determine if there are any round with missing counts in the registration
    if stitching_channel_df[stitching_channel_df[&#39;dot_id&#39;].isnull()].empty :
    
        all_counts_fov[&#39;r_px_registered&#39;] = np.nan
        all_counts_fov[&#39;c_px_registered&#39;] = np.nan
        all_counts_fov[&#39;r_shift_px&#39;] = np.nan
        all_counts_fov[&#39;c_shift_px&#39;] = np.nan
        all_counts_fov[&#39;min_number_matching_dots_registration&#39;] = np.nan
        all_counts_fov[&#39;RMS&#39;] = np.nan


        # Register fish and enter ref round info
        fish_ref_round = fish_df.loc[fish_df.round_num == reference_round_num,:]

        all_counts_fov.loc[fish_ref_round.index,&#39;r_px_registered&#39;] =  \
                fish_ref_round.loc[fish_ref_round.index,&#39;r_px_original&#39;]
        all_counts_fov.loc[fish_ref_round.index,&#39;c_px_registered&#39;] =  \
                fish_ref_round.loc[fish_ref_round.index,&#39;c_px_original&#39;]
        all_counts_fov.loc[fish_ref_round.index,&#39;r_shift_px&#39;] =  0
        all_counts_fov.loc[fish_ref_round.index,&#39;c_shift_px&#39;] =  0
        all_counts_fov.loc[fish_ref_round.index,&#39;min_number_matching_dots_registration&#39;] =  1000
        all_counts_fov.loc[fish_ref_round.index,&#39;RMS&#39;] =  0

        all_rounds = np.arange(img_stack.shape[0])
        all_rounds = all_rounds[all_rounds != ref_round_num_img]

        ref_img = img_stack[ref_round_num_img,:,:]
    
        for r_num in all_rounds:
            # Register fish
            fish_ref_round = fish_df.loc[fish_df.round_num == (r_num+1),:]

            shift, error, diffphase = phase_cross_correlation(ref_img, img_stack[r_num,:,:],return_error=True)    
            
            all_counts_fov.loc[fish_ref_round.index,&#39;r_px_registered&#39;] =  fish_ref_round[&#39;r_px_original&#39;] + shift[0] 
            all_counts_fov.loc[fish_ref_round.index,&#39;c_px_registered&#39;] =  fish_ref_round[&#39;c_px_original&#39;] + shift[1]
            all_counts_fov.loc[fish_ref_round.index,&#39;r_shift_px&#39;] =  shift[0] 
            all_counts_fov.loc[fish_ref_round.index,&#39;c_shift_px&#39;] =  shift[1]
            all_counts_fov.loc[fish_ref_round.index,
                        &#39;min_number_matching_dots_registration&#39;] =  error
            all_counts_fov.loc[fish_ref_round.index,&#39;RMS&#39;] =  0

    else:
        
        all_counts_fov[&#39;r_px_registered&#39;] = np.nan
        all_counts_fov[&#39;c_px_registered&#39;] = np.nan
        all_counts_fov[&#39;r_shift_px&#39;] = np.nan
        all_counts_fov[&#39;c_shift_px&#39;] = np.nan
        all_counts_fov[&#39;min_number_matching_dots_registration&#39;] = registration_errors.missing_counts_reg_channel
        all_counts_fov[&#39;RMS&#39;] = np.nan
     
    return all_counts_fov</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.register_fish"><code class="name flex">
<span>def <span class="ident">register_fish</span></span>(<span>processing_files:List, analysis_parameters:Dict, registered_reference_channel_df, all_rounds_shifts:Dict, file_tags:Dict, status:str, save=True)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def register_fish(processing_files:List,analysis_parameters:Dict,
                        registered_reference_channel_df,all_rounds_shifts:Dict,file_tags:Dict,status:str,
                        save=True):

    logger = selected_logger()
    registration_errors = Registration_errors()
    data_models = Output_models()
    fov = file_tags[&#39;fov&#39;]
    channel = (processing_files[0].stem).split(&#39;_&#39;)[-4]
    file_tags[&#39;channel&#39;] = channel
    registered_fish_df = data_models.output_registration_df

    if status == &#39;FAILED&#39;:
        error = registered_reference_channel_df[&#39;min_number_matching_dots_registration&#39;].values[0]
        round_num = registered_reference_channel_df[&#39;round_num&#39;].values[0]
        registered_fish_df = registered_fish_df.append({&#39;min_number_matching_dots_registration&#39;:error,
                                                           &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num) },ignore_index=True)
    elif status == &#39;SUCCESS&#39;:
        reference_hybridization = registered_reference_channel_df.attrs[fov][&#39;reference_hyb&#39;]
        reference_hybridization_str = &#39;Hybridization&#39; + str(reference_hybridization).zfill(2)
        for fpath in processing_files:
            round_num = int((fpath.stem).split(&#39;_&#39;)[-5].split(&#39;Hybridization&#39;)[-1])
            try:
                fish_counts, fish_img_metadata = pickle.load(open(fpath,&#39;rb&#39;))
            except:
                logger.error(f&#39;cannot open the processing files&#39;)
                
                registered_fish_df = registered_fish_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.cannot_load_file_fish_channel,
                                                &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:round_num },ignore_index=True)
                status = &#39;FAILED&#39;
                break
            else:                
                if np.any(np.isnan(fish_counts[&#39;r_px_original&#39;])):
                    logger.error(f&#39;There are no dots in there reference hyb for fov {fov} &#39;)
                    registered_fish_df = registered_fish_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.missing_counts_fish_channel,
                                                &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:round_num },ignore_index=True)
                    status = &#39;FAILED&#39;
                    break

                else:
                    if reference_hybridization_str in fpath.as_posix():
                        fish_img_metadata[&#39;reference_hyb&#39;] = reference_hybridization
                        registered_fish_df.attrs[fov] = fish_img_metadata
                    fish_counts_df = pd.DataFrame(fish_counts)
                    
                    subset_df = registered_reference_channel_df.loc[registered_reference_channel_df[&#39;round_num&#39;] == round_num, :]
                    subset_df = subset_df.reset_index()
                        
                    shift = all_rounds_shifts[round_num]
                    fish_counts_df[&#39;r_px_registered&#39;] = fish_counts[&#39;r_px_original&#39;] + shift[0]
                    fish_counts_df[&#39;c_px_registered&#39;] = fish_counts[&#39;c_px_original&#39;] + shift[1]
                    fish_counts_df[&#39;r_shift_px&#39;] = shift[0]
                    fish_counts_df[&#39;c_shift_px&#39;] = shift[1]
                    fish_counts_df[&#39;min_number_matching_dots_registration&#39;] = subset_df.loc[0,&#39;min_number_matching_dots_registration&#39;] 
                    # fish_counts_df[&#39;reference_hyb&#39;] = reference_hybridization
                    # fish_counts_df[&#39;experiment_type&#39;] = subset_df.loc[0,&#39;experiment_type&#39;]
                    # fish_counts_df[&#39;experiment_name&#39;] = subset_df.loc[0,&#39;experiment_name&#39;]
                    # fish_counts_df[&#39;pxl_um&#39;] = subset_df.loc[0,&#39;pxl_um&#39;]
                    # fish_counts_df[&#39;stitching_type&#39;] = subset_df.loc[0,&#39;stitching_type&#39;]
                    # fish_counts_df[&#39;fov_acquisition_coords_x&#39;] = subset_df.loc[0,&#39;fov_acquisition_coords_x&#39;]
                    # fish_counts_df[&#39;fov_acquisition_coords_y&#39;] = subset_df.loc[0,&#39;fov_acquisition_coords_y&#39;]
                    # fish_counts_df[&#39;fov_acquisition_coords_z&#39;] = subset_df.loc[0,&#39;fov_acquisition_coords_z&#39;]

                    registered_fish_df = pd.concat([registered_fish_df,fish_counts_df],axis=0,ignore_index=True)
                    status = &#39;SUCCESS&#39;

    if save:
        fname = file_tags[&#39;experiment_fpath&#39;] / &#39;tmp&#39; / &#39;registered_counts&#39; / (file_tags[&#39;experiment_name&#39;] + &#39;_&#39; + file_tags[&#39;channel&#39;] + &#39;_registered_fov_&#39; + file_tags[&#39;fov&#39;] + &#39;.parquet&#39;)
        registered_fish_df.to_parquet(fname,index=False)
    return registered_fish_df, file_tags, status</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.register_fish_on_nuclei"><code class="name flex">
<span>def <span class="ident">register_fish_on_nuclei</span></span>(<span>processing_files:List, analysis_parameters:Dict, registered_reference_channel_df, all_rounds_shifts:Dict, file_tags:Dict, status:str, save=True)</span>
</code></dt>
<dd>
<div class="desc"><p>The only difference to the other function is the channel name definition</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def register_fish_on_nuclei(processing_files:List,analysis_parameters:Dict,
                        registered_reference_channel_df,all_rounds_shifts:Dict,file_tags:Dict,status:str,
                        save=True):
    &#34;&#34;&#34;
    The only difference to the other function is the channel name definition
    &#34;&#34;&#34;
    logger = selected_logger()
    registration_errors = Registration_errors()
    data_models = Output_models()
    fov = file_tags[&#39;fov&#39;]
    channel = &#39;all_channels&#39;
    file_tags[&#39;channel&#39;] = channel
    registered_fish_df = data_models.output_registration_df

    if status == &#39;FAILED&#39;:
        error = registered_reference_channel_df[&#39;min_number_matching_dots_registration&#39;].values[0]
        round_num = registered_reference_channel_df[&#39;round_num&#39;].values[0]
        registered_fish_df = registered_fish_df.append({&#39;min_number_matching_dots_registration&#39;:error,
                                                           &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num) },ignore_index=True)
    elif status == &#39;SUCCESS&#39;:
        reference_hybridization = registered_reference_channel_df.attrs[fov][&#39;reference_hyb&#39;]
        reference_hybridization_str = &#39;Hybridization&#39; + str(reference_hybridization).zfill(2)
        for fpath in processing_files:
            round_num = int((fpath.stem).split(&#39;_&#39;)[-5].split(&#39;Hybridization&#39;)[-1])
            try:
                fish_counts, fish_img_metadata = pickle.load(open(fpath,&#39;rb&#39;))
            except:
                logger.error(f&#39;cannot open the processing files&#39;)
                
                registered_fish_df = registered_fish_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.cannot_load_file_fish_channel,
                                                &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:round_num },ignore_index=True)
                status = &#39;FAILED&#39;
                break
            else:                
                if np.any(np.isnan(fish_counts[&#39;r_px_original&#39;])):
                    logger.error(f&#39;There are no dots in there reference hyb for fov {fov} &#39;)
                    registered_fish_df = registered_fish_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.missing_counts_fish_channel,
                                                &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:round_num },ignore_index=True)
                    status = &#39;FAILED&#39;
                    break

                else:
                    if reference_hybridization_str in fpath.as_posix():
                        fish_img_metadata[&#39;reference_hyb&#39;] = reference_hybridization
                        registered_fish_df.attrs[fov] = fish_img_metadata
                    fish_counts_df = pd.DataFrame(fish_counts)
                    
                    subset_df = registered_reference_channel_df.loc[registered_reference_channel_df[&#39;round_num&#39;] == round_num, :]
                    subset_df = subset_df.reset_index()
                        
                    shift = all_rounds_shifts[round_num]
                    fish_counts_df[&#39;r_px_registered&#39;] = fish_counts[&#39;r_px_original&#39;] + shift[0]
                    fish_counts_df[&#39;c_px_registered&#39;] = fish_counts[&#39;c_px_original&#39;] + shift[1]
                    fish_counts_df[&#39;r_shift_px&#39;] = shift[0]
                    fish_counts_df[&#39;c_shift_px&#39;] = shift[1]
                    fish_counts_df[&#39;min_number_matching_dots_registration&#39;] = subset_df.loc[0,&#39;min_number_matching_dots_registration&#39;] 
                    registered_fish_df = pd.concat([registered_fish_df,fish_counts_df],axis=0,ignore_index=True)
                    status = &#39;SUCCESS&#39;

    if save:
        fname = file_tags[&#39;experiment_fpath&#39;] / &#39;tmp&#39; / &#39;registered_counts&#39; / (file_tags[&#39;experiment_name&#39;] + &#39;_&#39; + file_tags[&#39;channel&#39;] +&#39;_registered_fov_&#39; + file_tags[&#39;fov&#39;] + &#39;.parquet&#39;)
        registered_fish_df.to_parquet(fname,index=False)
    return registered_fish_df, file_tags, status</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.register_fish_on_nuclei_test"><code class="name flex">
<span>def <span class="ident">register_fish_on_nuclei_test</span></span>(<span>fov:int, counts_output:Dict, registered_reference_channel_df, all_rounds_shifts:Dict, analysis_parameters:Dict, status:str)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def register_fish_on_nuclei_test(fov:int,
                        counts_output:Dict,
                        registered_reference_channel_df,
                        all_rounds_shifts:Dict,
                        analysis_parameters:Dict,
                        status:str):

    logger = selected_logger()
    registration_errors = Registration_errors()
    data_models = Output_models()

    registered_fish_df = data_models.output_registration_df

    if status == &#39;FAILED&#39;:
        error = registered_reference_channel_df[&#39;min_number_matching_dots_registration&#39;].values[0]
        round_num = registered_reference_channel_df[&#39;round_num&#39;].values[0]
        registered_fish_df = registered_fish_df.append({&#39;min_number_matching_dots_registration&#39;:error,
                                                           &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num) },ignore_index=True)
    elif status == &#39;SUCCESS&#39;:
        reference_hybridization = analysis_parameters[&#39;RegistrationReferenceHybridization&#39;]
        reference_hybridization_str = &#39;Hybridization&#39; + str(reference_hybridization).zfill(2)
        
        for channel, all_counts_dict in counts_output[&#39;fish&#39;].items():
            for zarr_name, fish_counts_tpl in all_counts_dict.items():
                round_num = int(zarr_name.split(&#39;_&#39;)[-4].split(&#39;Hybridization&#39;)[-1])
                
                fish_counts, fish_img_metadata = fish_counts_tpl

                fish_counts_df = pd.DataFrame(fish_counts)
                shift = all_rounds_shifts[round_num]
                fish_counts_df[&#39;r_px_registered&#39;] = fish_counts[&#39;r_px_original&#39;] + shift[0]
                fish_counts_df[&#39;c_px_registered&#39;] = fish_counts[&#39;c_px_original&#39;] + shift[1]
                fish_counts_df[&#39;r_shift_px&#39;] = shift[0]
                fish_counts_df[&#39;c_shift_px&#39;] = shift[1]
                # fish_counts_df[&#39;min_number_matching_dots_registration&#39;] = fish_counts[&#39;min_number_matching_dots_registration&#39;]
                fish_counts_df[&#39;reference_hyb&#39;] = reference_hybridization
                # fish_counts_df[&#39;experiment_type&#39;] = fish_counts[&#39;experiment_type&#39;]
                # fish_counts_df[&#39;experiment_name&#39;] = fish_counts[&#39;experiment_name&#39;]
                # fish_counts_df[&#39;pxl_um&#39;] = fish_counts[&#39;pxl_um&#39;]
                # fish_counts_df[&#39;stitching_type&#39;] = fish_counts[&#39;stitching_type&#39;]
                # fish_counts_df[&#39;fov_acquisition_coords_x&#39;] = fish_counts[&#39;fov_acquisition_coords_x&#39;]
                # fish_counts_df[&#39;fov_acquisition_coords_y&#39;] = fish_counts[&#39;fov_acquisition_coords_y&#39;]
                # fish_counts_df[&#39;fov_acquisition_coords_z&#39;] = fish_counts[&#39;fov_acquisition_coords_z&#39;]
                # fish_counts_df[&#39;img_width_px&#39;] = fish_img_metadata[&#39;img_width&#39;]
                # fish_counts_df[&#39;img_height_px&#39;] = fish_img_metadata[&#39;img_height&#39;]
                
                registered_fish_df = pd.concat([registered_fish_df,fish_counts_df],axis=0,ignore_index=True)
        status = &#39;SUCCESS&#39;

    return registered_fish_df, status</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.register_fish_test"><code class="name flex">
<span>def <span class="ident">register_fish_test</span></span>(<span>fov:int, channel:str, counts_output:Dict, registered_reference_channel_df, all_rounds_shifts:Dict, analysis_parameters:Dict, status:str)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def register_fish_test(fov:int,
                        channel:str,
                        counts_output:Dict,
                        registered_reference_channel_df,
                        all_rounds_shifts:Dict,
                        analysis_parameters:Dict,
                        status:str):

    logger = selected_logger()
    registration_errors = Registration_errors()
    data_models = Output_models()

    registered_fish_df = data_models.output_registration_df

    counts_zarr_names = list(counts_output[&#39;fish&#39;][channel].keys())

    if status == &#39;FAILED&#39;:
        error = registered_reference_channel_df[&#39;min_number_matching_dots_registration&#39;].values[0]
        round_num = registered_reference_channel_df[&#39;round_num&#39;].values[0]
        registered_fish_df = registered_fish_df.append({&#39;min_number_matching_dots_registration&#39;:error,
                                                           &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:int(round_num) },ignore_index=True)
    elif status == &#39;SUCCESS&#39;:
        reference_hybridization = analysis_parameters[&#39;RegistrationReferenceHybridization&#39;]
        reference_hybridization_str = &#39;Hybridization&#39; + str(reference_hybridization).zfill(2)
        
        for zarr_name in counts_zarr_names:
            round_num = int(zarr_name.split(&#39;_&#39;)[-4].split(&#39;Hybridization&#39;)[-1])
            try:
                fish_counts, fish_img_metadata = counts_output[&#39;fish&#39;][channel][zarr_name]
            except:
                logger.error(f&#39;missing the counts in {zarr_name}&#39;)
                
                registered_fish_df = registered_fish_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.cannot_load_file_fish_channel,
                                                &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:round_num },ignore_index=True)
                status = &#39;FAILED&#39;
                break
            else:                
                if np.any(np.isnan(fish_counts[&#39;r_px_original&#39;])):
                    logger.error(f&#39;There are no dots in there reference hyb for fov {fov} &#39;)
                    registered_fish_df = registered_fish_df.append({&#39;min_number_matching_dots_registration&#39;:registration_errors.missing_counts_fish_channel,
                                                &#39;fov_num&#39;:int(fov),&#39;dot_channel&#39;:channel,&#39;round_num&#39;:round_num },ignore_index=True)
                    status = &#39;FAILED&#39;
                    break

                else:
                    if reference_hybridization_str in zarr_name:
                        fish_img_metadata[&#39;reference_hyb&#39;] = reference_hybridization
                        registered_fish_df.attrs[fov] = fish_img_metadata
                    fish_counts_df = pd.DataFrame(fish_counts)
                    
                    subset_df = registered_reference_channel_df.loc[registered_reference_channel_df[&#39;round_num&#39;] == round_num, :]
                    subset_df = subset_df.reset_index()
                        
                    shift = all_rounds_shifts[round_num]
                    fish_counts_df[&#39;r_px_registered&#39;] = fish_counts[&#39;r_px_original&#39;] + shift[0]
                    fish_counts_df[&#39;c_px_registered&#39;] = fish_counts[&#39;c_px_original&#39;] + shift[1]
                    fish_counts_df[&#39;r_shift_px&#39;] = shift[0]
                    fish_counts_df[&#39;c_shift_px&#39;] = shift[1]
                    fish_counts_df[&#39;min_number_matching_dots_registration&#39;] = subset_df.loc[0,&#39;min_number_matching_dots_registration&#39;] 
                    fish_counts_df[&#39;reference_hyb&#39;] = reference_hybridization
                    fish_counts_df[&#39;experiment_type&#39;] = subset_df.loc[0,&#39;experiment_type&#39;]
                    fish_counts_df[&#39;experiment_name&#39;] = subset_df.loc[0,&#39;experiment_name&#39;]
                    fish_counts_df[&#39;pxl_um&#39;] = subset_df.loc[0,&#39;pxl_um&#39;]
                    fish_counts_df[&#39;stitching_type&#39;] = subset_df.loc[0,&#39;stitching_type&#39;]
                    fish_counts_df[&#39;fov_acquisition_coords_x&#39;] = subset_df.loc[0,&#39;fov_acquisition_coords_x&#39;]
                    fish_counts_df[&#39;fov_acquisition_coords_y&#39;] = subset_df.loc[0,&#39;fov_acquisition_coords_y&#39;]
                    fish_counts_df[&#39;fov_acquisition_coords_z&#39;] = subset_df.loc[0,&#39;fov_acquisition_coords_z&#39;]
                    fish_counts_df[&#39;img_width_px&#39;] = fish_img_metadata[&#39;img_width&#39;]
                    fish_counts_df[&#39;img_height_px&#39;] = fish_img_metadata[&#39;img_height&#39;]




                    registered_fish_df = pd.concat([registered_fish_df,fish_counts_df],axis=0,ignore_index=True)
                    status = &#39;SUCCESS&#39;

    return registered_fish_df, status</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.register_images"><code class="name flex">
<span>def <span class="ident">register_images</span></span>(<span>img:numpy.ndarray, shift:numpy.ndarray) >numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Function to create a new image shifted according
a predefined shift.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>img</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Image to shift</dd>
<dt><strong><code>shift</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Shift</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Shifted image</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def register_images(img: np.ndarray, shift: np.ndarray)-&gt;np.ndarray:
    &#34;&#34;&#34;Function to create a new image shifted according
    a predefined shift.

    Args:
        img (np.ndarray): Image to shift
        shift (np.ndarray): Shift

    Returns:
        np.ndarray: Shifted image
    &#34;&#34;&#34;
    offset_image = fourier_shift(np.fft.fftn(img), shift)
    offset_image = np.fft.ifftn(offset_image).real
    return offset_image</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pysmFISH.fovs_registration.chunking"><code class="flex name class">
<span>class <span class="ident">chunking</span></span>
<span>(</span><span>region_dimensions, chunk_size, percent_padding, tl_coords)</span>
</code></dt>
<dd>
<div class="desc"><p>utility class to create processing chunks</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class chunking():
    &#34;&#34;&#34;
    utility class to create processing chunks
    &#34;&#34;&#34;

    def __init__(self, region_dimensions, chunk_size, percent_padding, tl_coords):
        self.region_dimensions = region_dimensions
        self.chunk_size = chunk_size
        self.percent_padding = percent_padding
        self.tl_coords = tl_coords
    

    @staticmethod
    def block_chunks_calculator(dimension,chunk_size):
        &#34;&#34;&#34;
        Helper function to calculate the size of the chunks created according
        the length of the vector and the chunk size.

        Parameters:
        -----------

        dimension: int
            Length of the vector to Chunk
        chunkSize: int 
            Dimension of the Chunks

        Returns:
        -----------

        chunks_sizes: np.array 
            Array of the sizes of the created chunks. It deals with conditions 
            when the expected chunks size do not fit an even number of times in the 
            dimension
        &#34;&#34;&#34;
        number_even_chunks=int(dimension//chunk_size)
        total_size_even_chunks=number_even_chunks*chunk_size
        odd_tile_size=dimension-total_size_even_chunks
        chunk_sizes=[]
        chunks_sizes=list(np.repeat(chunk_size,number_even_chunks-1))
        if odd_tile_size &lt; chunk_size:
            chunks_sizes.append(chunk_size+odd_tile_size)
        else:
            chunks_sizes.append(odd_tile_size)
        return tuple(chunks_sizes)
    
    def block_chunking(self):
        &#34;&#34;&#34;
        Function used to generate the coords of the images according to the
        chunking 

        Parameters:
        -----------

        PercentPadding: float 
            Percent of overlapping between the different images (Ex. 0.2).
        ChunkSize: int 
            Dimension of the Chunks.

        Returns:
        -----------

        Coords_Chunks_list: list 
            List of np.array with the coords of the images without padding
        Coords_Padded_Chunks_list: list 
            List of np.array with the coords of the images with padding

        Notes:
        ------

        For both lists each np.array contains the coords in the following order:
        [row_tl,row_br,col_tl,col_br]

        &#34;&#34;&#34;
        num_r,num_c = self.region_dimensions
        pixel_padding = int(self.chunk_size*self.percent_padding)
        self.starting_position = self.tl_coords

        # Calculate the size of the chunks
        r_chunks_size = self.block_chunks_calculator(num_r,self.chunk_size)
        
        c_chunks_size = self.block_chunks_calculator(num_c,self.chunk_size)
        
        # Calculate the total numbers of chunks
        nr_chunks = len(r_chunks_size)
        
        nc_chunks = len(c_chunks_size)
       


        # Coords top left corner (tl)
        if nr_chunks == 1:
            r_coords_tl = self.starting_position[0]
        else:  
            r_coords_tl = np.arange(self.starting_position[0],(self.starting_position[0]+self.chunk_size*(nr_chunks)),self.chunk_size)
        
        
        if nc_chunks == 1:
            c_coords_tl = self.starting_position[1]
        else:
            c_coords_tl = np.arange(self.starting_position[1],(self.starting_position[1]+self.chunk_size*(nc_chunks)),self.chunk_size)

        
        # Coords of all the tl in the image
        r_coords_tl_all,c_coords_tl_all = np.meshgrid(r_coords_tl,c_coords_tl,indexing=&#39;ij&#39;)
        self.coords_all_to_test = [r_coords_tl_all,c_coords_tl_all]
        # Calculate all the br coords
        r_coords_br_all = r_coords_tl_all.copy()
        c_coords_br_all = c_coords_tl_all.copy()

        for c in np.arange(0,r_coords_tl_all.shape[1]):
            r_coords_br_all[:,c] = r_coords_br_all[:,c]+r_chunks_size

        for r in np.arange(0,r_coords_tl_all.shape[0]):
             c_coords_br_all[r,:] = c_coords_br_all[r,:]+c_chunks_size

        # Calculate the padded coords
        r_coords_tl_all_padded = r_coords_tl_all-pixel_padding
        c_coords_tl_all_padded = c_coords_tl_all-pixel_padding
        r_coords_br_all_padded = r_coords_br_all+pixel_padding
        c_coords_br_all_padded = c_coords_br_all+pixel_padding

        # Correct for coords out of the image (where tl&lt;0,br&gt;Img.shape)
        r_coords_tl_all_padded[r_coords_tl_all_padded&lt;0] = r_coords_tl_all[r_coords_tl_all_padded&lt;0]
        c_coords_tl_all_padded[c_coords_tl_all_padded&lt;0] = c_coords_tl_all[c_coords_tl_all_padded&lt;0]
        r_coords_br_all_padded[r_coords_br_all_padded&gt;num_r] = r_coords_br_all[r_coords_br_all_padded&gt;num_r]
        c_coords_br_all_padded[c_coords_br_all_padded&gt;num_c] = c_coords_br_all[c_coords_br_all_padded&gt;num_c]

        # The coords list are generated as:
        # row_tl,row_br,col_tl,col_br


        # Create a list for the padded coords
        self.Coords_Padded_Chunks_list = list()
        for r in np.arange(0,r_coords_tl_all_padded.shape[0]):
            for c in np.arange(0,r_coords_tl_all_padded.shape[1]):
                self.Coords_Padded_Chunks_list.append(np.array([r_coords_tl_all_padded[r][c],\
                                                           r_coords_br_all_padded[r][c],\
                                                           c_coords_tl_all_padded[r][c],\
                                                           c_coords_br_all_padded[r][c]])) </code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="pysmFISH.fovs_registration.chunking.block_chunks_calculator"><code class="name flex">
<span>def <span class="ident">block_chunks_calculator</span></span>(<span>dimension, chunk_size)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper function to calculate the size of the chunks created according
the length of the vector and the chunk size.</p>
<h2 id="parameters">Parameters:</h2>
<p>dimension: int
Length of the vector to Chunk
chunkSize: int
Dimension of the Chunks</p>
<h2 id="returns">Returns:</h2>
<p>chunks_sizes: np.array
Array of the sizes of the created chunks. It deals with conditions
when the expected chunks size do not fit an even number of times in the
dimension</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def block_chunks_calculator(dimension,chunk_size):
    &#34;&#34;&#34;
    Helper function to calculate the size of the chunks created according
    the length of the vector and the chunk size.

    Parameters:
    -----------

    dimension: int
        Length of the vector to Chunk
    chunkSize: int 
        Dimension of the Chunks

    Returns:
    -----------

    chunks_sizes: np.array 
        Array of the sizes of the created chunks. It deals with conditions 
        when the expected chunks size do not fit an even number of times in the 
        dimension
    &#34;&#34;&#34;
    number_even_chunks=int(dimension//chunk_size)
    total_size_even_chunks=number_even_chunks*chunk_size
    odd_tile_size=dimension-total_size_even_chunks
    chunk_sizes=[]
    chunks_sizes=list(np.repeat(chunk_size,number_even_chunks-1))
    if odd_tile_size &lt; chunk_size:
        chunks_sizes.append(chunk_size+odd_tile_size)
    else:
        chunks_sizes.append(odd_tile_size)
    return tuple(chunks_sizes)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pysmFISH.fovs_registration.chunking.block_chunking"><code class="name flex">
<span>def <span class="ident">block_chunking</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to generate the coords of the images according to the
chunking </p>
<h2 id="parameters">Parameters:</h2>
<p>PercentPadding: float
Percent of overlapping between the different images (Ex. 0.2).
ChunkSize: int
Dimension of the Chunks.</p>
<h2 id="returns">Returns:</h2>
<p>Coords_Chunks_list: list
List of np.array with the coords of the images without padding
Coords_Padded_Chunks_list: list
List of np.array with the coords of the images with padding</p>
<h2 id="notes">Notes:</h2>
<p>For both lists each np.array contains the coords in the following order:
[row_tl,row_br,col_tl,col_br]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def block_chunking(self):
    &#34;&#34;&#34;
    Function used to generate the coords of the images according to the
    chunking 

    Parameters:
    -----------

    PercentPadding: float 
        Percent of overlapping between the different images (Ex. 0.2).
    ChunkSize: int 
        Dimension of the Chunks.

    Returns:
    -----------

    Coords_Chunks_list: list 
        List of np.array with the coords of the images without padding
    Coords_Padded_Chunks_list: list 
        List of np.array with the coords of the images with padding

    Notes:
    ------

    For both lists each np.array contains the coords in the following order:
    [row_tl,row_br,col_tl,col_br]

    &#34;&#34;&#34;
    num_r,num_c = self.region_dimensions
    pixel_padding = int(self.chunk_size*self.percent_padding)
    self.starting_position = self.tl_coords

    # Calculate the size of the chunks
    r_chunks_size = self.block_chunks_calculator(num_r,self.chunk_size)
    
    c_chunks_size = self.block_chunks_calculator(num_c,self.chunk_size)
    
    # Calculate the total numbers of chunks
    nr_chunks = len(r_chunks_size)
    
    nc_chunks = len(c_chunks_size)
   


    # Coords top left corner (tl)
    if nr_chunks == 1:
        r_coords_tl = self.starting_position[0]
    else:  
        r_coords_tl = np.arange(self.starting_position[0],(self.starting_position[0]+self.chunk_size*(nr_chunks)),self.chunk_size)
    
    
    if nc_chunks == 1:
        c_coords_tl = self.starting_position[1]
    else:
        c_coords_tl = np.arange(self.starting_position[1],(self.starting_position[1]+self.chunk_size*(nc_chunks)),self.chunk_size)

    
    # Coords of all the tl in the image
    r_coords_tl_all,c_coords_tl_all = np.meshgrid(r_coords_tl,c_coords_tl,indexing=&#39;ij&#39;)
    self.coords_all_to_test = [r_coords_tl_all,c_coords_tl_all]
    # Calculate all the br coords
    r_coords_br_all = r_coords_tl_all.copy()
    c_coords_br_all = c_coords_tl_all.copy()

    for c in np.arange(0,r_coords_tl_all.shape[1]):
        r_coords_br_all[:,c] = r_coords_br_all[:,c]+r_chunks_size

    for r in np.arange(0,r_coords_tl_all.shape[0]):
         c_coords_br_all[r,:] = c_coords_br_all[r,:]+c_chunks_size

    # Calculate the padded coords
    r_coords_tl_all_padded = r_coords_tl_all-pixel_padding
    c_coords_tl_all_padded = c_coords_tl_all-pixel_padding
    r_coords_br_all_padded = r_coords_br_all+pixel_padding
    c_coords_br_all_padded = c_coords_br_all+pixel_padding

    # Correct for coords out of the image (where tl&lt;0,br&gt;Img.shape)
    r_coords_tl_all_padded[r_coords_tl_all_padded&lt;0] = r_coords_tl_all[r_coords_tl_all_padded&lt;0]
    c_coords_tl_all_padded[c_coords_tl_all_padded&lt;0] = c_coords_tl_all[c_coords_tl_all_padded&lt;0]
    r_coords_br_all_padded[r_coords_br_all_padded&gt;num_r] = r_coords_br_all[r_coords_br_all_padded&gt;num_r]
    c_coords_br_all_padded[c_coords_br_all_padded&gt;num_c] = c_coords_br_all[c_coords_br_all_padded&gt;num_c]

    # The coords list are generated as:
    # row_tl,row_br,col_tl,col_br


    # Create a list for the padded coords
    self.Coords_Padded_Chunks_list = list()
    for r in np.arange(0,r_coords_tl_all_padded.shape[0]):
        for c in np.arange(0,r_coords_tl_all_padded.shape[1]):
            self.Coords_Padded_Chunks_list.append(np.array([r_coords_tl_all_padded[r][c],\
                                                       r_coords_br_all_padded[r][c],\
                                                       c_coords_tl_all_padded[r][c],\
                                                       c_coords_br_all_padded[r][c]])) </code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pysmFISH.fovs_registration.reference_beads_registration"><code class="flex name class">
<span>class <span class="ident">reference_beads_registration</span></span>
<span>(</span><span>ref_hyb_coords, comp_hyb_coords, Coords_Padded_Chunks_list, n_neighbors, min_acceptable_distance, min_samples, residual_threshold, max_trials, matching_radius)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class reference_beads_registration():

    def __init__(self,ref_hyb_coords, comp_hyb_coords, Coords_Padded_Chunks_list, n_neighbors,
                min_acceptable_distance, min_samples, residual_threshold, max_trials, matching_radius):

        self.ref_hyb_coords = ref_hyb_coords
        self.comp_hyb_coords = comp_hyb_coords
        self.Coords_Padded_Chunks_list = Coords_Padded_Chunks_list

        self.n_neighbors = n_neighbors
        self.min_acceptable_distance = min_acceptable_distance
        self.min_samples = min_samples
        self.residual_threshold = residual_threshold
        self.max_trials = max_trials
        self.matching_radius = matching_radius

        self.logger = logging.getLogger(__name__)

    @staticmethod
    def calculate_min_distances(selected_ref):
        ref_dist = distance.cdist(selected_ref.T, selected_ref.T)
        ref_dist = np.triu(ref_dist)
        ref_dist = ref_dist[:-1,:]
        mref = np.ma.masked_where(ref_dist==0,ref_dist)
        mref_min = mref.min(axis=1)
        return np.sort(mref_min.data)
    
    @staticmethod
    # CALCULATE ERROR OVER THE DIAGONAL
    def errors(transformed_coords, ref_good):
        diagonals = np.sqrt((ref_good[:,0]- transformed_coords[:,0])**2 + (ref_good[:,1]- transformed_coords[:,1])**2)
        diagonal_mean = np.mean(diagonals,axis=0)
        diagonal_median = np.median(diagonals,axis=0)
        err1 = np.sum((diagonals-diagonal_mean),axis=0)/len(diagonals)
        err2 = np.sum((diagonals-diagonal_mean)**2,axis=0)/len(diagonals)
        diag_std = np.std(diagonals)
        diag_sem = diag_std/len(diagonals)
        
        # delta = np.abs(ref_good - transformed_coords)
        # delta_mean = np.mean(delta,axis=0)
        # err1 = np.sum((delta-delta_mean),axis=0)/len(transformed_coords)
        # err2 = np.sum((delta-delta_mean)**2,axis=0)/len(transformed_coords)
        return err1,err2, diagonal_mean, diagonal_median, diag_std, diag_sem

    def calculate_NN_roi(self,chunk_coords):    
        r_tl = chunk_coords[0]
        r_br = chunk_coords[1]
        c_tl = chunk_coords[2]
        c_br = chunk_coords[3]

        # Select only the coords in the trimmed region
        ref_trimmed = self.ref_hyb_coords[:,((r_tl &lt; self.ref_hyb_coords[0,:]) &amp; (self.ref_hyb_coords[0,:]&lt;r_br)\
                                      &amp; (c_tl &lt;self.ref_hyb_coords[1,:]) &amp;(self.ref_hyb_coords[1,:]&lt;c_br)) ]
        tran_trimmed = self.comp_hyb_coords[:,((r_tl &lt; self.comp_hyb_coords[0,:]) &amp; (self.comp_hyb_coords[0,:]&lt;r_br)\
                                          &amp; (c_tl &lt;self.comp_hyb_coords[1,:]) &amp;(self.comp_hyb_coords[1,:]&lt;c_br)) ]
        
        # Add check if there are dots in the timmed region
        if ref_trimmed.size &gt;= 2*self.n_neighbors and tran_trimmed.size &gt;= 2*self.n_neighbors:
            nbrs_ref = NearestNeighbors(n_neighbors=self.n_neighbors, algorithm=&#39;ball_tree&#39;,radius=self.matching_radius).fit(ref_trimmed.T)
            nbrs_tr = NearestNeighbors(n_neighbors=self.n_neighbors, algorithm=&#39;ball_tree&#39;,radius=self.matching_radius).fit(tran_trimmed.T)
        else:
            nbrs_ref = nbrs_tr = np.nan
            
        return ref_trimmed, tran_trimmed, nbrs_ref, nbrs_tr
   

    def calculate_NN_overlapping_region(self, coords_overlapping_region):
        
        # Add check if there are dots in the timmed region
        if coords_overlapping_region.size &gt;= 2*self.n_neighbors and coords_overlapping_region.size &gt;= 2*self.n_neighbors:
            nbrs = NearestNeighbors(n_neighbors=self.n_neighbors, algorithm=&#39;ball_tree&#39;,radius=self.matching_radius).fit(coords_overlapping_region.T)
        else:
            nbrs = np.nan
            
        return nbrs

    
    def calculate_registration(self):
        
        self.c = []
        passing_num = 0
        matching_points = False
        if self.ref_hyb_coords.size and self.comp_hyb_coords.size:
            for chunk_coords in self.Coords_Padded_Chunks_list:
                ref_trimmed, tran_trimmed, nbrs_ref, nbrs_tr= self.calculate_NN_roi(chunk_coords)
                if ref_trimmed.size &gt;= 2*self.n_neighbors and tran_trimmed.size &gt;= 2*self.n_neighbors:
                    if nbrs_ref != np.nan and nbrs_tr != np.nan:
                        # create dots id list
                        trans_dot_id_list = np.arange(tran_trimmed.shape[1])
                        for tran_dot_id in trans_dot_id_list:
                            searching=tran_trimmed[:,tran_dot_id]
                            searching = searching[np.newaxis,:]
                            dist, idx  = nbrs_tr.kneighbors(searching,n_neighbors=self.n_neighbors)
                            selected_tran = tran_trimmed[:,idx[0]]
                            tran_dist = self.calculate_min_distances(selected_tran)
                            for id_r in np.arange(ref_trimmed.shape[1]):
                                searching_r=ref_trimmed[:,id_r]
                                searching_r = searching_r[np.newaxis,:]
                                dist_r, idx_r  = nbrs_ref.kneighbors(searching_r,n_neighbors=self.n_neighbors)
                                if idx_r[0].shape[0] == idx[0].shape[0]: 
                                    selected_ref = ref_trimmed[:,idx_r[0]]
                                    ref_dist = self.calculate_min_distances(selected_ref)
                                    if np.all(np.abs(ref_dist - tran_dist)&lt;self.min_acceptable_distance):
                                        ref = ref_trimmed[:,idx_r[0]]
                                        ref_srt = ref[:,ref[0,:].argsort()]
                                        tran = tran_trimmed[:,idx[0]]
                                        tran_srt = tran[:,tran[0,:].argsort()]
                                        cpls = np.concatenate((ref_srt.T,tran_srt.T),axis=1)
                                        self.c.append(cpls)
                                        if passing_num == 0:
                                            matching_points = cpls
                                            passing_num += 1
                                        else:
                                            matching_points = np.concatenate((matching_points,cpls),axis=0)
            if isinstance(matching_points,np.ndarray):
                matching_points = np.unique(matching_points,axis=0)
                self.ref = matching_points[:,0:2]
                self.tran = matching_points[:,2:]
                if (self.min_samples &lt; self.ref.shape[0]) and (self.min_samples &lt; self.tran.shape[0]):
                    self.model, self.inliers = ransac((self.tran, self.ref), transform.SimilarityTransform, min_samples=self.min_samples,
                                    residual_threshold=self.residual_threshold, max_trials=self.max_trials)
    #                 self.model = transform.estimate_transform(&#39;Affine&#39;,self.tran, self.ref)
                    self.missing_pos = False
                else:
                    self.missing_pos = True 
            else:
                self.missing_pos = True 
        else: 
            self.missing_pos = True
        
        if not self.missing_pos:
            if self.model:
                self.tr_good = self.tran[self.inliers]
                self.ref_good = self.ref[self.inliers]
                self.transformed_coords = transform.matrix_transform(self.tr_good, self.model.params)
                self.transformed_all_coords = transform.matrix_transform(self.comp_hyb_coords.T, self.model.params)
                self.delta = self.ref_good - self.tr_good
                self.translation_mean = np.mean(self.delta,axis=0)
                self.translation_median = np.median(self.delta,axis=0)
                self.translation_diagonal = np.sqrt((self.ref_good[:,0] - self.tr_good[:,0])**2 + (self.ref_good[:,1] - self.tr_good[:,1])**2)
                self.translational_diagonal_mean = np.mean(self.translation_diagonal)
                self.translational_diagonal_median = np.median(self.translation_diagonal)
                self.translation_diagonal_std = np.std(self.translation_diagonal)
                self.translation_diagonal_sem = np.std(self.translation_diagonal)/ len(self.translation_diagonal)
                self.err1,self.err2, self.diagonal_mean, self.diagonal_median, self.diag_std, self.diag_sem = self.errors(self.transformed_coords, self.ref_good)
                self.used_points = [self.ref_good,self.tr_good]
            else:
                self.missing_pos = True


    def deploy(self):
        self.registration_data = {}
        if self.ref_hyb_coords.size &gt;= 2*self.n_neighbors:
            self.ref_nbrs = self.calculate_NN_overlapping_region(self.ref_hyb_coords)
            if self.comp_hyb_coords.size &gt;= 2*self.n_neighbors:
                self.comp_nbrs = self.calculate_NN_overlapping_region(self.comp_hyb_coords)
                if (self.ref_nbrs != np.nan) and (self.comp_nbrs != np.nan):
                    self.calculate_registration()
                else:
                    self.logger.info(f&#39;no neighbors identified&#39;)
                    self.missing_pos = True
            else:
                self.logger.info(f&#39;comp region \
                        does not contain enough dots for registration&#39;)
                self.missing_pos = True
                
                # ADJUST WHEN SAVING THE DATA
                self.registration_data = {&#39;missing_pos&#39;:self.missing_pos}
        else:
            self.logger.info(f&#39;reference region\
                            does not contain enough dots for registration&#39;)
            self.missing_pos = True
            
        if self.missing_pos:
            self.registration_data = {&#39;missing_pos&#39;:self.missing_pos}
        else:
            self.registration_data = {&#39;translation_diagonal_mean&#39;:self.translational_diagonal_mean, 
                                    &#39;translation_diagonal_median&#39;: self.translational_diagonal_median, 
                                    &#39;translation_diagonal_std&#39;: self.translation_diagonal_std,
                                    &#39;translation_diagonal_sem&#39;:self.translation_diagonal_sem,
                                    &#39;used_points&#39;: self.used_points,
                                    &#39;model_params&#39;:self.model.params, 
                                    &#39;err1&#39;:self.err1, 
                                    &#39;err2&#39;:self.err2, 
                                    &#39;diagonal_mean&#39;:self.diagonal_mean,
                                    &#39;diagonal_median&#39;:self.translational_diagonal_median,
                                    &#39;diag_std&#39;:self.diag_std, 
                                    &#39;diag_sem&#39;:self.diag_sem,
                                    &#39;transformed_coords&#39;:self.transformed_coords,
                                    &#39;transformed_all_coords&#39;:self.transformed_all_coords,
                                    &#39;missing_pos&#39;:self.missing_pos}</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="pysmFISH.fovs_registration.reference_beads_registration.calculate_min_distances"><code class="name flex">
<span>def <span class="ident">calculate_min_distances</span></span>(<span>selected_ref)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def calculate_min_distances(selected_ref):
    ref_dist = distance.cdist(selected_ref.T, selected_ref.T)
    ref_dist = np.triu(ref_dist)
    ref_dist = ref_dist[:-1,:]
    mref = np.ma.masked_where(ref_dist==0,ref_dist)
    mref_min = mref.min(axis=1)
    return np.sort(mref_min.data)</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.reference_beads_registration.errors"><code class="name flex">
<span>def <span class="ident">errors</span></span>(<span>transformed_coords, ref_good)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
# CALCULATE ERROR OVER THE DIAGONAL
def errors(transformed_coords, ref_good):
    diagonals = np.sqrt((ref_good[:,0]- transformed_coords[:,0])**2 + (ref_good[:,1]- transformed_coords[:,1])**2)
    diagonal_mean = np.mean(diagonals,axis=0)
    diagonal_median = np.median(diagonals,axis=0)
    err1 = np.sum((diagonals-diagonal_mean),axis=0)/len(diagonals)
    err2 = np.sum((diagonals-diagonal_mean)**2,axis=0)/len(diagonals)
    diag_std = np.std(diagonals)
    diag_sem = diag_std/len(diagonals)
    
    # delta = np.abs(ref_good - transformed_coords)
    # delta_mean = np.mean(delta,axis=0)
    # err1 = np.sum((delta-delta_mean),axis=0)/len(transformed_coords)
    # err2 = np.sum((delta-delta_mean)**2,axis=0)/len(transformed_coords)
    return err1,err2, diagonal_mean, diagonal_median, diag_std, diag_sem</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pysmFISH.fovs_registration.reference_beads_registration.calculate_NN_overlapping_region"><code class="name flex">
<span>def <span class="ident">calculate_NN_overlapping_region</span></span>(<span>self, coords_overlapping_region)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_NN_overlapping_region(self, coords_overlapping_region):
    
    # Add check if there are dots in the timmed region
    if coords_overlapping_region.size &gt;= 2*self.n_neighbors and coords_overlapping_region.size &gt;= 2*self.n_neighbors:
        nbrs = NearestNeighbors(n_neighbors=self.n_neighbors, algorithm=&#39;ball_tree&#39;,radius=self.matching_radius).fit(coords_overlapping_region.T)
    else:
        nbrs = np.nan
        
    return nbrs</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.reference_beads_registration.calculate_NN_roi"><code class="name flex">
<span>def <span class="ident">calculate_NN_roi</span></span>(<span>self, chunk_coords)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_NN_roi(self,chunk_coords):    
    r_tl = chunk_coords[0]
    r_br = chunk_coords[1]
    c_tl = chunk_coords[2]
    c_br = chunk_coords[3]

    # Select only the coords in the trimmed region
    ref_trimmed = self.ref_hyb_coords[:,((r_tl &lt; self.ref_hyb_coords[0,:]) &amp; (self.ref_hyb_coords[0,:]&lt;r_br)\
                                  &amp; (c_tl &lt;self.ref_hyb_coords[1,:]) &amp;(self.ref_hyb_coords[1,:]&lt;c_br)) ]
    tran_trimmed = self.comp_hyb_coords[:,((r_tl &lt; self.comp_hyb_coords[0,:]) &amp; (self.comp_hyb_coords[0,:]&lt;r_br)\
                                      &amp; (c_tl &lt;self.comp_hyb_coords[1,:]) &amp;(self.comp_hyb_coords[1,:]&lt;c_br)) ]
    
    # Add check if there are dots in the timmed region
    if ref_trimmed.size &gt;= 2*self.n_neighbors and tran_trimmed.size &gt;= 2*self.n_neighbors:
        nbrs_ref = NearestNeighbors(n_neighbors=self.n_neighbors, algorithm=&#39;ball_tree&#39;,radius=self.matching_radius).fit(ref_trimmed.T)
        nbrs_tr = NearestNeighbors(n_neighbors=self.n_neighbors, algorithm=&#39;ball_tree&#39;,radius=self.matching_radius).fit(tran_trimmed.T)
    else:
        nbrs_ref = nbrs_tr = np.nan
        
    return ref_trimmed, tran_trimmed, nbrs_ref, nbrs_tr</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.reference_beads_registration.calculate_registration"><code class="name flex">
<span>def <span class="ident">calculate_registration</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_registration(self):
    
    self.c = []
    passing_num = 0
    matching_points = False
    if self.ref_hyb_coords.size and self.comp_hyb_coords.size:
        for chunk_coords in self.Coords_Padded_Chunks_list:
            ref_trimmed, tran_trimmed, nbrs_ref, nbrs_tr= self.calculate_NN_roi(chunk_coords)
            if ref_trimmed.size &gt;= 2*self.n_neighbors and tran_trimmed.size &gt;= 2*self.n_neighbors:
                if nbrs_ref != np.nan and nbrs_tr != np.nan:
                    # create dots id list
                    trans_dot_id_list = np.arange(tran_trimmed.shape[1])
                    for tran_dot_id in trans_dot_id_list:
                        searching=tran_trimmed[:,tran_dot_id]
                        searching = searching[np.newaxis,:]
                        dist, idx  = nbrs_tr.kneighbors(searching,n_neighbors=self.n_neighbors)
                        selected_tran = tran_trimmed[:,idx[0]]
                        tran_dist = self.calculate_min_distances(selected_tran)
                        for id_r in np.arange(ref_trimmed.shape[1]):
                            searching_r=ref_trimmed[:,id_r]
                            searching_r = searching_r[np.newaxis,:]
                            dist_r, idx_r  = nbrs_ref.kneighbors(searching_r,n_neighbors=self.n_neighbors)
                            if idx_r[0].shape[0] == idx[0].shape[0]: 
                                selected_ref = ref_trimmed[:,idx_r[0]]
                                ref_dist = self.calculate_min_distances(selected_ref)
                                if np.all(np.abs(ref_dist - tran_dist)&lt;self.min_acceptable_distance):
                                    ref = ref_trimmed[:,idx_r[0]]
                                    ref_srt = ref[:,ref[0,:].argsort()]
                                    tran = tran_trimmed[:,idx[0]]
                                    tran_srt = tran[:,tran[0,:].argsort()]
                                    cpls = np.concatenate((ref_srt.T,tran_srt.T),axis=1)
                                    self.c.append(cpls)
                                    if passing_num == 0:
                                        matching_points = cpls
                                        passing_num += 1
                                    else:
                                        matching_points = np.concatenate((matching_points,cpls),axis=0)
        if isinstance(matching_points,np.ndarray):
            matching_points = np.unique(matching_points,axis=0)
            self.ref = matching_points[:,0:2]
            self.tran = matching_points[:,2:]
            if (self.min_samples &lt; self.ref.shape[0]) and (self.min_samples &lt; self.tran.shape[0]):
                self.model, self.inliers = ransac((self.tran, self.ref), transform.SimilarityTransform, min_samples=self.min_samples,
                                residual_threshold=self.residual_threshold, max_trials=self.max_trials)
#                 self.model = transform.estimate_transform(&#39;Affine&#39;,self.tran, self.ref)
                self.missing_pos = False
            else:
                self.missing_pos = True 
        else:
            self.missing_pos = True 
    else: 
        self.missing_pos = True
    
    if not self.missing_pos:
        if self.model:
            self.tr_good = self.tran[self.inliers]
            self.ref_good = self.ref[self.inliers]
            self.transformed_coords = transform.matrix_transform(self.tr_good, self.model.params)
            self.transformed_all_coords = transform.matrix_transform(self.comp_hyb_coords.T, self.model.params)
            self.delta = self.ref_good - self.tr_good
            self.translation_mean = np.mean(self.delta,axis=0)
            self.translation_median = np.median(self.delta,axis=0)
            self.translation_diagonal = np.sqrt((self.ref_good[:,0] - self.tr_good[:,0])**2 + (self.ref_good[:,1] - self.tr_good[:,1])**2)
            self.translational_diagonal_mean = np.mean(self.translation_diagonal)
            self.translational_diagonal_median = np.median(self.translation_diagonal)
            self.translation_diagonal_std = np.std(self.translation_diagonal)
            self.translation_diagonal_sem = np.std(self.translation_diagonal)/ len(self.translation_diagonal)
            self.err1,self.err2, self.diagonal_mean, self.diagonal_median, self.diag_std, self.diag_sem = self.errors(self.transformed_coords, self.ref_good)
            self.used_points = [self.ref_good,self.tr_good]
        else:
            self.missing_pos = True</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.reference_beads_registration.deploy"><code class="name flex">
<span>def <span class="ident">deploy</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def deploy(self):
    self.registration_data = {}
    if self.ref_hyb_coords.size &gt;= 2*self.n_neighbors:
        self.ref_nbrs = self.calculate_NN_overlapping_region(self.ref_hyb_coords)
        if self.comp_hyb_coords.size &gt;= 2*self.n_neighbors:
            self.comp_nbrs = self.calculate_NN_overlapping_region(self.comp_hyb_coords)
            if (self.ref_nbrs != np.nan) and (self.comp_nbrs != np.nan):
                self.calculate_registration()
            else:
                self.logger.info(f&#39;no neighbors identified&#39;)
                self.missing_pos = True
        else:
            self.logger.info(f&#39;comp region \
                    does not contain enough dots for registration&#39;)
            self.missing_pos = True
            
            # ADJUST WHEN SAVING THE DATA
            self.registration_data = {&#39;missing_pos&#39;:self.missing_pos}
    else:
        self.logger.info(f&#39;reference region\
                        does not contain enough dots for registration&#39;)
        self.missing_pos = True
        
    if self.missing_pos:
        self.registration_data = {&#39;missing_pos&#39;:self.missing_pos}
    else:
        self.registration_data = {&#39;translation_diagonal_mean&#39;:self.translational_diagonal_mean, 
                                &#39;translation_diagonal_median&#39;: self.translational_diagonal_median, 
                                &#39;translation_diagonal_std&#39;: self.translation_diagonal_std,
                                &#39;translation_diagonal_sem&#39;:self.translation_diagonal_sem,
                                &#39;used_points&#39;: self.used_points,
                                &#39;model_params&#39;:self.model.params, 
                                &#39;err1&#39;:self.err1, 
                                &#39;err2&#39;:self.err2, 
                                &#39;diagonal_mean&#39;:self.diagonal_mean,
                                &#39;diagonal_median&#39;:self.translational_diagonal_median,
                                &#39;diag_std&#39;:self.diag_std, 
                                &#39;diag_sem&#39;:self.diag_sem,
                                &#39;transformed_coords&#39;:self.transformed_coords,
                                &#39;transformed_all_coords&#39;:self.transformed_all_coords,
                                &#39;missing_pos&#39;:self.missing_pos}</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pysmFISH.fovs_registration.reference_beads_registration_couple"><code class="flex name class">
<span>class <span class="ident">reference_beads_registration_couple</span></span>
<span>(</span><span>ref_hyb_coords, comp_hyb_coords, Coords_Padded_Chunks_list, n_neighbors, min_acceptable_distance, min_samples, residual_threshold, max_trials, matching_radius)</span>
</code></dt>
<dd>
<div class="desc"><p>class used to register a couple of rounds. It is used to monitor the outcome
because it saves a lot of information useful for troubleshooting. Once the
parameters are well define the corresponding non test function is used in the
data processing</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class reference_beads_registration_couple():

    &#34;&#34;&#34;
    class used to register a couple of rounds. It is used to monitor the outcome
    because it saves a lot of information useful for troubleshooting. Once the
    parameters are well define the corresponding non test function is used in the
    data processing
    &#34;&#34;&#34;

    def __init__(self,ref_hyb_coords, comp_hyb_coords, Coords_Padded_Chunks_list, n_neighbors,
                min_acceptable_distance, min_samples, residual_threshold, max_trials, matching_radius):

        self.ref_hyb_coords = ref_hyb_coords
        self.comp_hyb_coords = comp_hyb_coords
        self.Coords_Padded_Chunks_list = Coords_Padded_Chunks_list

        self.n_neighbors = n_neighbors
        self.min_acceptable_distance = min_acceptable_distance
        self.min_samples = min_samples
        self.residual_threshold = residual_threshold
        self.max_trials = max_trials
        self.matching_radius = matching_radius

        self.logger = logging.getLogger(__name__)

    @staticmethod
    def calculate_min_distances(selected_ref):
        ref_dist = distance.cdist(selected_ref, selected_ref)
        ref_dist = np.triu(ref_dist)
        ref_dist = ref_dist[:-1,:]
        mref = np.ma.masked_where(ref_dist==0,ref_dist)
        mref_min = mref.min(axis=1)
        return np.sort(mref_min.data)
    
    @staticmethod
    # CALCULATE ERROR OVER THE DIAGONAL
    def errors(transformed_coords, ref_good):
        diagonals = np.sqrt((ref_good[:,0]- transformed_coords[:,0])**2 + (ref_good[:,1]- transformed_coords[:,1])**2)
        diagonal_mean = np.mean(diagonals,axis=0)
        diagonal_median = np.median(diagonals,axis=0)
        err1 = np.sum((diagonals-diagonal_mean),axis=0)/len(diagonals)
        err2 = np.sum((diagonals-diagonal_mean)**2,axis=0)/len(diagonals)
        diag_std = np.std(diagonals)
        diag_sem = diag_std/len(diagonals)
        
        # delta = np.abs(ref_good - transformed_coords)
        # delta_mean = np.mean(delta,axis=0)
        # err1 = np.sum((delta-delta_mean),axis=0)/len(transformed_coords)
        # err2 = np.sum((delta-delta_mean)**2,axis=0)/len(transformed_coords)
        return err1,err2, diagonal_mean, diagonal_median, diag_std, diag_sem

    def calculate_NN_roi(self,chunk_coords):    
        r_tl = chunk_coords[0]
        r_br = chunk_coords[1]
        c_tl = chunk_coords[2]
        c_br = chunk_coords[3]

        # Select only the coords in the trimmed region
        ref_trimmed = self.ref_hyb_coords[((r_tl &lt; self.ref_hyb_coords[:,0]) &amp; (self.ref_hyb_coords[:,0]&lt;r_br)\
                                      &amp; (c_tl &lt;self.ref_hyb_coords[:,1]) &amp;(self.ref_hyb_coords[:,1]&lt;c_br)),:]
        tran_trimmed = self.comp_hyb_coords[((r_tl &lt; self.comp_hyb_coords[:,0]) &amp; (self.comp_hyb_coords[:,0]&lt;r_br)\
                                          &amp; (c_tl &lt;self.comp_hyb_coords[:,1]) &amp;(self.comp_hyb_coords[:,1]&lt;c_br)),:]
        
        # Add check if there are dots in the timmed region
        if ref_trimmed.size &gt;= 2*self.n_neighbors and tran_trimmed.size &gt;= 2*self.n_neighbors:
            nbrs_ref = NearestNeighbors(n_neighbors=self.n_neighbors, algorithm=&#39;ball_tree&#39;,radius=self.matching_radius).fit(ref_trimmed)
            nbrs_tr = NearestNeighbors(n_neighbors=self.n_neighbors, algorithm=&#39;ball_tree&#39;,radius=self.matching_radius).fit(tran_trimmed)
        else:
            nbrs_ref = nbrs_tr = np.nan
            
        return ref_trimmed, tran_trimmed, nbrs_ref, nbrs_tr
   

    def calculate_NN_overlapping_region(self, coords_overlapping_region):
        
        # Add check if there are dots in the timmed region
        if coords_overlapping_region.size &gt;= 2*self.n_neighbors and coords_overlapping_region.size &gt;= 2*self.n_neighbors:
            nbrs = NearestNeighbors(n_neighbors=self.n_neighbors, algorithm=&#39;ball_tree&#39;,radius=self.matching_radius).fit(coords_overlapping_region)
        else:
            nbrs = np.nan
            
        return nbrs

    
    def calculate_registration(self):
        self.monitor = []
        self.c = []
        passing_num = 0
        self.matching_points = False
        if self.ref_hyb_coords.size and self.comp_hyb_coords.size:
            for chunk_coords in self.Coords_Padded_Chunks_list:
                ref_trimmed, tran_trimmed, nbrs_ref, nbrs_tr= self.calculate_NN_roi(chunk_coords)
                #if ref_trimmed.shape[0] &gt;= 2*self.n_neighbors and tran_trimmed.shape[0] &gt;= 2*self.n_neighbors:
                if ref_trimmed.shape[0] &gt;= 20 and tran_trimmed.shape[0] &gt;= 20: 
                    self.monitor.append((ref_trimmed,tran_trimmed))
                    if nbrs_ref != np.nan and nbrs_tr != np.nan:
                        # create dots id list
                        trans_dot_id_list = np.arange(tran_trimmed.shape[0])
                        for tran_dot_id in trans_dot_id_list:
                            searching=tran_trimmed[tran_dot_id,:]
                            searching = searching[np.newaxis,:]
                            dist, idx  = nbrs_tr.kneighbors(searching,n_neighbors=self.n_neighbors)
                            selected_tran = tran_trimmed[idx[0],:]
                            tran_dist = self.calculate_min_distances(selected_tran)
                            for id_r in np.arange(ref_trimmed.shape[0]):
                                self.searching_r=ref_trimmed[id_r,:]
                                self.searching_r = self.searching_r[np.newaxis,:]
                                dist_r, self.idx_r  = nbrs_ref.kneighbors(self.searching_r,n_neighbors=self.n_neighbors)
                                if self.idx_r[0].shape[0] == idx[0].shape[0]: 
                                    selected_ref = ref_trimmed[self.idx_r[0],:]
                                    ref_dist = self.calculate_min_distances(selected_ref)
                                    if np.all(np.abs(ref_dist - tran_dist)&lt;self.min_acceptable_distance):
                                        ref = ref_trimmed[self.idx_r[0],:]
                                        ref_srt = ref[ref[0,:].argsort(),:]
                                        tran = tran_trimmed[idx[0],:]
                                        tran_srt = tran[tran[0,:].argsort(),:]
                                        cpls = np.concatenate((ref_srt,tran_srt),axis=1)
                                        self.c.append(cpls)
                                        if passing_num == 0:
                                            self.matching_points = cpls
                                            passing_num += 1
                                        else:
                                            self.matching_points = np.concatenate((self.matching_points,cpls),axis=0)
            if isinstance(self.matching_points,np.ndarray):
                self.matching_points = np.unique(self.matching_points,axis=0)
                self.ref = self.matching_points[:,0:2]
                self.tran = self.matching_points[:,2:]
                if (self.min_samples &lt; self.ref.shape[0]) and (self.min_samples &lt; self.tran.shape[0]):
                    self.model, self.inliers = ransac((self.tran, self.ref), transform.SimilarityTransform, min_samples=self.min_samples,
                                    residual_threshold=self.residual_threshold, max_trials=self.max_trials)
    #                 self.model = transform.estimate_transform(&#39;Affine&#39;,self.tran, self.ref)
                    self.missing_pos = False
                else:
                    self.missing_pos = True 
            else:
                self.missing_pos = True 
        else: 
            self.missing_pos = True
        
        if not self.missing_pos:
            if self.model:
                self.tr_good = self.tran[self.inliers]
                self.ref_good = self.ref[self.inliers]
                self.transformed_coords = transform.matrix_transform(self.tr_good, self.model.params)
                self.transformed_all_coords = transform.matrix_transform(self.comp_hyb_coords, self.model.params)
                self.delta = self.ref_good - self.tr_good
                self.translation_mean = np.mean(self.delta,axis=0)
                self.translation_median = np.median(self.delta,axis=0)
                self.translation_diagonal = np.sqrt((self.ref_good[:,0] - self.tr_good[:,0])**2 + (self.ref_good[:,1] - self.tr_good[:,1])**2)
                self.translational_diagonal_mean = np.mean(self.translation_diagonal)
                self.translational_diagonal_median = np.median(self.translation_diagonal)
                self.translation_diagonal_std = np.std(self.translation_diagonal)
                self.translation_diagonal_sem = np.std(self.translation_diagonal)/ len(self.translation_diagonal)
                self.err1,self.err2, self.diagonal_mean, self.diagonal_median, self.diag_std, self.diag_sem = self.errors(self.transformed_coords, self.ref_good)
                self.used_points = [self.ref_good,self.tr_good]
            else:
                self.missing_pos = True


    def deploy(self):
        self.registration_data = {}
        if self.ref_hyb_coords.size &gt;= 2*self.n_neighbors:
            self.ref_nbrs = self.calculate_NN_overlapping_region(self.ref_hyb_coords)
            if self.comp_hyb_coords.size &gt;= 2*self.n_neighbors:
                self.comp_nbrs = self.calculate_NN_overlapping_region(self.comp_hyb_coords)
                if (self.ref_nbrs != np.nan) and (self.comp_nbrs != np.nan):
                    self.calculate_registration()
                else:
                    self.logger.info(f&#39;no neighbors identified&#39;)
                    self.missing_pos = True
            else:
                self.logger.info(f&#39;comp region \
                        does not contain enough dots for registration&#39;)
                self.missing_pos = True
                
                # ADJUST WHEN SAVING THE DATA
                self.registration_data = {&#39;missing_pos&#39;:self.missing_pos}
        else:
            self.logger.info(f&#39;reference region\
                            does not contain enough dots for registration&#39;)
            self.missing_pos = True
            
        if self.missing_pos:
            self.registration_data = {&#39;missing_pos&#39;:self.missing_pos}
        else:
            self.registration_data = {&#39;translation_diagonal_mean&#39;:self.translational_diagonal_mean, 
                                    &#39;translation_diagonal_median&#39;: self.translational_diagonal_median, 
                                    &#39;translation_diagonal_std&#39;: self.translation_diagonal_std,
                                    &#39;translation_diagonal_sem&#39;:self.translation_diagonal_sem,
                                    &#39;used_points&#39;: self.used_points,
                                    &#39;model_params&#39;:self.model.params, 
                                    &#39;err1&#39;:self.err1, 
                                    &#39;err2&#39;:self.err2, 
                                    &#39;diagonal_mean&#39;:self.diagonal_mean,
                                    &#39;diagonal_median&#39;:self.translational_diagonal_median,
                                    &#39;diag_std&#39;:self.diag_std, 
                                    &#39;diag_sem&#39;:self.diag_sem,
                                    &#39;transformed_coords&#39;:self.transformed_coords,
                                    &#39;transformed_all_coords&#39;:self.transformed_all_coords,
                                    &#39;missing_pos&#39;:self.missing_pos}</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="pysmFISH.fovs_registration.reference_beads_registration_couple.calculate_min_distances"><code class="name flex">
<span>def <span class="ident">calculate_min_distances</span></span>(<span>selected_ref)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def calculate_min_distances(selected_ref):
    ref_dist = distance.cdist(selected_ref, selected_ref)
    ref_dist = np.triu(ref_dist)
    ref_dist = ref_dist[:-1,:]
    mref = np.ma.masked_where(ref_dist==0,ref_dist)
    mref_min = mref.min(axis=1)
    return np.sort(mref_min.data)</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.reference_beads_registration_couple.errors"><code class="name flex">
<span>def <span class="ident">errors</span></span>(<span>transformed_coords, ref_good)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
# CALCULATE ERROR OVER THE DIAGONAL
def errors(transformed_coords, ref_good):
    diagonals = np.sqrt((ref_good[:,0]- transformed_coords[:,0])**2 + (ref_good[:,1]- transformed_coords[:,1])**2)
    diagonal_mean = np.mean(diagonals,axis=0)
    diagonal_median = np.median(diagonals,axis=0)
    err1 = np.sum((diagonals-diagonal_mean),axis=0)/len(diagonals)
    err2 = np.sum((diagonals-diagonal_mean)**2,axis=0)/len(diagonals)
    diag_std = np.std(diagonals)
    diag_sem = diag_std/len(diagonals)
    
    # delta = np.abs(ref_good - transformed_coords)
    # delta_mean = np.mean(delta,axis=0)
    # err1 = np.sum((delta-delta_mean),axis=0)/len(transformed_coords)
    # err2 = np.sum((delta-delta_mean)**2,axis=0)/len(transformed_coords)
    return err1,err2, diagonal_mean, diagonal_median, diag_std, diag_sem</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pysmFISH.fovs_registration.reference_beads_registration_couple.calculate_NN_overlapping_region"><code class="name flex">
<span>def <span class="ident">calculate_NN_overlapping_region</span></span>(<span>self, coords_overlapping_region)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_NN_overlapping_region(self, coords_overlapping_region):
    
    # Add check if there are dots in the timmed region
    if coords_overlapping_region.size &gt;= 2*self.n_neighbors and coords_overlapping_region.size &gt;= 2*self.n_neighbors:
        nbrs = NearestNeighbors(n_neighbors=self.n_neighbors, algorithm=&#39;ball_tree&#39;,radius=self.matching_radius).fit(coords_overlapping_region)
    else:
        nbrs = np.nan
        
    return nbrs</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.reference_beads_registration_couple.calculate_NN_roi"><code class="name flex">
<span>def <span class="ident">calculate_NN_roi</span></span>(<span>self, chunk_coords)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_NN_roi(self,chunk_coords):    
    r_tl = chunk_coords[0]
    r_br = chunk_coords[1]
    c_tl = chunk_coords[2]
    c_br = chunk_coords[3]

    # Select only the coords in the trimmed region
    ref_trimmed = self.ref_hyb_coords[((r_tl &lt; self.ref_hyb_coords[:,0]) &amp; (self.ref_hyb_coords[:,0]&lt;r_br)\
                                  &amp; (c_tl &lt;self.ref_hyb_coords[:,1]) &amp;(self.ref_hyb_coords[:,1]&lt;c_br)),:]
    tran_trimmed = self.comp_hyb_coords[((r_tl &lt; self.comp_hyb_coords[:,0]) &amp; (self.comp_hyb_coords[:,0]&lt;r_br)\
                                      &amp; (c_tl &lt;self.comp_hyb_coords[:,1]) &amp;(self.comp_hyb_coords[:,1]&lt;c_br)),:]
    
    # Add check if there are dots in the timmed region
    if ref_trimmed.size &gt;= 2*self.n_neighbors and tran_trimmed.size &gt;= 2*self.n_neighbors:
        nbrs_ref = NearestNeighbors(n_neighbors=self.n_neighbors, algorithm=&#39;ball_tree&#39;,radius=self.matching_radius).fit(ref_trimmed)
        nbrs_tr = NearestNeighbors(n_neighbors=self.n_neighbors, algorithm=&#39;ball_tree&#39;,radius=self.matching_radius).fit(tran_trimmed)
    else:
        nbrs_ref = nbrs_tr = np.nan
        
    return ref_trimmed, tran_trimmed, nbrs_ref, nbrs_tr</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.reference_beads_registration_couple.calculate_registration"><code class="name flex">
<span>def <span class="ident">calculate_registration</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_registration(self):
    self.monitor = []
    self.c = []
    passing_num = 0
    self.matching_points = False
    if self.ref_hyb_coords.size and self.comp_hyb_coords.size:
        for chunk_coords in self.Coords_Padded_Chunks_list:
            ref_trimmed, tran_trimmed, nbrs_ref, nbrs_tr= self.calculate_NN_roi(chunk_coords)
            #if ref_trimmed.shape[0] &gt;= 2*self.n_neighbors and tran_trimmed.shape[0] &gt;= 2*self.n_neighbors:
            if ref_trimmed.shape[0] &gt;= 20 and tran_trimmed.shape[0] &gt;= 20: 
                self.monitor.append((ref_trimmed,tran_trimmed))
                if nbrs_ref != np.nan and nbrs_tr != np.nan:
                    # create dots id list
                    trans_dot_id_list = np.arange(tran_trimmed.shape[0])
                    for tran_dot_id in trans_dot_id_list:
                        searching=tran_trimmed[tran_dot_id,:]
                        searching = searching[np.newaxis,:]
                        dist, idx  = nbrs_tr.kneighbors(searching,n_neighbors=self.n_neighbors)
                        selected_tran = tran_trimmed[idx[0],:]
                        tran_dist = self.calculate_min_distances(selected_tran)
                        for id_r in np.arange(ref_trimmed.shape[0]):
                            self.searching_r=ref_trimmed[id_r,:]
                            self.searching_r = self.searching_r[np.newaxis,:]
                            dist_r, self.idx_r  = nbrs_ref.kneighbors(self.searching_r,n_neighbors=self.n_neighbors)
                            if self.idx_r[0].shape[0] == idx[0].shape[0]: 
                                selected_ref = ref_trimmed[self.idx_r[0],:]
                                ref_dist = self.calculate_min_distances(selected_ref)
                                if np.all(np.abs(ref_dist - tran_dist)&lt;self.min_acceptable_distance):
                                    ref = ref_trimmed[self.idx_r[0],:]
                                    ref_srt = ref[ref[0,:].argsort(),:]
                                    tran = tran_trimmed[idx[0],:]
                                    tran_srt = tran[tran[0,:].argsort(),:]
                                    cpls = np.concatenate((ref_srt,tran_srt),axis=1)
                                    self.c.append(cpls)
                                    if passing_num == 0:
                                        self.matching_points = cpls
                                        passing_num += 1
                                    else:
                                        self.matching_points = np.concatenate((self.matching_points,cpls),axis=0)
        if isinstance(self.matching_points,np.ndarray):
            self.matching_points = np.unique(self.matching_points,axis=0)
            self.ref = self.matching_points[:,0:2]
            self.tran = self.matching_points[:,2:]
            if (self.min_samples &lt; self.ref.shape[0]) and (self.min_samples &lt; self.tran.shape[0]):
                self.model, self.inliers = ransac((self.tran, self.ref), transform.SimilarityTransform, min_samples=self.min_samples,
                                residual_threshold=self.residual_threshold, max_trials=self.max_trials)
#                 self.model = transform.estimate_transform(&#39;Affine&#39;,self.tran, self.ref)
                self.missing_pos = False
            else:
                self.missing_pos = True 
        else:
            self.missing_pos = True 
    else: 
        self.missing_pos = True
    
    if not self.missing_pos:
        if self.model:
            self.tr_good = self.tran[self.inliers]
            self.ref_good = self.ref[self.inliers]
            self.transformed_coords = transform.matrix_transform(self.tr_good, self.model.params)
            self.transformed_all_coords = transform.matrix_transform(self.comp_hyb_coords, self.model.params)
            self.delta = self.ref_good - self.tr_good
            self.translation_mean = np.mean(self.delta,axis=0)
            self.translation_median = np.median(self.delta,axis=0)
            self.translation_diagonal = np.sqrt((self.ref_good[:,0] - self.tr_good[:,0])**2 + (self.ref_good[:,1] - self.tr_good[:,1])**2)
            self.translational_diagonal_mean = np.mean(self.translation_diagonal)
            self.translational_diagonal_median = np.median(self.translation_diagonal)
            self.translation_diagonal_std = np.std(self.translation_diagonal)
            self.translation_diagonal_sem = np.std(self.translation_diagonal)/ len(self.translation_diagonal)
            self.err1,self.err2, self.diagonal_mean, self.diagonal_median, self.diag_std, self.diag_sem = self.errors(self.transformed_coords, self.ref_good)
            self.used_points = [self.ref_good,self.tr_good]
        else:
            self.missing_pos = True</code></pre>
</details>
</dd>
<dt id="pysmFISH.fovs_registration.reference_beads_registration_couple.deploy"><code class="name flex">
<span>def <span class="ident">deploy</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def deploy(self):
    self.registration_data = {}
    if self.ref_hyb_coords.size &gt;= 2*self.n_neighbors:
        self.ref_nbrs = self.calculate_NN_overlapping_region(self.ref_hyb_coords)
        if self.comp_hyb_coords.size &gt;= 2*self.n_neighbors:
            self.comp_nbrs = self.calculate_NN_overlapping_region(self.comp_hyb_coords)
            if (self.ref_nbrs != np.nan) and (self.comp_nbrs != np.nan):
                self.calculate_registration()
            else:
                self.logger.info(f&#39;no neighbors identified&#39;)
                self.missing_pos = True
        else:
            self.logger.info(f&#39;comp region \
                    does not contain enough dots for registration&#39;)
            self.missing_pos = True
            
            # ADJUST WHEN SAVING THE DATA
            self.registration_data = {&#39;missing_pos&#39;:self.missing_pos}
    else:
        self.logger.info(f&#39;reference region\
                        does not contain enough dots for registration&#39;)
        self.missing_pos = True
        
    if self.missing_pos:
        self.registration_data = {&#39;missing_pos&#39;:self.missing_pos}
    else:
        self.registration_data = {&#39;translation_diagonal_mean&#39;:self.translational_diagonal_mean, 
                                &#39;translation_diagonal_median&#39;: self.translational_diagonal_median, 
                                &#39;translation_diagonal_std&#39;: self.translation_diagonal_std,
                                &#39;translation_diagonal_sem&#39;:self.translation_diagonal_sem,
                                &#39;used_points&#39;: self.used_points,
                                &#39;model_params&#39;:self.model.params, 
                                &#39;err1&#39;:self.err1, 
                                &#39;err2&#39;:self.err2, 
                                &#39;diagonal_mean&#39;:self.diagonal_mean,
                                &#39;diagonal_median&#39;:self.translational_diagonal_median,
                                &#39;diag_std&#39;:self.diag_std, 
                                &#39;diag_sem&#39;:self.diag_sem,
                                &#39;transformed_coords&#39;:self.transformed_coords,
                                &#39;transformed_all_coords&#39;:self.transformed_all_coords,
                                &#39;missing_pos&#39;:self.missing_pos}</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pysmFISH" href="index.html">pysmFISH</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pysmFISH.fovs_registration.beads_based_registration" href="#pysmFISH.fovs_registration.beads_based_registration">beads_based_registration</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.beads_based_registration_fish" href="#pysmFISH.fovs_registration.beads_based_registration_fish">beads_based_registration_fish</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.beads_based_registration_stitching_channel" href="#pysmFISH.fovs_registration.beads_based_registration_stitching_channel">beads_based_registration_stitching_channel</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.calculate_shift_hybridization_fov" href="#pysmFISH.fovs_registration.calculate_shift_hybridization_fov">calculate_shift_hybridization_fov</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.calculate_shift_hybridization_fov_nuclei" href="#pysmFISH.fovs_registration.calculate_shift_hybridization_fov_nuclei">calculate_shift_hybridization_fov_nuclei</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.calculate_shift_hybridization_fov_nuclei_test" href="#pysmFISH.fovs_registration.calculate_shift_hybridization_fov_nuclei_test">calculate_shift_hybridization_fov_nuclei_test</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.calculate_shift_hybridization_fov_test" href="#pysmFISH.fovs_registration.calculate_shift_hybridization_fov_test">calculate_shift_hybridization_fov_test</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.combine_register_filtered_image_single_channel" href="#pysmFISH.fovs_registration.combine_register_filtered_image_single_channel">combine_register_filtered_image_single_channel</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.combine_register_filtered_images" href="#pysmFISH.fovs_registration.combine_register_filtered_images">combine_register_filtered_images</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.create_fake_image" href="#pysmFISH.fovs_registration.create_fake_image">create_fake_image</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.create_registration_grps" href="#pysmFISH.fovs_registration.create_registration_grps">create_registration_grps</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.determine_overlap_region" href="#pysmFISH.fovs_registration.determine_overlap_region">determine_overlap_region</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.fft_registration_beads" href="#pysmFISH.fovs_registration.fft_registration_beads">fft_registration_beads</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.identify_matching_register_dots_NN" href="#pysmFISH.fovs_registration.identify_matching_register_dots_NN">identify_matching_register_dots_NN</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.nuclei_based_registration" href="#pysmFISH.fovs_registration.nuclei_based_registration">nuclei_based_registration</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.register_fish" href="#pysmFISH.fovs_registration.register_fish">register_fish</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.register_fish_on_nuclei" href="#pysmFISH.fovs_registration.register_fish_on_nuclei">register_fish_on_nuclei</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.register_fish_on_nuclei_test" href="#pysmFISH.fovs_registration.register_fish_on_nuclei_test">register_fish_on_nuclei_test</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.register_fish_test" href="#pysmFISH.fovs_registration.register_fish_test">register_fish_test</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.register_images" href="#pysmFISH.fovs_registration.register_images">register_images</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pysmFISH.fovs_registration.chunking" href="#pysmFISH.fovs_registration.chunking">chunking</a></code></h4>
<ul class="">
<li><code><a title="pysmFISH.fovs_registration.chunking.block_chunking" href="#pysmFISH.fovs_registration.chunking.block_chunking">block_chunking</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.chunking.block_chunks_calculator" href="#pysmFISH.fovs_registration.chunking.block_chunks_calculator">block_chunks_calculator</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pysmFISH.fovs_registration.reference_beads_registration" href="#pysmFISH.fovs_registration.reference_beads_registration">reference_beads_registration</a></code></h4>
<ul class="">
<li><code><a title="pysmFISH.fovs_registration.reference_beads_registration.calculate_NN_overlapping_region" href="#pysmFISH.fovs_registration.reference_beads_registration.calculate_NN_overlapping_region">calculate_NN_overlapping_region</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.reference_beads_registration.calculate_NN_roi" href="#pysmFISH.fovs_registration.reference_beads_registration.calculate_NN_roi">calculate_NN_roi</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.reference_beads_registration.calculate_min_distances" href="#pysmFISH.fovs_registration.reference_beads_registration.calculate_min_distances">calculate_min_distances</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.reference_beads_registration.calculate_registration" href="#pysmFISH.fovs_registration.reference_beads_registration.calculate_registration">calculate_registration</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.reference_beads_registration.deploy" href="#pysmFISH.fovs_registration.reference_beads_registration.deploy">deploy</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.reference_beads_registration.errors" href="#pysmFISH.fovs_registration.reference_beads_registration.errors">errors</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pysmFISH.fovs_registration.reference_beads_registration_couple" href="#pysmFISH.fovs_registration.reference_beads_registration_couple">reference_beads_registration_couple</a></code></h4>
<ul class="">
<li><code><a title="pysmFISH.fovs_registration.reference_beads_registration_couple.calculate_NN_overlapping_region" href="#pysmFISH.fovs_registration.reference_beads_registration_couple.calculate_NN_overlapping_region">calculate_NN_overlapping_region</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.reference_beads_registration_couple.calculate_NN_roi" href="#pysmFISH.fovs_registration.reference_beads_registration_couple.calculate_NN_roi">calculate_NN_roi</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.reference_beads_registration_couple.calculate_min_distances" href="#pysmFISH.fovs_registration.reference_beads_registration_couple.calculate_min_distances">calculate_min_distances</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.reference_beads_registration_couple.calculate_registration" href="#pysmFISH.fovs_registration.reference_beads_registration_couple.calculate_registration">calculate_registration</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.reference_beads_registration_couple.deploy" href="#pysmFISH.fovs_registration.reference_beads_registration_couple.deploy">deploy</a></code></li>
<li><code><a title="pysmFISH.fovs_registration.reference_beads_registration_couple.errors" href="#pysmFISH.fovs_registration.reference_beads_registration_couple.errors">errors</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>