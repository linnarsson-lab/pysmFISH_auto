<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>pysmFISH.microscopy_file_parsers API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pysmFISH.microscopy_file_parsers</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from typing import *
import pickle
import sys
import re
import shutil
import numpy as np
import zarr
import nd2reader
# import xarray as xr
import pandas as pd
from pathlib import Path
from dask import distributed

from pysmFISH import io
from pysmFISH import utils
from pysmFISH import configuration_files
from pysmFISH import qc_utils

from pysmFISH.logger_utils import selected_logger



def create_dark_img(experiment_fpath:str, metadata: pd.DataFrame):
    &#34;&#34;&#34;Function used to generate the image containing the camera noise.png

    The image is acquired as .nd2 file labeled Blank*.nd2 and is stored
    in the extra_files subfolder. The file contain a stack of images
    acquired with no illumination in order to evaluate the camera noise.
    
    If the files is present in the extra_files folder than the median is calculated 
    and saved as experiment_name + machine_name +&#39;_dark_img.npy&#39; in the
    extra_processing_files subfolder.

    If the file is not present than the machine +&#39;_dark_img.npy&#39; present in the
    config_db folder is copied in the extra_processing_files subfolder.

    Args:
        experiment_fpath (str): path to the experiment to process
        metadata (pd.DataFrame): dictionary with the metadata of the experiment
    &#34;&#34;&#34;
    logger = selected_logger()
    experiment_fpath = Path(experiment_fpath)
    experiment_name = metadata[&#39;experiment_name&#39;]
    machine = metadata[&#39;machine&#39;]
    # Check if the dark image is already present
    nd2_blank = None
    
    # Look in the extra files
    nd2_list = list((experiment_fpath / &#39;extra_files&#39;).glob(&#39;*.nd2&#39;))
    nd2_blank = [el for el in nd2_list if &#39;Blank&#39; in el.stem]
    
    if nd2_blank:
        nd2fh = nd2reader.ND2Reader(nd2_blank[0])
        nd2fh.bundle_axes = &#39;zyx&#39;
        nd2fh.iter_axes = &#39;z&#39;
        # Image with single channel
        channel = nd2fh.metadata[&#39;channels&#39;][0]
        # I can collect just one z because error of the reader
        # that created both z and t planes
        dark_img = np.median(nd2fh[0],axis=0)
        dark_img = dark_img.astype(np.uint16)
        fname = experiment_fpath / &#39;extra_processing_data&#39; / (experiment_name + &#39;_&#39; + machine + &#39;_dark_img.npy&#39;)
        np.save(fname, dark_img)
        logger.debug(f&#39;Created dark image from .nd2 file&#39;)
    else:
        logger.debug(f&#39;the Blank .nd2 for the dark image is missing in experiment folder&#39;)
        try:
            pres = list((experiment_fpath / &#39;extra_processing_data&#39;).glob(&#39;*_dark_img.npy&#39;))[0]
        except IndexError:
            try:
                pres = list((experiment_fpath.parent / &#39;config_db&#39;).glob(machine+&#39;_dark_img.npy&#39;))[0]
                new_location = experiment_fpath / &#39;extra_processing_data&#39; / pres.name
                shutil.copy2(pres,new_location)
            except IndexError:
                logger.error(f&#39;Missing .npy dask image&#39;)
            else:
                logger.error(f&#39;the Blank .nd2 for the dark image is missing in experiment folder&#39;)
        else:
            logger.debug(f&#39;the dark image is already present in the config_db&#39;)



def create_dark_img_from_standalone(image_fpath:str, machine: str):
    &#34;&#34;&#34;Function used to generate the image containing the camera noise.png

    The image is acquired as .nd2 file and is acquired separately as
    standalone file.The file contain a stack of images
    acquired with no illumination in order to evaluate the camera noise.
    
    The median is calculated and saved as machine_name +&#39;_dark_img.npy&#39; in the
    same folder of the original image.

    Args:
        image_fpath (str): path to nd2 file to process
        machine (str): machine used to acquire the blank image
    &#34;&#34;&#34;
    logger = selected_logger()
    image_fpath = Path(image_fpath)
    
    nd2fh = nd2reader.ND2Reader(image_fpath)
    nd2fh.bundle_axes = &#39;zyx&#39;
    nd2fh.iter_axes = &#39;z&#39;
    # Image with single channel
    channel = nd2fh.metadata[&#39;channels&#39;][0]
    # I can collect just one z because error of the reader
    # that created both z and t planes
    dark_img = np.median(nd2fh[0],axis=0)
    dark_img = dark_img.astype(np.uint16)
    fname = image_fpath.parent / (machine + &#39;_dark_img.npy&#39;)
    np.save(fname, dark_img)
    logger.debug(f&#39;Created dark image from .nd2 file&#39;)


def nd2_raw_files_selector(experiment_fpath: str) -&gt; list:
    &#34;&#34;&#34;
    Identify the nd2 raw microscopy files generated by
    the robofish machine. The files must contain CountXXXXX in the name. 

    Args:
        experiment_fpath (str): Path to the folder to process.

    Returns:
        all_files_to_process (list):
            List of PosixPath of the microscopy files to process
        
    &#34;&#34;&#34;
    logger = selected_logger()

    experiment_fpath = Path(experiment_fpath)
    # assert &#39;_auto&#39; in experiment_fpath.stem, sys.exit(&#39;no _auto in the experiment name&#39;)

    searching_key = &#39;*Count*.nd2&#39;
    all_files_to_process = list(experiment_fpath.glob(searching_key))

    assert all_files_to_process, sys.exit(&#39;no .nd2 raw files to process&#39;)
    
    logger.debug(f&#39;Number of files to process {len(all_files_to_process)}.&#39;)
    return all_files_to_process




def nd2_raw_files_selector_general(folder_fpath: str) -&gt; list:

    &#34;&#34;&#34;
    Function used to identify the .nd2 files in a folder. The files
    do not need to have the CountXXX or the _auto suffix. This
    class can be used to identify the .nd2 files that need to be
    reparsed.

    Args:
        folder_fpath (str): 
            Path to the folder to process. 
    Returns:
        all_files_to_process (list):
            List of PosixPath of the microscopy files to process
        
    &#34;&#34;&#34;
    logger = selected_logger()
    folder_fpath = Path(folder_fpath)
    
    searching_key = &#39;*.nd2&#39;
    all_files_to_process = list(folder_fpath.glob(searching_key))

    assert all_files_to_process, sys.exit(&#39;no .nd2 raw files to process&#39;)
    
    logger.debug(f&#39;Number of files to process {len(all_files_to_process)}.&#39;)
    return all_files_to_process



def nikon_nd2_autoparser_zarr(nd2_file_path: str, parsed_raw_data_fpath: str, experiment_info: dict):

    &#34;&#34;&#34;
    Function to parse nikon .nd2 files generated by robofish.
    This parser not consider the possibility to have multiple experiment running at
    the same time with the raw imaging data present in the same folder. 
    Once the data are parsed by hybridization are saved in
    the same folder.

    NB: The file and the corresponding metadata file generated by the microscope
        must contain &#39;CountXXXXX&#39; in order to be processed

    The parsed_tmp and raw_data directories are created in a previous step of the 
    pipeline during data sorting

    QC step run before parsing take care of checking if the nd2 files are present
    and in the corresponding pickle configuration files are in the folder

    This nd2 parser process one .nd2 file

    Args:
        nd2_file_path (str): Path to the .nd2 file to be parsed
        parsed_raw_data_fpath (str): Path to the zarr file that will store the parsed data
        experiment_info (dict): Dictionary with overall experiment info
    &#34;&#34;&#34;

    logger = selected_logger()
    parsed_raw_data_fpath = Path(parsed_raw_data_fpath)
    nd2_file_path = Path(nd2_file_path)
    nd2_fname = nd2_file_path.stem

    logger.debug(f&#39;processing file {nd2_fname}&#39;)

    experiment_fpath = nd2_file_path.parent
    experiment_name = nd2_file_path.parent.stem
    experiment_name = experiment_name.split(&#39;_auto&#39;)[0]
    
    raw_files_dir = experiment_fpath / &#39;raw_data&#39;
    
    # Extract the Count code from the file name
    count_code = re.search(r&#39;(Count)\d{5}&#39;, nd2_file_path.stem).group()
    
    all_info_files = experiment_fpath.glob(&#39;*.pkl&#39;)
    
    info_file = [info_file for info_file in all_info_files if count_code  in info_file.stem][0]
    
    info_data = pickle.load(open(info_file, &#39;rb&#39;))
    logger.debug(f&#39;loaded info data file {info_file.stem}&#39;)
    
    hybridization_name = info_data[&#39;channels&#39;][&#39;Hybridization&#39;]
    logger.debug(f&#39;processing hybridization {hybridization_name}&#39;)
    
    try:
        nd2fh = nd2reader.ND2Reader(nd2_file_path.as_posix())
    except:
        logger.error(f&#39;Cannot load the nd2 file {nd2_file_path}&#39;)
        sys.exit(f&#39;Cannot load the nd2 file {nd2_file_path}&#39;)
    else:
        # Collect metadata
        all_metadata = nd2fh.parser._raw_metadata
        parsed_metadata = nd2fh.parser._raw_metadata.get_parsed_metadata()
        
        channel = parsed_metadata[&#39;channels&#39;][0] # works because there is only one channel for file
        logger.debug(f&#39;processing channel {channel}&#39;)

        img_shape = np.array([parsed_metadata[&#39;height&#39;],parsed_metadata[&#39;width&#39;]])
        pixel_microns = parsed_metadata[&#39;pixel_microns&#39;]
        z_levels = parsed_metadata[&#39;z_levels&#39;]
        fields_of_view = parsed_metadata[&#39;fields_of_view&#39;]
        
        # Collect FOV coords
        x_data = np.array(all_metadata.x_data)
        x_data = x_data[:,np.newaxis]
        y_data = np.array(all_metadata.y_data)
        y_data = y_data[:,np.newaxis]
        z_data = np.array(all_metadata.z_data)
        z_data = z_data[:,np.newaxis]
        all_coords = np.hstack((z_data,x_data,y_data))
        fov_coords = all_coords[0::len(z_levels),:]
        
        tag_name = experiment_name + &#39;_&#39; + hybridization_name + &#39;_&#39; + channel
        
        
        # Save the file as zarr
        store = zarr.DirectoryStore(parsed_raw_data_fpath)
        root = zarr.group(store=store,overwrite=False)


        # Save the fov_coords
        fname = experiment_fpath / &#39;microscope_tiles_coords&#39; / (tag_name + &#39;_fovs_coords.npy&#39;)
        np.save(fname, fov_coords)

        nd2fh.bundle_axes = &#39;zyx&#39;
        # set iteration over the fields of view
        nd2fh.iter_axes = &#39;v&#39;
        
        # Save coords of the FOV
        rows = np.arange(parsed_metadata[&#39;width&#39;])
        cols = np.arange(parsed_metadata[&#39;height&#39;])
        hybridization_num = int(hybridization_name.split(&#39;Hybridization&#39;)[-1])
        for fov in fields_of_view:
            img = np.array(nd2fh[fov],dtype=np.uint16)      
            array_name = tag_name + &#39;_fov_&#39; + str(fov)
            dgrp = root.create_group(array_name)
            fov_name = &#39;raw_data_fov_&#39; + str(fov)
            # Remember that attrs must be JSON-serializable to be stored
            # in zarr
            dgrp.attrs[&#39;grp_name&#39;] = array_name
            dgrp.attrs[&#39;fov_name&#39;] = fov_name
            dgrp.attrs[&#39;channel&#39;] = channel
            dgrp.attrs[&#39;target_name&#39;] = info_data[&#39;channels&#39;][channel]
            dgrp.attrs[&#39;img_width&#39;] = parsed_metadata[&#39;width&#39;]
            dgrp.attrs[&#39;img_height&#39;] = parsed_metadata[&#39;height&#39;]
            dgrp.attrs[&#39;pixel_microns&#39;] = pixel_microns
            dgrp.attrs[&#39;zstack&#39;] = len(list(z_levels))
            dgrp.attrs[&#39;total_fovs&#39;] = len(list(fields_of_view))
            dgrp.attrs[&#39;fov_num&#39;] = fov
            dgrp.attrs[&#39;stitching_channel&#39;] = experiment_info[&#39;StitchingChannel&#39;]
            dgrp.attrs[&#39;stitching_type&#39;] = experiment_info[&#39;Stitching_type&#39;]
            dgrp.attrs[&#39;experiment_type&#39;] = experiment_info[&#39;Experiment_type&#39;]     
            dgrp.attrs[&#39;barcode_length&#39;] = experiment_info[&#39;Barcode_length&#39;]
            dgrp.attrs[&#39;barcode&#39;] = experiment_info[&#39;Barcode&#39;]
            
            codebook_channel = &#39;Codebook_&#39; + channel
            codebook_name = experiment_info[&#39;Codebooks&#39;][codebook_channel]
            dgrp.attrs[&#39;codebook&#39;] = codebook_name
            
            probes_channel = &#39;Probes_FASTA_&#39; + channel
            probes_name = experiment_info[&#39;Probes_FASTA&#39;][probes_channel]
            dgrp.attrs[&#39;probe_fasta_name&#39;] = probes_name

            dgrp.attrs[&#39;machine&#39;] = experiment_info[&#39;Machine&#39;]
            dgrp.attrs[&#39;operator&#39;] = experiment_info[&#39;Operator&#39;]
            dgrp.attrs[&#39;overlapping_percentage&#39;] = experiment_info[&#39;Overlapping_percentage&#39;]
            dgrp.attrs[&#39;species&#39;] = experiment_info[&#39;Species&#39;]
            dgrp.attrs[&#39;start_date&#39;] = experiment_info[&#39;Start_date&#39;]
            dgrp.attrs[&#39;strain&#39;] = experiment_info[&#39;Strain&#39;]
            dgrp.attrs[&#39;tissue&#39;] = experiment_info[&#39;Tissue&#39;]
            dgrp.attrs[&#39;pipeline&#39;] = experiment_info[&#39;Pipeline&#39;]
            dgrp.attrs[&#39;round_num&#39;] = hybridization_num
            dgrp.attrs[&#39;experiment_name&#39;] = experiment_name
            dgrp.attrs[&#39;fov_acquisition_coords_x&#39;] = fov_coords[fov,1]
            dgrp.attrs[&#39;fov_acquisition_coords_y&#39;] = fov_coords[fov,2]
            dgrp.attrs[&#39;fov_acquisition_coords_z&#39;] = fov_coords[fov,0]


            if info_data[&#39;StitchingChannel&#39;] == channel:
                dgrp.attrs[&#39;processing_type&#39;] = dgrp.attrs[&#39;stitching_type&#39;]
            elif &#39;_ST&#39; in dgrp.attrs[&#39;target_name&#39;]:
                dgrp.attrs[&#39;processing_type&#39;] = &#39;staining&#39;
            else:
                dgrp.attrs[&#39;processing_type&#39;] = &#39;fish&#39;

            dset = dgrp.create_dataset(fov_name, data=img, shape=img.shape, chunks=(1,None,None),overwrite=True)

        # Rename the nd2 files
        new_file_name = tag_name + &#39;.nd2&#39;
        logger.debug(f&#39;.nd2 file renamed {new_file_name}&#39;)
        new_file_path = raw_files_dir / new_file_name
        nd2_file_path.rename(new_file_path)
        nd2_file_path = new_file_path
        
        # Copy the pkl files
        new_file_name = tag_name + &#39;_info.pkl&#39;
        logger.debug(f&#39;info data file renamed {new_file_name}&#39;)
        new_file_path = raw_files_dir / new_file_name
        # Must copy the pkl file in order to be able to use the file for the other channels
        shutil.copy(str(info_file), str(new_file_path))
        


def nikon_nd2_reparser_zarr(nd2_file_path: str,parsed_raw_data_fpath: str,experiment_info: dict):
    &#34;&#34;&#34;
    This function is used to reparse the raw data stored in the raw_data folder during
    the processing. 

    NB: The file and the corresponding metadata file generated by the microscope
        have the same starting name:
        LBEXP20201014_EEL_Mouse_2420um_Hybridization01_Cy5.nd2
        LBEXP20201014_EEL_Mouse_2420um_Hybridization01_Cy5_info.pkl

    The parsed_tmp directory is created in a previous step of the 
    pipeline during data sorting


    This nd2 parser process one .nd2 file

    Args:
        nd2_file_path (str): Path to the .nd2 file to be parsed
        parsed_raw_data_fpath (str): Path to the zarr file that will store the parsed data
        experiment_info (dict): Dictionary with overall experiment info
    &#34;&#34;&#34;

    logger = selected_logger()
    nd2_file_path = Path(nd2_file_path)
    nd2_fname = nd2_file_path.stem
    parsed_raw_data_fpath = Path(parsed_raw_data_fpath)
    logger.debug(f&#39;processing file {nd2_fname}&#39;)

    experiment_fpath = nd2_file_path.parent.parent
    experiment_name = nd2_file_path.parent.parent.stem
    # experiment_name = experiment_name.split(&#39;_auto&#39;)[0]
    
    info_file = nd2_file_path.parent / (nd2_fname + &#39;_info.pkl&#39;)
    info_data = pickle.load(open(info_file, &#39;rb&#39;))
    hybridization_name = info_data[&#39;channels&#39;][&#39;Hybridization&#39;]
    
    try:
        nd2fh = nd2reader.ND2Reader(nd2_file_path.as_posix())
    except:
        logger.error(f&#39;Cannot load the {nd2_fname} nd2 file&#39;)
        sys.exit(&#39;fCannot load the {nd2_fname} nd2 file&#39;)
    else:
        # Collect metadata
        all_metadata = nd2fh.parser._raw_metadata
        parsed_metadata = nd2fh.parser._raw_metadata.get_parsed_metadata()
        
        channel = parsed_metadata[&#39;channels&#39;][0] # works because there is only one channel for file
        img_shape = np.array([parsed_metadata[&#39;height&#39;],parsed_metadata[&#39;width&#39;]])
        pixel_microns = parsed_metadata[&#39;pixel_microns&#39;]
        z_levels = parsed_metadata[&#39;z_levels&#39;]
        fields_of_view = parsed_metadata[&#39;fields_of_view&#39;]
        
        # Collect FOV coords
        x_data = np.array(all_metadata.x_data)
        x_data = x_data[:,np.newaxis]
        y_data = np.array(all_metadata.y_data)
        y_data = y_data[:,np.newaxis]
        z_data = np.array(all_metadata.z_data)
        z_data = z_data[:,np.newaxis]
        all_coords = np.hstack((z_data,x_data,y_data))
        fov_coords = all_coords[0::len(z_levels),:]
        
        tag_name = experiment_name + &#39;_&#39; + hybridization_name + &#39;_&#39; + channel
    
        # Save the fov_coords
        new_exp_location = parsed_raw_data_fpath.parent
        fname = new_exp_location /&#39;microscope_tiles_coords&#39; / (tag_name + &#39;_fovs_coords.npy&#39;)
        np.save(fname, fov_coords)


        # Save the file as zarr
        store = zarr.DirectoryStore(parsed_raw_data_fpath)
        root = zarr.group(store=store,overwrite=False)

        
        nd2fh.bundle_axes = &#39;zyx&#39;
        # set iteration over the fields of view
        nd2fh.iter_axes = &#39;v&#39;
        
        # Save coords of the FOV
        rows = np.arange(parsed_metadata[&#39;width&#39;])
        cols = np.arange(parsed_metadata[&#39;height&#39;])
        hybridization_num = int(hybridization_name.split(&#39;Hybridization&#39;)[-1])
        for fov in fields_of_view:
            img = np.array(nd2fh[fov],dtype=np.uint16)      
            array_name = tag_name + &#39;_fov_&#39; + str(fov)
            dgrp = root.create_group(array_name)
            fov_name = &#39;raw_data_fov_&#39; + str(fov)
            # Remember that attrs must be JSON-serializable to be stored
            # in zarr
            dgrp.attrs[&#39;grp_name&#39;] = array_name
            dgrp.attrs[&#39;fov_name&#39;] = fov_name
            dgrp.attrs[&#39;channel&#39;] = channel
            dgrp.attrs[&#39;target_name&#39;] = info_data[&#39;channels&#39;][channel]
            dgrp.attrs[&#39;img_width&#39;] = parsed_metadata[&#39;width&#39;]
            dgrp.attrs[&#39;img_height&#39;] = parsed_metadata[&#39;height&#39;]
            dgrp.attrs[&#39;pixel_microns&#39;] = pixel_microns
            dgrp.attrs[&#39;zstack&#39;] = len(list(z_levels))
            dgrp.attrs[&#39;total_fovs&#39;] = len(list(fields_of_view))
            dgrp.attrs[&#39;fov_num&#39;] = fov
            dgrp.attrs[&#39;stitching_channel&#39;] = experiment_info[&#39;StitchingChannel&#39;]
            dgrp.attrs[&#39;stitching_type&#39;] = experiment_info[&#39;Stitching_type&#39;]
            dgrp.attrs[&#39;experiment_type&#39;] = experiment_info[&#39;Experiment_type&#39;]
            dgrp.attrs[&#39;round_num&#39;] = hybridization_num
            dgrp.attrs[&#39;experiment_name&#39;] = experiment_name
            dgrp.attrs[&#39;barcode_length&#39;] = experiment_info[&#39;Barcode_length&#39;]

            codebook_channel = &#39;Codebook_&#39; + channel
            codebook_name = experiment_info[&#39;Codebooks&#39;][codebook_channel]
            dgrp.attrs[&#39;codebook&#39;] = codebook_name
            
            probes_channel = &#39;Probes_FASTA_&#39; + channel
            probes_name = experiment_info[&#39;Probes_FASTA&#39;][probes_channel]
            dgrp.attrs[&#39;probe_fasta_name&#39;] = probes_name

            dgrp.attrs[&#39;barcode&#39;] = experiment_info[&#39;Barcode&#39;]
            dgrp.attrs[&#39;machine&#39;] = experiment_info[&#39;Machine&#39;]
            dgrp.attrs[&#39;operator&#39;] = experiment_info[&#39;Operator&#39;]
            dgrp.attrs[&#39;overlapping_percentage&#39;] = experiment_info[&#39;Overlapping_percentage&#39;]
            dgrp.attrs[&#39;species&#39;] = experiment_info[&#39;Species&#39;]
            dgrp.attrs[&#39;start_date&#39;] = experiment_info[&#39;Start_date&#39;]
            dgrp.attrs[&#39;strain&#39;] = experiment_info[&#39;Strain&#39;]
            dgrp.attrs[&#39;tissue&#39;] = experiment_info[&#39;Tissue&#39;]
            dgrp.attrs[&#39;pipeline&#39;] = experiment_info[&#39;Pipeline&#39;]
            dgrp.attrs[&#39;fov_acquisition_coords_x&#39;] = fov_coords[fov,1]
            dgrp.attrs[&#39;fov_acquisition_coords_y&#39;] = fov_coords[fov,2]
            dgrp.attrs[&#39;fov_acquisition_coords_z&#39;] = fov_coords[fov,0]

            if info_data[&#39;StitchingChannel&#39;] == channel:
                dgrp.attrs[&#39;processing_type&#39;] = dgrp.attrs[&#39;stitching_type&#39;]
            elif &#39;_ST&#39; in dgrp.attrs[&#39;target_name&#39;]:
                dgrp.attrs[&#39;processing_type&#39;] = &#39;staining&#39;
            else:
                dgrp.attrs[&#39;processing_type&#39;] = &#39;fish&#39;

            dset = dgrp.create_dataset(fov_name, data=img, shape=img.shape, chunks=(1,None,None),overwrite=True)



def nikon_nd2_parser_simple_mfov(nd2_file_path: str):

    &#34;&#34;&#34;
    Function to parse a generic nikon .nd2 files generated by robofish.
    
    Args:
        nd2_file_path (str): Path to the .nd2 file to be parsed
        parsed_raw_data_fpath (str): Path to the zarr file that will store the parsed data
    &#34;&#34;&#34;

    logger = selected_logger()
    nd2_file_path = Path(nd2_file_path)
    nd2_fname = nd2_file_path.stem

    logger.debug(f&#39;processing file {nd2_fname}&#39;)

    experiment_fpath = nd2_file_path.parent
    experiment_name = nd2_file_path.stem
    experiment_name = experiment_name.split(&#39;_auto&#39;)[0]
    
    parsed_raw_data_fpath = experiment_fpath / (experiment_name + &#39;_img_data.zarr&#39;)

    try:
        nd2fh = nd2reader.ND2Reader(nd2_file_path)
    except:
        logger.error(f&#39;Cannot load the nd2 file {nd2_file_path}&#39;)
        sys.exit(f&#39;Cannot load the nd2 file {nd2_file_path}&#39;)
    else:
        # Collect metadata
        all_metadata = nd2fh.parser._raw_metadata
        parsed_metadata = nd2fh.parser._raw_metadata.get_parsed_metadata()
        
        channel = parsed_metadata[&#39;channels&#39;][0] # works because there is only one channel for file
        logger.debug(f&#39;processing channel {channel}&#39;)

        img_shape = np.array([parsed_metadata[&#39;height&#39;],parsed_metadata[&#39;width&#39;]])
        pixel_microns = parsed_metadata[&#39;pixel_microns&#39;]
        z_levels = parsed_metadata[&#39;z_levels&#39;]
        fields_of_view = parsed_metadata[&#39;fields_of_view&#39;]
        
        # Collect FOV coords
        x_data = np.array(all_metadata.x_data)
        x_data = x_data[:,np.newaxis]
        y_data = np.array(all_metadata.y_data)
        y_data = y_data[:,np.newaxis]
        z_data = np.array(all_metadata.z_data)
        z_data = z_data[:,np.newaxis]
        all_coords = np.hstack((z_data,x_data,y_data))
        fov_coords = all_coords[0::len(z_levels),:]
        
        tag_name = experiment_name
        
        
        # Save the file as zarr
        store = zarr.DirectoryStore(parsed_raw_data_fpath)
        root = zarr.group(store=store,overwrite=False)


        # Save the fov_coords
        fname = experiment_fpath / (tag_name + &#39;_fovs_coords.npy&#39;)
        np.save(fname, fov_coords)

        nd2fh.bundle_axes = &#39;zyx&#39;
        # set iteration over the fields of view
        nd2fh.iter_axes = &#39;v&#39;
        
        # Save coords of the FOV
        rows = np.arange(parsed_metadata[&#39;width&#39;])
        cols = np.arange(parsed_metadata[&#39;height&#39;])
        for fov in fields_of_view:
            img = np.array(nd2fh[fov],dtype=np.uint16)      
            array_name = tag_name + &#39;_fov_&#39; + str(fov)
            dgrp = root.create_group(array_name)
            fov_name = &#39;raw_data_fov_&#39; + str(fov)
            # Remember that attrs must be JSON-serializable to be stored
            # in zarr
            dgrp.attrs[&#39;grp_name&#39;] = array_name
            dgrp.attrs[&#39;fov_name&#39;] = fov_name
            dgrp.attrs[&#39;channel&#39;] = channel
            dgrp.attrs[&#39;img_width&#39;] = parsed_metadata[&#39;width&#39;]
            dgrp.attrs[&#39;img_height&#39;] = parsed_metadata[&#39;height&#39;]
            dgrp.attrs[&#39;pixel_microns&#39;] = pixel_microns
            dgrp.attrs[&#39;zstack&#39;] = len(list(z_levels))
            dgrp.attrs[&#39;total_fovs&#39;] = len(list(fields_of_view))
            dgrp.attrs[&#39;fov_num&#39;] = fov
            dgrp.attrs[&#39;experiment_name&#39;] = experiment_name
            dgrp.attrs[&#39;fov_acquisition_coords_x&#39;] = fov_coords[fov,1]
            dgrp.attrs[&#39;fov_acquisition_coords_y&#39;] = fov_coords[fov,2]
            dgrp.attrs[&#39;fov_acquisition_coords_z&#39;] = fov_coords[fov,0]

            dgrp.attrs[&#39;target_name&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;stitching_channel&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;stitching_type&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;experiment_type&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;round_num&#39;] = 1
            dgrp.attrs[&#39;barcode_length&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;barcode&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;codebook&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;machine&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;operator&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;overlapping_percentage&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;probe_fasta_name&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;species&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;start_date&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;strain&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;tissue&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;pipeline&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;processing_type&#39;] = &#39;undefined&#39;

            dgrp.attrs[&#39;round_num&#39;] = 1

            dset = dgrp.create_dataset(fov_name, data=img, shape=img.shape, chunks=(1,None,None),overwrite=True)

        # # Rename the nd2 files
        # new_file_name = tag_name + &#39;.nd2&#39;
        # logger.debug(f&#39;.nd2 file renamed {new_file_name}&#39;)
        # new_file_path = experiment_fpath / new_file_name
        # nd2_file_path.rename(new_file_path)
        # nd2_file_path = new_file_path



def nikon_nd2_parsing_graph(experiment_fpath: str,
                                parsing_type: str, parsed_image_tag: str, 
                                storage_experiment_fpath: str,
                                client: distributed.Client):
    &#34;&#34;&#34;Function that create and run a dask graph for the parsing of the
    raw nikon files.
    The parsing can be run on original files generated by robofish or on
    previously parsed and renamed files raw nd2 files stored in the experiment
    folder or in a storage directory.
    The parsed data are stored in a zarr DirectoryStore and each fov is saved as
    separated group.
    Steps run in the graph: 
    - Create a specific analysis configuration file (it will not rewrite it if it is
        already present)
    - Create the empy zarr storage that will contain the parsed files
    - If the files are parsed from a newly generated experiment:
        -- The files in the folder will be sorted and organized
        -- A QC step will make sure that the number of metadata files will
           match the raw .nd2 files

    - After parsing the zarr metadata are consolidated in one single large
      JSON file (.zmetadata) that will allow faster read of the metadata
      collected from the raw images.

    Args:
        experiment_fpath (str): Path of the experiment to process
        parsing_type (str): Can be:
        - original: if the experiment to process has been newly generated by the robofish system
        - reparsing_from_processing_folder: if the raw data to parse have been parsed and renamed
          before but are still contained in the subfolder raw_data in the experiment folder
        - reparsing_from_storage: if the raw data to parse have been parsed and renamed
          before and are stored in a subfolder raw_data in the experiment folder that has been
          moved in a storage directory.
        parsed_image_tag (str): Tag to identify the zarr file with parsed images (default: img_data)
        storage_experiment_fpath (str): Path to folder in the storage HD where to store (or are stored) the raw data for
                                    the current experiment.
        client (distributed.Client): Dask client responsible for handling the processing of the graph.
    &#34;&#34;&#34;
    logger = selected_logger()
    experiment_fpath = Path(experiment_fpath)
    storage_experiment_fpath = Path(storage_experiment_fpath)
    
    experiment_info = configuration_files.load_experiment_config_file(experiment_fpath)
    configuration_files.create_specific_analysis_config_file(experiment_fpath, experiment_info)
    # Create empty zarr file for the parse data
    parsed_raw_data_fpath = io.create_empty_zarr_file(experiment_fpath=experiment_fpath,
                                        tag=parsed_image_tag)
    if parsing_type == &#39;original&#39;:
        utils.collect_processing_files(experiment_fpath, experiment_info)
        utils.sort_data_into_folders(experiment_fpath, experiment_info)
        all_raw_nd2 = nd2_raw_files_selector(experiment_fpath)
        qc_utils.QC_matching_nd2_metadata_robofish(all_raw_nd2)
        parsing_futures = client.map(nikon_nd2_autoparser_zarr,
                                all_raw_nd2,
                                parsed_raw_data_fpath=parsed_raw_data_fpath,
                                experiment_info=experiment_info)

        # wait(parsing_futures)
        _ = client.gather(parsing_futures)
        list_pkl = experiment_fpath.glob(&#39;*.pkl&#39;)
        for pkl_fpath in list_pkl:
            new_file_path = experiment_fpath / &#39;raw_data&#39; / pkl_fpath.name
            pkl_fpath.rename(new_file_path)
            
    else:
        # add error if not correct parsing type
        if parsing_type == &#39;reparsing_from_processing_folder&#39;:
            raw_files_fpath = experiment_fpath / &#39;raw_data&#39;
            logger.info(f&#39;raw_files_fpath {raw_files_fpath}&#39;)
        elif parsing_type == &#39;reparsing_from_storage&#39;:
            raw_files_fpath = storage_experiment_fpath / &#39;raw_data&#39;
        
        all_raw_nd2 = nd2_raw_files_selector_general(folder_fpath=raw_files_fpath)
        parsing_futures = client.map(nikon_nd2_reparser_zarr,
                                all_raw_nd2,
                                parsed_raw_data_fpath=parsed_raw_data_fpath,
                                experiment_info=experiment_info)

        _ = client.gather(parsing_futures)
    consolidated_grp = io.consolidate_zarr_metadata(parsed_raw_data_fpath)


# TODO Remove xarray conversion functions
# ----------------------------------------------------------------------------------


# def nikon_nd2_autoparser_xarray_zarr(nd2_file_path, parsed_raw_data_fpath, experiment_info):

#     &#34;&#34;&#34;
#     Function to parse nikon .nd2 files generated by robofish.
#     This parser not consider the possibility to have multiple experiment running at
#     the same time with the raw imaging data present in the same folder. 
#     Once the data are parsed by hybridization are saved in
#     the same folder.

#     NB: The file and the corresponding metadata file generated by the microscope
#         must contain &#39;CountXXXXX&#39; in order to be processed

#     The parsed_tmp and raw_data directories are created in a previous step of the 
#     pipeline during data sorting

#     QC step run before parsing take care of checking if the nd2 files are present
#     and in the corresponding pickle configuration files are in the folder

#     This nd2 parser process one .nd2 file

#     Args:
#         nd2_file_path: str
#             Path to the .nd2 file to be parsed
#         parsed_raw_data_fpath: str
#             Path to the zarr file that will store the parsed data
#         experiment_info: dict
#             Dictionary with overall experiment info

#     Returns:
#         processing_info: list of tuples
#         each tuple contain the path of the zarr storage and the number of fov
#     &#34;&#34;&#34;

#     logger = selected_logger()

#     parsed_raw_data_fpath = Path(parsed_raw_data_fpath)
#     nd2_file_path = Path(nd2_file_path)
#     nd2_fname = nd2_file_path.stem

#     logger.debug(f&#39;processing file {nd2_fname}&#39;)

#     experiment_fpath = nd2_file_path.parent
#     experiment_name = nd2_file_path.parent.stem
#     experiment_name = experiment_name.split(&#39;_auto&#39;)[0]
    
#     raw_files_dir = experiment_fpath / &#39;raw_data&#39;
    
#     # Extract the Count code from the file name
#     count_code = re.search(r&#39;(Count)\d{5}&#39;, nd2_file_path.stem).group()
    
#     all_info_files = experiment_fpath.glob(&#39;*.pkl&#39;)
    
#     info_file = [info_file for info_file in all_info_files if count_code  in info_file.stem][0]
    
#     info_data = pickle.load(open(info_file, &#39;rb&#39;))
#     logger.debug(f&#39;loaded info data file {info_file.stem}&#39;)
    
#     hybridization_name = info_data[&#39;channels&#39;][&#39;Hybridization&#39;]
#     logger.debug(f&#39;processing hybridization {hybridization_name}&#39;)
    
#     try:
#         nd2fh = nd2reader.ND2Reader(nd2_file_path)
#     except:
#         logger.error(&#39;Cannot load the nd2 file&#39;)
#         err = signals.FAIL(&#39;Cannot load the nd2 file&#39;)
#         raise err
#     else:
#         # Collect metadata
#         all_metadata = nd2fh.parser._raw_metadata
#         parsed_metadata = nd2fh.parser._raw_metadata.get_parsed_metadata()
        
#         channel = parsed_metadata[&#39;channels&#39;][0] # works because there is only one channel for file
#         logger.debug(f&#39;processing channel {channel}&#39;)

#         img_shape = np.array([parsed_metadata[&#39;height&#39;],parsed_metadata[&#39;width&#39;]])
#         pixel_microns = parsed_metadata[&#39;pixel_microns&#39;]
#         z_levels = parsed_metadata[&#39;z_levels&#39;]
#         fields_of_view = parsed_metadata[&#39;fields_of_view&#39;]
        
#         # Collect FOV coords
#         x_data = np.array(all_metadata.x_data)
#         x_data = x_data[:,np.newaxis]
#         y_data = np.array(all_metadata.y_data)
#         y_data = y_data[:,np.newaxis]
#         z_data = np.array(all_metadata.z_data)
#         z_data = z_data[:,np.newaxis]
#         all_coords = np.hstack((z_data,x_data,y_data))
#         fov_coords = all_coords[0::len(z_levels),:]
        
#         tag_name = experiment_name + &#39;_&#39; + hybridization_name + &#39;_&#39; + channel
        
    

#         # Save the fov_coords
#         fname = experiment_fpath / &#39;microscope_tiles_coords&#39; / (tag_name + &#39;_fovs_coords.npy&#39;)
#         np.save(fname, fov_coords)

#         nd2fh.bundle_axes = &#39;zyx&#39;
#         # set iteration over the fields of view
#         nd2fh.iter_axes = &#39;v&#39;
        
#         round_num = int(nd2_file_path.stem.split(&#39;_&#39;)[-2].split(&#39;Hybridization&#39;)[-1])
#         z = np.arange(nd2fh.sizes[&#39;z&#39;])
#         r = np.arange(nd2fh.sizes[&#39;y&#39;])
#         c = np.arange(nd2fh.sizes[&#39;x&#39;])
#         channel_arr = np.array([channel])
#         round_num = np.array([round_num])
#         experiment_name_arr = np.array([experiment_name])
#         chunks_dict = {&#39;experiment_name&#39;:1,&#39;channel&#39;:1,&#39;fov&#39;:1,&#39;round_num&#39;:1,
#                        &#39;zstack&#39;:nd2fh.sizes[&#39;z&#39;],&#39;rows&#39;:nd2fh.sizes[&#39;y&#39;],&#39;columns&#39;:nd2fh.sizes[&#39;x&#39;]}
#         chunks_tuple = (1,1,1,1,nd2fh.sizes[&#39;z&#39;],nd2fh.sizes[&#39;y&#39;],nd2fh.sizes[&#39;x&#39;])
        
#         hybridization_num = int(hybridization_name.split(&#39;Hybridization&#39;)[-1])
#         for fov in fields_of_view:
    
#             array_name = tag_name + &#39;_fov_&#39; + str(fov)
#             attrs = {}
#             attrs[&#39;grp_name&#39;] = array_name
#             attrs[&#39;fov_name&#39;] = &#39;fov_&#39; + str(fov) 
#             attrs[&#39;channel&#39;] = channel
#             attrs[&#39;target_name&#39;] = info_data[&#39;channels&#39;][channel]
#             attrs[&#39;img_width&#39;] = parsed_metadata[&#39;width&#39;]
#             attrs[&#39;img_height&#39;] = parsed_metadata[&#39;height&#39;]
#             attrs[&#39;pixel_microns&#39;] = pixel_microns
#             attrs[&#39;z_levels&#39;] = list(z_levels)
#             attrs[&#39;fields_of_view&#39;] = list(fields_of_view)
#             attrs[&#39;fov_num&#39;] = fov
#             attrs[&#39;stitching_channel&#39;] = experiment_info[&#39;StitchingChannel&#39;]
#             attrs[&#39;stitching_type&#39;] = experiment_info[&#39;Stitching_type&#39;]
#             attrs[&#39;experiment_type&#39;] = experiment_info[&#39;Experiment_type&#39;]
#             attrs[&#39;hybridization_num&#39;] = hybridization_num
#             attrs[&#39;experiment_name&#39;] = experiment_name
#             attrs[&#39;fov_acquisition_coords_x&#39;] = fov_coords[fov,1]
#             attrs[&#39;fov_acquisition_coords_y&#39;] = fov_coords[fov,2]
#             attrs[&#39;fov_acquisition_coords_z&#39;] = fov_coords[fov,0]


#             if info_data[&#39;StitchingChannel&#39;] == channel:
#                 attrs[&#39;processing_type&#39;] = attrs[&#39;stitching_type&#39;]
#             elif &#39;_ST&#39; in attrs[&#39;target_name&#39;]:
#                 attrs[&#39;processing_type&#39;] = &#39;staining&#39;
#             else:
#                 attrs[&#39;processing_type&#39;] = &#39;fish&#39;


#             fov_arr = np.array([fov])
#             arr = np.array(nd2fh[fov],dtype=np.uint16)
#             arr = arr[np.newaxis,np.newaxis,np.newaxis,np.newaxis, :,:,:]
#             # arr = da.from_array(arr, chunks=(None,None,None,None,None,None,None))
#             data_xr =  xr.DataArray(arr,
#                                    coords = {
#                                        &#39;experiment_name&#39;:experiment_name_arr,
#                                        &#39;channel&#39;:channel_arr, 
#                                        &#39;fov&#39;: fov_arr, 
#                                        &#39;round_num&#39;:round_num,
#                                        &#39;zstack&#39;:z,
#                                        &#39;rows&#39;:r,
#                                        &#39;columns&#39;:c},
#                                     dims=[&#39;experiment_name&#39;,&#39;channel&#39;,&#39;fov&#39;,&#39;round_num&#39;,
#                                           &#39;zstack&#39;,&#39;rows&#39;,&#39;columns&#39;],
#                                     attrs= attrs
#                                   )
#             # data_xr = data_xr.chunk(chunks_dict)
#             data_dset_name = tag_name + &#39;_fov_&#39; + str(fov)
#             data_dset_path = (parsed_raw_data_fpath / (data_dset_name + &#39;.zarr&#39;)).as_posix()
# #             data_dset = xr.Dataset({data_dset_name: data_xr})
#             data_dset = xr.Dataset({&#39;raw_data&#39;: data_xr},attrs=attrs)
#             data_dset.to_zarr(store=data_dset_path,mode=&#39;w&#39;)
#             # data_dset.to_netcdf(data_dset_path,mode=&#39;w&#39;)

#         # Rename the nd2 files
#         new_file_name = tag_name + &#39;.nd2&#39;
#         logger.debug(f&#39;.nd2 file renamed {new_file_name}&#39;)
#         new_file_path = raw_files_dir / new_file_name
#         nd2_file_path.rename(new_file_path)
#         nd2_file_path = new_file_path
        
#         # Copy the pkl files
#         new_file_name = tag_name + &#39;_info.pkl&#39;
#         logger.debug(f&#39;info data file renamed {new_file_name}&#39;)
#         new_file_path = raw_files_dir / new_file_name
#         # Must copy the pkl file in order to be able to use the file for the other channels
#         shutil.copy(str(info_file), str(new_file_path))
    

# def nikon_nd2_reparser_xarray_zarr(nd2_file_path,parsed_raw_data_fpath,experiment_info):
#     &#34;&#34;&#34;
#     This function is used to reparse the raw data stored in the raw_data folder during
#     the processing. 

#     NB: The file and the corresponding metadata file generated by the microscope
#         have the same starting name:
#         LBEXP20201014_EEL_Mouse_2420um_Hybridization01_Cy5.nd2
#         LBEXP20201014_EEL_Mouse_2420um_Hybridization01_Cy5_info.pkl

#     The parsed_tmp directory is created in a previous step of the 
#     pipeline during data sorting


#     This nd2 parser process one .nd2 file

#     Args:
#         nd2_file_path: str
#             Path to the .nd2 file to be parsed
#         parsed_raw_data_fpath: str
#             Path to the zarr file that will store the parsed data
#         experiment_info: dict
#             Dictionary with overall experiment info

#     Returns:
#         processing_info: list of tuples
#         each tuple contain the path of the zarr storage and the number of fov
#     &#34;&#34;&#34;

#     logger = selected_logger()
#     nd2_file_path = Path(nd2_file_path)
#     nd2_fname = nd2_file_path.stem

#     parsed_raw_data_fpath = Path(parsed_raw_data_fpath)

#     logger.debug(f&#39;processing file {nd2_fname}&#39;)

#     experiment_fpath = nd2_file_path.parent.parent
#     experiment_name = nd2_file_path.parent.parent.stem
#     # experiment_name = experiment_name.split(&#39;_auto&#39;)[0]
    
#     info_file = nd2_file_path.parent / (nd2_fname + &#39;_info.pkl&#39;)
#     info_data = pickle.load(open(info_file, &#39;rb&#39;))
#     hybridization_name = info_data[&#39;channels&#39;][&#39;Hybridization&#39;]
    
#     try:
#         nd2fh = nd2reader.ND2Reader(nd2_file_path)
#     except:
#         logger.error(&#39;Cannot load the {nd2_fname} nd2 file&#39;)
#         sys.exit(&#39;Cannot load the {nd2_fname} nd2 file&#39;)
#     else:
#         # Collect metadata
#         all_metadata = nd2fh.parser._raw_metadata
#         parsed_metadata = nd2fh.parser._raw_metadata.get_parsed_metadata()
        
#         channel = parsed_metadata[&#39;channels&#39;][0] # works because there is only one channel for file
#         img_shape = np.array([parsed_metadata[&#39;height&#39;],parsed_metadata[&#39;width&#39;]])
#         pixel_microns = parsed_metadata[&#39;pixel_microns&#39;]
#         z_levels = parsed_metadata[&#39;z_levels&#39;]
#         fields_of_view = parsed_metadata[&#39;fields_of_view&#39;]
        
#         # Collect FOV coords
#         x_data = np.array(all_metadata.x_data)
#         x_data = x_data[:,np.newaxis]
#         y_data = np.array(all_metadata.y_data)
#         y_data = y_data[:,np.newaxis]
#         z_data = np.array(all_metadata.z_data)
#         z_data = z_data[:,np.newaxis]
#         all_coords = np.hstack((z_data,x_data,y_data))
#         fov_coords = all_coords[0::len(z_levels),:]
        
#         tag_name = experiment_name + &#39;_&#39; + hybridization_name + &#39;_&#39; + channel
    
#         # Save the fov_coords
#         new_exp_location = parsed_raw_data_fpath.parent
#         fname = new_exp_location /  &#39;microscope_tiles_coords&#39; / (tag_name + &#39;_fovs_coords.npy&#39;)
#         np.save(fname, fov_coords)


#         # Save the file as zarr
#         # store = zarr.DirectoryStore(parsed_raw_data_fpath)
#         # root = zarr.group(store=store,overwrite=False)

        
#         nd2fh.bundle_axes = &#39;zyx&#39;
#         # set iteration over the fields of view
#         nd2fh.iter_axes = &#39;v&#39;
        
#         round_num = int(nd2_file_path.stem.split(&#39;_&#39;)[-2].split(&#39;Hybridization&#39;)[-1])
#         z = np.arange(nd2fh.sizes[&#39;z&#39;])
#         r = np.arange(nd2fh.sizes[&#39;y&#39;])
#         c = np.arange(nd2fh.sizes[&#39;x&#39;])
#         channel_arr = np.array([channel])
#         round_num = np.array([round_num])
#         experiment_name_arr = np.array([experiment_name])
#         chunks_dict = {&#39;experiment_name&#39;:1,&#39;channel&#39;:1,&#39;fov&#39;:1,&#39;round_num&#39;:1,
#                        &#39;zstack&#39;:nd2fh.sizes[&#39;z&#39;],&#39;rows&#39;:nd2fh.sizes[&#39;y&#39;],&#39;columns&#39;:nd2fh.sizes[&#39;x&#39;]}
#         chunks_tuple = (1,1,1,1,nd2fh.sizes[&#39;z&#39;],nd2fh.sizes[&#39;y&#39;],nd2fh.sizes[&#39;x&#39;])
        
#         hybridization_num = int(hybridization_name.split(&#39;Hybridization&#39;)[-1])
#         for fov in fields_of_view:
    
#             array_name = tag_name + &#39;_fov_&#39; + str(fov)
#             attrs = {}
#             attrs[&#39;grp_name&#39;] = array_name
#             attrs[&#39;fov_name&#39;] = &#39;fov_&#39; + str(fov) 
#             attrs[&#39;channel&#39;] = channel
#             attrs[&#39;target_name&#39;] = info_data[&#39;channels&#39;][channel]
#             attrs[&#39;img_width&#39;] = parsed_metadata[&#39;width&#39;]
#             attrs[&#39;img_height&#39;] = parsed_metadata[&#39;height&#39;]
#             attrs[&#39;pixel_microns&#39;] = pixel_microns
#             attrs[&#39;z_levels&#39;] = list(z_levels)
#             attrs[&#39;fields_of_view&#39;] = list(fields_of_view)
#             attrs[&#39;fov_num&#39;] = fov
#             attrs[&#39;stitching_channel&#39;] = experiment_info[&#39;StitchingChannel&#39;]
#             attrs[&#39;stitching_type&#39;] = experiment_info[&#39;Stitching_type&#39;]
#             attrs[&#39;experiment_type&#39;] = experiment_info[&#39;Experiment_type&#39;]
#             attrs[&#39;hybridization_num&#39;] = hybridization_num
#             attrs[&#39;experiment_name&#39;] = experiment_name
#             attrs[&#39;fov_acquisition_coords_x&#39;] = fov_coords[fov,1]
#             attrs[&#39;fov_acquisition_coords_y&#39;] = fov_coords[fov,2]
#             attrs[&#39;fov_acquisition_coords_z&#39;] = fov_coords[fov,0]

#             if info_data[&#39;StitchingChannel&#39;] == channel:
#                 attrs[&#39;processing_type&#39;] = attrs[&#39;stitching_type&#39;]
#             elif &#39;_ST&#39; in attrs[&#39;target_name&#39;]:
#                 attrs[&#39;processing_type&#39;] = &#39;staining&#39;
#             else:
#                 attrs[&#39;processing_type&#39;] = &#39;fish&#39;


#             fov_arr = np.array([fov])
#             arr = np.array(nd2fh[fov],dtype=np.uint16)
#             arr = arr[np.newaxis,np.newaxis,np.newaxis,np.newaxis, :,:,:]
#             # arr = da.from_array(arr, chunks=(None,None,None,None,None,None,None))
#             data_xr =  xr.DataArray(arr,
#                                    coords = {
#                                        &#39;experiment_name&#39;:experiment_name_arr,
#                                        &#39;channel&#39;:channel_arr, 
#                                        &#39;fov&#39;: fov_arr, 
#                                        &#39;round_num&#39;:round_num,
#                                        &#39;zstack&#39;:z,
#                                        &#39;rows&#39;:r,
#                                        &#39;columns&#39;:c},
#                                     dims=[&#39;experiment_name&#39;,&#39;channel&#39;,&#39;fov&#39;,&#39;round_num&#39;,
#                                           &#39;zstack&#39;,&#39;rows&#39;,&#39;columns&#39;],
#                                     attrs= attrs
#                                   )
#             # data_xr = data_xr.chunk(chunks_dict)
#             data_dset_name = tag_name + &#39;_fov_&#39; + str(fov)
#             data_dset_path = (parsed_raw_data_fpath / (data_dset_name + &#39;.zarr&#39;)).as_posix()
# #             data_dset = xr.Dataset({data_dset_name: data_xr})
#             data_dset = xr.Dataset({&#39;raw_data&#39;: data_xr},attrs=attrs)
#             data_dset.to_zarr(store=data_dset_path,mode=&#39;w&#39;)
#             # data_dset.to_netcdf(data_dset_path,mode=&#39;w&#39;)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pysmFISH.microscopy_file_parsers.create_dark_img"><code class="name flex">
<span>def <span class="ident">create_dark_img</span></span>(<span>experiment_fpath:str, metadata:pandas.core.frame.DataFrame)</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to generate the image containing the camera noise.png</p>
<p>The image is acquired as .nd2 file labeled Blank*.nd2 and is stored
in the extra_files subfolder. The file contain a stack of images
acquired with no illumination in order to evaluate the camera noise.</p>
<p>If the files is present in the extra_files folder than the median is calculated
and saved as experiment_name + machine_name +'_dark_img.npy' in the
extra_processing_files subfolder.</p>
<p>If the file is not present than the machine +'_dark_img.npy' present in the
config_db folder is copied in the extra_processing_files subfolder.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>path to the experiment to process</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>dictionary with the metadata of the experiment</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_dark_img(experiment_fpath:str, metadata: pd.DataFrame):
    &#34;&#34;&#34;Function used to generate the image containing the camera noise.png

    The image is acquired as .nd2 file labeled Blank*.nd2 and is stored
    in the extra_files subfolder. The file contain a stack of images
    acquired with no illumination in order to evaluate the camera noise.
    
    If the files is present in the extra_files folder than the median is calculated 
    and saved as experiment_name + machine_name +&#39;_dark_img.npy&#39; in the
    extra_processing_files subfolder.

    If the file is not present than the machine +&#39;_dark_img.npy&#39; present in the
    config_db folder is copied in the extra_processing_files subfolder.

    Args:
        experiment_fpath (str): path to the experiment to process
        metadata (pd.DataFrame): dictionary with the metadata of the experiment
    &#34;&#34;&#34;
    logger = selected_logger()
    experiment_fpath = Path(experiment_fpath)
    experiment_name = metadata[&#39;experiment_name&#39;]
    machine = metadata[&#39;machine&#39;]
    # Check if the dark image is already present
    nd2_blank = None
    
    # Look in the extra files
    nd2_list = list((experiment_fpath / &#39;extra_files&#39;).glob(&#39;*.nd2&#39;))
    nd2_blank = [el for el in nd2_list if &#39;Blank&#39; in el.stem]
    
    if nd2_blank:
        nd2fh = nd2reader.ND2Reader(nd2_blank[0])
        nd2fh.bundle_axes = &#39;zyx&#39;
        nd2fh.iter_axes = &#39;z&#39;
        # Image with single channel
        channel = nd2fh.metadata[&#39;channels&#39;][0]
        # I can collect just one z because error of the reader
        # that created both z and t planes
        dark_img = np.median(nd2fh[0],axis=0)
        dark_img = dark_img.astype(np.uint16)
        fname = experiment_fpath / &#39;extra_processing_data&#39; / (experiment_name + &#39;_&#39; + machine + &#39;_dark_img.npy&#39;)
        np.save(fname, dark_img)
        logger.debug(f&#39;Created dark image from .nd2 file&#39;)
    else:
        logger.debug(f&#39;the Blank .nd2 for the dark image is missing in experiment folder&#39;)
        try:
            pres = list((experiment_fpath / &#39;extra_processing_data&#39;).glob(&#39;*_dark_img.npy&#39;))[0]
        except IndexError:
            try:
                pres = list((experiment_fpath.parent / &#39;config_db&#39;).glob(machine+&#39;_dark_img.npy&#39;))[0]
                new_location = experiment_fpath / &#39;extra_processing_data&#39; / pres.name
                shutil.copy2(pres,new_location)
            except IndexError:
                logger.error(f&#39;Missing .npy dask image&#39;)
            else:
                logger.error(f&#39;the Blank .nd2 for the dark image is missing in experiment folder&#39;)
        else:
            logger.debug(f&#39;the dark image is already present in the config_db&#39;)</code></pre>
</details>
</dd>
<dt id="pysmFISH.microscopy_file_parsers.create_dark_img_from_standalone"><code class="name flex">
<span>def <span class="ident">create_dark_img_from_standalone</span></span>(<span>image_fpath:str, machine:str)</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to generate the image containing the camera noise.png</p>
<p>The image is acquired as .nd2 file and is acquired separately as
standalone file.The file contain a stack of images
acquired with no illumination in order to evaluate the camera noise.</p>
<p>The median is calculated and saved as machine_name +'_dark_img.npy' in the
same folder of the original image.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>image_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>path to nd2 file to process</dd>
<dt><strong><code>machine</code></strong> :&ensp;<code>str</code></dt>
<dd>machine used to acquire the blank image</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_dark_img_from_standalone(image_fpath:str, machine: str):
    &#34;&#34;&#34;Function used to generate the image containing the camera noise.png

    The image is acquired as .nd2 file and is acquired separately as
    standalone file.The file contain a stack of images
    acquired with no illumination in order to evaluate the camera noise.
    
    The median is calculated and saved as machine_name +&#39;_dark_img.npy&#39; in the
    same folder of the original image.

    Args:
        image_fpath (str): path to nd2 file to process
        machine (str): machine used to acquire the blank image
    &#34;&#34;&#34;
    logger = selected_logger()
    image_fpath = Path(image_fpath)
    
    nd2fh = nd2reader.ND2Reader(image_fpath)
    nd2fh.bundle_axes = &#39;zyx&#39;
    nd2fh.iter_axes = &#39;z&#39;
    # Image with single channel
    channel = nd2fh.metadata[&#39;channels&#39;][0]
    # I can collect just one z because error of the reader
    # that created both z and t planes
    dark_img = np.median(nd2fh[0],axis=0)
    dark_img = dark_img.astype(np.uint16)
    fname = image_fpath.parent / (machine + &#39;_dark_img.npy&#39;)
    np.save(fname, dark_img)
    logger.debug(f&#39;Created dark image from .nd2 file&#39;)</code></pre>
</details>
</dd>
<dt id="pysmFISH.microscopy_file_parsers.nd2_raw_files_selector"><code class="name flex">
<span>def <span class="ident">nd2_raw_files_selector</span></span>(<span>experiment_fpath:str) >list</span>
</code></dt>
<dd>
<div class="desc"><p>Identify the nd2 raw microscopy files generated by
the robofish machine. The files must contain CountXXXXX in the name. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the folder to process.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>all_files_to_process (list):
List of PosixPath of the microscopy files to process</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nd2_raw_files_selector(experiment_fpath: str) -&gt; list:
    &#34;&#34;&#34;
    Identify the nd2 raw microscopy files generated by
    the robofish machine. The files must contain CountXXXXX in the name. 

    Args:
        experiment_fpath (str): Path to the folder to process.

    Returns:
        all_files_to_process (list):
            List of PosixPath of the microscopy files to process
        
    &#34;&#34;&#34;
    logger = selected_logger()

    experiment_fpath = Path(experiment_fpath)
    # assert &#39;_auto&#39; in experiment_fpath.stem, sys.exit(&#39;no _auto in the experiment name&#39;)

    searching_key = &#39;*Count*.nd2&#39;
    all_files_to_process = list(experiment_fpath.glob(searching_key))

    assert all_files_to_process, sys.exit(&#39;no .nd2 raw files to process&#39;)
    
    logger.debug(f&#39;Number of files to process {len(all_files_to_process)}.&#39;)
    return all_files_to_process</code></pre>
</details>
</dd>
<dt id="pysmFISH.microscopy_file_parsers.nd2_raw_files_selector_general"><code class="name flex">
<span>def <span class="ident">nd2_raw_files_selector_general</span></span>(<span>folder_fpath:str) >list</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to identify the .nd2 files in a folder. The files
do not need to have the CountXXX or the _auto suffix. This
class can be used to identify the .nd2 files that need to be
reparsed.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>folder_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the folder to process. </dd>
</dl>
<h2 id="returns">Returns</h2>
<p>all_files_to_process (list):
List of PosixPath of the microscopy files to process</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nd2_raw_files_selector_general(folder_fpath: str) -&gt; list:

    &#34;&#34;&#34;
    Function used to identify the .nd2 files in a folder. The files
    do not need to have the CountXXX or the _auto suffix. This
    class can be used to identify the .nd2 files that need to be
    reparsed.

    Args:
        folder_fpath (str): 
            Path to the folder to process. 
    Returns:
        all_files_to_process (list):
            List of PosixPath of the microscopy files to process
        
    &#34;&#34;&#34;
    logger = selected_logger()
    folder_fpath = Path(folder_fpath)
    
    searching_key = &#39;*.nd2&#39;
    all_files_to_process = list(folder_fpath.glob(searching_key))

    assert all_files_to_process, sys.exit(&#39;no .nd2 raw files to process&#39;)
    
    logger.debug(f&#39;Number of files to process {len(all_files_to_process)}.&#39;)
    return all_files_to_process</code></pre>
</details>
</dd>
<dt id="pysmFISH.microscopy_file_parsers.nikon_nd2_autoparser_zarr"><code class="name flex">
<span>def <span class="ident">nikon_nd2_autoparser_zarr</span></span>(<span>nd2_file_path:str, parsed_raw_data_fpath:str, experiment_info:dict)</span>
</code></dt>
<dd>
<div class="desc"><p>Function to parse nikon .nd2 files generated by robofish.
This parser not consider the possibility to have multiple experiment running at
the same time with the raw imaging data present in the same folder.
Once the data are parsed by hybridization are saved in
the same folder.</p>
<p>NB: The file and the corresponding metadata file generated by the microscope
must contain 'CountXXXXX' in order to be processed</p>
<p>The parsed_tmp and raw_data directories are created in a previous step of the
pipeline during data sorting</p>
<p>QC step run before parsing take care of checking if the nd2 files are present
and in the corresponding pickle configuration files are in the folder</p>
<p>This nd2 parser process one .nd2 file</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>nd2_file_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the .nd2 file to be parsed</dd>
<dt><strong><code>parsed_raw_data_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the zarr file that will store the parsed data</dd>
<dt><strong><code>experiment_info</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary with overall experiment info</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nikon_nd2_autoparser_zarr(nd2_file_path: str, parsed_raw_data_fpath: str, experiment_info: dict):

    &#34;&#34;&#34;
    Function to parse nikon .nd2 files generated by robofish.
    This parser not consider the possibility to have multiple experiment running at
    the same time with the raw imaging data present in the same folder. 
    Once the data are parsed by hybridization are saved in
    the same folder.

    NB: The file and the corresponding metadata file generated by the microscope
        must contain &#39;CountXXXXX&#39; in order to be processed

    The parsed_tmp and raw_data directories are created in a previous step of the 
    pipeline during data sorting

    QC step run before parsing take care of checking if the nd2 files are present
    and in the corresponding pickle configuration files are in the folder

    This nd2 parser process one .nd2 file

    Args:
        nd2_file_path (str): Path to the .nd2 file to be parsed
        parsed_raw_data_fpath (str): Path to the zarr file that will store the parsed data
        experiment_info (dict): Dictionary with overall experiment info
    &#34;&#34;&#34;

    logger = selected_logger()
    parsed_raw_data_fpath = Path(parsed_raw_data_fpath)
    nd2_file_path = Path(nd2_file_path)
    nd2_fname = nd2_file_path.stem

    logger.debug(f&#39;processing file {nd2_fname}&#39;)

    experiment_fpath = nd2_file_path.parent
    experiment_name = nd2_file_path.parent.stem
    experiment_name = experiment_name.split(&#39;_auto&#39;)[0]
    
    raw_files_dir = experiment_fpath / &#39;raw_data&#39;
    
    # Extract the Count code from the file name
    count_code = re.search(r&#39;(Count)\d{5}&#39;, nd2_file_path.stem).group()
    
    all_info_files = experiment_fpath.glob(&#39;*.pkl&#39;)
    
    info_file = [info_file for info_file in all_info_files if count_code  in info_file.stem][0]
    
    info_data = pickle.load(open(info_file, &#39;rb&#39;))
    logger.debug(f&#39;loaded info data file {info_file.stem}&#39;)
    
    hybridization_name = info_data[&#39;channels&#39;][&#39;Hybridization&#39;]
    logger.debug(f&#39;processing hybridization {hybridization_name}&#39;)
    
    try:
        nd2fh = nd2reader.ND2Reader(nd2_file_path.as_posix())
    except:
        logger.error(f&#39;Cannot load the nd2 file {nd2_file_path}&#39;)
        sys.exit(f&#39;Cannot load the nd2 file {nd2_file_path}&#39;)
    else:
        # Collect metadata
        all_metadata = nd2fh.parser._raw_metadata
        parsed_metadata = nd2fh.parser._raw_metadata.get_parsed_metadata()
        
        channel = parsed_metadata[&#39;channels&#39;][0] # works because there is only one channel for file
        logger.debug(f&#39;processing channel {channel}&#39;)

        img_shape = np.array([parsed_metadata[&#39;height&#39;],parsed_metadata[&#39;width&#39;]])
        pixel_microns = parsed_metadata[&#39;pixel_microns&#39;]
        z_levels = parsed_metadata[&#39;z_levels&#39;]
        fields_of_view = parsed_metadata[&#39;fields_of_view&#39;]
        
        # Collect FOV coords
        x_data = np.array(all_metadata.x_data)
        x_data = x_data[:,np.newaxis]
        y_data = np.array(all_metadata.y_data)
        y_data = y_data[:,np.newaxis]
        z_data = np.array(all_metadata.z_data)
        z_data = z_data[:,np.newaxis]
        all_coords = np.hstack((z_data,x_data,y_data))
        fov_coords = all_coords[0::len(z_levels),:]
        
        tag_name = experiment_name + &#39;_&#39; + hybridization_name + &#39;_&#39; + channel
        
        
        # Save the file as zarr
        store = zarr.DirectoryStore(parsed_raw_data_fpath)
        root = zarr.group(store=store,overwrite=False)


        # Save the fov_coords
        fname = experiment_fpath / &#39;microscope_tiles_coords&#39; / (tag_name + &#39;_fovs_coords.npy&#39;)
        np.save(fname, fov_coords)

        nd2fh.bundle_axes = &#39;zyx&#39;
        # set iteration over the fields of view
        nd2fh.iter_axes = &#39;v&#39;
        
        # Save coords of the FOV
        rows = np.arange(parsed_metadata[&#39;width&#39;])
        cols = np.arange(parsed_metadata[&#39;height&#39;])
        hybridization_num = int(hybridization_name.split(&#39;Hybridization&#39;)[-1])
        for fov in fields_of_view:
            img = np.array(nd2fh[fov],dtype=np.uint16)      
            array_name = tag_name + &#39;_fov_&#39; + str(fov)
            dgrp = root.create_group(array_name)
            fov_name = &#39;raw_data_fov_&#39; + str(fov)
            # Remember that attrs must be JSON-serializable to be stored
            # in zarr
            dgrp.attrs[&#39;grp_name&#39;] = array_name
            dgrp.attrs[&#39;fov_name&#39;] = fov_name
            dgrp.attrs[&#39;channel&#39;] = channel
            dgrp.attrs[&#39;target_name&#39;] = info_data[&#39;channels&#39;][channel]
            dgrp.attrs[&#39;img_width&#39;] = parsed_metadata[&#39;width&#39;]
            dgrp.attrs[&#39;img_height&#39;] = parsed_metadata[&#39;height&#39;]
            dgrp.attrs[&#39;pixel_microns&#39;] = pixel_microns
            dgrp.attrs[&#39;zstack&#39;] = len(list(z_levels))
            dgrp.attrs[&#39;total_fovs&#39;] = len(list(fields_of_view))
            dgrp.attrs[&#39;fov_num&#39;] = fov
            dgrp.attrs[&#39;stitching_channel&#39;] = experiment_info[&#39;StitchingChannel&#39;]
            dgrp.attrs[&#39;stitching_type&#39;] = experiment_info[&#39;Stitching_type&#39;]
            dgrp.attrs[&#39;experiment_type&#39;] = experiment_info[&#39;Experiment_type&#39;]     
            dgrp.attrs[&#39;barcode_length&#39;] = experiment_info[&#39;Barcode_length&#39;]
            dgrp.attrs[&#39;barcode&#39;] = experiment_info[&#39;Barcode&#39;]
            
            codebook_channel = &#39;Codebook_&#39; + channel
            codebook_name = experiment_info[&#39;Codebooks&#39;][codebook_channel]
            dgrp.attrs[&#39;codebook&#39;] = codebook_name
            
            probes_channel = &#39;Probes_FASTA_&#39; + channel
            probes_name = experiment_info[&#39;Probes_FASTA&#39;][probes_channel]
            dgrp.attrs[&#39;probe_fasta_name&#39;] = probes_name

            dgrp.attrs[&#39;machine&#39;] = experiment_info[&#39;Machine&#39;]
            dgrp.attrs[&#39;operator&#39;] = experiment_info[&#39;Operator&#39;]
            dgrp.attrs[&#39;overlapping_percentage&#39;] = experiment_info[&#39;Overlapping_percentage&#39;]
            dgrp.attrs[&#39;species&#39;] = experiment_info[&#39;Species&#39;]
            dgrp.attrs[&#39;start_date&#39;] = experiment_info[&#39;Start_date&#39;]
            dgrp.attrs[&#39;strain&#39;] = experiment_info[&#39;Strain&#39;]
            dgrp.attrs[&#39;tissue&#39;] = experiment_info[&#39;Tissue&#39;]
            dgrp.attrs[&#39;pipeline&#39;] = experiment_info[&#39;Pipeline&#39;]
            dgrp.attrs[&#39;round_num&#39;] = hybridization_num
            dgrp.attrs[&#39;experiment_name&#39;] = experiment_name
            dgrp.attrs[&#39;fov_acquisition_coords_x&#39;] = fov_coords[fov,1]
            dgrp.attrs[&#39;fov_acquisition_coords_y&#39;] = fov_coords[fov,2]
            dgrp.attrs[&#39;fov_acquisition_coords_z&#39;] = fov_coords[fov,0]


            if info_data[&#39;StitchingChannel&#39;] == channel:
                dgrp.attrs[&#39;processing_type&#39;] = dgrp.attrs[&#39;stitching_type&#39;]
            elif &#39;_ST&#39; in dgrp.attrs[&#39;target_name&#39;]:
                dgrp.attrs[&#39;processing_type&#39;] = &#39;staining&#39;
            else:
                dgrp.attrs[&#39;processing_type&#39;] = &#39;fish&#39;

            dset = dgrp.create_dataset(fov_name, data=img, shape=img.shape, chunks=(1,None,None),overwrite=True)

        # Rename the nd2 files
        new_file_name = tag_name + &#39;.nd2&#39;
        logger.debug(f&#39;.nd2 file renamed {new_file_name}&#39;)
        new_file_path = raw_files_dir / new_file_name
        nd2_file_path.rename(new_file_path)
        nd2_file_path = new_file_path
        
        # Copy the pkl files
        new_file_name = tag_name + &#39;_info.pkl&#39;
        logger.debug(f&#39;info data file renamed {new_file_name}&#39;)
        new_file_path = raw_files_dir / new_file_name
        # Must copy the pkl file in order to be able to use the file for the other channels
        shutil.copy(str(info_file), str(new_file_path))</code></pre>
</details>
</dd>
<dt id="pysmFISH.microscopy_file_parsers.nikon_nd2_parser_simple_mfov"><code class="name flex">
<span>def <span class="ident">nikon_nd2_parser_simple_mfov</span></span>(<span>nd2_file_path:str)</span>
</code></dt>
<dd>
<div class="desc"><p>Function to parse a generic nikon .nd2 files generated by robofish.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>nd2_file_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the .nd2 file to be parsed</dd>
<dt><strong><code>parsed_raw_data_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the zarr file that will store the parsed data</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nikon_nd2_parser_simple_mfov(nd2_file_path: str):

    &#34;&#34;&#34;
    Function to parse a generic nikon .nd2 files generated by robofish.
    
    Args:
        nd2_file_path (str): Path to the .nd2 file to be parsed
        parsed_raw_data_fpath (str): Path to the zarr file that will store the parsed data
    &#34;&#34;&#34;

    logger = selected_logger()
    nd2_file_path = Path(nd2_file_path)
    nd2_fname = nd2_file_path.stem

    logger.debug(f&#39;processing file {nd2_fname}&#39;)

    experiment_fpath = nd2_file_path.parent
    experiment_name = nd2_file_path.stem
    experiment_name = experiment_name.split(&#39;_auto&#39;)[0]
    
    parsed_raw_data_fpath = experiment_fpath / (experiment_name + &#39;_img_data.zarr&#39;)

    try:
        nd2fh = nd2reader.ND2Reader(nd2_file_path)
    except:
        logger.error(f&#39;Cannot load the nd2 file {nd2_file_path}&#39;)
        sys.exit(f&#39;Cannot load the nd2 file {nd2_file_path}&#39;)
    else:
        # Collect metadata
        all_metadata = nd2fh.parser._raw_metadata
        parsed_metadata = nd2fh.parser._raw_metadata.get_parsed_metadata()
        
        channel = parsed_metadata[&#39;channels&#39;][0] # works because there is only one channel for file
        logger.debug(f&#39;processing channel {channel}&#39;)

        img_shape = np.array([parsed_metadata[&#39;height&#39;],parsed_metadata[&#39;width&#39;]])
        pixel_microns = parsed_metadata[&#39;pixel_microns&#39;]
        z_levels = parsed_metadata[&#39;z_levels&#39;]
        fields_of_view = parsed_metadata[&#39;fields_of_view&#39;]
        
        # Collect FOV coords
        x_data = np.array(all_metadata.x_data)
        x_data = x_data[:,np.newaxis]
        y_data = np.array(all_metadata.y_data)
        y_data = y_data[:,np.newaxis]
        z_data = np.array(all_metadata.z_data)
        z_data = z_data[:,np.newaxis]
        all_coords = np.hstack((z_data,x_data,y_data))
        fov_coords = all_coords[0::len(z_levels),:]
        
        tag_name = experiment_name
        
        
        # Save the file as zarr
        store = zarr.DirectoryStore(parsed_raw_data_fpath)
        root = zarr.group(store=store,overwrite=False)


        # Save the fov_coords
        fname = experiment_fpath / (tag_name + &#39;_fovs_coords.npy&#39;)
        np.save(fname, fov_coords)

        nd2fh.bundle_axes = &#39;zyx&#39;
        # set iteration over the fields of view
        nd2fh.iter_axes = &#39;v&#39;
        
        # Save coords of the FOV
        rows = np.arange(parsed_metadata[&#39;width&#39;])
        cols = np.arange(parsed_metadata[&#39;height&#39;])
        for fov in fields_of_view:
            img = np.array(nd2fh[fov],dtype=np.uint16)      
            array_name = tag_name + &#39;_fov_&#39; + str(fov)
            dgrp = root.create_group(array_name)
            fov_name = &#39;raw_data_fov_&#39; + str(fov)
            # Remember that attrs must be JSON-serializable to be stored
            # in zarr
            dgrp.attrs[&#39;grp_name&#39;] = array_name
            dgrp.attrs[&#39;fov_name&#39;] = fov_name
            dgrp.attrs[&#39;channel&#39;] = channel
            dgrp.attrs[&#39;img_width&#39;] = parsed_metadata[&#39;width&#39;]
            dgrp.attrs[&#39;img_height&#39;] = parsed_metadata[&#39;height&#39;]
            dgrp.attrs[&#39;pixel_microns&#39;] = pixel_microns
            dgrp.attrs[&#39;zstack&#39;] = len(list(z_levels))
            dgrp.attrs[&#39;total_fovs&#39;] = len(list(fields_of_view))
            dgrp.attrs[&#39;fov_num&#39;] = fov
            dgrp.attrs[&#39;experiment_name&#39;] = experiment_name
            dgrp.attrs[&#39;fov_acquisition_coords_x&#39;] = fov_coords[fov,1]
            dgrp.attrs[&#39;fov_acquisition_coords_y&#39;] = fov_coords[fov,2]
            dgrp.attrs[&#39;fov_acquisition_coords_z&#39;] = fov_coords[fov,0]

            dgrp.attrs[&#39;target_name&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;stitching_channel&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;stitching_type&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;experiment_type&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;round_num&#39;] = 1
            dgrp.attrs[&#39;barcode_length&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;barcode&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;codebook&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;machine&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;operator&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;overlapping_percentage&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;probe_fasta_name&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;species&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;start_date&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;strain&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;tissue&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;pipeline&#39;] = &#39;undefined&#39;
            dgrp.attrs[&#39;processing_type&#39;] = &#39;undefined&#39;

            dgrp.attrs[&#39;round_num&#39;] = 1

            dset = dgrp.create_dataset(fov_name, data=img, shape=img.shape, chunks=(1,None,None),overwrite=True)</code></pre>
</details>
</dd>
<dt id="pysmFISH.microscopy_file_parsers.nikon_nd2_parsing_graph"><code class="name flex">
<span>def <span class="ident">nikon_nd2_parsing_graph</span></span>(<span>experiment_fpath:str, parsing_type:str, parsed_image_tag:str, storage_experiment_fpath:str, client:distributed.client.Client)</span>
</code></dt>
<dd>
<div class="desc"><p>Function that create and run a dask graph for the parsing of the
raw nikon files.
The parsing can be run on original files generated by robofish or on
previously parsed and renamed files raw nd2 files stored in the experiment
folder or in a storage directory.
The parsed data are stored in a zarr DirectoryStore and each fov is saved as
separated group.
Steps run in the graph:
- Create a specific analysis configuration file (it will not rewrite it if it is
already present)
- Create the empy zarr storage that will contain the parsed files
- If the files are parsed from a newly generated experiment:
&ndash; The files in the folder will be sorted and organized
&ndash; A QC step will make sure that the number of metadata files will
match the raw .nd2 files</p>
<ul>
<li>After parsing the zarr metadata are consolidated in one single large
JSON file (.zmetadata) that will allow faster read of the metadata
collected from the raw images.</li>
</ul>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path of the experiment to process</dd>
<dt><strong><code>parsing_type</code></strong> :&ensp;<code>str</code></dt>
<dd>Can be:</dd>
</dl>
<ul>
<li>original: if the experiment to process has been newly generated by the robofish system</li>
<li>reparsing_from_processing_folder: if the raw data to parse have been parsed and renamed
before but are still contained in the subfolder raw_data in the experiment folder</li>
<li>
<dl>
<dt>reparsing_from_storage: if the raw data to parse have been parsed and renamed</dt>
<dt>before and are stored in a subfolder raw_data in the experiment folder that has been</dt>
<dt>moved in a storage directory.</dt>
<dt><strong><code>parsed_image_tag</code></strong> :&ensp;<code>str</code></dt>
<dd>Tag to identify the zarr file with parsed images (default: img_data)</dd>
</dl>
</li>
</ul>
<dl>
<dt><strong><code>storage_experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to folder in the storage HD where to store (or are stored) the raw data for
the current experiment.</dd>
<dt><strong><code>client</code></strong> :&ensp;<code>distributed.Client</code></dt>
<dd>Dask client responsible for handling the processing of the graph.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nikon_nd2_parsing_graph(experiment_fpath: str,
                                parsing_type: str, parsed_image_tag: str, 
                                storage_experiment_fpath: str,
                                client: distributed.Client):
    &#34;&#34;&#34;Function that create and run a dask graph for the parsing of the
    raw nikon files.
    The parsing can be run on original files generated by robofish or on
    previously parsed and renamed files raw nd2 files stored in the experiment
    folder or in a storage directory.
    The parsed data are stored in a zarr DirectoryStore and each fov is saved as
    separated group.
    Steps run in the graph: 
    - Create a specific analysis configuration file (it will not rewrite it if it is
        already present)
    - Create the empy zarr storage that will contain the parsed files
    - If the files are parsed from a newly generated experiment:
        -- The files in the folder will be sorted and organized
        -- A QC step will make sure that the number of metadata files will
           match the raw .nd2 files

    - After parsing the zarr metadata are consolidated in one single large
      JSON file (.zmetadata) that will allow faster read of the metadata
      collected from the raw images.

    Args:
        experiment_fpath (str): Path of the experiment to process
        parsing_type (str): Can be:
        - original: if the experiment to process has been newly generated by the robofish system
        - reparsing_from_processing_folder: if the raw data to parse have been parsed and renamed
          before but are still contained in the subfolder raw_data in the experiment folder
        - reparsing_from_storage: if the raw data to parse have been parsed and renamed
          before and are stored in a subfolder raw_data in the experiment folder that has been
          moved in a storage directory.
        parsed_image_tag (str): Tag to identify the zarr file with parsed images (default: img_data)
        storage_experiment_fpath (str): Path to folder in the storage HD where to store (or are stored) the raw data for
                                    the current experiment.
        client (distributed.Client): Dask client responsible for handling the processing of the graph.
    &#34;&#34;&#34;
    logger = selected_logger()
    experiment_fpath = Path(experiment_fpath)
    storage_experiment_fpath = Path(storage_experiment_fpath)
    
    experiment_info = configuration_files.load_experiment_config_file(experiment_fpath)
    configuration_files.create_specific_analysis_config_file(experiment_fpath, experiment_info)
    # Create empty zarr file for the parse data
    parsed_raw_data_fpath = io.create_empty_zarr_file(experiment_fpath=experiment_fpath,
                                        tag=parsed_image_tag)
    if parsing_type == &#39;original&#39;:
        utils.collect_processing_files(experiment_fpath, experiment_info)
        utils.sort_data_into_folders(experiment_fpath, experiment_info)
        all_raw_nd2 = nd2_raw_files_selector(experiment_fpath)
        qc_utils.QC_matching_nd2_metadata_robofish(all_raw_nd2)
        parsing_futures = client.map(nikon_nd2_autoparser_zarr,
                                all_raw_nd2,
                                parsed_raw_data_fpath=parsed_raw_data_fpath,
                                experiment_info=experiment_info)

        # wait(parsing_futures)
        _ = client.gather(parsing_futures)
        list_pkl = experiment_fpath.glob(&#39;*.pkl&#39;)
        for pkl_fpath in list_pkl:
            new_file_path = experiment_fpath / &#39;raw_data&#39; / pkl_fpath.name
            pkl_fpath.rename(new_file_path)
            
    else:
        # add error if not correct parsing type
        if parsing_type == &#39;reparsing_from_processing_folder&#39;:
            raw_files_fpath = experiment_fpath / &#39;raw_data&#39;
            logger.info(f&#39;raw_files_fpath {raw_files_fpath}&#39;)
        elif parsing_type == &#39;reparsing_from_storage&#39;:
            raw_files_fpath = storage_experiment_fpath / &#39;raw_data&#39;
        
        all_raw_nd2 = nd2_raw_files_selector_general(folder_fpath=raw_files_fpath)
        parsing_futures = client.map(nikon_nd2_reparser_zarr,
                                all_raw_nd2,
                                parsed_raw_data_fpath=parsed_raw_data_fpath,
                                experiment_info=experiment_info)

        _ = client.gather(parsing_futures)
    consolidated_grp = io.consolidate_zarr_metadata(parsed_raw_data_fpath)</code></pre>
</details>
</dd>
<dt id="pysmFISH.microscopy_file_parsers.nikon_nd2_reparser_zarr"><code class="name flex">
<span>def <span class="ident">nikon_nd2_reparser_zarr</span></span>(<span>nd2_file_path:str, parsed_raw_data_fpath:str, experiment_info:dict)</span>
</code></dt>
<dd>
<div class="desc"><p>This function is used to reparse the raw data stored in the raw_data folder during
the processing. </p>
<p>NB: The file and the corresponding metadata file generated by the microscope
have the same starting name:
LBEXP20201014_EEL_Mouse_2420um_Hybridization01_Cy5.nd2
LBEXP20201014_EEL_Mouse_2420um_Hybridization01_Cy5_info.pkl</p>
<p>The parsed_tmp directory is created in a previous step of the
pipeline during data sorting</p>
<p>This nd2 parser process one .nd2 file</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>nd2_file_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the .nd2 file to be parsed</dd>
<dt><strong><code>parsed_raw_data_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the zarr file that will store the parsed data</dd>
<dt><strong><code>experiment_info</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary with overall experiment info</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nikon_nd2_reparser_zarr(nd2_file_path: str,parsed_raw_data_fpath: str,experiment_info: dict):
    &#34;&#34;&#34;
    This function is used to reparse the raw data stored in the raw_data folder during
    the processing. 

    NB: The file and the corresponding metadata file generated by the microscope
        have the same starting name:
        LBEXP20201014_EEL_Mouse_2420um_Hybridization01_Cy5.nd2
        LBEXP20201014_EEL_Mouse_2420um_Hybridization01_Cy5_info.pkl

    The parsed_tmp directory is created in a previous step of the 
    pipeline during data sorting


    This nd2 parser process one .nd2 file

    Args:
        nd2_file_path (str): Path to the .nd2 file to be parsed
        parsed_raw_data_fpath (str): Path to the zarr file that will store the parsed data
        experiment_info (dict): Dictionary with overall experiment info
    &#34;&#34;&#34;

    logger = selected_logger()
    nd2_file_path = Path(nd2_file_path)
    nd2_fname = nd2_file_path.stem
    parsed_raw_data_fpath = Path(parsed_raw_data_fpath)
    logger.debug(f&#39;processing file {nd2_fname}&#39;)

    experiment_fpath = nd2_file_path.parent.parent
    experiment_name = nd2_file_path.parent.parent.stem
    # experiment_name = experiment_name.split(&#39;_auto&#39;)[0]
    
    info_file = nd2_file_path.parent / (nd2_fname + &#39;_info.pkl&#39;)
    info_data = pickle.load(open(info_file, &#39;rb&#39;))
    hybridization_name = info_data[&#39;channels&#39;][&#39;Hybridization&#39;]
    
    try:
        nd2fh = nd2reader.ND2Reader(nd2_file_path.as_posix())
    except:
        logger.error(f&#39;Cannot load the {nd2_fname} nd2 file&#39;)
        sys.exit(&#39;fCannot load the {nd2_fname} nd2 file&#39;)
    else:
        # Collect metadata
        all_metadata = nd2fh.parser._raw_metadata
        parsed_metadata = nd2fh.parser._raw_metadata.get_parsed_metadata()
        
        channel = parsed_metadata[&#39;channels&#39;][0] # works because there is only one channel for file
        img_shape = np.array([parsed_metadata[&#39;height&#39;],parsed_metadata[&#39;width&#39;]])
        pixel_microns = parsed_metadata[&#39;pixel_microns&#39;]
        z_levels = parsed_metadata[&#39;z_levels&#39;]
        fields_of_view = parsed_metadata[&#39;fields_of_view&#39;]
        
        # Collect FOV coords
        x_data = np.array(all_metadata.x_data)
        x_data = x_data[:,np.newaxis]
        y_data = np.array(all_metadata.y_data)
        y_data = y_data[:,np.newaxis]
        z_data = np.array(all_metadata.z_data)
        z_data = z_data[:,np.newaxis]
        all_coords = np.hstack((z_data,x_data,y_data))
        fov_coords = all_coords[0::len(z_levels),:]
        
        tag_name = experiment_name + &#39;_&#39; + hybridization_name + &#39;_&#39; + channel
    
        # Save the fov_coords
        new_exp_location = parsed_raw_data_fpath.parent
        fname = new_exp_location /&#39;microscope_tiles_coords&#39; / (tag_name + &#39;_fovs_coords.npy&#39;)
        np.save(fname, fov_coords)


        # Save the file as zarr
        store = zarr.DirectoryStore(parsed_raw_data_fpath)
        root = zarr.group(store=store,overwrite=False)

        
        nd2fh.bundle_axes = &#39;zyx&#39;
        # set iteration over the fields of view
        nd2fh.iter_axes = &#39;v&#39;
        
        # Save coords of the FOV
        rows = np.arange(parsed_metadata[&#39;width&#39;])
        cols = np.arange(parsed_metadata[&#39;height&#39;])
        hybridization_num = int(hybridization_name.split(&#39;Hybridization&#39;)[-1])
        for fov in fields_of_view:
            img = np.array(nd2fh[fov],dtype=np.uint16)      
            array_name = tag_name + &#39;_fov_&#39; + str(fov)
            dgrp = root.create_group(array_name)
            fov_name = &#39;raw_data_fov_&#39; + str(fov)
            # Remember that attrs must be JSON-serializable to be stored
            # in zarr
            dgrp.attrs[&#39;grp_name&#39;] = array_name
            dgrp.attrs[&#39;fov_name&#39;] = fov_name
            dgrp.attrs[&#39;channel&#39;] = channel
            dgrp.attrs[&#39;target_name&#39;] = info_data[&#39;channels&#39;][channel]
            dgrp.attrs[&#39;img_width&#39;] = parsed_metadata[&#39;width&#39;]
            dgrp.attrs[&#39;img_height&#39;] = parsed_metadata[&#39;height&#39;]
            dgrp.attrs[&#39;pixel_microns&#39;] = pixel_microns
            dgrp.attrs[&#39;zstack&#39;] = len(list(z_levels))
            dgrp.attrs[&#39;total_fovs&#39;] = len(list(fields_of_view))
            dgrp.attrs[&#39;fov_num&#39;] = fov
            dgrp.attrs[&#39;stitching_channel&#39;] = experiment_info[&#39;StitchingChannel&#39;]
            dgrp.attrs[&#39;stitching_type&#39;] = experiment_info[&#39;Stitching_type&#39;]
            dgrp.attrs[&#39;experiment_type&#39;] = experiment_info[&#39;Experiment_type&#39;]
            dgrp.attrs[&#39;round_num&#39;] = hybridization_num
            dgrp.attrs[&#39;experiment_name&#39;] = experiment_name
            dgrp.attrs[&#39;barcode_length&#39;] = experiment_info[&#39;Barcode_length&#39;]

            codebook_channel = &#39;Codebook_&#39; + channel
            codebook_name = experiment_info[&#39;Codebooks&#39;][codebook_channel]
            dgrp.attrs[&#39;codebook&#39;] = codebook_name
            
            probes_channel = &#39;Probes_FASTA_&#39; + channel
            probes_name = experiment_info[&#39;Probes_FASTA&#39;][probes_channel]
            dgrp.attrs[&#39;probe_fasta_name&#39;] = probes_name

            dgrp.attrs[&#39;barcode&#39;] = experiment_info[&#39;Barcode&#39;]
            dgrp.attrs[&#39;machine&#39;] = experiment_info[&#39;Machine&#39;]
            dgrp.attrs[&#39;operator&#39;] = experiment_info[&#39;Operator&#39;]
            dgrp.attrs[&#39;overlapping_percentage&#39;] = experiment_info[&#39;Overlapping_percentage&#39;]
            dgrp.attrs[&#39;species&#39;] = experiment_info[&#39;Species&#39;]
            dgrp.attrs[&#39;start_date&#39;] = experiment_info[&#39;Start_date&#39;]
            dgrp.attrs[&#39;strain&#39;] = experiment_info[&#39;Strain&#39;]
            dgrp.attrs[&#39;tissue&#39;] = experiment_info[&#39;Tissue&#39;]
            dgrp.attrs[&#39;pipeline&#39;] = experiment_info[&#39;Pipeline&#39;]
            dgrp.attrs[&#39;fov_acquisition_coords_x&#39;] = fov_coords[fov,1]
            dgrp.attrs[&#39;fov_acquisition_coords_y&#39;] = fov_coords[fov,2]
            dgrp.attrs[&#39;fov_acquisition_coords_z&#39;] = fov_coords[fov,0]

            if info_data[&#39;StitchingChannel&#39;] == channel:
                dgrp.attrs[&#39;processing_type&#39;] = dgrp.attrs[&#39;stitching_type&#39;]
            elif &#39;_ST&#39; in dgrp.attrs[&#39;target_name&#39;]:
                dgrp.attrs[&#39;processing_type&#39;] = &#39;staining&#39;
            else:
                dgrp.attrs[&#39;processing_type&#39;] = &#39;fish&#39;

            dset = dgrp.create_dataset(fov_name, data=img, shape=img.shape, chunks=(1,None,None),overwrite=True)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pysmFISH" href="index.html">pysmFISH</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pysmFISH.microscopy_file_parsers.create_dark_img" href="#pysmFISH.microscopy_file_parsers.create_dark_img">create_dark_img</a></code></li>
<li><code><a title="pysmFISH.microscopy_file_parsers.create_dark_img_from_standalone" href="#pysmFISH.microscopy_file_parsers.create_dark_img_from_standalone">create_dark_img_from_standalone</a></code></li>
<li><code><a title="pysmFISH.microscopy_file_parsers.nd2_raw_files_selector" href="#pysmFISH.microscopy_file_parsers.nd2_raw_files_selector">nd2_raw_files_selector</a></code></li>
<li><code><a title="pysmFISH.microscopy_file_parsers.nd2_raw_files_selector_general" href="#pysmFISH.microscopy_file_parsers.nd2_raw_files_selector_general">nd2_raw_files_selector_general</a></code></li>
<li><code><a title="pysmFISH.microscopy_file_parsers.nikon_nd2_autoparser_zarr" href="#pysmFISH.microscopy_file_parsers.nikon_nd2_autoparser_zarr">nikon_nd2_autoparser_zarr</a></code></li>
<li><code><a title="pysmFISH.microscopy_file_parsers.nikon_nd2_parser_simple_mfov" href="#pysmFISH.microscopy_file_parsers.nikon_nd2_parser_simple_mfov">nikon_nd2_parser_simple_mfov</a></code></li>
<li><code><a title="pysmFISH.microscopy_file_parsers.nikon_nd2_parsing_graph" href="#pysmFISH.microscopy_file_parsers.nikon_nd2_parsing_graph">nikon_nd2_parsing_graph</a></code></li>
<li><code><a title="pysmFISH.microscopy_file_parsers.nikon_nd2_reparser_zarr" href="#pysmFISH.microscopy_file_parsers.nikon_nd2_reparser_zarr">nikon_nd2_reparser_zarr</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>