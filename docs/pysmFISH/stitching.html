<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>pysmFISH.stitching API documentation</title>
<meta name="description" content="Collection of functions used for the stitching â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pysmFISH.stitching</code></h1>
</header>
<section id="section-intro">
<p>Collection of functions used for the stitching.</p>
<p>IMPORTANT:
The identification of the organization of the fovs in the composite image
can be simplified if the (0,0) coords of the stage/camera will
be set to the same position for all machine used in the analysis.
In our case we started running experiments with the coords not adjusted
so the position of (0,0) is different for all the machine that
are used to generate the data.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Collection of functions used for the stitching.

IMPORTANT: 
The identification of the organization of the fovs in the composite image
can be simplified if the (0,0) coords of the stage/camera will 
be set to the same position for all machine used in the analysis.
In our case we started running experiments with the coords not adjusted
so the position of (0,0) is different for all the machine that
are used to generate the data. 

&#34;&#34;&#34;
from typing import *
import logging
import shutil
import copy
import itertools
import math
import pickle
import zarr
import sys
import operator
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from itertools import groupby
from pathlib import Path
from sklearn.neighbors import NearestNeighbors
import sklearn.linear_model as linmod
from skimage.feature import register_translation
from skimage import measure
from scipy.optimize import minimize

from pynndescent import NNDescent

from pysmFISH.logger_utils import selected_logger
from pysmFISH.fovs_registration import create_fake_image
from pysmFISH.data_models import Dataset
from pysmFISH import io

 

class organize_square_tiles():
    
    &#34;&#34;&#34;Class designed to determine the tile organization and identify the coords of the
    overlapping regions between the tiles. 
    
    IMPORTANT: The normalize_coords method should be adjusted according to the
                setup of the microscope. 

    &#34;&#34;&#34;
   
    def __init__(self, experiment_fpath:str,dataset: pd.DataFrame, 
                                    metadata:Dict,round_num:int):
        &#34;&#34;&#34;Class initialization

        Args:
            experiment_fpath (str): Path to the experiment to process
            dataset (pd.DataFrame): Properties of the images of the experiment
            metadata (Dict): Metadata describing the experiment
            round_num (int): Reference acquisition round number
        &#34;&#34;&#34;

        
        self.logger = selected_logger()
        self.experiment_fpath = Path(experiment_fpath)
        self.dataset = dataset
        self.metadata = metadata
        self.round_num = round_num
        
        self.experiment_name = self.metadata[&#39;experiment_name&#39;]
        self.stitching_channel = self.metadata[&#39;stitching_channel&#39;]
        self.overlapping_percentage = int(self.metadata[&#39;overlapping_percentage&#39;]) / 100
         
        self.pixel_size = self.metadata[&#39;pixel_microns&#39;]
        self.img_width = self.metadata[&#39;img_width&#39;]
        self.img_height = self.metadata[&#39;img_height&#39;]
        
        logging.getLogger(&#39;matplotlib.font_manager&#39;).disabled = True
        
        if  self.img_width ==  self.img_height:
            self.img_size = self.img_width
        else:
            self.logger.error(f&#39;the images to stitch are not square&#39;)
            sys.exit(f&#39;the images to stitch are not square&#39;)
            
    
    def extract_microscope_coords(self): 
        &#34;&#34;&#34;Method to extract images coords in the stage reference
        system&#34;&#34;&#34;
        

        selected = self.dataset.loc[self.dataset.round_num == self.round_num, 
                                    [&#39;round_num&#39;,&#39;fov_num&#39;,&#39;fov_acquisition_coords_x&#39;,&#39;fov_acquisition_coords_y&#39;]]
        selected.drop_duplicates(subset=[&#39;fov_num&#39;],inplace=True)
        selected.sort_values(by=&#39;fov_num&#39;, ascending=True, inplace=True)
        self.x_coords = selected.loc[:,&#39;fov_acquisition_coords_x&#39;].to_numpy()
        self.y_coords = selected.loc[:,&#39;fov_acquisition_coords_y&#39;].to_numpy()

    
    def normalize_coords(self):
        &#34;&#34;&#34;
        Normalize the coords according to how the stage/camera are set.
        This function must be modified according to the stage/camera setup.

        ROBOFISH1 has stage with x increasing left-&gt; right and y top-&gt;bottom 
            ------&gt; (x)
            |
            |
            V (y)
        
        ROBOFISH2 has stage with x increasing right-&gt; left and y top-&gt;bottom 
        (x) &lt;------
                  |
                  |
                  V (y)
        

        ROBOFISH3 has stage with x increasing left-&gt; right and y bottom-&gt;top 
            ^ (y)
            |
            |
            ------&gt; (x)

        Axis modifications steps:
        (1) The reference system will be first converted to image style:
            ------&gt; (x)
            |
            |
            V (y)

        This step will cause a change in the position of the reference corner
        for each fov. After image acquisition the reference corner is top-left
        however after converting the axis direction to image-style the reference corner
        will change postion:
        ROBOFISH1: top-left --&gt; top-left
        ROBOFISH2: top-left --&gt; top-right
        ROBOFISH3: top-left --&gt; bottom-left

        (2) The coords will be translated to (0,0)

        (3) then to matrix (python) notation
            ------&gt; (columns)
            |
            |
            V (rows)

        &#34;&#34;&#34;

        # port the coords to image type coords
        if self.metadata[&#39;machine&#39;] == &#39;ROBOFISH2&#39;:
            self.x_coords = - self.x_coords
            self.reference_corner_fov_position = &#39;top-right&#39;
        elif self.metadata[&#39;machine&#39;] == &#39;ROBOFISH3&#39;:
            self.x_coords = - self.x_coords
            self.y_coords = - self.y_coords
            self.reference_corner_fov_position = &#39;bottom-left&#39;
        elif self.metadata[&#39;machine&#39;] == &#39;ROBOFISH1&#39;:
            self.reference_corner_fov_position = &#39;top-left&#39;
        elif self.metadata[&#39;machine&#39;] == &#39;NOT_DEFINED&#39;:
            self.logger.error(f&#39;Need to define the specs for stitching NOT_DEFINED machine&#39;)
            sys.exit(f&#39;Need to define the specs for stitching NOT_DEFINED machine&#39;)
        else:
            self.logger.error(f&#39;define the right machine used to collected the data&#39;)
            sys.exit(f&#39;define the right machine used to collected the data&#39;)

        # shift the coords to reference point (0,0) 
        # consider that we get the top-right corner of the image as well
        y_min = np.amin(self.y_coords)
        x_min = np.amin(self.x_coords)
        x_max = np.amax(self.x_coords)
        y_max = np.amax(self.y_coords)


        # Put the coords to zero
        if x_min &gt;=0 :
            self.x_coords = self.x_coords - x_min
        else:
            self.x_coords = self.x_coords + np.abs(x_min)
        
        if y_min&gt;0:
            self.y_coords = self.y_coords - y_min
        else:
            self.y_coords = self.y_coords + np.abs(y_min)


        # if x_max &gt;=0 :
        #     self.x_coords = self.x_coords - x_min
        # else:
        #     self.x_coords = self.x_coords + np.abs(x_min)
        
        # if y_max&gt;0:
        #     self.y_coords = self.y_coords - y_min
        # else:
        #     self.y_coords = self.y_coords + np.abs(y_min)

        # change the coords from x,y to r,c
        adjusted_coords = np.zeros([self.x_coords.shape[0],2])
        adjusted_coords[:,0] = self.y_coords
        adjusted_coords[:,1] = self.x_coords

        # move coords to pxl space
        self.tile_corners_coords_pxl = adjusted_coords / self.pixel_size


    
    # def save_graph_original_coords(self):
    # to correct because I already converted the coords to image
    #     # Turn interactive plotting off
    #     saving_fpath = self.experiment_fpath / &#39;output_figures&#39; / &#39;microscope_space_tiles_organization.png&#39;
    #     plt.ioff()
    #     # Create image type axes
    #     labels = [str(nr) for nr in np.arange(self.x_coords.shape[0])]
    #     fig = plt.figure(figsize=(20,10))
    #     plt.plot(self.x_coords,self.y_coords,&#39;or&#39;)

    #     for label, x, y in zip(labels, self.x_coords,self.y_coords):
    #         plt.annotate(
    #             label,
    #             xy=(x,y), xytext=(-2, 2),
    #             textcoords=&#39;offset points&#39;, ha=&#39;center&#39;, va=&#39;bottom&#39;,fontsize=12)
    #     plt.tight_layout()
    #     plt.savefig(saving_fpath)
    
    
    def save_graph_image_space_coords(self):
        &#34;&#34;&#34;Method used to save the organization of the tiles
        &#34;&#34;&#34;
        # Turn interactive plotting off
        saving_fpath = self.experiment_fpath / &#39;output_figures&#39; / &#39;image_space_tiles_organization.png&#39;
        plt.ioff()
        # Create image type axes
        labels = [str(nr) for nr in np.arange(self.tile_corners_coords_pxl.shape[0])]
        fig = plt.figure(figsize=(20,10))
        plt.gca().invert_yaxis()
        plt.plot(self.tile_corners_coords_pxl[:,1],self.tile_corners_coords_pxl[:,0],&#39;or&#39;)

        for label, x, y in zip(labels, self.tile_corners_coords_pxl[:,1],self.tile_corners_coords_pxl[:,0]):
            plt.annotate(
                label,
                xy=(x,y), xytext=(-2, 2),
                textcoords=&#39;offset points&#39;, ha=&#39;center&#39;, va=&#39;bottom&#39;,fontsize=12)
        plt.tight_layout()
        plt.savefig(saving_fpath)
        
    
    def identify_adjacent_tiles(self):
        &#34;&#34;&#34;Method that use Nearest neighbors to identify the beighbouring tiles
        &#34;&#34;&#34;
        shift_percent_tolerance = 0.05
        searching_radius = self.img_size - (self.img_size*self.overlapping_percentage) + (self.img_size*shift_percent_tolerance)
        nn = NearestNeighbors(n_neighbors=5,radius=searching_radius, metric=&#39;euclidean&#39;)
        nn.fit(self.tile_corners_coords_pxl)
        self.dists, self.indices = nn.kneighbors(self.tile_corners_coords_pxl, return_distance=True)


    def determine_overlapping_regions(self):
        &#34;&#34;&#34;Method used to calculate the coords of the overlapping regions between the tiles.
        &#34;&#34;&#34;
        # remember that overlapping region can be an empty dictionary
        self.overlapping_regions = {}
        self.overlapping_order ={}
        for idx in np.arange(self.indices.shape[0]):
            self.overlapping_regions[idx] = {}
            self.overlapping_order[idx] = {}
        for idx in np.arange(self.indices.shape[0]):
            # Determine the indices that identify the correct adjacent
            processing_indices = self.indices[idx,:]
            processing_dists = self.dists[idx,:]
            ref_tile = processing_indices[0]
            self.overlapping_regions[ref_tile] = {}
            self.overlapping_order[ref_tile] = {}
            trimmed_indices = processing_indices[1:]
            trimmed_dists = processing_dists[1:]

            idx_adj = np.where(trimmed_dists &lt; self.img_size)
            adj_tiles_id = trimmed_indices[idx_adj]
            adj_cpls = [(ref_tile, adj_tile) for adj_tile in adj_tiles_id]
            
            # remove pairs that are already selected
            only_new_cpls = [cpl for cpl in adj_cpls if (cpl[1],cpl[0]) not in self.overlapping_regions[cpl[1]].keys()]
            # only_new_cpls = [cpl for cpl in adj_cpls]

            if self.reference_corner_fov_position == &#39;top-left&#39;:
                for cpl in only_new_cpls:
                    tile1_r_coords = self.tile_corners_coords_pxl[cpl[0]][0]
                    tile2_r_coords = self.tile_corners_coords_pxl[cpl[1]][0]
                    tile1_c_coords = self.tile_corners_coords_pxl[cpl[0]][1]
                    tile2_c_coords = self.tile_corners_coords_pxl[cpl[1]][1]

                    if tile1_r_coords &gt; tile2_r_coords:
                            r_tl = tile1_r_coords
                            r_br = tile2_r_coords + self.img_height

                            row_order = (&#39;bottom&#39;,&#39;top&#39;)

                    else:
                        r_tl = tile2_r_coords
                        r_br = tile1_r_coords + self.img_height

                        row_order = (&#39;top&#39;,&#39;bottom&#39;)

                    if tile1_c_coords &gt; tile2_c_coords:
                        c_tl = tile1_c_coords
                        c_br = tile2_c_coords + self.img_width

                        col_order = (&#39;right&#39;,&#39;left&#39;)

                    else:
                        c_tl = tile2_c_coords
                        c_br = tile1_c_coords + self.img_width

                        col_order = (&#39;left&#39;,&#39;right&#39;)

                    self.overlapping_regions[ref_tile][cpl] = [r_tl, r_br, c_tl, c_br]
                    self.overlapping_order[ref_tile][cpl] = {&#39;row_order&#39;:row_order,&#39;column_order&#39;:col_order}
            
            elif self.reference_corner_fov_position == &#39;top-right&#39;:
                for cpl in only_new_cpls:
                    tile1_r_coords = self.tile_corners_coords_pxl[cpl[0]][0]
                    tile2_r_coords = self.tile_corners_coords_pxl[cpl[1]][0]
                    tile1_c_coords = self.tile_corners_coords_pxl[cpl[0]][1]
                    tile2_c_coords = self.tile_corners_coords_pxl[cpl[1]][1]

                    if tile1_r_coords &gt; tile2_r_coords:
                            r_tl = tile1_r_coords
                            r_br = tile2_r_coords + self.img_height

                            row_order = (&#39;bottom&#39;,&#39;top&#39;)

                    else:
                        r_tl = tile2_r_coords
                        r_br = tile1_r_coords + self.img_height

                        row_order = (&#39;top&#39;,&#39;bottom&#39;)

                    if tile1_c_coords &gt; tile2_c_coords:
                        c_tl = tile1_c_coords - self.img_width
                        c_br = tile2_c_coords 
                        col_order = (&#39;right&#39;,&#39;left&#39;)

                    else:
                        c_tl = tile2_c_coords - self.img_width
                        c_br = tile1_c_coords

                        col_order = (&#39;left&#39;,&#39;right&#39;)

                    self.overlapping_regions[ref_tile][cpl] = [r_tl, r_br, c_tl, c_br]
                    self.overlapping_order[ref_tile][cpl] = {&#39;row_order&#39;:row_order,&#39;column_order&#39;:col_order}


            elif self.reference_corner_fov_position == &#39;bottom-left&#39;:
                for cpl in only_new_cpls:
                    tile1_r_coords = self.tile_corners_coords_pxl[cpl[0]][0]
                    tile2_r_coords = self.tile_corners_coords_pxl[cpl[1]][0]
                    tile1_c_coords = self.tile_corners_coords_pxl[cpl[0]][1]
                    tile2_c_coords = self.tile_corners_coords_pxl[cpl[1]][1]

                    if tile1_r_coords &gt; tile2_r_coords:
                            r_tl = tile1_r_coords - self.img_height
                            r_br = tile2_r_coords

                            row_order = (&#39;bottom&#39;,&#39;top&#39;)

                    else:
                        r_tl = tile2_r_coords - self.img_height
                        r_br = tile1_r_coords

                        row_order = (&#39;top&#39;,&#39;bottom&#39;)

                    if tile1_c_coords &gt; tile2_c_coords:
                        c_tl = tile1_c_coords
                        c_br = tile2_c_coords + self.img_width 
                        col_order = (&#39;right&#39;,&#39;left&#39;)

                    else:
                        c_tl = tile2_c_coords 
                        c_br = tile1_c_coords + self.img_width 

                        col_order = (&#39;left&#39;,&#39;right&#39;)

                    self.overlapping_regions[ref_tile][cpl] = [r_tl, r_br, c_tl, c_br]
                    self.overlapping_order[ref_tile][cpl] = {&#39;row_order&#39;:row_order,&#39;column_order&#39;:col_order}


    def run_tiles_organization(self):
        &#34;&#34;&#34;Method used to run all the methods
        &#34;&#34;&#34;
        self.extract_microscope_coords()
        # self.save_graph_original_coords()
        self.normalize_coords()
        self.save_graph_image_space_coords()
        self.identify_adjacent_tiles()
        self.determine_overlapping_regions()
        fname = self.experiment_fpath / &#39;results&#39; / &#39;microscope_tile_corners_coords_pxl.npy&#39;
        np.save(fname,self.tile_corners_coords_pxl)




class organize_square_tiles_old_room():

    &#34;&#34;&#34;
    Class used to identify the orgabnization of the tiles before the
    reorganization of the Robofish room of April 2021 when Robofish3
    was assembled.
    &#34;&#34;&#34;

    def __init__(self, experiment_fpath:str,dataset, metadata:Dict,round_num:int):
        &#34;&#34;&#34;
        round_num = int
            reference channel
        &#34;&#34;&#34;
        
        self.logger = selected_logger()
        self.experiment_fpath = Path(experiment_fpath)
        self.dataset = dataset
        self.metadata = metadata
        self.round_num = round_num
        
        self.experiment_name = self.metadata[&#39;experiment_name&#39;]
        self.stitching_channel = self.metadata[&#39;stitching_channel&#39;]
        self.overlapping_percentage = int(self.metadata[&#39;overlapping_percentage&#39;]) / 100
         
        self.pixel_size = self.metadata[&#39;pixel_microns&#39;]
        self.img_width = self.metadata[&#39;img_width&#39;]
        self.img_height = self.metadata[&#39;img_height&#39;]
        
        logging.getLogger(&#39;matplotlib.font_manager&#39;).disabled = True
        
        if  self.img_width ==  self.img_height:
            self.img_size = self.img_width
        else:
            self.logger.error(f&#39;the images to stitch are not square&#39;)
            sys.exit(f&#39;the images to stitch are not square&#39;)
            
    
    def extract_microscope_coords(self): 
        

        selected = self.dataset.loc[self.dataset.round_num == self.round_num, 
                                    [&#39;round_num&#39;,&#39;fov_num&#39;,&#39;fov_acquisition_coords_x&#39;,&#39;fov_acquisition_coords_y&#39;]]
        selected.drop_duplicates(subset=[&#39;fov_num&#39;],inplace=True)
        selected.sort_values(by=&#39;fov_num&#39;, ascending=True, inplace=True)
        self.x_coords = selected.loc[:,&#39;fov_acquisition_coords_x&#39;].to_numpy()
        self.y_coords = selected.loc[:,&#39;fov_acquisition_coords_y&#39;].to_numpy()


    def normalize_coords(self):

        if self.metadata[&#39;machine&#39;] == &#39;ROBOFISH2&#39;:
            # RobofishII has stage with reference point
            # in the center (0,0)
            # consider that we get the top-right corner of the image as well

            self.reference_corner_fov_position = &#39;old-room-robofish2&#39;  # Not sure (i don&#39;t remember)
            # consider that we get the top-right corner of the image as well
            y_min = np.amin(self.y_coords)
            x_min = np.amin(self.x_coords)
            x_max = np.amax(self.x_coords)
            y_max = np.amax(self.y_coords)

            # Put the coords to zero
    
            if x_max &gt;=0 :
                self.x_coords = self.x_coords - x_min
            else:
                self.x_coords = self.x_coords + np.abs(x_min)
            
            if y_max&gt;0:
                self.y_coords = self.y_coords - y_min
            else:
                self.y_coords = self.y_coords + np.abs(y_min)

            # flip y_axis
            self.y_coords = self.y_coords - self.y_coords.max()
            self.y_coords = - self.y_coords


            # change the coords from x,y to r,c
            adjusted_coords = np.zeros([self.x_coords.shape[0],2])
            adjusted_coords[:,0] = self.y_coords
            adjusted_coords[:,1] = self.x_coords

        elif self.metadata[&#39;machine&#39;] == &#39;ROBOFISH1&#39;:
            # The current system has stage ref coords BOTTOM-RIGH
            self.reference_corner_fov_position = &#39;bottom-right&#39;
            # Normalize to (0,0) still BOTTOM-RIGHT
            y_min = np.amin(self.y_coords)
            x_min = np.amin(self.x_coords)

            self.x_coords = self.x_coords - x_min
            self.y_coords = self.y_coords - y_min

            # flip axis to move (0,0) on TOP-LEF
            self.x_coords = self.x_coords - self.x_coords.max()
            self.x_coords = - self.x_coords

            self.y_coords = self.y_coords - self.y_coords.max()
            self.y_coords = - self.y_coords

            # change the coords from x,y to r,c
            adjusted_coords = np.zeros([self.x_coords.shape[0],2])
            adjusted_coords[:,0] = self.y_coords
            adjusted_coords[:,1] = self.x_coords
        
        elif self.metadata[&#39;machine&#39;] == &#39;NOT_DEFINED&#39;:
            self.logger.error(f&#39;Need to define the specs for stitching NOT_DEFINED machine&#39;)
            sys.exit(f&#39;Need to define the specs for stitching NOT_DEFINED machine&#39;)
            
        else:
            self.logger.error(f&#39;define the right machine used to collected the data&#39;)
            sys.exit(f&#39;define the right machine used to collected the data&#39;)
        
        self.tile_corners_coords_pxl = adjusted_coords / self.pixel_size
    
    
    def save_graph_original_coords(self):
        # Turn interactive plotting off
        saving_fpath = self.experiment_fpath / &#39;output_figures&#39; / &#39;microscope_space_tiles_organization.png&#39;
        plt.ioff()
        # Create image type axes
        labels = [str(nr) for nr in np.arange(self.x_coords.shape[0])]
        fig = plt.figure(figsize=(20,10))
        plt.plot(self.x_coords,self.y_coords,&#39;or&#39;)

        for label, x, y in zip(labels, self.x_coords,self.y_coords):
            plt.annotate(
                label,
                xy=(x,y), xytext=(-2, 2),
                textcoords=&#39;offset points&#39;, ha=&#39;center&#39;, va=&#39;bottom&#39;,fontsize=12)
        plt.tight_layout()
        plt.savefig(saving_fpath)
    
    
    def save_graph_image_space_coords(self):
        # Turn interactive plotting off
        saving_fpath = self.experiment_fpath / &#39;output_figures&#39; / &#39;image_space_tiles_organization.png&#39;
        plt.ioff()
        # Create image type axes
        labels = [str(nr) for nr in np.arange(self.tile_corners_coords_pxl.shape[0])]
        fig = plt.figure(figsize=(20,10))
        plt.gca().invert_yaxis()
        plt.plot(self.tile_corners_coords_pxl[:,1],self.tile_corners_coords_pxl[:,0],&#39;or&#39;)

        for label, x, y in zip(labels, self.tile_corners_coords_pxl[:,1],self.tile_corners_coords_pxl[:,0]):
            plt.annotate(
                label,
                xy=(x,y), xytext=(-2, 2),
                textcoords=&#39;offset points&#39;, ha=&#39;center&#39;, va=&#39;bottom&#39;,fontsize=12)
        plt.tight_layout()
        plt.savefig(saving_fpath)
        
    
    def identify_adjacent_tiles(self):
        shift_percent_tolerance = 0.05
        searching_radius = self.img_size - (self.img_size*self.overlapping_percentage) + (self.img_size*shift_percent_tolerance)
        nn = NearestNeighbors(n_neighbors=5,radius=searching_radius, metric=&#39;euclidean&#39;)
        nn.fit(self.tile_corners_coords_pxl)
        self.dists, self.indices = nn.kneighbors(self.tile_corners_coords_pxl, return_distance=True)


    def determine_overlapping_regions(self):
        # remember that overlapping region can be an empty dictionary
        self.overlapping_regions = {}
        self.overlapping_order ={}
        for idx in np.arange(self.indices.shape[0]):
            self.overlapping_regions[idx] = {}
            self.overlapping_order[idx] = {}
        for idx in np.arange(self.indices.shape[0]):
            # Determine the indices that identify the correct adjacent
            processing_indices = self.indices[idx,:]
            processing_dists = self.dists[idx,:]
            ref_tile = processing_indices[0]
            self.overlapping_regions[ref_tile] = {}
            self.overlapping_order[ref_tile] = {}
            trimmed_indices = processing_indices[1:]
            trimmed_dists = processing_dists[1:]

            idx_adj = np.where(trimmed_dists &lt; self.img_size)
            adj_tiles_id = trimmed_indices[idx_adj]
            adj_cpls = [(ref_tile, adj_tile) for adj_tile in adj_tiles_id]
            
            # remove pairs that are already selected
            only_new_cpls = [cpl for cpl in adj_cpls if (cpl[1],cpl[0]) not in self.overlapping_regions[cpl[1]].keys()]
            # only_new_cpls = [cpl for cpl in adj_cpls]

            if self.metadata[&#39;machine&#39;] == &#39;ROBOFISH2&#39;:
                # If tile coords are top left
                for cpl in only_new_cpls:

                    tile1_r_coords = self.tile_corners_coords_pxl[cpl[0]][0]
                    tile2_r_coords = self.tile_corners_coords_pxl[cpl[1]][0]
                    tile1_c_coords = self.tile_corners_coords_pxl[cpl[0]][1]
                    tile2_c_coords = self.tile_corners_coords_pxl[cpl[1]][1]

                    if tile1_r_coords &gt; tile2_r_coords:
                        r_tl = tile1_r_coords
                        r_br = tile2_r_coords + self.img_size

                        r_bl = tile2_c_coords + self.img_size
                        r_tr = tile1_c_coords

                        row_order = (&#39;bottom&#39;,&#39;top&#39;)

                    else:
                        r_tl = tile2_r_coords
                        r_br = tile1_r_coords + self.img_size

                        r_bl = tile1_r_coords + self.img_size
                        r_tr = tile2_r_coords

                        row_order = (&#39;top&#39;,&#39;bottom&#39;)

                    if tile1_c_coords &gt; tile2_c_coords:
                        c_tl = tile1_c_coords
                        c_br = tile2_c_coords + self.img_size

                        c_tr = tile2_c_coords + self.img_size
                        c_bl = tile1_c_coords

                        col_order = (&#39;right&#39;,&#39;left&#39;)

                    else:
                        c_tl = tile2_c_coords
                        c_br = tile1_c_coords + self.img_size

                        c_bl = tile2_c_coords
                        c_tr = tile1_c_coords + self.img_size

                        col_order = (&#39;left&#39;,&#39;right&#39;)

                

            elif self.metadata[&#39;machine&#39;] == &#39;ROBOFISH1&#39;:
                # If tile coords are bottom right
                for cpl in only_new_cpls:

                    tile1_r_coords = self.tile_corners_coords_pxl[cpl[0]][0]
                    tile2_r_coords = self.tile_corners_coords_pxl[cpl[1]][0]
                    tile1_c_coords = self.tile_corners_coords_pxl[cpl[0]][1]
                    tile2_c_coords = self.tile_corners_coords_pxl[cpl[1]][1]

                    if tile1_r_coords &gt; tile2_r_coords:
                        r_tl = tile1_r_coords - self.img_size
                        r_br = tile2_r_coords

                        r_bl = tile2_c_coords
                        r_tr = tile1_c_coords - self.img_size

                        row_order = (&#39;bottom&#39;,&#39;top&#39;)

                    else:
                        r_tl = tile2_r_coords - self.img_size
                        r_br = tile1_r_coords 

                        r_bl = tile1_r_coords 
                        r_tr = tile2_r_coords - self.img_size

                        row_order = (&#39;top&#39;,&#39;bottom&#39;)

                    if tile1_c_coords &gt; tile2_c_coords:
                        c_tl = tile1_c_coords - self.img_size
                        c_br = tile2_c_coords 

                        c_tr = tile2_c_coords
                        c_bl = tile1_c_coords - self.img_size

                        col_order = (&#39;right&#39;,&#39;left&#39;)

                    else:
                        c_tl = tile2_c_coords - self.img_size
                        c_br = tile1_c_coords 

                        c_bl = tile2_c_coords - self.img_size
                        c_tr = tile1_c_coords 

                        col_order = (&#39;left&#39;,&#39;right&#39;)
            else:
                pass

            self.overlapping_regions[ref_tile][cpl] = [r_tl, r_br, c_tl, c_br]
            self.overlapping_order[ref_tile][cpl] = {&#39;row_order&#39;:row_order,&#39;column_order&#39;:col_order}

    def run_tiles_organization(self):
        self.extract_microscope_coords()
        self.save_graph_original_coords()
        self.normalize_coords()
        self.save_graph_image_space_coords()
        self.identify_adjacent_tiles()
        self.determine_overlapping_regions()
        fname = self.experiment_fpath / &#39;results&#39; / &#39;microscope_tile_corners_coords_pxl.npy&#39;
        np.save(fname,self.tile_corners_coords_pxl)



def stitch_using_coords_general(decoded_df: pd.DataFrame, tile_corners_coords_pxl: np.ndarray, 
    reference_corner_fov_position: str, metadata: Dict, tag: str):
    &#34;&#34;&#34;Function to create a stitched image using the fov coords 
    of the stage.

    Args:
        decoded_df (pd.DataFrame): Counts after decoding
        tile_corners_coords_pxl (np.ndarray): Coords of the fovs according to the stage
        reference_corner_fov_position (str): Position of the reference corner determine by
            the organization stage/camera. In our setup can be:
            - top-left
            - top-right
            - bottom_left
        metadata (Dict): [description]
        tag (str): [description]

    Returns:
        [type]: Decoded counts with coords of the dots adjusted to the stage
                reference point
    &#34;&#34;&#34;
    logger = selected_logger()

    was_file = 0
    if not isinstance(decoded_df, pd.DataFrame):
        was_file = 1
        decoded_df_fpath = copy.deepcopy(decoded_df)
        decoded_df = pd.read_parquet(decoded_df)
        
    if decoded_df[&#39;r_px_registered&#39;].empty:
        decoded_df[&#39;r_px_&#39;+tag] = np.nan
        decoded_df[&#39;c_px_&#39;+tag] = np.nan
    else:

        #fov = decoded_df.iloc[0][&#39;fov_num&#39;]
        fov = int(decoded_df.fov_num.unique()[0])
        r_microscope_coords = tile_corners_coords_pxl[fov,0]
        c_microscope_coords = tile_corners_coords_pxl[fov,1]
        
        if reference_corner_fov_position == &#39;top-left&#39;:
            decoded_df[&#39;r_px_&#39;+tag] =  r_microscope_coords + decoded_df[&#39;r_px_registered&#39;]
            decoded_df[&#39;c_px_&#39;+tag] =  c_microscope_coords + decoded_df[&#39;c_px_registered&#39;]

        elif reference_corner_fov_position == &#39;top-right&#39;:
            decoded_df[&#39;r_px_&#39;+tag] =  r_microscope_coords + decoded_df[&#39;r_px_registered&#39;]
            decoded_df[&#39;c_px_&#39;+tag] =  c_microscope_coords - (metadata[&#39;img_width&#39;] - decoded_df[&#39;c_px_registered&#39;])

        elif reference_corner_fov_position == &#39;bottom-left&#39;:
            decoded_df[&#39;r_px_&#39;+tag] =  r_microscope_coords + (metadata[&#39;img_height&#39;] - decoded_df[&#39;r_px_registered&#39;])
            decoded_df[&#39;c_px_&#39;+tag] =  c_microscope_coords + decoded_df[&#39;c_px_registered&#39;]

        elif reference_corner_fov_position == &#39;bottom-right&#39;:
            decoded_df[&#39;r_px_&#39;+tag] =  r_microscope_coords + (metadata[&#39;img_height&#39;] - decoded_df[&#39;r_px_registered&#39;])
            decoded_df[&#39;c_px_&#39;+tag] =  c_microscope_coords - (metadata[&#39;img_width&#39;] - decoded_df[&#39;c_px_registered&#39;])

        elif reference_corner_fov_position == &#39;old-room-robofish2&#39;:
            decoded_df[&#39;r_px_&#39;+tag] =  r_microscope_coords -  decoded_df[&#39;r_px_registered&#39;]
            decoded_df[&#39;c_px_&#39;+tag] =  c_microscope_coords -  decoded_df[&#39;c_px_registered&#39;]

        else:
            logger.error(f&#34;the referernce corner fov position name is wrong&#34;)
            sys.exit(f&#34;the referernce corner fov position name is wrong&#34;)
        # decoded_df[&#39;r_px_&#39;+tag] =  r_microscope_coords - decoded_df[&#39;r_px_registered&#39;]
        # decoded_df[&#39;c_px_&#39;+tag] =  c_microscope_coords - decoded_df[&#39;c_px_registered&#39;]
    
    if was_file:
        decoded_df.to_parquet(decoded_df_fpath,index=False)
    else:
        return decoded_df




def stitch_using_coords_general_segmented_objects(fov,obj_dict,tile_corners_coords_pxl,reference_corner_fov_position, metadata):
    &#34;&#34;&#34;
    Function used to stitch the segmented object used for defining the cells.
    &#34;&#34;&#34;

    r_microscope_coords = tile_corners_coords_pxl[fov,0]
    c_microscope_coords = tile_corners_coords_pxl[fov,1]
    
    if obj_dict:
        
        if reference_corner_fov_position == &#39;top-left&#39;:
            for el,coords_dict in obj_dict.items():
                coords_dict[&#39;stitched_coords&#39;] = np.vstack([r_microscope_coords + coords_dict[&#39;original_coords&#39;][:,0],
                                                            c_microscope_coords + coords_dict[&#39;original_coords&#39;][:,1]]).T

        elif reference_corner_fov_position == &#39;top-right&#39;:
            for el,coords_dict in obj_dict.items():
                coords_dict[&#39;stitched_coords&#39;] = np.vstack([r_microscope_coords + coords_dict[&#39;original_coords&#39;][:,0],
                                                            c_microscope_coords - (metadata[&#39;img_width&#39;] -coords_dict[&#39;original_coords&#39;][:,1])]).T

        elif reference_corner_fov_position == &#39;bottom_left&#39;:
            for el,coords_dict in obj_dict.items():
                coords_dict[&#39;stitched_coords&#39;] = np.vstack([r_microscope_coords + (metadata[&#39;img_height&#39;] -coords_dict[&#39;original_coords&#39;][:,0]),
                                                            c_microscope_coords + coords_dict[&#39;original_coords&#39;][:,1]]).T

    return obj_dict


def register_coords_obj(fov,segmentation_output_path,
                    stitching_parameters,
                    reference_corner_fov_position,
                    metadata):
    &#34;&#34;&#34;Function used to register the coords of the segmented object to th 

    Args:
        fov ([type]): [description]
        segmentation_output_path ([type]): [description]
    &#34;&#34;&#34;
    segmented_output = pickle.load(open(segmentation_output_path / (&#39;preprocessed_data_fov_&#39; + str(fov) + &#39;_mask.pkl&#39;), &#39;rb&#39;))
    segmented_regions = measure.regionprops(segmented_output)
    segmented_regions_dict = {}
    for prop in segmented_regions:
        segmented_regions_dict[str(fov)+&#39;-&#39;+str(prop.label)] = {}
        segmented_regions_dict[str(fov)+&#39;-&#39;+str(prop.label)][&#39;original_coords&#39;]=prop.coords
        segmented_regions_dict[str(fov)+&#39;-&#39;+str(prop.label)][&#39;stitched_coords&#39;]= np.nan
        segmented_regions_dict = stitch_using_coords_general_segmented_objects(fov,segmented_regions_dict,
                                                                         stitching_parameters,reference_corner_fov_position, metadata)
        pickle.dump(segmented_regions_dict,open(segmentation_output_path / (&#39;registered_objs_dict_fov_&#39; + str(fov) + &#39;.pkl&#39;), &#39;wb&#39;))




def get_all_dots_in_overlapping_regions(counts_df, chunk_coords, stitching_selected=&#39;microscope_stitched&#39;):    
    
    r_tag = &#39;r_px_&#39; + stitching_selected
    c_tag = &#39;c_px_&#39; + stitching_selected
    
    r_tl = chunk_coords[0]
    r_br = chunk_coords[1]
    c_tl = chunk_coords[2]
    c_br = chunk_coords[3]
    
    overlapping_ref_df = counts_df.loc[(counts_df[r_tag] &gt; r_tl) &amp; (counts_df[r_tag] &lt; r_br) 
                                               &amp; (counts_df[c_tag] &gt; c_tl) &amp; (counts_df[c_tag] &lt; c_br),:]
        
    return overlapping_ref_df



# TODO adjust the registration with dots (triangulation)

def register_cpl(cpl, chunk_coords, experiment_fpath,
                                    stitching_channel,
                                    reference_round):

    logger = selected_logger()
    registration = {}
    experiment_fpath = Path(experiment_fpath)
    
    try:
        counts1_fpath = list((experiment_fpath / &#39;results&#39;).glob(&#39;*decoded_fov_&#39; + str(cpl[0]) + &#39;.parquet&#39;))[0]
    except:
        logger.error(f&#39;count file missing for fov {cpl[0]}&#39;)
    
    else:
        try:
            counts2_fpath = list((experiment_fpath / &#39;results&#39;).glob(&#39;*decoded_fov_&#39; + str(cpl[1]) + &#39;.parquet&#39;))[0]
        except:
            logger.error(f&#39;count file missing for fov {cpl[1]}&#39;)
        else:
    
            counts1_df = pd.read_parquet(counts1_fpath)
            counts2_df = pd.read_parquet(counts2_fpath)

            count1_grp = counts1_df.loc[(counts1_df.channel == stitching_channel) &amp;
                                        (counts1_df.round_num == reference_round),:]
            count2_grp = counts2_df.loc[(counts2_df.channel == stitching_channel) &amp;
                                        (counts2_df.round_num == reference_round),:]
            count1_grp = counts1_df.loc[counts1_df.channel == stitching_channel,:]
            count2_grp = counts2_df.loc[counts2_df.channel == stitching_channel,:]
            
            overlap_count1 = get_all_dots_in_overlapping_regions(count1_grp, chunk_coords,stitching_selected=&#39;microscope_stitched&#39;)
            overlap_count2 = get_all_dots_in_overlapping_regions(count2_grp, chunk_coords,stitching_selected=&#39;microscope_stitched&#39;)
         
            if overlap_count1.empty or overlap_count2.empty:
                shift = np.array([1000,1000])
                registration[cpl] = [shift, np.nan]
                
            else:
                # TODO
                # Maybe add a selction step where if the number of beads is below X the beads based registration will be run or fft based
                # registration if the number of beads is high enough
                
                r_tl = chunk_coords[0]
                c_tl = chunk_coords[2]
                img_shape = np.array([np.abs(chunk_coords[1]-chunk_coords[0]),np.abs(chunk_coords[3]-chunk_coords[2])]).astype(&#39;int&#39;) + 1
                norm_ref_coords = overlap_count1.loc[:,[&#39;r_px_microscope_stitched&#39;,&#39;c_px_microscope_stitched&#39;]].to_numpy() -[r_tl, c_tl]
                norm_comp_coords =  overlap_count2.loc[:,[&#39;r_px_microscope_stitched&#39;,&#39;c_px_microscope_stitched&#39;]].to_numpy() -[r_tl, c_tl]
                img_ref = create_fake_image(img_shape, norm_ref_coords)
                img_tran = create_fake_image(img_shape, norm_comp_coords)
                shift, error, diffphase = register_translation(img_ref, img_tran)
                registration[cpl] = [shift, error]
    
            return registration




def register_cpl_fresh_nuclei(cpl: Tuple, chunk_coords: np.ndarray, order: dict, 
                              metadata:dict, experiment_fpath:str):
    &#34;&#34;&#34;Function to register orverlapping regions of nuclear staining for stitching

    Args:
        cpl (Tuple): overlapping tiles
        chunk_coords (np.ndarray): coords of the overlapping region [r_tl,r_br,c_tl,c_br]
        order (dict): description of the position of the tiles
        metadata (dict): dictionary with the general experiment data
        experiment_fpath (str): path to the experiment to process

    Returns:
        dict: registration output [shift, error]
    &#34;&#34;&#34;

    logger = selected_logger()
    registration = {}
    experiment_fpath = Path(experiment_fpath)
    img_width = metadata[&#39;img_width&#39;]
    img_height = metadata[&#39;img_height&#39;]
    experiment_name = metadata[&#39;experiment_name&#39;]
    error = 0
    
    filtered_nuclei_fpath = experiment_fpath / &#39;fresh_tissue&#39; / &#39;fresh_tissue_nuclei_preprocessed_img_data.zarr&#39;
    
    try:
        st = zarr.DirectoryStore(filtered_nuclei_fpath)
        root = zarr.group(store=st, overwrite=False)
    except:
        logger.error(f&#39;cannot load the zarr files with filtered nuclei&#39;)    
        
    else:
        try:
            img1 = root[experiment_name + &#39;_fresh_tissue_nuclei_fov_&#39; + str(cpl[0])][&#39;preprocessed_data_fov_&#39;+str(cpl[0])][...]
        except:
            logger.error(f&#39;image file cannot be loaded for nuclei of fov {cpl[0]}&#39;)   
            
        else:
            try:
                img2 = root[experiment_name + &#39;_fresh_tissue_nuclei_fov_&#39; + str(cpl[1])][&#39;preprocessed_data_fov_&#39;+str(cpl[1])][...]
            except:
                logger.error(f&#39;image file cannot be loaded for nuclei of fov {cpl[1]}&#39;)  
                
            else:

                img_shape = np.array([np.abs(chunk_coords[1]-chunk_coords[0]),np.abs(chunk_coords[3]-chunk_coords[2])]).astype(&#39;int&#39;)
                if order == {&#39;row_order&#39;: (&#39;top&#39;, &#39;bottom&#39;), &#39;column_order&#39;: (&#39;right&#39;, &#39;left&#39;)}:
                    img1_slice = img1[(img_height-img_shape[0]):img_height,0:img_shape[1]]
                    img2_slice = img2[0:img_shape[0],(img_width-img_shape[1]):img_width]
                elif order == {&#39;row_order&#39;: (&#39;top&#39;, &#39;bottom&#39;), &#39;column_order&#39;: (&#39;left&#39;, &#39;right&#39;)}:
                    img1_slice = img1[img_height-img_shape[0]:img_height,img_width-img_shape[1]:img_width]
                    img2_slice = img2[0:img_shape[0],0:img_shape[1]]
                elif order == {&#39;row_order&#39;: (&#39;bottom&#39;, &#39;top&#39;), &#39;column_order&#39;: (&#39;left&#39;, &#39;right&#39;)}:
                    img1_slice = img1[0:img_shape[0],img_width-img_shape[1]:img_width]
                    img2_slice = img2[img_height-img_shape[0]:img_height,0:img_shape[1]]
                elif order == {&#39;row_order&#39;: (&#39;bottom&#39;, &#39;top&#39;), &#39;column_order&#39;: (&#39;right&#39;, &#39;left&#39;)}:
                    img1_slice = img1[0:img_shape[0],0:img_shape[1]]
                    img2_slice = img2[img_height-img_shape[0]:img_height,img_width-img_shape[1]:img_width]
                else:
                    logger.error(f&#39;unknown fovs order&#39;)
                    error = 1
                
                if error:
                    shift = np.array([1000,1000])
                    registration[cpl] = [shift, np.nan]
                else:
                    shift, error, diffphase = register_translation(img1_slice, img2_slice)
                    registration[cpl] = [shift, error]
    
                return registration






def stitching_graph(experiment_fpath, stitching_channel,tiles_org, metadata, 
                    reference_round, client, nr_dim = 2):
    
    logger = selected_logger()
    unfolded_overlapping_regions_dict = {key:value for (k,v) in tiles_org.overlapping_regions.items() for (key,value) in v.items()}
    
    futures = []
    for cpl, chunk_coords in unfolded_overlapping_regions_dict.items():

        future = client.submit(register_cpl,cpl, chunk_coords, experiment_fpath,stitching_channel,
                            reference_round)

        futures.append(future)
    all_registrations = client.gather(futures)


    all_registrations = [reg for reg in all_registrations if reg ]
    all_registrations_dict = {}

    for output_dict in all_registrations:
        all_registrations_dict.update(output_dict)

    # Run registration only if there are not too many overlappig regions without 
    # dots
    
    # counts_cpls_missing_overlapping_dots = 0
    # cpls_missing_overlapping_dots = []
    # for cpl, registration_output in all_registrations_dict.items():
    #     if np.isnan(registration_output[1]):
    #         cpls_missing_overlapping_dots.append(cpl)
    #         counts_cpls_missing_overlapping_dots += 1
    
    # global_stitching_done = 0
    # if len(cpls_missing_overlapping_dots) &gt; 10:
    #     logger.error(f&#34;Too many cpl of fovs without overlapping reference dots&#34;)
    #     pickle.dump([cpls_missing_overlapping_dots,counts_cpls_missing_overlapping_dots ],
    #         open(experiment_fpath / &#39;results&#39; / &#39;fovs_without_overlapping_reference_dots_no_global_stitching.pkl&#39;,&#39;rb&#39;))
    #     global_stitching_done = 0
    #     return tiles_org.tile_corners_coords_pxl, global_stitching_done

    # else:
    #     global_stitching_done = 1
    #     logger.error(f&#34;The number of cpls of fovs without overlapping reference dots is low, test global stitching&#34;)
    #     pickle.dump([cpls_missing_overlapping_dots,counts_cpls_missing_overlapping_dots ],
    #         open(experiment_fpath / &#39;results&#39; / &#39;fovs_without_overlapping_reference_dots_yes_global_stitching.pkl&#39;,&#39;wb&#39;))

    overlapping_coords_reorganized = {}
    for idx, cpl_dict in tiles_org.overlapping_regions.items():
        overlapping_coords_reorganized.update(cpl_dict)

    all_registrations_removed_large_shift = {k:v for (k,v) in all_registrations_dict.items() if np.all(np.abs(v[0]) &lt; 20)}

    cpls = all_registrations_removed_large_shift.keys()
    # cpls = list(unfolded_overlapping_regions_dict.keys())
    total_cpls = len(cpls)
    nr_tiles = tiles_org.tile_corners_coords_pxl.shape[0]

    weights_err1 = np.zeros((total_cpls * nr_dim))
    weights_err2 = np.zeros((total_cpls * nr_dim))
    P = np.zeros(total_cpls * nr_dim)
    ZQ = np.zeros((total_cpls * nr_dim,nr_tiles * nr_dim))

    weights_err = np.zeros((total_cpls * nr_dim))
    for i, (a, b) in enumerate(cpls):
        shift = all_registrations_removed_large_shift[(a,b)][0]
        dr = shift[0]
        dc = shift[1]
        P[i * nr_dim] = dr
        P[i * nr_dim +1 ] = dc
        weights_err[i * nr_dim:i * nr_dim + nr_dim] = all_registrations_removed_large_shift[(a,b)][1]

    for i, (a, b) in enumerate(cpls):
        # Y row:
        Z = np.zeros((nr_tiles * nr_dim))
        Z[nr_dim * a:nr_dim * a + 1] = -1
        Z[nr_dim * b:nr_dim * b + 1] = 1
        ZQ[i * nr_dim, :] = Z
        # X row
        Z = np.zeros((nr_tiles * nr_dim))
        Z[nr_dim * a + 1:nr_dim * a + 2] = -1
        Z[nr_dim * b + 1:nr_dim * b + 2] = 1
        ZQ[i * nr_dim + 1, :] = Z

    lrg = linmod.LinearRegression(fit_intercept=False)
    lrg.fit(ZQ,P)
    global_translrg = lrg.coef_.reshape(nr_tiles, nr_dim)
    gb =  -1 * (-lrg.coef_.reshape((nr_tiles, nr_dim)) \
                                + lrg.coef_.reshape((nr_tiles, nr_dim))[0:1, :])
    global_shift = gb.astype(int)
    adjusted_coords = tiles_org.tile_corners_coords_pxl + global_shift

    # Determine shift of missing tiles

    out_level = 1000
    low = np.where(global_shift&lt; -out_level)[0]
    high = np.where(global_shift&gt; out_level)[0]
    low_high = np.hstack((low,high))

    missing_tiles_id = np.unique(low_high)
    missing_tiles_coords = tiles_org.tile_corners_coords_pxl[missing_tiles_id,:]

    if missing_tiles_coords.shape[0] &gt;0:
        coords_cl = np.delete(tiles_org.tile_corners_coords_pxl, missing_tiles_id, 0)
        ad_coords_cl = np.delete(adjusted_coords, missing_tiles_id, 0 )
        tst = linmod.LinearRegression(fit_intercept=False)
        tst.fit(coords_cl,ad_coords_cl)
        corrected_missing = tst.predict(missing_tiles_coords)

        for idx, tile_id in enumerate(missing_tiles_id):
            adjusted_coords[tile_id] = corrected_missing[idx]


    dec_fpath = (experiment_fpath / &#39;results&#39;).glob(&#39;*_decoded_fov*&#39;)
    for fpath in dec_fpath:
        global_stitched_decoded_df = stitch_using_coords_general(fpath,
                                    adjusted_coords,
                                    tiles_org.reference_corner_fov_position,
                                    metadata,
                                    &#39;global_stitched&#39;)
        if isinstance(global_stitched_decoded_df,pd.DataFrame):
            global_stitched_decoded_df.to_parquet(fpath)

    global_shift = tiles_org.tile_corners_coords_pxl - adjusted_coords
    pickle.dump(global_shift,open(experiment_fpath / &#39;results&#39;/ &#39;stitching_global_shift.pkl&#39;,&#39;wb&#39;))
    pickle.dump(adjusted_coords,open(experiment_fpath / &#39;results&#39;/ &#39;global_stitched_coords.pkl&#39;,&#39;wb&#39;))

    return adjusted_coords
    # return adjusted_coords, global_stitching_done


def stitching_graph_fresh_nuclei(experiment_fpath,tiles_org, metadata, 
                            client, nr_dim = 2):
    
    logger = selected_logger()
    unfolded_overlapping_regions_dict = {key:value for (k,v) in tiles_org.overlapping_regions.items() for (key,value) in v.items()}
    unfolded_overlapping_order_dict = {key:value for (k,v) in tiles_org.overlapping_order.items() for (key,value) in v.items()}


    futures = []
    for cpl, chunk_coords in unfolded_overlapping_regions_dict.items():

        future = client.submit(register_cpl_fresh_nuclei,cpl, chunk_coords, 
                            unfolded_overlapping_order_dict[cpl],
                            metadata,
                            experiment_fpath)

        futures.append(future)
    all_registrations = client.gather(futures)


    all_registrations = [reg for reg in all_registrations if reg ]
    all_registrations_dict = {}

    for output_dict in all_registrations:
        all_registrations_dict.update(output_dict)


    overlapping_coords_reorganized = {}
    for idx, cpl_dict in tiles_org.overlapping_regions.items():
        overlapping_coords_reorganized.update(cpl_dict)

    all_registrations_removed_large_shift = {k:v for (k,v) in all_registrations_dict.items() if np.all(np.abs(v[0]) &lt; 20)}

    cpls = all_registrations_removed_large_shift.keys()
    # cpls = list(unfolded_overlapping_regions_dict.keys())
    total_cpls = len(cpls)
    nr_tiles = tiles_org.tile_corners_coords_pxl.shape[0]

    weights_err1 = np.zeros((total_cpls * nr_dim))
    weights_err2 = np.zeros((total_cpls * nr_dim))
    P = np.zeros(total_cpls * nr_dim)
    ZQ = np.zeros((total_cpls * nr_dim,nr_tiles * nr_dim))

    weights_err = np.zeros((total_cpls * nr_dim))
    for i, (a, b) in enumerate(cpls):
        shift = all_registrations_removed_large_shift[(a,b)][0]
        dr = shift[0]
        dc = shift[1]
        P[i * nr_dim] = dr
        P[i * nr_dim +1 ] = dc
        weights_err[i * nr_dim:i * nr_dim + nr_dim] = all_registrations_removed_large_shift[(a,b)][1]

    for i, (a, b) in enumerate(cpls):
        # Y row:
        Z = np.zeros((nr_tiles * nr_dim))
        Z[nr_dim * a:nr_dim * a + 1] = -1
        Z[nr_dim * b:nr_dim * b + 1] = 1
        ZQ[i * nr_dim, :] = Z
        # X row
        Z = np.zeros((nr_tiles * nr_dim))
        Z[nr_dim * a + 1:nr_dim * a + 2] = -1
        Z[nr_dim * b + 1:nr_dim * b + 2] = 1
        ZQ[i * nr_dim + 1, :] = Z

    lrg = linmod.LinearRegression(fit_intercept=False)
    lrg.fit(ZQ,P)
    global_translrg = lrg.coef_.reshape(nr_tiles, nr_dim)
    gb =  -1 * (-lrg.coef_.reshape((nr_tiles, nr_dim)) \
                                + lrg.coef_.reshape((nr_tiles, nr_dim))[0:1, :])
    global_shift = gb.astype(int)
    adjusted_coords = tiles_org.tile_corners_coords_pxl + global_shift

    # Determine shift of missing tiles

    out_level = 1000
    low = np.where(global_shift&lt; -out_level)[0]
    high = np.where(global_shift&gt; out_level)[0]
    low_high = np.hstack((low,high))

    missing_tiles_id = np.unique(low_high)
    missing_tiles_coords = tiles_org.tile_corners_coords_pxl[missing_tiles_id,:]

    if missing_tiles_coords.shape[0] &gt;0:
        coords_cl = np.delete(tiles_org.tile_corners_coords_pxl, missing_tiles_id, 0)
        ad_coords_cl = np.delete(adjusted_coords, missing_tiles_id, 0 )
        tst = linmod.LinearRegression(fit_intercept=False)
        tst.fit(coords_cl,ad_coords_cl)
        corrected_missing = tst.predict(missing_tiles_coords)

        for idx, tile_id in enumerate(missing_tiles_id):
            adjusted_coords[tile_id] = corrected_missing[idx]


    dec_fpath = (experiment_fpath / &#39;fresh_tissue&#39;/ &#39;results&#39;).glob(&#39;*_decoded_fov*&#39;)
    for fpath in dec_fpath:
        global_stitched_decoded_df = stitch_using_coords_general(fpath,
                                    adjusted_coords,
                                    tiles_org.reference_corner_fov_position,
                                    metadata,
                                    &#39;global_stitched_nuclei&#39;)
        if isinstance(global_stitched_decoded_df,pd.DataFrame):
            global_stitched_decoded_df.to_parquet(fpath)

    global_shift = tiles_org.tile_corners_coords_pxl - adjusted_coords
    pickle.dump(global_shift,open(experiment_fpath / &#39;fresh_tissue&#39; /  &#39;results&#39;/ &#39;stitching_global_shift.pkl&#39;,&#39;wb&#39;))
    pickle.dump(adjusted_coords,open(experiment_fpath / &#39;fresh_tissue&#39; / &#39;results&#39;/ &#39;global_stitched_coords.pkl&#39;,&#39;wb&#39;))

    return adjusted_coords
    # return adjusted_coords, global_stitching_done



def stitching_graph_serial_nuclei(experiment_fpath,tiles_org, metadata, 
                                registration_reference_hybridization,
                                client, nr_dim = 2):
    
    logger = selected_logger()
    unfolded_overlapping_regions_dict = {key:value for (k,v) in tiles_org.overlapping_regions.items() for (key,value) in v.items()}
    unfolded_overlapping_order_dict = {key:value for (k,v) in tiles_org.overlapping_order.items() for (key,value) in v.items()}


    futures = []
    for cpl, chunk_coords in unfolded_overlapping_regions_dict.items():

        future = client.submit(register_cpl_fresh_nuclei,cpl, chunk_coords, 
                            unfolded_overlapping_order_dict[cpl],
                            metadata,
                            experiment_fpath)

        futures.append(future)
    all_registrations = client.gather(futures)


    all_registrations = [reg for reg in all_registrations if reg ]
    all_registrations_dict = {}

    for output_dict in all_registrations:
        all_registrations_dict.update(output_dict)


    overlapping_coords_reorganized = {}
    for idx, cpl_dict in tiles_org.overlapping_regions.items():
        overlapping_coords_reorganized.update(cpl_dict)

    all_registrations_removed_large_shift = {k:v for (k,v) in all_registrations_dict.items() if np.all(np.abs(v[0]) &lt; 20)}

    cpls = all_registrations_removed_large_shift.keys()
    # cpls = list(unfolded_overlapping_regions_dict.keys())
    total_cpls = len(cpls)
    nr_tiles = tiles_org.tile_corners_coords_pxl.shape[0]

    weights_err1 = np.zeros((total_cpls * nr_dim))
    weights_err2 = np.zeros((total_cpls * nr_dim))
    P = np.zeros(total_cpls * nr_dim)
    ZQ = np.zeros((total_cpls * nr_dim,nr_tiles * nr_dim))

    weights_err = np.zeros((total_cpls * nr_dim))
    for i, (a, b) in enumerate(cpls):
        shift = all_registrations_removed_large_shift[(a,b)][0]
        dr = shift[0]
        dc = shift[1]
        P[i * nr_dim] = dr
        P[i * nr_dim +1 ] = dc
        weights_err[i * nr_dim:i * nr_dim + nr_dim] = all_registrations_removed_large_shift[(a,b)][1]

    for i, (a, b) in enumerate(cpls):
        # Y row:
        Z = np.zeros((nr_tiles * nr_dim))
        Z[nr_dim * a:nr_dim * a + 1] = -1
        Z[nr_dim * b:nr_dim * b + 1] = 1
        ZQ[i * nr_dim, :] = Z
        # X row
        Z = np.zeros((nr_tiles * nr_dim))
        Z[nr_dim * a + 1:nr_dim * a + 2] = -1
        Z[nr_dim * b + 1:nr_dim * b + 2] = 1
        ZQ[i * nr_dim + 1, :] = Z

    lrg = linmod.LinearRegression(fit_intercept=False)
    lrg.fit(ZQ,P)
    global_translrg = lrg.coef_.reshape(nr_tiles, nr_dim)
    gb =  -1 * (-lrg.coef_.reshape((nr_tiles, nr_dim)) \
                                + lrg.coef_.reshape((nr_tiles, nr_dim))[0:1, :])
    global_shift = gb.astype(int)
    adjusted_coords = tiles_org.tile_corners_coords_pxl + global_shift

    # Determine shift of missing tiles

    out_level = 1000
    low = np.where(global_shift&lt; -out_level)[0]
    high = np.where(global_shift&gt; out_level)[0]
    low_high = np.hstack((low,high))

    missing_tiles_id = np.unique(low_high)
    missing_tiles_coords = tiles_org.tile_corners_coords_pxl[missing_tiles_id,:]

    if missing_tiles_coords.shape[0] &gt;0:
        coords_cl = np.delete(tiles_org.tile_corners_coords_pxl, missing_tiles_id, 0)
        ad_coords_cl = np.delete(adjusted_coords, missing_tiles_id, 0 )
        tst = linmod.LinearRegression(fit_intercept=False)
        tst.fit(coords_cl,ad_coords_cl)
        corrected_missing = tst.predict(missing_tiles_coords)

        for idx, tile_id in enumerate(missing_tiles_id):
            adjusted_coords[tile_id] = corrected_missing[idx]


    dec_fpath = (experiment_fpath / &#39;results&#39;).glob(&#39;*_decoded_fov*&#39;)
    for fpath in dec_fpath:
        global_stitched_decoded_df = stitch_using_coords_general(fpath,
                                    adjusted_coords,
                                    tiles_org.reference_corner_fov_position,
                                    metadata,
                                    &#39;global_stitched_nuclei&#39;)
        if isinstance(global_stitched_decoded_df,pd.DataFrame):
            global_stitched_decoded_df.to_parquet(fpath)

    global_shift = tiles_org.tile_corners_coords_pxl - adjusted_coords
    pickle.dump(global_shift,open(experiment_fpath / &#39;results&#39;/ &#39;stitching_global_shift.pkl&#39;,&#39;wb&#39;))
    pickle.dump(adjusted_coords,open(experiment_fpath / &#39;results&#39;/ &#39;global_stitched_coords.pkl&#39;,&#39;wb&#39;))

    return adjusted_coords
    # return adjusted_coords, global_stitching_done










def stitched_beads_on_nuclei_fresh_tissue(experiment_fpath:str,
                                      client,
                                      nuclei_tag:str=&#39;_ChannelCy3_Nuclei_&#39;,
                                      beads_tag:str=&#39;_ChannelEuropium_Cy3_&#39;,
                                      round_num:int = 1,
                                      overlapping_percentage:int=5,
                                      machine:str=&#39;ROBOFISH2&#39;
                                     ):
    &#34;&#34;&#34;Function tun run the stitching of the dots in the fresh images using 
    the nuclei images as reference

    Args:
        experiment_fpath (str): path of the experiment to process
        client ([type]): dask client for parallel processing
        nuclei_tag (str, optional): Tag to identify the nuclei dataset. Defaults to &#39;_ChannelCy3_Nuclei_&#39;.
        beads_tag (str, optional): Tag to identify the beads dataset. Defaults to &#39;_ChannelEuropium_Cy3_&#39;.
        round_num (int, optional): Reference round,for the fresh tissue there is only one. Defaults to 1.
        overlapping_percentage (int, optional): Overlapping between the different tiles. Defaults to 5.
        machine (str, optional): machine running the experiment. Defaults to &#39;ROBOFISH2&#39;.
    &#34;&#34;&#34;
    experiment_fpath = Path(experiment_fpath)
    fresh_tissue_path = experiment_fpath / &#39;fresh_tissue&#39;
    beads_dataset_fpath = list(fresh_tissue_path.glob(&#39;*&#39;+ beads_tag +&#39;*.parquet&#39;))[0]
    nuclei_dataset_fpath = list(fresh_tissue_path.glob(&#39;*&#39;+ nuclei_tag +&#39;*.parquet&#39;))[0]
    
    # Collect and adjust beads dataset with missing values
    beads_data = Dataset()
    beads_data.load_dataset(beads_dataset_fpath)
    beads_data.dataset[&#39;processing_type&#39;] = &#39;undefined&#39;
    beads_data.dataset[&#39;overlapping_percentage&#39;] = overlapping_percentage / 100
    beads_data.dataset[&#39;machine&#39;] = machine

    metadata_beads = beads_data.collect_metadata(beads_data.dataset)
    beads_org_tiles = organize_square_tiles(experiment_fpath,beads_data.dataset,metadata_beads,round_num)
    beads_org_tiles.run_tiles_organization()
    flist = list((fresh_tissue_path / &#39;results&#39;).glob(&#39;*decoded_fov*.parquet&#39;))

    # duplicate registered
    for fpath in flist:
        data = pd.read_parquet(fpath)
        data[&#39;r_px_registered&#39;] = data[&#39;r_px_original&#39;]
        data[&#39;c_px_registered&#39;] = data[&#39;c_px_original&#39;]
        data[&#39;hamming_distance&#39;] = 0
        data[&#39;decoded_genes&#39;] = &#39;beads&#39;
        data.to_parquet(fpath)


    all_futures = []
    for fpath in flist:
        future = client.submit(stitch_using_coords_general, fpath,
                                              beads_org_tiles.tile_corners_coords_pxl,
                                              beads_org_tiles.reference_corner_fov_position,
                                              metadata_beads,tag=&#39;microscope_stitched&#39;)

        all_futures.append(future)
    _ = client.gather(all_futures)

    io.simple_output_plotting(fresh_tissue_path,
                              stitching_selected= &#39;microscope_stitched&#39;,
                             selected_Hdistance=0,
                             client = client,
                             input_file_tag = &#39;decoded_fov&#39;,
                             file_tag = &#39;stitched_microscope&#39;)


    # Collect and adjust nuclei dataset with missing values
    nuclei_data = Dataset()
    nuclei_data.load_dataset(nuclei_dataset_fpath)
    nuclei_data.dataset[&#39;processing_type&#39;] = &#39;undefined&#39;
    nuclei_data.dataset[&#39;overlapping_percentage&#39;] = overlapping_percentage / 100
    nuclei_data.dataset[&#39;machine&#39;] = machine

    metadata_nuclei = nuclei_data.collect_metadata(nuclei_data.dataset)
    nuclei_org_tiles = organize_square_tiles(experiment_fpath,nuclei_data.dataset,metadata_nuclei,round_num)
    nuclei_org_tiles.run_tiles_organization()

    _ =stitching_graph_fresh_nuclei(experiment_fpath,nuclei_org_tiles, metadata_nuclei, 
                                client, nr_dim = 2)


    io.simple_output_plotting(fresh_tissue_path,
                              stitching_selected= &#39;global_stitched_nuclei&#39;,
                             selected_Hdistance=0,
                             client = client,
                             input_file_tag = &#39;decoded_fov&#39;,
                             file_tag = &#39;global_stitched_nuclei&#39;)








# REMOVED OVERLAPPING DOTS ACCORDING TO FOV (MUCH FASTER THAN FOR GENE)
# EXPECIALLY FOR LARGE AREAS WITH A LOT OF COUNTS


def identify_duplicated_dots_NNDescend(ref_tiles_df: pd.DataFrame,comp_tiles_df: pd.DataFrame,
                    stitching_selected: str,same_dot_radius: int)-&gt; list:
    &#34;&#34;&#34;Function used to identify duplicated dots for a gene in the overlapping regions. This
    version of the function uses the fast nearest neighbor coded in NNDescend

    Args:
        ref_tiles_df (pd.DataFrame): Counts of the reference tiles
        comp_tiles_df (pd.DataFrame): Counts in the comparing tiles
        stitching_selected (str): String that identify the coords of the pixels
            according to the stitching used to process the data
        same_dot_radius (int): searching radius used to define if two dots are
            the same

    Returns:
        list: dot ids to remove
    &#34;&#34;&#34;
    
    r_tag = &#39;r_px_&#39; + stitching_selected
    c_tag = &#39;c_px_&#39; + stitching_selected

    overlapping_ref_coords = ref_tiles_df.loc[:, [r_tag,c_tag]].to_numpy()
    overlapping_comp_coords = comp_tiles_df.loc[:, [r_tag,c_tag]].to_numpy()
    dots_ids = comp_tiles_df.loc[:, [&#39;dot_id&#39;]].to_numpy()
    index = NNDescent(overlapping_ref_coords,metric=&#39;euclidean&#39;,n_neighbors=1)
    indices, dists = index.query(overlapping_comp_coords,k=1)
    idx_dists = np.where(dists &lt; same_dot_radius)[0]
    dots_id_to_remove = dots_ids[idx_dists]
    dots_id_to_remove = list(dots_id_to_remove.reshape(dots_id_to_remove.shape[0],))
    return dots_id_to_remove

def identify_duplicated_dots_sklearn(ref_tiles_df: pd.DataFrame,comp_tiles_df: pd.DataFrame,
                    stitching_selected: str,same_dot_radius: int)-&gt; list:
    &#34;&#34;&#34;Function used to identify duplicated dots for a gene in the overlapping regions. This
    version of the function uses the fast nearest neighbor coded in NNDescend

    Args:
        ref_tiles_df (pd.DataFrame): Counts of the reference tiles
        comp_tiles_df (pd.DataFrame): Counts in the comparing tiles
        stitching_selected (str): String that identify the coords of the pixels
            according to the stitching used to process the data
        same_dot_radius (int): searching radius used to define if two dots are
            the same
    Returns:
        list: dot ids to remove
    &#34;&#34;&#34;
    nn = NearestNeighbors(n_neighbors=1,radius=same_dot_radius, metric=&#39;euclidean&#39;,algorithm=&#39;kd_tree&#39;)
    
    r_tag = &#39;r_px_&#39; + stitching_selected
    c_tag = &#39;c_px_&#39; + stitching_selected
    
    overlapping_ref_coords = ref_tiles_df.loc[:, [r_tag,c_tag]].to_numpy()
    overlapping_comp_coords = comp_tiles_df.loc[:, [r_tag,c_tag]].to_numpy()
    dots_ids = comp_tiles_df.loc[:, [&#39;dot_id&#39;]].to_numpy()
    nn.fit(overlapping_ref_coords)
    dists, indices = nn.kneighbors(overlapping_comp_coords, return_distance=True)
    idx_dists = np.where(dists &lt;= same_dot_radius)[0]
    dots_id_to_remove = dots_ids[idx_dists]
    dots_id_to_remove = list(dots_id_to_remove.reshape(dots_id_to_remove.shape[0],))
    
    return dots_id_to_remove

def remove_overlapping_dots_fov(cpl: Tuple[int,int], chunk_coords: np.ndarray, 
                    experiment_fpath: str, stitching_selected:str,
                    hamming_distance: float, same_dot_radius: int)-&gt; Dict[Tuple[int,int],List[str]]:
    &#34;&#34;&#34;Function that identify the overlapping dots between two different tiles. The duplicated dots
    for all genes are identified

    Args:
        cpl (Tuple[int,int]): Adjacent tiles to compare
        chunk_coords (np.ndarray): Coords of the overlapping regions between the two tiles to compare
        experiment_fpath (str): Path to the experiment to process
        stitching_selected (str): String that identify the coords of the pixels
            according to the stitching used to process the data
        hamming_distance (float): Selected distance from the code
        same_dot_radius (int): searching radius used to define if two dots are
            the same

    Returns:
        Dict[Tuple[int,int],List[str]]: {cpl:all_dots_id_to_remove}
    &#34;&#34;&#34;

    logger = selected_logger()
    all_dots_id_to_remove = []
    experiment_fpath = Path(experiment_fpath)
    
    try:
        counts1_fpath = list((experiment_fpath / &#39;results&#39;).glob(&#39;*decoded*_fov_&#39; + str(cpl[0]) + &#39;.parquet&#39;))[0]
    except:
        logger.error(f&#39;count file missing for fov {cpl[0]}&#39;)
    
    else:
        try:
            counts2_fpath = list((experiment_fpath / &#39;results&#39;).glob(&#39;*decoded*_fov_&#39; + str(cpl[1]) + &#39;.parquet&#39;))[0]
        except:
            logger.error(f&#39;count file missing for fov {cpl[1]}&#39;)
        else:
    
            counts1_df = pd.read_parquet(counts1_fpath)
            counts2_df = pd.read_parquet(counts2_fpath)

            count1_grp = counts1_df.loc[counts1_df.hamming_distance &lt; hamming_distance,:]
            count2_grp = counts2_df.loc[counts2_df.hamming_distance &lt; hamming_distance,:]
            
            overlap_count1 = get_all_dots_in_overlapping_regions(counts1_df, chunk_coords, 
                            stitching_selected)
            overlap_count2 = get_all_dots_in_overlapping_regions(counts2_df, chunk_coords, 
                            stitching_selected)
            


            count1_grp = overlap_count1.groupby(&#39;decoded_genes&#39;)
            count2_grp = overlap_count2.groupby(&#39;decoded_genes&#39;)
            
            for gene, over_c1_df in count1_grp:
                try:
                    over_c2_df = count2_grp.get_group(gene)
                except:
                    pass
                else:
                    dots_id_to_remove = identify_duplicated_dots_sklearn(over_c1_df,over_c2_df,
                                                                stitching_selected,same_dot_radius)
                    if len(dots_id_to_remove):
                        all_dots_id_to_remove.append(dots_id_to_remove)
            all_dots_id_to_remove = [el for tg in all_dots_id_to_remove for el in tg]
            return {cpl:all_dots_id_to_remove}

def clean_from_duplicated_dots(fov: int, dots_id_to_remove: list, experiment_fpath: str,
                                tag_cleaned_file:str):
    &#34;&#34;&#34;Function to remove the dulicated dots.

    Args:
        fov (int): Field of view to process
        dots_id_to_remove (str): ids of the duplicated dots
        experiment_fpath (str): Path to the experiment to process
        tag_cleaned_file (str): tag name of the file with cleaned counts
    &#34;&#34;&#34;
    logger = selected_logger()
    experiment_fpath = Path(experiment_fpath)
    try:
        fname = list((experiment_fpath / &#39;results&#39;).glob(&#39;*_decoded_fov_&#39; + str(fov) + &#39;.parquet&#39;))[0]
    except:
        logger.error(f&#39;missing decoded file for fov {fov}&#39;)
    else:
        save_name = fname.stem.split(&#39;_decoded_fov_&#39;)[0] + &#39;_&#39;+ tag_cleaned_file +&#39;_cleaned_df_fov_&#39; + str(fov) + &#39;.parquet&#39;
        save_name = experiment_fpath / &#39;results&#39; / save_name
        if len(dots_id_to_remove):
            try:
                counts_df = pd.read_parquet(fname)
                logger.error(f&#39;loaded {fname}&#39;)
                
            except:
                logger.error(f&#39;missing {fname}&#39;)
            else:
                cleaned_df = counts_df.loc[~counts_df.dot_id.isin(dots_id_to_remove), :]
                cleaned_df.to_parquet(save_name,index=False)
                logger.error(f&#39;saved {fname}&#39;)

                save_name = fname.stem.split(&#39;_decoded_fov_&#39;)[0] + tag_cleaned_file + &#39;_removed_df_fov_&#39; + str(fov) + &#39;.parquet&#39;
                save_name = experiment_fpath / &#39;results&#39; / save_name
                removed_df = counts_df.loc[counts_df.dot_id.isin(dots_id_to_remove), :]
                removed_df.to_parquet(save_name,index=False)
        else:
            try:
                _ = shutil.copy2(fname.as_posix(),save_name.as_posix())
                logger.error(f&#39;copied {fname}&#39;)
            except:
                logger.error(f&#39;cannot copy {fname} to {save_name}&#39;)



&#34;&#34;&#34;
    The overlapping dots are not removed right after being identified
    to avoid race conditions
    &#34;&#34;&#34;
def remove_duplicated_dots_graph(experiment_fpath: str,dataset: pd.DataFrame,
                                tiles_org, hamming_distance: float,
                                same_dot_radius: int, 
                                stitching_selected: str, client):
    &#34;&#34;&#34;Dask task graph builder/runner function to parallel remove duplicated dots
    The overlapping dots are not removed right after being identified
    because the same fov can be part of two different overlapping couples.

    Args:
        experiment_fpath (str): Path to the experiment to process
        dataset (pd.DataFrame): Properties of the images of the experiment
        tiles_org ([type]): Organization of the tiles 
        hamming_distance (float): Selected distance from the code
        same_dot_radius (int): searching radius used to define if two dots are
            the same
        stitching_selected (str): String that identify the coords of the pixels
            according to the stitching used to process the data
        client (dask.distributed.Client): Dask client in charge of controlling
            the processing of the task graph.
        tag_cleaned_file (str): tag name of the file with cleaned counts
    &#34;&#34;&#34;
    
    logger = selected_logger()
    fovs = dataset.loc[:,&#39;fov_num&#39;].unique()
    unfolded_overlapping_regions_dict = {key:value for (k,v) in tiles_org.overlapping_regions.items() for (key,value) in v.items()}

    # Prepare the dataframe
    r_tag = &#39;r_px_&#39; + stitching_selected
    c_tag = &#39;c_px_&#39; + stitching_selected

    all_futures = []

    for cpl,chunk_coords in unfolded_overlapping_regions_dict.items():
        future = client.submit(remove_overlapping_dots_fov,
                                cpl = cpl,
                                chunk_coords=chunk_coords,
                                experiment_fpath=experiment_fpath,
                                stitching_selected=stitching_selected,
                                hamming_distance=hamming_distance,
                                same_dot_radius = same_dot_radius)

        all_futures.append(future)

    to_remove = client.gather(all_futures)  
    to_remove_comb = {k: v for d in to_remove for k, v in d.items()}

    removed_dot_dict = {}
    for key, items in to_remove_comb.items():
        if key[1] not in removed_dot_dict.keys():
            removed_dot_dict[key[1]] = []
        removed_dot_dict[key[1]].append(items)
    
    for key, items in removed_dot_dict.items():
        removed_dot_dict[key] = [el for tg in items for el in tg]

    for fov,dots_id_to_remove in removed_dot_dict.items():
        future = client.submit(clean_from_duplicated_dots,
                                fov = fov,
                                dots_id_to_remove=dots_id_to_remove,
                                experiment_fpath=experiment_fpath,
                                tag_cleaned_file=stitching_selected)

        all_futures.append(future)

    _ = client.gather(all_futures)




# TODO Remove functions


def stitch_using_coords_general_df(decoded_df,tile_corners_coords_pxl,reference_corner_fov_position, metadata,tag):
    &#34;&#34;&#34;
    Tiles are placed directly on the position indicated by the microscope
    coords
    &#34;&#34;&#34;



    if decoded_df[&#39;r_px_registered&#39;].empty:
        decoded_df[&#39;r_px_&#39;+tag] = np.nan
        decoded_df[&#39;c_px_&#39;+tag] = np.nan
    else:

        fov = decoded_df.iloc[0][&#39;fov_num&#39;]
        r_microscope_coords = tile_corners_coords_pxl[fov,0]
        c_microscope_coords = tile_corners_coords_pxl[fov,1]
        
        if reference_corner_fov_position == &#39;top-left&#39;:
            decoded_df[&#39;r_px_&#39;+tag] =  r_microscope_coords + decoded_df[&#39;r_px_registered&#39;]
            decoded_df[&#39;c_px_&#39;+tag] =  c_microscope_coords + decoded_df[&#39;c_px_registered&#39;]

        elif reference_corner_fov_position == &#39;top-right&#39;:
            decoded_df[&#39;r_px_&#39;+tag] =  r_microscope_coords + decoded_df[&#39;r_px_registered&#39;]
            decoded_df[&#39;c_px_&#39;+tag] =  c_microscope_coords - (metadata[&#39;img_width&#39;] - decoded_df[&#39;c_px_registered&#39;])

        elif reference_corner_fov_position == &#39;bottom_left&#39;:
            decoded_df[&#39;r_px_&#39;+tag] =  r_microscope_coords + (metadata[&#39;img_height&#39;] - decoded_df[&#39;r_px_registered&#39;])
            decoded_df[&#39;c_px_&#39;+tag] =  c_microscope_coords + decoded_df[&#39;c_px_registered&#39;]
    # if decoded_df[&#39;r_px_registered&#39;].empty:
    #     decoded_df[&#39;r_px_microscope_stitched&#39;] = np.nan
    #     decoded_df[&#39;c_px_microscope_stitched&#39;] = np.nan
    # else:
    #     fov = decoded_df.iloc[0][&#39;fov_num&#39;]
    #     r_microscope_coords = tile_corners_coords_pxl[fov,0]
    #     c_microscope_coords = tile_corners_coords_pxl[fov,1]
    #     decoded_df[&#39;r_px_microscope_stitched&#39;] =  r_microscope_coords - decoded_df[&#39;r_px_registered&#39;]
    #     decoded_df[&#39;c_px_microscope_stitched&#39;] =  c_microscope_coords - decoded_df[&#39;c_px_registered&#39;]

        # new room
        # decoded_df[&#39;r_px_microscope_stitched&#39;] =  r_microscope_coords + decoded_df[&#39;r_px_registered&#39;]
        # decoded_df[&#39;c_px_microscope_stitched&#39;] =  c_microscope_coords + decoded_df[&#39;c_px_registered&#39;]
    return decoded_df




# REMOVE OVERLAPPING DOTS ACCORDING TO GENE
# preprocessing and removal part to put in the flow file

# all_files = (Path(experiment_fpath) / &#39;tmp&#39; / &#39;registered_counts&#39;).glob(&#39;*decoded*.parquet&#39;)
# counts_dd_list = [dd.read_parquet(counts_file) for counts_file in all_files]
# counts_dd = dd.concat(counts_dd_list, axis=0)
# counts_dd = counts_dd.loc[counts_dd.dot_id == counts_dd.barcode_reference_dot_id,[&#39;barcode_reference_dot_id&#39;,
#                                                                                     r_tag, c_tag, select_genes, 
#                                                                                     &#39;fov_num&#39;]]
# counts_df = counts_dd.dropna(subset=[select_genes]).compute()
# grpd = counts_df.groupby(select_genes)

# all_futures = []

# for gene, count_df in grpd:
#     future = client.submit(remove_overlapping_dots_from_gene,
#                             experiment_fpath = experiment_fpath,
#                             counts_df=counts_df,
#                             unfolded_overlapping_regions_dict=corrected_overlapping_regions_dict,
#                             stitching_selected=stitching_selected,
#                             gene = gene,
#                             same_dot_radius = same_dot_radius)
    
#     all_futures.append(future)

def get_dots_in_overlapping_regions(counts_df, unfolded_overlapping_regions_dict, 
                       stitching_selected, gene):    
    r_tag = &#39;r_px_&#39; + stitching_selected
    c_tag = &#39;c_px_&#39; + stitching_selected
    
    ref_tiles_df = pd.DataFrame(columns=counts_df.columns)
    comp_tiles_df = pd.DataFrame(columns=counts_df.columns)
    
    
    grpd_df = counts_df.groupby(&#39;fov_num&#39;)
    list_fov = list(grpd_df.groups.keys())
    
    for cpl, chunk_coords in unfolded_overlapping_regions_dict.items():
        
        if (cpl[0] in list_fov) and (cpl[1] in list_fov):
            r_tl = chunk_coords[0]
            r_br = chunk_coords[1]
            c_tl = chunk_coords[2]
            c_br = chunk_coords[3]

            barcoded_ref_df = grpd_df.get_group(cpl[0])
            barcoded_comp_df = grpd_df.get_group(cpl[1])

            overlapping_ref_df = barcoded_ref_df.loc[(barcoded_ref_df[r_tag] &gt; r_tl) &amp; (barcoded_ref_df[r_tag] &lt; r_br) 
                                               &amp; (barcoded_ref_df[c_tag] &gt; c_tl) &amp; (barcoded_ref_df[c_tag] &lt; c_br),:]


            overlapping_comp_df = barcoded_comp_df.loc[(barcoded_comp_df[r_tag] &gt; r_tl) &amp; (barcoded_comp_df[r_tag] &lt; r_br) 
                                               &amp; (barcoded_comp_df[c_tag] &gt; c_tl) &amp; (barcoded_comp_df[c_tag] &lt; c_br),:]


            ref_tiles_df = ref_tiles_df.append(overlapping_ref_df)
            comp_tiles_df = comp_tiles_df.append(overlapping_comp_df)
        
    return ref_tiles_df, comp_tiles_df


def identify_duplicated_dots(ref_tiles_df,comp_tiles_df,stitching_selected,same_dot_radius):
    
    r_tag = &#39;r_px_&#39; + stitching_selected
    c_tag = &#39;c_px_&#39; + stitching_selected

    overlapping_ref_coords = ref_tiles_df.loc[:, [r_tag,c_tag]].to_numpy()
    overlapping_comp_coords = comp_tiles_df.loc[:, [r_tag,c_tag]].to_numpy()
    dots_ids = comp_tiles_df.loc[:, [&#39;dot_id&#39;]].to_numpy()
    index = NNDescent(overlapping_ref_coords,metric=&#39;euclidean&#39;,n_neighbors=1)
    indices, dists = index.query(overlapping_comp_coords,k=1)
    idx_dists = np.where(dists &lt; same_dot_radius)[0]
    dots_id_to_remove = dots_ids[idx_dists]
    dots_id_to_remove = list(dots_id_to_remove.reshape(dots_id_to_remove.shape[0],))
    return dots_id_to_remove


def remove_overlapping_dots_from_gene(experiment_fpath,counts_df,unfolded_overlapping_regions_dict,
                                    stitching_selected,gene,same_dot_radius):

    experiment_fpath = Path(experiment_fpath)
    ref_tiles_df, comp_tiles_df = get_dots_in_overlapping_regions(counts_df,unfolded_overlapping_regions_dict, 
                       stitching_selected, gene)
    dots_id_to_remove = identify_duplicated_dots(ref_tiles_df,comp_tiles_df,stitching_selected,same_dot_radius)
    cleaned_df = counts_df.loc[~counts_df.barcode_reference_dot_id.isin(dots_id_to_remove), :]
    fpath = experiment_fpath / &#39;results&#39; / (experiment_fpath.stem + &#39;_&#39; + gene +&#39;_counts.parquet&#39;)
    cleaned_df.to_parquet(fpath,index=False)





class r_c_chunking():
    &#34;&#34;&#34;
    Utility class used to chunk and arbitrary region and obtain the coords if the chunks.
    The chunking can be different between row and 
    columns

    Parameters:
    -----------

    region_dimensions: np.ndarray
        number of rows and columns of the region to chunk
    r_chunk_size: float
        size of the chunks along the rows
    c_chunk_size: float
        size of the chunks along the columns
    tl_coords: np.ndarray
        coordinate of the top left corner of the region to chunk
        to use to calculate the coords of the chunks

    &#34;&#34;&#34;

    def __init__(self, region_dimensions, r_chunk_size, c_chunk_size, tl_coords):
        self.region_dimensions = region_dimensions
        self.r_chunk_size = r_chunk_size
        self.c_chunk_size = c_chunk_size
        self.tl_coords = tl_coords
    

    @staticmethod
    def block_chunks_calculator(dimension,chunk_size):
        &#34;&#34;&#34;
        Helper function to calculate the size of the chunks created according
        the length of the vector and the chunk size.

        Parameters:
        -----------

        dimension: int
            Length of the vector to Chunk
        chunkSize: int 
            Dimension of the Chunks

        Returns:
        -----------

        chunks_sizes: np.array 
            Array of the sizes of the created chunks. It deals with conditions 
            when the expected chunks size do not fit an even number of times in the 
            dimension
        &#34;&#34;&#34;
        number_even_chunks=int(dimension//chunk_size)
        total_size_even_chunks=number_even_chunks*chunk_size
        odd_tile_size=dimension-total_size_even_chunks
        chunk_sizes=[]
        chunks_sizes=list(np.repeat(chunk_size,number_even_chunks-1))
        if odd_tile_size &lt; chunk_size:
            chunks_sizes.append(chunk_size+odd_tile_size)
        else:
            chunks_sizes.append(odd_tile_size)
        return tuple(chunks_sizes)
    
    def block_chunking(self):
        &#34;&#34;&#34;
        Function used to generate the coords of the images according to the
        chunking 

        Notes:
        ------

        For both lists each np.array contains the coords in the following order:
        [row_tl,row_br,col_tl,col_br]

        &#34;&#34;&#34;
        num_r,num_c = self.region_dimensions
        self.starting_position = self.tl_coords
        self.end_position = self.tl_coords + self.region_dimensions

        # Calculate the size of the chunks
        r_chunks_size = self.block_chunks_calculator(num_r,self.r_chunk_size)
        
        c_chunks_size = self.block_chunks_calculator(num_c,self.c_chunk_size)
        
        # Calculate the total numbers of chunks
        nr_chunks = len(r_chunks_size)
        
        nc_chunks = len(c_chunks_size)
       


        # Coords top left corner (tl)
        if nr_chunks == 1:
            r_coords_tl = self.starting_position[0]
        else: 
            r_coords_tl = [self.starting_position[0]]
            for i in np.arange(1,nr_chunks):
                r_coords_tl.append(r_coords_tl[i-1] + self.r_chunk_size )
            r_coords_tl = np.array(r_coords_tl)
            # r_coords_tl = np.arange(self.starting_position[0],(self.starting_position[0]+self.r_chunk_size*(nr_chunks)),self.r_chunk_size)
            
        if nc_chunks == 1:
            c_coords_tl = self.starting_position[1]
        else:
            c_coords_tl = [self.starting_position[1]]
            for i in np.arange(1,nc_chunks):
                c_coords_tl.append(c_coords_tl[i-1] + self.c_chunk_size )
            c_coords_tl = np.array(c_coords_tl)

            # c_coords_tl = np.arange(self.starting_position[1],(self.starting_position[1]+self.c_chunk_size*(nc_chunks)),self.c_chunk_size)

        
        # Coords of all the tl in the image
        r_coords_tl_all,c_coords_tl_all = np.meshgrid(r_coords_tl,c_coords_tl,indexing=&#39;ij&#39;)
        self.coords_all_to_test = [r_coords_tl_all,c_coords_tl_all]
        # Calculate all the br coords
        r_coords_br_all = r_coords_tl_all.copy()
        c_coords_br_all = c_coords_tl_all.copy()

        for c in np.arange(0,r_coords_tl_all.shape[1]):
            r_coords_br_all[:,c] = r_coords_br_all[:,c]+r_chunks_size

        for r in np.arange(0,r_coords_tl_all.shape[0]):
             c_coords_br_all[r,:] = c_coords_br_all[r,:]+c_chunks_size

        
        # The coords list are generated as:
        # row_tl,row_br,col_tl,col_br


        # Create a list for the padded coords
        self.coords_chunks_list = list()
        for r in np.arange(0,r_coords_tl_all.shape[0]):
            for c in np.arange(0,r_coords_tl_all.shape[1]):
                self.coords_chunks_list.append(np.array([r_coords_tl_all[r][c],\
                                                           r_coords_br_all[r][c],\
                                                           c_coords_tl_all[r][c],\
                                                           c_coords_br_all[r][c]])) 
    


class triangles_based_dots_stitching():
    &#34;&#34;&#34;
    Class used to register the different rounds by searaching and
    matching all possible triangles formed by the dots in the reference
    and translated image. This function run only a registration to the reference
    round
    
    The calculation of the triangle is based on list processing and may 
    be improved in ported to numpy.
    https://stackoverflow.com/questions/43126580/match-set-of-x-y-points-to-another-set-that-is-scaled-rotated-translated-and

    &#34;&#34;&#34;

    
    def __init__(self, ref_overlapping_counts, comp_overlapping_counts, chunk_coords):
        self.ref_overlapping_counts = ref_overlapping_counts
        self.comp_overlapping_counts = comp_overlapping_counts
        self.chunk_coords = chunk_coords
        
        self.r_tl = self.chunk_coords[0]
        self.r_br = self.chunk_coords[1]
        self.c_tl = self.chunk_coords[2]
        self.c_br = self.chunk_coords[3]
        
        
        num_r = np.abs(np.abs(self.r_tl) - np.abs(self.r_br))
        num_c = np.abs(np.abs(self.c_tl) - np.abs(self.c_br))
        self.overlapping_region_dimensions = np.array([num_r,num_c])
        
        if num_r &gt; num_c:
            self.chunk_search_ax = &#39;r&#39;
            self.r_chunk_size = num_c
            self.c_chunk_size = num_c
            self.max_chunk_size = num_r
        else:
            self.chunk_search_ax = &#39;c&#39;
            self.r_chunk_size = num_r
            self.c_chunk_size = num_r
            self.max_chunk_size = num_c
        
        self.min_dots_chunk = 6
        self.min_error_triangles = 1
        self.max_dots = 12
        self.logger = logging.getLogger(__name__)
        self.tl_coords = np.array([self.r_tl, self.c_tl])
          

    @staticmethod
    def obj_fun(pars,x,src):
        tx, ty = pars
        H = np.array([[1, 0, tx],\
            [0, 1, ty]])
        src1 = np.c_[src,np.ones(src.shape[0])]
        return np.sum( (x - src1.dot(H.T)[:,:2])**2 )

    @staticmethod
    def apply_transform(pars, src):
        tx, ty = pars
        H = np.array([[1, 0, tx],\
            [0, 1, ty]])
        src1 = np.c_[src,np.ones(src.shape[0])]
        return src1.dot(H.T)[:,:2]

    @staticmethod
    def distance(x1,y1,x2,y2):
        return math.sqrt((x2 - x1)**2 + (y2 - y1)**2 )

    @staticmethod
    def list_subtract(list1,list2):
        return np.absolute(np.array(list1)-np.array(list2))

    def tri_sides(self,set_x, set_x_tri):

        triangles = []
        for i in range(len(set_x_tri)):

            point1 = set_x_tri[i][0]
            point2 = set_x_tri[i][1]
            point3 = set_x_tri[i][2]

            point1x, point1y = set_x[point1][0], set_x[point1][1]
            point2x, point2y = set_x[point2][0], set_x[point2][1]
            point3x, point3y = set_x[point3][0], set_x[point3][1] 

            len1 = self.distance(point1x,point1y,point2x,point2y)
            len2 = self.distance(point1x,point1y,point3x,point3y)
            len3 = self.distance(point2x,point2y,point3x,point3y)

            # you need to normalize in case the ref and the tran
            # are warped
            #min_side = min(len1,len2,len3)
            #len1/=min_side
            #len2/=min_side
            #len3/=min_side
            t=[len1,len2,len3]
            t.sort()
            triangles.append(t)

        return triangles


    def identify_matching_coords(self,set_A, set_B, threshold):
        match_A_pts = []
        match_B_pts = []
        set_A_tri = list(itertools.combinations(range(len(set_A)), 3))
        set_B_tri = list(itertools.combinations(range(len(set_B)), 3))
        A_triangles = self.tri_sides(set_A, set_A_tri)
        B_triangles = self.tri_sides(set_B, set_B_tri)
        sums = []
        for i in range(len(A_triangles)):
            for j in range(len(B_triangles)):
                k = sum(self.list_subtract(A_triangles[i], B_triangles[j]))
                if k &lt; threshold:
                    sums.append([i,j,k])
        # sort by smallest sum
        sums = sorted(sums, key=operator.itemgetter(2))
        if len(sums):
            match_A = set_A_tri[sums[0][0]]
            match_B = set_B_tri[sums[0][1]]
            for i in range(3):
                match_A_pts.append(set_A[match_A[i]])
                match_B_pts.append(set_B[match_B[i]])
        return (match_A_pts,match_B_pts)



    def calculate_chunks(self):
        self.chunks = r_c_chunking(self.overlapping_region_dimensions,self.r_chunk_size,
                        self.c_chunk_size,self.tl_coords)   
        self.chunks.block_chunking()
        self.coords_chunks_list = self.chunks.coords_chunks_list
        
    def calculate_dots_chunks(self,coords,chunk_coords):  
        r_tl = chunk_coords[0]
        r_br = chunk_coords[1]
        c_tl = chunk_coords[2]
        c_br = chunk_coords[3]

        # Select only the coords in the trimmed region
        coords_in_chunk = coords[((r_tl &lt; coords[:,0]) &amp; (coords[:,0]&lt;r_br)\
                    &amp; (c_tl &lt;coords[:,1]) &amp;(coords[:,1]&lt;c_br)),: ]
        return coords_in_chunk


    def optimize_chunking(self,ref_coords, tran_coords):       
        self.enough_dots = False
        if self.chunk_search_ax == &#39;c&#39;:
            chunk_size = self.c_chunk_size
        else:
            chunk_size = self.r_chunk_size
        
        while chunk_size &lt; self.max_chunk_size:
            chunks = r_c_chunking(self.overlapping_region_dimensions,self.r_chunk_size,
                        self.c_chunk_size,self.tl_coords)
            chunks.block_chunking()
            coords_chunks_list = chunks.coords_chunks_list
            ref_max_number_dots = []
            tran_max_number_dots = []
            ref_total = []
            tran_total = []
            for chunk_coords in coords_chunks_list:
                ref_coords_in_chunk = self.calculate_dots_chunks(ref_coords,chunk_coords)
                tran_coords_in_chunk = self.calculate_dots_chunks(tran_coords,chunk_coords)
                if ref_coords_in_chunk.shape[0] &gt; self.min_dots_chunk and tran_coords_in_chunk.shape[0] &gt; self.min_dots_chunk:
                        self.enough_dots = True
                        break
            if self.enough_dots:
                break
            else:
                self.enough_dots = False
                chunk_size += 200
                if self.chunk_search_ax == &#39;c&#39;:
                    self.c_chunk_size += 200
                else:
                    self.r_chunk_size += 200
                                  
        if self.enough_dots:
            # Collect the ref and tran coords from the chunks with enough dots
            self.ref_tran_screening_list = []
            for chunk_coords in coords_chunks_list:
                ref_coords_in_chunk = self.calculate_dots_chunks(ref_coords,chunk_coords)
                tran_coords_in_chunk = self.calculate_dots_chunks(tran_coords,chunk_coords)
                if ref_coords_in_chunk.shape[0] &gt; self.min_dots_chunk and tran_coords_in_chunk.shape[0] &gt; self.min_dots_chunk:
                    self.ref_tran_screening_list.append((ref_coords_in_chunk,tran_coords_in_chunk,chunk_coords))

    def register(self,ref_coords,tran_coords):
        self.optimize_chunking(ref_coords, tran_coords)
        self.completed_registration = False
        if self.enough_dots:
            match_ref_pts_all = []
            match_tran_pts_all = []
            # Collect all matching dots in all chunked regions with number of dots above threshold
            for ref_coords_in_chunk,tran_coords_in_chunk, chunk_coords in self.ref_tran_screening_list:
                    match_ref_pts, match_tran_pts = self.identify_matching_coords(ref_coords_in_chunk,tran_coords_in_chunk,self.min_error_triangles)
                    if len(match_ref_pts) and len(match_tran_pts):
                        match_ref_pts_all.append(match_ref_pts)
                        match_tran_pts_all.append(match_tran_pts)
                    if len(match_ref_pts_all) &gt; self.max_dots:
                        break
            match_ref_pts_all = [pts for grp in match_ref_pts_all for pts in grp]
            match_tran_pts_all = [pts for grp in match_tran_pts_all for pts in grp]

            if len(match_ref_pts_all):
                match_ref_pts_all = np.vstack(match_ref_pts_all)
                match_tran_pts_all = np.vstack(match_tran_pts_all)
                minimization_output = minimize(self.obj_fun,[0,0],args=(match_ref_pts_all,match_tran_pts_all), method=&#39;Nelder-Mead&#39;)
                if minimization_output.success:
                    self.tran_registered_coords = self.apply_transform(minimization_output.x, tran_coords)
                    self.transformation_matrix = minimization_output.x
                    self.completed_registration = True
                else:
                    self.logger.info(f&#39;chunk {chunk_coords} failed minimization of distances&#39;)
            else:
                self.logger.info(f&#39;chunk {chunk_coords} did not find matching triangles&#39;)

        else:
            self.logger.info(f&#39;cannot register rounds not enough dots&#39;)
            self.tran_registered_coords = tran_coords
            self.transformation_matrix = np.empty([1,2])
            self.transformation_matrix[:] = np.nan

        if not self.completed_registration:
            self.logger.info(f&#39;was not possible to register &#39;)
            self.tran_registered_coords = tran_coords
            self.transformation_matrix = np.empty([1,2])
            self.transformation_matrix[:] = np.nan



def register_adj_tiles(experiment_fpath, roi_num, stitching_channel, idx_reference_tile,overlapping_regions,tile_corners_coords_pxl):
    stitching_shift = {}
    # tmp = []
    experiment_fpath = Path(experiment_fpath)
    counts_fpath = experiment_fpath / &#39;counts&#39;/ (&#39;roi_&#39; + str(roi_num)) / stitching_channel
    search_key = &#39;*_fov_&#39; + str(idx_reference_tile) + &#39;.parquet&#39;
    # Adde crosscheck for error
    ref_counts_fpath = list(counts_fpath.glob(search_key))[0]
    ref_counts_df = pd.read_parquet(ref_counts_fpath)

    ref_tile_coords = tile_corners_coords_pxl[idx_reference_tile]
    ref_counts_selected = ref_counts_df.loc[ref_counts_df.round_num == 1, [&#39;r_px_registered&#39;, &#39;c_px_registered&#39;]]
    ref_counts_selected.loc[:, [&#39;r_px_registered&#39;, &#39;c_px_registered&#39;]] += ref_tile_coords

    for cpl, chunk_coords in overlapping_regions[idx_reference_tile].items():
        # Add crosscheck for error
        search_key = &#39;*_fov_&#39; + str(cpl[1]) + &#39;.parquet&#39;
        comp_counts_fpath = list(counts_fpath.glob(search_key))[0]
        comp_counts_df = pd.read_parquet(comp_counts_fpath)
        comp_counts_selected = comp_counts_df.loc[comp_counts_df.round_num == 1, [&#39;r_px_registered&#39;, &#39;c_px_registered&#39;]]
        comp_tile_coords = tile_corners_coords_pxl[cpl[1]]
        comp_counts_selected.loc[:, [&#39;r_px_registered&#39;, &#39;c_px_registered&#39;]] += comp_tile_coords

        r_tl = chunk_coords[0]
        r_br = chunk_coords[1]
        c_tl = chunk_coords[2]
        c_br = chunk_coords[3]

        overlapping_ref_coords_df = ref_counts_selected.loc[(ref_counts_selected.r_px_registered &gt; r_tl) &amp; (ref_counts_selected.r_px_registered &lt; r_br) 
                                                   &amp; (ref_counts_selected.c_px_registered &gt; c_tl) &amp; (ref_counts_selected.c_px_registered &lt; c_br),[&#39;r_px_registered&#39;,&#39;c_px_registered&#39;]]

        overlapping_comp_coords_df = comp_counts_selected.loc[(comp_counts_selected.r_px_registered &gt; r_tl) &amp; (comp_counts_selected.r_px_registered &lt; r_br) 
                                                   &amp; (comp_counts_selected.c_px_registered &gt; c_tl) &amp; (comp_counts_selected.c_px_registered &lt; c_br),[&#39;r_px_registered&#39;,&#39;c_px_registered&#39;]]

        overlapping_ref_coords = overlapping_ref_coords_df.to_numpy()
        overlapping_comp_coords = overlapping_comp_coords_df.to_numpy()

        tr_st = triangles_based_dots_stitching(overlapping_ref_coords, overlapping_comp_coords, chunk_coords)
        tr_st.optimize_chunking(overlapping_ref_coords,overlapping_comp_coords)
        tr_st.register(overlapping_ref_coords,overlapping_comp_coords)
        stitching_shift[cpl] = tr_st.transformation_matrix
        # tmp.append([overlapping_ref_coords, overlapping_comp_coords, tr_st.tran_registered_coords])
        
    return stitching_shift



if __name__ ==  &#39;__main__&#39;:

    exp = &#39;/Users/simone/Documents/local_data_storage/test_micdata/LBEXP20200325_oPool11&#39;
    stitching_channel = &#39;Europium&#39;
    roi_num = 0
    to = organize_square_tiles(exp,stitching_channel,roi_num)
    # to.save_graph()
    to.normalize_coords()
    to.identify_adjacent_tiles()
    to.determine_overlapping_regions()
    idx_reference_tile = 0
    experiment_fpath = &#39;/Users/simone/Documents/local_data_storage/dots_analysis/LBEXP20200325_oPool11/&#39;
    stitching_shift, tmp = register_adj_tiles(experiment_fpath, roi_num, stitching_channel, idx_reference_tile,to.overlapping_regions,to.tile_corners_coords_pxl)
    to.save_graph()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pysmFISH.stitching.clean_from_duplicated_dots"><code class="name flex">
<span>def <span class="ident">clean_from_duplicated_dots</span></span>(<span>fov:Â int, dots_id_to_remove:Â list, experiment_fpath:Â str, tag_cleaned_file:Â str)</span>
</code></dt>
<dd>
<div class="desc"><p>Function to remove the dulicated dots.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>fov</code></strong> :&ensp;<code>int</code></dt>
<dd>Field of view to process</dd>
<dt><strong><code>dots_id_to_remove</code></strong> :&ensp;<code>str</code></dt>
<dd>ids of the duplicated dots</dd>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the experiment to process</dd>
<dt><strong><code>tag_cleaned_file</code></strong> :&ensp;<code>str</code></dt>
<dd>tag name of the file with cleaned counts</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_from_duplicated_dots(fov: int, dots_id_to_remove: list, experiment_fpath: str,
                                tag_cleaned_file:str):
    &#34;&#34;&#34;Function to remove the dulicated dots.

    Args:
        fov (int): Field of view to process
        dots_id_to_remove (str): ids of the duplicated dots
        experiment_fpath (str): Path to the experiment to process
        tag_cleaned_file (str): tag name of the file with cleaned counts
    &#34;&#34;&#34;
    logger = selected_logger()
    experiment_fpath = Path(experiment_fpath)
    try:
        fname = list((experiment_fpath / &#39;results&#39;).glob(&#39;*_decoded_fov_&#39; + str(fov) + &#39;.parquet&#39;))[0]
    except:
        logger.error(f&#39;missing decoded file for fov {fov}&#39;)
    else:
        save_name = fname.stem.split(&#39;_decoded_fov_&#39;)[0] + &#39;_&#39;+ tag_cleaned_file +&#39;_cleaned_df_fov_&#39; + str(fov) + &#39;.parquet&#39;
        save_name = experiment_fpath / &#39;results&#39; / save_name
        if len(dots_id_to_remove):
            try:
                counts_df = pd.read_parquet(fname)
                logger.error(f&#39;loaded {fname}&#39;)
                
            except:
                logger.error(f&#39;missing {fname}&#39;)
            else:
                cleaned_df = counts_df.loc[~counts_df.dot_id.isin(dots_id_to_remove), :]
                cleaned_df.to_parquet(save_name,index=False)
                logger.error(f&#39;saved {fname}&#39;)

                save_name = fname.stem.split(&#39;_decoded_fov_&#39;)[0] + tag_cleaned_file + &#39;_removed_df_fov_&#39; + str(fov) + &#39;.parquet&#39;
                save_name = experiment_fpath / &#39;results&#39; / save_name
                removed_df = counts_df.loc[counts_df.dot_id.isin(dots_id_to_remove), :]
                removed_df.to_parquet(save_name,index=False)
        else:
            try:
                _ = shutil.copy2(fname.as_posix(),save_name.as_posix())
                logger.error(f&#39;copied {fname}&#39;)
            except:
                logger.error(f&#39;cannot copy {fname} to {save_name}&#39;)</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.get_all_dots_in_overlapping_regions"><code class="name flex">
<span>def <span class="ident">get_all_dots_in_overlapping_regions</span></span>(<span>counts_df, chunk_coords, stitching_selected='microscope_stitched')</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_all_dots_in_overlapping_regions(counts_df, chunk_coords, stitching_selected=&#39;microscope_stitched&#39;):    
    
    r_tag = &#39;r_px_&#39; + stitching_selected
    c_tag = &#39;c_px_&#39; + stitching_selected
    
    r_tl = chunk_coords[0]
    r_br = chunk_coords[1]
    c_tl = chunk_coords[2]
    c_br = chunk_coords[3]
    
    overlapping_ref_df = counts_df.loc[(counts_df[r_tag] &gt; r_tl) &amp; (counts_df[r_tag] &lt; r_br) 
                                               &amp; (counts_df[c_tag] &gt; c_tl) &amp; (counts_df[c_tag] &lt; c_br),:]
        
    return overlapping_ref_df</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.get_dots_in_overlapping_regions"><code class="name flex">
<span>def <span class="ident">get_dots_in_overlapping_regions</span></span>(<span>counts_df, unfolded_overlapping_regions_dict, stitching_selected, gene)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_dots_in_overlapping_regions(counts_df, unfolded_overlapping_regions_dict, 
                       stitching_selected, gene):    
    r_tag = &#39;r_px_&#39; + stitching_selected
    c_tag = &#39;c_px_&#39; + stitching_selected
    
    ref_tiles_df = pd.DataFrame(columns=counts_df.columns)
    comp_tiles_df = pd.DataFrame(columns=counts_df.columns)
    
    
    grpd_df = counts_df.groupby(&#39;fov_num&#39;)
    list_fov = list(grpd_df.groups.keys())
    
    for cpl, chunk_coords in unfolded_overlapping_regions_dict.items():
        
        if (cpl[0] in list_fov) and (cpl[1] in list_fov):
            r_tl = chunk_coords[0]
            r_br = chunk_coords[1]
            c_tl = chunk_coords[2]
            c_br = chunk_coords[3]

            barcoded_ref_df = grpd_df.get_group(cpl[0])
            barcoded_comp_df = grpd_df.get_group(cpl[1])

            overlapping_ref_df = barcoded_ref_df.loc[(barcoded_ref_df[r_tag] &gt; r_tl) &amp; (barcoded_ref_df[r_tag] &lt; r_br) 
                                               &amp; (barcoded_ref_df[c_tag] &gt; c_tl) &amp; (barcoded_ref_df[c_tag] &lt; c_br),:]


            overlapping_comp_df = barcoded_comp_df.loc[(barcoded_comp_df[r_tag] &gt; r_tl) &amp; (barcoded_comp_df[r_tag] &lt; r_br) 
                                               &amp; (barcoded_comp_df[c_tag] &gt; c_tl) &amp; (barcoded_comp_df[c_tag] &lt; c_br),:]


            ref_tiles_df = ref_tiles_df.append(overlapping_ref_df)
            comp_tiles_df = comp_tiles_df.append(overlapping_comp_df)
        
    return ref_tiles_df, comp_tiles_df</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.identify_duplicated_dots"><code class="name flex">
<span>def <span class="ident">identify_duplicated_dots</span></span>(<span>ref_tiles_df, comp_tiles_df, stitching_selected, same_dot_radius)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def identify_duplicated_dots(ref_tiles_df,comp_tiles_df,stitching_selected,same_dot_radius):
    
    r_tag = &#39;r_px_&#39; + stitching_selected
    c_tag = &#39;c_px_&#39; + stitching_selected

    overlapping_ref_coords = ref_tiles_df.loc[:, [r_tag,c_tag]].to_numpy()
    overlapping_comp_coords = comp_tiles_df.loc[:, [r_tag,c_tag]].to_numpy()
    dots_ids = comp_tiles_df.loc[:, [&#39;dot_id&#39;]].to_numpy()
    index = NNDescent(overlapping_ref_coords,metric=&#39;euclidean&#39;,n_neighbors=1)
    indices, dists = index.query(overlapping_comp_coords,k=1)
    idx_dists = np.where(dists &lt; same_dot_radius)[0]
    dots_id_to_remove = dots_ids[idx_dists]
    dots_id_to_remove = list(dots_id_to_remove.reshape(dots_id_to_remove.shape[0],))
    return dots_id_to_remove</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.identify_duplicated_dots_NNDescend"><code class="name flex">
<span>def <span class="ident">identify_duplicated_dots_NNDescend</span></span>(<span>ref_tiles_df:Â pandas.core.frame.DataFrame, comp_tiles_df:Â pandas.core.frame.DataFrame, stitching_selected:Â str, same_dot_radius:Â int) â€‘>Â list</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to identify duplicated dots for a gene in the overlapping regions. This
version of the function uses the fast nearest neighbor coded in NNDescend</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>ref_tiles_df</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Counts of the reference tiles</dd>
<dt><strong><code>comp_tiles_df</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Counts in the comparing tiles</dd>
<dt><strong><code>stitching_selected</code></strong> :&ensp;<code>str</code></dt>
<dd>String that identify the coords of the pixels
according to the stitching used to process the data</dd>
<dt><strong><code>same_dot_radius</code></strong> :&ensp;<code>int</code></dt>
<dd>searching radius used to define if two dots are
the same</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>dot ids to remove</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def identify_duplicated_dots_NNDescend(ref_tiles_df: pd.DataFrame,comp_tiles_df: pd.DataFrame,
                    stitching_selected: str,same_dot_radius: int)-&gt; list:
    &#34;&#34;&#34;Function used to identify duplicated dots for a gene in the overlapping regions. This
    version of the function uses the fast nearest neighbor coded in NNDescend

    Args:
        ref_tiles_df (pd.DataFrame): Counts of the reference tiles
        comp_tiles_df (pd.DataFrame): Counts in the comparing tiles
        stitching_selected (str): String that identify the coords of the pixels
            according to the stitching used to process the data
        same_dot_radius (int): searching radius used to define if two dots are
            the same

    Returns:
        list: dot ids to remove
    &#34;&#34;&#34;
    
    r_tag = &#39;r_px_&#39; + stitching_selected
    c_tag = &#39;c_px_&#39; + stitching_selected

    overlapping_ref_coords = ref_tiles_df.loc[:, [r_tag,c_tag]].to_numpy()
    overlapping_comp_coords = comp_tiles_df.loc[:, [r_tag,c_tag]].to_numpy()
    dots_ids = comp_tiles_df.loc[:, [&#39;dot_id&#39;]].to_numpy()
    index = NNDescent(overlapping_ref_coords,metric=&#39;euclidean&#39;,n_neighbors=1)
    indices, dists = index.query(overlapping_comp_coords,k=1)
    idx_dists = np.where(dists &lt; same_dot_radius)[0]
    dots_id_to_remove = dots_ids[idx_dists]
    dots_id_to_remove = list(dots_id_to_remove.reshape(dots_id_to_remove.shape[0],))
    return dots_id_to_remove</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.identify_duplicated_dots_sklearn"><code class="name flex">
<span>def <span class="ident">identify_duplicated_dots_sklearn</span></span>(<span>ref_tiles_df:Â pandas.core.frame.DataFrame, comp_tiles_df:Â pandas.core.frame.DataFrame, stitching_selected:Â str, same_dot_radius:Â int) â€‘>Â list</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to identify duplicated dots for a gene in the overlapping regions. This
version of the function uses the fast nearest neighbor coded in NNDescend</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>ref_tiles_df</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Counts of the reference tiles</dd>
<dt><strong><code>comp_tiles_df</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Counts in the comparing tiles</dd>
<dt><strong><code>stitching_selected</code></strong> :&ensp;<code>str</code></dt>
<dd>String that identify the coords of the pixels
according to the stitching used to process the data</dd>
<dt><strong><code>same_dot_radius</code></strong> :&ensp;<code>int</code></dt>
<dd>searching radius used to define if two dots are
the same</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>dot ids to remove</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def identify_duplicated_dots_sklearn(ref_tiles_df: pd.DataFrame,comp_tiles_df: pd.DataFrame,
                    stitching_selected: str,same_dot_radius: int)-&gt; list:
    &#34;&#34;&#34;Function used to identify duplicated dots for a gene in the overlapping regions. This
    version of the function uses the fast nearest neighbor coded in NNDescend

    Args:
        ref_tiles_df (pd.DataFrame): Counts of the reference tiles
        comp_tiles_df (pd.DataFrame): Counts in the comparing tiles
        stitching_selected (str): String that identify the coords of the pixels
            according to the stitching used to process the data
        same_dot_radius (int): searching radius used to define if two dots are
            the same
    Returns:
        list: dot ids to remove
    &#34;&#34;&#34;
    nn = NearestNeighbors(n_neighbors=1,radius=same_dot_radius, metric=&#39;euclidean&#39;,algorithm=&#39;kd_tree&#39;)
    
    r_tag = &#39;r_px_&#39; + stitching_selected
    c_tag = &#39;c_px_&#39; + stitching_selected
    
    overlapping_ref_coords = ref_tiles_df.loc[:, [r_tag,c_tag]].to_numpy()
    overlapping_comp_coords = comp_tiles_df.loc[:, [r_tag,c_tag]].to_numpy()
    dots_ids = comp_tiles_df.loc[:, [&#39;dot_id&#39;]].to_numpy()
    nn.fit(overlapping_ref_coords)
    dists, indices = nn.kneighbors(overlapping_comp_coords, return_distance=True)
    idx_dists = np.where(dists &lt;= same_dot_radius)[0]
    dots_id_to_remove = dots_ids[idx_dists]
    dots_id_to_remove = list(dots_id_to_remove.reshape(dots_id_to_remove.shape[0],))
    
    return dots_id_to_remove</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.register_adj_tiles"><code class="name flex">
<span>def <span class="ident">register_adj_tiles</span></span>(<span>experiment_fpath, roi_num, stitching_channel, idx_reference_tile, overlapping_regions, tile_corners_coords_pxl)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def register_adj_tiles(experiment_fpath, roi_num, stitching_channel, idx_reference_tile,overlapping_regions,tile_corners_coords_pxl):
    stitching_shift = {}
    # tmp = []
    experiment_fpath = Path(experiment_fpath)
    counts_fpath = experiment_fpath / &#39;counts&#39;/ (&#39;roi_&#39; + str(roi_num)) / stitching_channel
    search_key = &#39;*_fov_&#39; + str(idx_reference_tile) + &#39;.parquet&#39;
    # Adde crosscheck for error
    ref_counts_fpath = list(counts_fpath.glob(search_key))[0]
    ref_counts_df = pd.read_parquet(ref_counts_fpath)

    ref_tile_coords = tile_corners_coords_pxl[idx_reference_tile]
    ref_counts_selected = ref_counts_df.loc[ref_counts_df.round_num == 1, [&#39;r_px_registered&#39;, &#39;c_px_registered&#39;]]
    ref_counts_selected.loc[:, [&#39;r_px_registered&#39;, &#39;c_px_registered&#39;]] += ref_tile_coords

    for cpl, chunk_coords in overlapping_regions[idx_reference_tile].items():
        # Add crosscheck for error
        search_key = &#39;*_fov_&#39; + str(cpl[1]) + &#39;.parquet&#39;
        comp_counts_fpath = list(counts_fpath.glob(search_key))[0]
        comp_counts_df = pd.read_parquet(comp_counts_fpath)
        comp_counts_selected = comp_counts_df.loc[comp_counts_df.round_num == 1, [&#39;r_px_registered&#39;, &#39;c_px_registered&#39;]]
        comp_tile_coords = tile_corners_coords_pxl[cpl[1]]
        comp_counts_selected.loc[:, [&#39;r_px_registered&#39;, &#39;c_px_registered&#39;]] += comp_tile_coords

        r_tl = chunk_coords[0]
        r_br = chunk_coords[1]
        c_tl = chunk_coords[2]
        c_br = chunk_coords[3]

        overlapping_ref_coords_df = ref_counts_selected.loc[(ref_counts_selected.r_px_registered &gt; r_tl) &amp; (ref_counts_selected.r_px_registered &lt; r_br) 
                                                   &amp; (ref_counts_selected.c_px_registered &gt; c_tl) &amp; (ref_counts_selected.c_px_registered &lt; c_br),[&#39;r_px_registered&#39;,&#39;c_px_registered&#39;]]

        overlapping_comp_coords_df = comp_counts_selected.loc[(comp_counts_selected.r_px_registered &gt; r_tl) &amp; (comp_counts_selected.r_px_registered &lt; r_br) 
                                                   &amp; (comp_counts_selected.c_px_registered &gt; c_tl) &amp; (comp_counts_selected.c_px_registered &lt; c_br),[&#39;r_px_registered&#39;,&#39;c_px_registered&#39;]]

        overlapping_ref_coords = overlapping_ref_coords_df.to_numpy()
        overlapping_comp_coords = overlapping_comp_coords_df.to_numpy()

        tr_st = triangles_based_dots_stitching(overlapping_ref_coords, overlapping_comp_coords, chunk_coords)
        tr_st.optimize_chunking(overlapping_ref_coords,overlapping_comp_coords)
        tr_st.register(overlapping_ref_coords,overlapping_comp_coords)
        stitching_shift[cpl] = tr_st.transformation_matrix
        # tmp.append([overlapping_ref_coords, overlapping_comp_coords, tr_st.tran_registered_coords])
        
    return stitching_shift</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.register_coords_obj"><code class="name flex">
<span>def <span class="ident">register_coords_obj</span></span>(<span>fov, segmentation_output_path, stitching_parameters, reference_corner_fov_position, metadata)</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to register the coords of the segmented object to th </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>fov</code></strong> :&ensp;<code>[type]</code></dt>
<dd>[description]</dd>
<dt><strong><code>segmentation_output_path</code></strong> :&ensp;<code>[type]</code></dt>
<dd>[description]</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def register_coords_obj(fov,segmentation_output_path,
                    stitching_parameters,
                    reference_corner_fov_position,
                    metadata):
    &#34;&#34;&#34;Function used to register the coords of the segmented object to th 

    Args:
        fov ([type]): [description]
        segmentation_output_path ([type]): [description]
    &#34;&#34;&#34;
    segmented_output = pickle.load(open(segmentation_output_path / (&#39;preprocessed_data_fov_&#39; + str(fov) + &#39;_mask.pkl&#39;), &#39;rb&#39;))
    segmented_regions = measure.regionprops(segmented_output)
    segmented_regions_dict = {}
    for prop in segmented_regions:
        segmented_regions_dict[str(fov)+&#39;-&#39;+str(prop.label)] = {}
        segmented_regions_dict[str(fov)+&#39;-&#39;+str(prop.label)][&#39;original_coords&#39;]=prop.coords
        segmented_regions_dict[str(fov)+&#39;-&#39;+str(prop.label)][&#39;stitched_coords&#39;]= np.nan
        segmented_regions_dict = stitch_using_coords_general_segmented_objects(fov,segmented_regions_dict,
                                                                         stitching_parameters,reference_corner_fov_position, metadata)
        pickle.dump(segmented_regions_dict,open(segmentation_output_path / (&#39;registered_objs_dict_fov_&#39; + str(fov) + &#39;.pkl&#39;), &#39;wb&#39;))</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.register_cpl"><code class="name flex">
<span>def <span class="ident">register_cpl</span></span>(<span>cpl, chunk_coords, experiment_fpath, stitching_channel, reference_round)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def register_cpl(cpl, chunk_coords, experiment_fpath,
                                    stitching_channel,
                                    reference_round):

    logger = selected_logger()
    registration = {}
    experiment_fpath = Path(experiment_fpath)
    
    try:
        counts1_fpath = list((experiment_fpath / &#39;results&#39;).glob(&#39;*decoded_fov_&#39; + str(cpl[0]) + &#39;.parquet&#39;))[0]
    except:
        logger.error(f&#39;count file missing for fov {cpl[0]}&#39;)
    
    else:
        try:
            counts2_fpath = list((experiment_fpath / &#39;results&#39;).glob(&#39;*decoded_fov_&#39; + str(cpl[1]) + &#39;.parquet&#39;))[0]
        except:
            logger.error(f&#39;count file missing for fov {cpl[1]}&#39;)
        else:
    
            counts1_df = pd.read_parquet(counts1_fpath)
            counts2_df = pd.read_parquet(counts2_fpath)

            count1_grp = counts1_df.loc[(counts1_df.channel == stitching_channel) &amp;
                                        (counts1_df.round_num == reference_round),:]
            count2_grp = counts2_df.loc[(counts2_df.channel == stitching_channel) &amp;
                                        (counts2_df.round_num == reference_round),:]
            count1_grp = counts1_df.loc[counts1_df.channel == stitching_channel,:]
            count2_grp = counts2_df.loc[counts2_df.channel == stitching_channel,:]
            
            overlap_count1 = get_all_dots_in_overlapping_regions(count1_grp, chunk_coords,stitching_selected=&#39;microscope_stitched&#39;)
            overlap_count2 = get_all_dots_in_overlapping_regions(count2_grp, chunk_coords,stitching_selected=&#39;microscope_stitched&#39;)
         
            if overlap_count1.empty or overlap_count2.empty:
                shift = np.array([1000,1000])
                registration[cpl] = [shift, np.nan]
                
            else:
                # TODO
                # Maybe add a selction step where if the number of beads is below X the beads based registration will be run or fft based
                # registration if the number of beads is high enough
                
                r_tl = chunk_coords[0]
                c_tl = chunk_coords[2]
                img_shape = np.array([np.abs(chunk_coords[1]-chunk_coords[0]),np.abs(chunk_coords[3]-chunk_coords[2])]).astype(&#39;int&#39;) + 1
                norm_ref_coords = overlap_count1.loc[:,[&#39;r_px_microscope_stitched&#39;,&#39;c_px_microscope_stitched&#39;]].to_numpy() -[r_tl, c_tl]
                norm_comp_coords =  overlap_count2.loc[:,[&#39;r_px_microscope_stitched&#39;,&#39;c_px_microscope_stitched&#39;]].to_numpy() -[r_tl, c_tl]
                img_ref = create_fake_image(img_shape, norm_ref_coords)
                img_tran = create_fake_image(img_shape, norm_comp_coords)
                shift, error, diffphase = register_translation(img_ref, img_tran)
                registration[cpl] = [shift, error]
    
            return registration</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.register_cpl_fresh_nuclei"><code class="name flex">
<span>def <span class="ident">register_cpl_fresh_nuclei</span></span>(<span>cpl:Â Tuple, chunk_coords:Â numpy.ndarray, order:Â dict, metadata:Â dict, experiment_fpath:Â str)</span>
</code></dt>
<dd>
<div class="desc"><p>Function to register orverlapping regions of nuclear staining for stitching</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>cpl</code></strong> :&ensp;<code>Tuple</code></dt>
<dd>overlapping tiles</dd>
<dt><strong><code>chunk_coords</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>coords of the overlapping region [r_tl,r_br,c_tl,c_br]</dd>
<dt><strong><code>order</code></strong> :&ensp;<code>dict</code></dt>
<dd>description of the position of the tiles</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>dict</code></dt>
<dd>dictionary with the general experiment data</dd>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>path to the experiment to process</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>registration output [shift, error]</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def register_cpl_fresh_nuclei(cpl: Tuple, chunk_coords: np.ndarray, order: dict, 
                              metadata:dict, experiment_fpath:str):
    &#34;&#34;&#34;Function to register orverlapping regions of nuclear staining for stitching

    Args:
        cpl (Tuple): overlapping tiles
        chunk_coords (np.ndarray): coords of the overlapping region [r_tl,r_br,c_tl,c_br]
        order (dict): description of the position of the tiles
        metadata (dict): dictionary with the general experiment data
        experiment_fpath (str): path to the experiment to process

    Returns:
        dict: registration output [shift, error]
    &#34;&#34;&#34;

    logger = selected_logger()
    registration = {}
    experiment_fpath = Path(experiment_fpath)
    img_width = metadata[&#39;img_width&#39;]
    img_height = metadata[&#39;img_height&#39;]
    experiment_name = metadata[&#39;experiment_name&#39;]
    error = 0
    
    filtered_nuclei_fpath = experiment_fpath / &#39;fresh_tissue&#39; / &#39;fresh_tissue_nuclei_preprocessed_img_data.zarr&#39;
    
    try:
        st = zarr.DirectoryStore(filtered_nuclei_fpath)
        root = zarr.group(store=st, overwrite=False)
    except:
        logger.error(f&#39;cannot load the zarr files with filtered nuclei&#39;)    
        
    else:
        try:
            img1 = root[experiment_name + &#39;_fresh_tissue_nuclei_fov_&#39; + str(cpl[0])][&#39;preprocessed_data_fov_&#39;+str(cpl[0])][...]
        except:
            logger.error(f&#39;image file cannot be loaded for nuclei of fov {cpl[0]}&#39;)   
            
        else:
            try:
                img2 = root[experiment_name + &#39;_fresh_tissue_nuclei_fov_&#39; + str(cpl[1])][&#39;preprocessed_data_fov_&#39;+str(cpl[1])][...]
            except:
                logger.error(f&#39;image file cannot be loaded for nuclei of fov {cpl[1]}&#39;)  
                
            else:

                img_shape = np.array([np.abs(chunk_coords[1]-chunk_coords[0]),np.abs(chunk_coords[3]-chunk_coords[2])]).astype(&#39;int&#39;)
                if order == {&#39;row_order&#39;: (&#39;top&#39;, &#39;bottom&#39;), &#39;column_order&#39;: (&#39;right&#39;, &#39;left&#39;)}:
                    img1_slice = img1[(img_height-img_shape[0]):img_height,0:img_shape[1]]
                    img2_slice = img2[0:img_shape[0],(img_width-img_shape[1]):img_width]
                elif order == {&#39;row_order&#39;: (&#39;top&#39;, &#39;bottom&#39;), &#39;column_order&#39;: (&#39;left&#39;, &#39;right&#39;)}:
                    img1_slice = img1[img_height-img_shape[0]:img_height,img_width-img_shape[1]:img_width]
                    img2_slice = img2[0:img_shape[0],0:img_shape[1]]
                elif order == {&#39;row_order&#39;: (&#39;bottom&#39;, &#39;top&#39;), &#39;column_order&#39;: (&#39;left&#39;, &#39;right&#39;)}:
                    img1_slice = img1[0:img_shape[0],img_width-img_shape[1]:img_width]
                    img2_slice = img2[img_height-img_shape[0]:img_height,0:img_shape[1]]
                elif order == {&#39;row_order&#39;: (&#39;bottom&#39;, &#39;top&#39;), &#39;column_order&#39;: (&#39;right&#39;, &#39;left&#39;)}:
                    img1_slice = img1[0:img_shape[0],0:img_shape[1]]
                    img2_slice = img2[img_height-img_shape[0]:img_height,img_width-img_shape[1]:img_width]
                else:
                    logger.error(f&#39;unknown fovs order&#39;)
                    error = 1
                
                if error:
                    shift = np.array([1000,1000])
                    registration[cpl] = [shift, np.nan]
                else:
                    shift, error, diffphase = register_translation(img1_slice, img2_slice)
                    registration[cpl] = [shift, error]
    
                return registration</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.remove_duplicated_dots_graph"><code class="name flex">
<span>def <span class="ident">remove_duplicated_dots_graph</span></span>(<span>experiment_fpath:Â str, dataset:Â pandas.core.frame.DataFrame, tiles_org, hamming_distance:Â float, same_dot_radius:Â int, stitching_selected:Â str, client)</span>
</code></dt>
<dd>
<div class="desc"><p>Dask task graph builder/runner function to parallel remove duplicated dots
The overlapping dots are not removed right after being identified
because the same fov can be part of two different overlapping couples.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the experiment to process</dd>
<dt><strong><code>dataset</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Properties of the images of the experiment</dd>
<dt><strong><code>tiles_org</code></strong> :&ensp;<code>[type]</code></dt>
<dd>Organization of the tiles </dd>
<dt><strong><code>hamming_distance</code></strong> :&ensp;<code>float</code></dt>
<dd>Selected distance from the code</dd>
<dt><strong><code>same_dot_radius</code></strong> :&ensp;<code>int</code></dt>
<dd>searching radius used to define if two dots are
the same</dd>
<dt><strong><code>stitching_selected</code></strong> :&ensp;<code>str</code></dt>
<dd>String that identify the coords of the pixels
according to the stitching used to process the data</dd>
<dt><strong><code>client</code></strong> :&ensp;<code>dask.distributed.Client</code></dt>
<dd>Dask client in charge of controlling
the processing of the task graph.</dd>
<dt><strong><code>tag_cleaned_file</code></strong> :&ensp;<code>str</code></dt>
<dd>tag name of the file with cleaned counts</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove_duplicated_dots_graph(experiment_fpath: str,dataset: pd.DataFrame,
                                tiles_org, hamming_distance: float,
                                same_dot_radius: int, 
                                stitching_selected: str, client):
    &#34;&#34;&#34;Dask task graph builder/runner function to parallel remove duplicated dots
    The overlapping dots are not removed right after being identified
    because the same fov can be part of two different overlapping couples.

    Args:
        experiment_fpath (str): Path to the experiment to process
        dataset (pd.DataFrame): Properties of the images of the experiment
        tiles_org ([type]): Organization of the tiles 
        hamming_distance (float): Selected distance from the code
        same_dot_radius (int): searching radius used to define if two dots are
            the same
        stitching_selected (str): String that identify the coords of the pixels
            according to the stitching used to process the data
        client (dask.distributed.Client): Dask client in charge of controlling
            the processing of the task graph.
        tag_cleaned_file (str): tag name of the file with cleaned counts
    &#34;&#34;&#34;
    
    logger = selected_logger()
    fovs = dataset.loc[:,&#39;fov_num&#39;].unique()
    unfolded_overlapping_regions_dict = {key:value for (k,v) in tiles_org.overlapping_regions.items() for (key,value) in v.items()}

    # Prepare the dataframe
    r_tag = &#39;r_px_&#39; + stitching_selected
    c_tag = &#39;c_px_&#39; + stitching_selected

    all_futures = []

    for cpl,chunk_coords in unfolded_overlapping_regions_dict.items():
        future = client.submit(remove_overlapping_dots_fov,
                                cpl = cpl,
                                chunk_coords=chunk_coords,
                                experiment_fpath=experiment_fpath,
                                stitching_selected=stitching_selected,
                                hamming_distance=hamming_distance,
                                same_dot_radius = same_dot_radius)

        all_futures.append(future)

    to_remove = client.gather(all_futures)  
    to_remove_comb = {k: v for d in to_remove for k, v in d.items()}

    removed_dot_dict = {}
    for key, items in to_remove_comb.items():
        if key[1] not in removed_dot_dict.keys():
            removed_dot_dict[key[1]] = []
        removed_dot_dict[key[1]].append(items)
    
    for key, items in removed_dot_dict.items():
        removed_dot_dict[key] = [el for tg in items for el in tg]

    for fov,dots_id_to_remove in removed_dot_dict.items():
        future = client.submit(clean_from_duplicated_dots,
                                fov = fov,
                                dots_id_to_remove=dots_id_to_remove,
                                experiment_fpath=experiment_fpath,
                                tag_cleaned_file=stitching_selected)

        all_futures.append(future)

    _ = client.gather(all_futures)</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.remove_overlapping_dots_fov"><code class="name flex">
<span>def <span class="ident">remove_overlapping_dots_fov</span></span>(<span>cpl:Â Tuple[int,Â int], chunk_coords:Â numpy.ndarray, experiment_fpath:Â str, stitching_selected:Â str, hamming_distance:Â float, same_dot_radius:Â int) â€‘>Â Dict[Tuple[int,Â int],Â List[str]]</span>
</code></dt>
<dd>
<div class="desc"><p>Function that identify the overlapping dots between two different tiles. The duplicated dots
for all genes are identified</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>cpl</code></strong> :&ensp;<code>Tuple[int,int]</code></dt>
<dd>Adjacent tiles to compare</dd>
<dt><strong><code>chunk_coords</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Coords of the overlapping regions between the two tiles to compare</dd>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the experiment to process</dd>
<dt><strong><code>stitching_selected</code></strong> :&ensp;<code>str</code></dt>
<dd>String that identify the coords of the pixels
according to the stitching used to process the data</dd>
<dt><strong><code>hamming_distance</code></strong> :&ensp;<code>float</code></dt>
<dd>Selected distance from the code</dd>
<dt><strong><code>same_dot_radius</code></strong> :&ensp;<code>int</code></dt>
<dd>searching radius used to define if two dots are
the same</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Dict[Tuple[int,int],List[str]]</code></dt>
<dd>{cpl:all_dots_id_to_remove}</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove_overlapping_dots_fov(cpl: Tuple[int,int], chunk_coords: np.ndarray, 
                    experiment_fpath: str, stitching_selected:str,
                    hamming_distance: float, same_dot_radius: int)-&gt; Dict[Tuple[int,int],List[str]]:
    &#34;&#34;&#34;Function that identify the overlapping dots between two different tiles. The duplicated dots
    for all genes are identified

    Args:
        cpl (Tuple[int,int]): Adjacent tiles to compare
        chunk_coords (np.ndarray): Coords of the overlapping regions between the two tiles to compare
        experiment_fpath (str): Path to the experiment to process
        stitching_selected (str): String that identify the coords of the pixels
            according to the stitching used to process the data
        hamming_distance (float): Selected distance from the code
        same_dot_radius (int): searching radius used to define if two dots are
            the same

    Returns:
        Dict[Tuple[int,int],List[str]]: {cpl:all_dots_id_to_remove}
    &#34;&#34;&#34;

    logger = selected_logger()
    all_dots_id_to_remove = []
    experiment_fpath = Path(experiment_fpath)
    
    try:
        counts1_fpath = list((experiment_fpath / &#39;results&#39;).glob(&#39;*decoded*_fov_&#39; + str(cpl[0]) + &#39;.parquet&#39;))[0]
    except:
        logger.error(f&#39;count file missing for fov {cpl[0]}&#39;)
    
    else:
        try:
            counts2_fpath = list((experiment_fpath / &#39;results&#39;).glob(&#39;*decoded*_fov_&#39; + str(cpl[1]) + &#39;.parquet&#39;))[0]
        except:
            logger.error(f&#39;count file missing for fov {cpl[1]}&#39;)
        else:
    
            counts1_df = pd.read_parquet(counts1_fpath)
            counts2_df = pd.read_parquet(counts2_fpath)

            count1_grp = counts1_df.loc[counts1_df.hamming_distance &lt; hamming_distance,:]
            count2_grp = counts2_df.loc[counts2_df.hamming_distance &lt; hamming_distance,:]
            
            overlap_count1 = get_all_dots_in_overlapping_regions(counts1_df, chunk_coords, 
                            stitching_selected)
            overlap_count2 = get_all_dots_in_overlapping_regions(counts2_df, chunk_coords, 
                            stitching_selected)
            


            count1_grp = overlap_count1.groupby(&#39;decoded_genes&#39;)
            count2_grp = overlap_count2.groupby(&#39;decoded_genes&#39;)
            
            for gene, over_c1_df in count1_grp:
                try:
                    over_c2_df = count2_grp.get_group(gene)
                except:
                    pass
                else:
                    dots_id_to_remove = identify_duplicated_dots_sklearn(over_c1_df,over_c2_df,
                                                                stitching_selected,same_dot_radius)
                    if len(dots_id_to_remove):
                        all_dots_id_to_remove.append(dots_id_to_remove)
            all_dots_id_to_remove = [el for tg in all_dots_id_to_remove for el in tg]
            return {cpl:all_dots_id_to_remove}</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.remove_overlapping_dots_from_gene"><code class="name flex">
<span>def <span class="ident">remove_overlapping_dots_from_gene</span></span>(<span>experiment_fpath, counts_df, unfolded_overlapping_regions_dict, stitching_selected, gene, same_dot_radius)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove_overlapping_dots_from_gene(experiment_fpath,counts_df,unfolded_overlapping_regions_dict,
                                    stitching_selected,gene,same_dot_radius):

    experiment_fpath = Path(experiment_fpath)
    ref_tiles_df, comp_tiles_df = get_dots_in_overlapping_regions(counts_df,unfolded_overlapping_regions_dict, 
                       stitching_selected, gene)
    dots_id_to_remove = identify_duplicated_dots(ref_tiles_df,comp_tiles_df,stitching_selected,same_dot_radius)
    cleaned_df = counts_df.loc[~counts_df.barcode_reference_dot_id.isin(dots_id_to_remove), :]
    fpath = experiment_fpath / &#39;results&#39; / (experiment_fpath.stem + &#39;_&#39; + gene +&#39;_counts.parquet&#39;)
    cleaned_df.to_parquet(fpath,index=False)</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.stitch_using_coords_general"><code class="name flex">
<span>def <span class="ident">stitch_using_coords_general</span></span>(<span>decoded_df:Â pandas.core.frame.DataFrame, tile_corners_coords_pxl:Â numpy.ndarray, reference_corner_fov_position:Â str, metadata:Â Dict, tag:Â str)</span>
</code></dt>
<dd>
<div class="desc"><p>Function to create a stitched image using the fov coords
of the stage.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>decoded_df</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Counts after decoding</dd>
<dt><strong><code>tile_corners_coords_pxl</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Coords of the fovs according to the stage</dd>
<dt><strong><code>reference_corner_fov_position</code></strong> :&ensp;<code>str</code></dt>
<dd>Position of the reference corner determine by
the organization stage/camera. In our setup can be:
- top-left
- top-right
- bottom_left</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>Dict</code></dt>
<dd>[description]</dd>
<dt><strong><code>tag</code></strong> :&ensp;<code>str</code></dt>
<dd>[description]</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>[type]</code></dt>
<dd>Decoded counts with coords of the dots adjusted to the stage
reference point</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stitch_using_coords_general(decoded_df: pd.DataFrame, tile_corners_coords_pxl: np.ndarray, 
    reference_corner_fov_position: str, metadata: Dict, tag: str):
    &#34;&#34;&#34;Function to create a stitched image using the fov coords 
    of the stage.

    Args:
        decoded_df (pd.DataFrame): Counts after decoding
        tile_corners_coords_pxl (np.ndarray): Coords of the fovs according to the stage
        reference_corner_fov_position (str): Position of the reference corner determine by
            the organization stage/camera. In our setup can be:
            - top-left
            - top-right
            - bottom_left
        metadata (Dict): [description]
        tag (str): [description]

    Returns:
        [type]: Decoded counts with coords of the dots adjusted to the stage
                reference point
    &#34;&#34;&#34;
    logger = selected_logger()

    was_file = 0
    if not isinstance(decoded_df, pd.DataFrame):
        was_file = 1
        decoded_df_fpath = copy.deepcopy(decoded_df)
        decoded_df = pd.read_parquet(decoded_df)
        
    if decoded_df[&#39;r_px_registered&#39;].empty:
        decoded_df[&#39;r_px_&#39;+tag] = np.nan
        decoded_df[&#39;c_px_&#39;+tag] = np.nan
    else:

        #fov = decoded_df.iloc[0][&#39;fov_num&#39;]
        fov = int(decoded_df.fov_num.unique()[0])
        r_microscope_coords = tile_corners_coords_pxl[fov,0]
        c_microscope_coords = tile_corners_coords_pxl[fov,1]
        
        if reference_corner_fov_position == &#39;top-left&#39;:
            decoded_df[&#39;r_px_&#39;+tag] =  r_microscope_coords + decoded_df[&#39;r_px_registered&#39;]
            decoded_df[&#39;c_px_&#39;+tag] =  c_microscope_coords + decoded_df[&#39;c_px_registered&#39;]

        elif reference_corner_fov_position == &#39;top-right&#39;:
            decoded_df[&#39;r_px_&#39;+tag] =  r_microscope_coords + decoded_df[&#39;r_px_registered&#39;]
            decoded_df[&#39;c_px_&#39;+tag] =  c_microscope_coords - (metadata[&#39;img_width&#39;] - decoded_df[&#39;c_px_registered&#39;])

        elif reference_corner_fov_position == &#39;bottom-left&#39;:
            decoded_df[&#39;r_px_&#39;+tag] =  r_microscope_coords + (metadata[&#39;img_height&#39;] - decoded_df[&#39;r_px_registered&#39;])
            decoded_df[&#39;c_px_&#39;+tag] =  c_microscope_coords + decoded_df[&#39;c_px_registered&#39;]

        elif reference_corner_fov_position == &#39;bottom-right&#39;:
            decoded_df[&#39;r_px_&#39;+tag] =  r_microscope_coords + (metadata[&#39;img_height&#39;] - decoded_df[&#39;r_px_registered&#39;])
            decoded_df[&#39;c_px_&#39;+tag] =  c_microscope_coords - (metadata[&#39;img_width&#39;] - decoded_df[&#39;c_px_registered&#39;])

        elif reference_corner_fov_position == &#39;old-room-robofish2&#39;:
            decoded_df[&#39;r_px_&#39;+tag] =  r_microscope_coords -  decoded_df[&#39;r_px_registered&#39;]
            decoded_df[&#39;c_px_&#39;+tag] =  c_microscope_coords -  decoded_df[&#39;c_px_registered&#39;]

        else:
            logger.error(f&#34;the referernce corner fov position name is wrong&#34;)
            sys.exit(f&#34;the referernce corner fov position name is wrong&#34;)
        # decoded_df[&#39;r_px_&#39;+tag] =  r_microscope_coords - decoded_df[&#39;r_px_registered&#39;]
        # decoded_df[&#39;c_px_&#39;+tag] =  c_microscope_coords - decoded_df[&#39;c_px_registered&#39;]
    
    if was_file:
        decoded_df.to_parquet(decoded_df_fpath,index=False)
    else:
        return decoded_df</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.stitch_using_coords_general_df"><code class="name flex">
<span>def <span class="ident">stitch_using_coords_general_df</span></span>(<span>decoded_df, tile_corners_coords_pxl, reference_corner_fov_position, metadata, tag)</span>
</code></dt>
<dd>
<div class="desc"><p>Tiles are placed directly on the position indicated by the microscope
coords</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stitch_using_coords_general_df(decoded_df,tile_corners_coords_pxl,reference_corner_fov_position, metadata,tag):
    &#34;&#34;&#34;
    Tiles are placed directly on the position indicated by the microscope
    coords
    &#34;&#34;&#34;



    if decoded_df[&#39;r_px_registered&#39;].empty:
        decoded_df[&#39;r_px_&#39;+tag] = np.nan
        decoded_df[&#39;c_px_&#39;+tag] = np.nan
    else:

        fov = decoded_df.iloc[0][&#39;fov_num&#39;]
        r_microscope_coords = tile_corners_coords_pxl[fov,0]
        c_microscope_coords = tile_corners_coords_pxl[fov,1]
        
        if reference_corner_fov_position == &#39;top-left&#39;:
            decoded_df[&#39;r_px_&#39;+tag] =  r_microscope_coords + decoded_df[&#39;r_px_registered&#39;]
            decoded_df[&#39;c_px_&#39;+tag] =  c_microscope_coords + decoded_df[&#39;c_px_registered&#39;]

        elif reference_corner_fov_position == &#39;top-right&#39;:
            decoded_df[&#39;r_px_&#39;+tag] =  r_microscope_coords + decoded_df[&#39;r_px_registered&#39;]
            decoded_df[&#39;c_px_&#39;+tag] =  c_microscope_coords - (metadata[&#39;img_width&#39;] - decoded_df[&#39;c_px_registered&#39;])

        elif reference_corner_fov_position == &#39;bottom_left&#39;:
            decoded_df[&#39;r_px_&#39;+tag] =  r_microscope_coords + (metadata[&#39;img_height&#39;] - decoded_df[&#39;r_px_registered&#39;])
            decoded_df[&#39;c_px_&#39;+tag] =  c_microscope_coords + decoded_df[&#39;c_px_registered&#39;]
    # if decoded_df[&#39;r_px_registered&#39;].empty:
    #     decoded_df[&#39;r_px_microscope_stitched&#39;] = np.nan
    #     decoded_df[&#39;c_px_microscope_stitched&#39;] = np.nan
    # else:
    #     fov = decoded_df.iloc[0][&#39;fov_num&#39;]
    #     r_microscope_coords = tile_corners_coords_pxl[fov,0]
    #     c_microscope_coords = tile_corners_coords_pxl[fov,1]
    #     decoded_df[&#39;r_px_microscope_stitched&#39;] =  r_microscope_coords - decoded_df[&#39;r_px_registered&#39;]
    #     decoded_df[&#39;c_px_microscope_stitched&#39;] =  c_microscope_coords - decoded_df[&#39;c_px_registered&#39;]

        # new room
        # decoded_df[&#39;r_px_microscope_stitched&#39;] =  r_microscope_coords + decoded_df[&#39;r_px_registered&#39;]
        # decoded_df[&#39;c_px_microscope_stitched&#39;] =  c_microscope_coords + decoded_df[&#39;c_px_registered&#39;]
    return decoded_df</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.stitch_using_coords_general_segmented_objects"><code class="name flex">
<span>def <span class="ident">stitch_using_coords_general_segmented_objects</span></span>(<span>fov, obj_dict, tile_corners_coords_pxl, reference_corner_fov_position, metadata)</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to stitch the segmented object used for defining the cells.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stitch_using_coords_general_segmented_objects(fov,obj_dict,tile_corners_coords_pxl,reference_corner_fov_position, metadata):
    &#34;&#34;&#34;
    Function used to stitch the segmented object used for defining the cells.
    &#34;&#34;&#34;

    r_microscope_coords = tile_corners_coords_pxl[fov,0]
    c_microscope_coords = tile_corners_coords_pxl[fov,1]
    
    if obj_dict:
        
        if reference_corner_fov_position == &#39;top-left&#39;:
            for el,coords_dict in obj_dict.items():
                coords_dict[&#39;stitched_coords&#39;] = np.vstack([r_microscope_coords + coords_dict[&#39;original_coords&#39;][:,0],
                                                            c_microscope_coords + coords_dict[&#39;original_coords&#39;][:,1]]).T

        elif reference_corner_fov_position == &#39;top-right&#39;:
            for el,coords_dict in obj_dict.items():
                coords_dict[&#39;stitched_coords&#39;] = np.vstack([r_microscope_coords + coords_dict[&#39;original_coords&#39;][:,0],
                                                            c_microscope_coords - (metadata[&#39;img_width&#39;] -coords_dict[&#39;original_coords&#39;][:,1])]).T

        elif reference_corner_fov_position == &#39;bottom_left&#39;:
            for el,coords_dict in obj_dict.items():
                coords_dict[&#39;stitched_coords&#39;] = np.vstack([r_microscope_coords + (metadata[&#39;img_height&#39;] -coords_dict[&#39;original_coords&#39;][:,0]),
                                                            c_microscope_coords + coords_dict[&#39;original_coords&#39;][:,1]]).T

    return obj_dict</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.stitched_beads_on_nuclei_fresh_tissue"><code class="name flex">
<span>def <span class="ident">stitched_beads_on_nuclei_fresh_tissue</span></span>(<span>experiment_fpath:Â str, client, nuclei_tag:Â strÂ =Â '_ChannelCy3_Nuclei_', beads_tag:Â strÂ =Â '_ChannelEuropium_Cy3_', round_num:Â intÂ =Â 1, overlapping_percentage:Â intÂ =Â 5, machine:Â strÂ =Â 'ROBOFISH2')</span>
</code></dt>
<dd>
<div class="desc"><p>Function tun run the stitching of the dots in the fresh images using
the nuclei images as reference</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>path of the experiment to process</dd>
<dt><strong><code>client</code></strong> :&ensp;<code>[type]</code></dt>
<dd>dask client for parallel processing</dd>
<dt><strong><code>nuclei_tag</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Tag to identify the nuclei dataset. Defaults to '<em>ChannelCy3_Nuclei</em>'.</dd>
<dt><strong><code>beads_tag</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Tag to identify the beads dataset. Defaults to '<em>ChannelEuropium_Cy3</em>'.</dd>
<dt><strong><code>round_num</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Reference round,for the fresh tissue there is only one. Defaults to 1.</dd>
<dt><strong><code>overlapping_percentage</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Overlapping between the different tiles. Defaults to 5.</dd>
<dt><strong><code>machine</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>machine running the experiment. Defaults to 'ROBOFISH2'.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stitched_beads_on_nuclei_fresh_tissue(experiment_fpath:str,
                                      client,
                                      nuclei_tag:str=&#39;_ChannelCy3_Nuclei_&#39;,
                                      beads_tag:str=&#39;_ChannelEuropium_Cy3_&#39;,
                                      round_num:int = 1,
                                      overlapping_percentage:int=5,
                                      machine:str=&#39;ROBOFISH2&#39;
                                     ):
    &#34;&#34;&#34;Function tun run the stitching of the dots in the fresh images using 
    the nuclei images as reference

    Args:
        experiment_fpath (str): path of the experiment to process
        client ([type]): dask client for parallel processing
        nuclei_tag (str, optional): Tag to identify the nuclei dataset. Defaults to &#39;_ChannelCy3_Nuclei_&#39;.
        beads_tag (str, optional): Tag to identify the beads dataset. Defaults to &#39;_ChannelEuropium_Cy3_&#39;.
        round_num (int, optional): Reference round,for the fresh tissue there is only one. Defaults to 1.
        overlapping_percentage (int, optional): Overlapping between the different tiles. Defaults to 5.
        machine (str, optional): machine running the experiment. Defaults to &#39;ROBOFISH2&#39;.
    &#34;&#34;&#34;
    experiment_fpath = Path(experiment_fpath)
    fresh_tissue_path = experiment_fpath / &#39;fresh_tissue&#39;
    beads_dataset_fpath = list(fresh_tissue_path.glob(&#39;*&#39;+ beads_tag +&#39;*.parquet&#39;))[0]
    nuclei_dataset_fpath = list(fresh_tissue_path.glob(&#39;*&#39;+ nuclei_tag +&#39;*.parquet&#39;))[0]
    
    # Collect and adjust beads dataset with missing values
    beads_data = Dataset()
    beads_data.load_dataset(beads_dataset_fpath)
    beads_data.dataset[&#39;processing_type&#39;] = &#39;undefined&#39;
    beads_data.dataset[&#39;overlapping_percentage&#39;] = overlapping_percentage / 100
    beads_data.dataset[&#39;machine&#39;] = machine

    metadata_beads = beads_data.collect_metadata(beads_data.dataset)
    beads_org_tiles = organize_square_tiles(experiment_fpath,beads_data.dataset,metadata_beads,round_num)
    beads_org_tiles.run_tiles_organization()
    flist = list((fresh_tissue_path / &#39;results&#39;).glob(&#39;*decoded_fov*.parquet&#39;))

    # duplicate registered
    for fpath in flist:
        data = pd.read_parquet(fpath)
        data[&#39;r_px_registered&#39;] = data[&#39;r_px_original&#39;]
        data[&#39;c_px_registered&#39;] = data[&#39;c_px_original&#39;]
        data[&#39;hamming_distance&#39;] = 0
        data[&#39;decoded_genes&#39;] = &#39;beads&#39;
        data.to_parquet(fpath)


    all_futures = []
    for fpath in flist:
        future = client.submit(stitch_using_coords_general, fpath,
                                              beads_org_tiles.tile_corners_coords_pxl,
                                              beads_org_tiles.reference_corner_fov_position,
                                              metadata_beads,tag=&#39;microscope_stitched&#39;)

        all_futures.append(future)
    _ = client.gather(all_futures)

    io.simple_output_plotting(fresh_tissue_path,
                              stitching_selected= &#39;microscope_stitched&#39;,
                             selected_Hdistance=0,
                             client = client,
                             input_file_tag = &#39;decoded_fov&#39;,
                             file_tag = &#39;stitched_microscope&#39;)


    # Collect and adjust nuclei dataset with missing values
    nuclei_data = Dataset()
    nuclei_data.load_dataset(nuclei_dataset_fpath)
    nuclei_data.dataset[&#39;processing_type&#39;] = &#39;undefined&#39;
    nuclei_data.dataset[&#39;overlapping_percentage&#39;] = overlapping_percentage / 100
    nuclei_data.dataset[&#39;machine&#39;] = machine

    metadata_nuclei = nuclei_data.collect_metadata(nuclei_data.dataset)
    nuclei_org_tiles = organize_square_tiles(experiment_fpath,nuclei_data.dataset,metadata_nuclei,round_num)
    nuclei_org_tiles.run_tiles_organization()

    _ =stitching_graph_fresh_nuclei(experiment_fpath,nuclei_org_tiles, metadata_nuclei, 
                                client, nr_dim = 2)


    io.simple_output_plotting(fresh_tissue_path,
                              stitching_selected= &#39;global_stitched_nuclei&#39;,
                             selected_Hdistance=0,
                             client = client,
                             input_file_tag = &#39;decoded_fov&#39;,
                             file_tag = &#39;global_stitched_nuclei&#39;)</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.stitching_graph"><code class="name flex">
<span>def <span class="ident">stitching_graph</span></span>(<span>experiment_fpath, stitching_channel, tiles_org, metadata, reference_round, client, nr_dim=2)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stitching_graph(experiment_fpath, stitching_channel,tiles_org, metadata, 
                    reference_round, client, nr_dim = 2):
    
    logger = selected_logger()
    unfolded_overlapping_regions_dict = {key:value for (k,v) in tiles_org.overlapping_regions.items() for (key,value) in v.items()}
    
    futures = []
    for cpl, chunk_coords in unfolded_overlapping_regions_dict.items():

        future = client.submit(register_cpl,cpl, chunk_coords, experiment_fpath,stitching_channel,
                            reference_round)

        futures.append(future)
    all_registrations = client.gather(futures)


    all_registrations = [reg for reg in all_registrations if reg ]
    all_registrations_dict = {}

    for output_dict in all_registrations:
        all_registrations_dict.update(output_dict)

    # Run registration only if there are not too many overlappig regions without 
    # dots
    
    # counts_cpls_missing_overlapping_dots = 0
    # cpls_missing_overlapping_dots = []
    # for cpl, registration_output in all_registrations_dict.items():
    #     if np.isnan(registration_output[1]):
    #         cpls_missing_overlapping_dots.append(cpl)
    #         counts_cpls_missing_overlapping_dots += 1
    
    # global_stitching_done = 0
    # if len(cpls_missing_overlapping_dots) &gt; 10:
    #     logger.error(f&#34;Too many cpl of fovs without overlapping reference dots&#34;)
    #     pickle.dump([cpls_missing_overlapping_dots,counts_cpls_missing_overlapping_dots ],
    #         open(experiment_fpath / &#39;results&#39; / &#39;fovs_without_overlapping_reference_dots_no_global_stitching.pkl&#39;,&#39;rb&#39;))
    #     global_stitching_done = 0
    #     return tiles_org.tile_corners_coords_pxl, global_stitching_done

    # else:
    #     global_stitching_done = 1
    #     logger.error(f&#34;The number of cpls of fovs without overlapping reference dots is low, test global stitching&#34;)
    #     pickle.dump([cpls_missing_overlapping_dots,counts_cpls_missing_overlapping_dots ],
    #         open(experiment_fpath / &#39;results&#39; / &#39;fovs_without_overlapping_reference_dots_yes_global_stitching.pkl&#39;,&#39;wb&#39;))

    overlapping_coords_reorganized = {}
    for idx, cpl_dict in tiles_org.overlapping_regions.items():
        overlapping_coords_reorganized.update(cpl_dict)

    all_registrations_removed_large_shift = {k:v for (k,v) in all_registrations_dict.items() if np.all(np.abs(v[0]) &lt; 20)}

    cpls = all_registrations_removed_large_shift.keys()
    # cpls = list(unfolded_overlapping_regions_dict.keys())
    total_cpls = len(cpls)
    nr_tiles = tiles_org.tile_corners_coords_pxl.shape[0]

    weights_err1 = np.zeros((total_cpls * nr_dim))
    weights_err2 = np.zeros((total_cpls * nr_dim))
    P = np.zeros(total_cpls * nr_dim)
    ZQ = np.zeros((total_cpls * nr_dim,nr_tiles * nr_dim))

    weights_err = np.zeros((total_cpls * nr_dim))
    for i, (a, b) in enumerate(cpls):
        shift = all_registrations_removed_large_shift[(a,b)][0]
        dr = shift[0]
        dc = shift[1]
        P[i * nr_dim] = dr
        P[i * nr_dim +1 ] = dc
        weights_err[i * nr_dim:i * nr_dim + nr_dim] = all_registrations_removed_large_shift[(a,b)][1]

    for i, (a, b) in enumerate(cpls):
        # Y row:
        Z = np.zeros((nr_tiles * nr_dim))
        Z[nr_dim * a:nr_dim * a + 1] = -1
        Z[nr_dim * b:nr_dim * b + 1] = 1
        ZQ[i * nr_dim, :] = Z
        # X row
        Z = np.zeros((nr_tiles * nr_dim))
        Z[nr_dim * a + 1:nr_dim * a + 2] = -1
        Z[nr_dim * b + 1:nr_dim * b + 2] = 1
        ZQ[i * nr_dim + 1, :] = Z

    lrg = linmod.LinearRegression(fit_intercept=False)
    lrg.fit(ZQ,P)
    global_translrg = lrg.coef_.reshape(nr_tiles, nr_dim)
    gb =  -1 * (-lrg.coef_.reshape((nr_tiles, nr_dim)) \
                                + lrg.coef_.reshape((nr_tiles, nr_dim))[0:1, :])
    global_shift = gb.astype(int)
    adjusted_coords = tiles_org.tile_corners_coords_pxl + global_shift

    # Determine shift of missing tiles

    out_level = 1000
    low = np.where(global_shift&lt; -out_level)[0]
    high = np.where(global_shift&gt; out_level)[0]
    low_high = np.hstack((low,high))

    missing_tiles_id = np.unique(low_high)
    missing_tiles_coords = tiles_org.tile_corners_coords_pxl[missing_tiles_id,:]

    if missing_tiles_coords.shape[0] &gt;0:
        coords_cl = np.delete(tiles_org.tile_corners_coords_pxl, missing_tiles_id, 0)
        ad_coords_cl = np.delete(adjusted_coords, missing_tiles_id, 0 )
        tst = linmod.LinearRegression(fit_intercept=False)
        tst.fit(coords_cl,ad_coords_cl)
        corrected_missing = tst.predict(missing_tiles_coords)

        for idx, tile_id in enumerate(missing_tiles_id):
            adjusted_coords[tile_id] = corrected_missing[idx]


    dec_fpath = (experiment_fpath / &#39;results&#39;).glob(&#39;*_decoded_fov*&#39;)
    for fpath in dec_fpath:
        global_stitched_decoded_df = stitch_using_coords_general(fpath,
                                    adjusted_coords,
                                    tiles_org.reference_corner_fov_position,
                                    metadata,
                                    &#39;global_stitched&#39;)
        if isinstance(global_stitched_decoded_df,pd.DataFrame):
            global_stitched_decoded_df.to_parquet(fpath)

    global_shift = tiles_org.tile_corners_coords_pxl - adjusted_coords
    pickle.dump(global_shift,open(experiment_fpath / &#39;results&#39;/ &#39;stitching_global_shift.pkl&#39;,&#39;wb&#39;))
    pickle.dump(adjusted_coords,open(experiment_fpath / &#39;results&#39;/ &#39;global_stitched_coords.pkl&#39;,&#39;wb&#39;))

    return adjusted_coords</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.stitching_graph_fresh_nuclei"><code class="name flex">
<span>def <span class="ident">stitching_graph_fresh_nuclei</span></span>(<span>experiment_fpath, tiles_org, metadata, client, nr_dim=2)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stitching_graph_fresh_nuclei(experiment_fpath,tiles_org, metadata, 
                            client, nr_dim = 2):
    
    logger = selected_logger()
    unfolded_overlapping_regions_dict = {key:value for (k,v) in tiles_org.overlapping_regions.items() for (key,value) in v.items()}
    unfolded_overlapping_order_dict = {key:value for (k,v) in tiles_org.overlapping_order.items() for (key,value) in v.items()}


    futures = []
    for cpl, chunk_coords in unfolded_overlapping_regions_dict.items():

        future = client.submit(register_cpl_fresh_nuclei,cpl, chunk_coords, 
                            unfolded_overlapping_order_dict[cpl],
                            metadata,
                            experiment_fpath)

        futures.append(future)
    all_registrations = client.gather(futures)


    all_registrations = [reg for reg in all_registrations if reg ]
    all_registrations_dict = {}

    for output_dict in all_registrations:
        all_registrations_dict.update(output_dict)


    overlapping_coords_reorganized = {}
    for idx, cpl_dict in tiles_org.overlapping_regions.items():
        overlapping_coords_reorganized.update(cpl_dict)

    all_registrations_removed_large_shift = {k:v for (k,v) in all_registrations_dict.items() if np.all(np.abs(v[0]) &lt; 20)}

    cpls = all_registrations_removed_large_shift.keys()
    # cpls = list(unfolded_overlapping_regions_dict.keys())
    total_cpls = len(cpls)
    nr_tiles = tiles_org.tile_corners_coords_pxl.shape[0]

    weights_err1 = np.zeros((total_cpls * nr_dim))
    weights_err2 = np.zeros((total_cpls * nr_dim))
    P = np.zeros(total_cpls * nr_dim)
    ZQ = np.zeros((total_cpls * nr_dim,nr_tiles * nr_dim))

    weights_err = np.zeros((total_cpls * nr_dim))
    for i, (a, b) in enumerate(cpls):
        shift = all_registrations_removed_large_shift[(a,b)][0]
        dr = shift[0]
        dc = shift[1]
        P[i * nr_dim] = dr
        P[i * nr_dim +1 ] = dc
        weights_err[i * nr_dim:i * nr_dim + nr_dim] = all_registrations_removed_large_shift[(a,b)][1]

    for i, (a, b) in enumerate(cpls):
        # Y row:
        Z = np.zeros((nr_tiles * nr_dim))
        Z[nr_dim * a:nr_dim * a + 1] = -1
        Z[nr_dim * b:nr_dim * b + 1] = 1
        ZQ[i * nr_dim, :] = Z
        # X row
        Z = np.zeros((nr_tiles * nr_dim))
        Z[nr_dim * a + 1:nr_dim * a + 2] = -1
        Z[nr_dim * b + 1:nr_dim * b + 2] = 1
        ZQ[i * nr_dim + 1, :] = Z

    lrg = linmod.LinearRegression(fit_intercept=False)
    lrg.fit(ZQ,P)
    global_translrg = lrg.coef_.reshape(nr_tiles, nr_dim)
    gb =  -1 * (-lrg.coef_.reshape((nr_tiles, nr_dim)) \
                                + lrg.coef_.reshape((nr_tiles, nr_dim))[0:1, :])
    global_shift = gb.astype(int)
    adjusted_coords = tiles_org.tile_corners_coords_pxl + global_shift

    # Determine shift of missing tiles

    out_level = 1000
    low = np.where(global_shift&lt; -out_level)[0]
    high = np.where(global_shift&gt; out_level)[0]
    low_high = np.hstack((low,high))

    missing_tiles_id = np.unique(low_high)
    missing_tiles_coords = tiles_org.tile_corners_coords_pxl[missing_tiles_id,:]

    if missing_tiles_coords.shape[0] &gt;0:
        coords_cl = np.delete(tiles_org.tile_corners_coords_pxl, missing_tiles_id, 0)
        ad_coords_cl = np.delete(adjusted_coords, missing_tiles_id, 0 )
        tst = linmod.LinearRegression(fit_intercept=False)
        tst.fit(coords_cl,ad_coords_cl)
        corrected_missing = tst.predict(missing_tiles_coords)

        for idx, tile_id in enumerate(missing_tiles_id):
            adjusted_coords[tile_id] = corrected_missing[idx]


    dec_fpath = (experiment_fpath / &#39;fresh_tissue&#39;/ &#39;results&#39;).glob(&#39;*_decoded_fov*&#39;)
    for fpath in dec_fpath:
        global_stitched_decoded_df = stitch_using_coords_general(fpath,
                                    adjusted_coords,
                                    tiles_org.reference_corner_fov_position,
                                    metadata,
                                    &#39;global_stitched_nuclei&#39;)
        if isinstance(global_stitched_decoded_df,pd.DataFrame):
            global_stitched_decoded_df.to_parquet(fpath)

    global_shift = tiles_org.tile_corners_coords_pxl - adjusted_coords
    pickle.dump(global_shift,open(experiment_fpath / &#39;fresh_tissue&#39; /  &#39;results&#39;/ &#39;stitching_global_shift.pkl&#39;,&#39;wb&#39;))
    pickle.dump(adjusted_coords,open(experiment_fpath / &#39;fresh_tissue&#39; / &#39;results&#39;/ &#39;global_stitched_coords.pkl&#39;,&#39;wb&#39;))

    return adjusted_coords</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.stitching_graph_serial_nuclei"><code class="name flex">
<span>def <span class="ident">stitching_graph_serial_nuclei</span></span>(<span>experiment_fpath, tiles_org, metadata, registration_reference_hybridization, client, nr_dim=2)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stitching_graph_serial_nuclei(experiment_fpath,tiles_org, metadata, 
                                registration_reference_hybridization,
                                client, nr_dim = 2):
    
    logger = selected_logger()
    unfolded_overlapping_regions_dict = {key:value for (k,v) in tiles_org.overlapping_regions.items() for (key,value) in v.items()}
    unfolded_overlapping_order_dict = {key:value for (k,v) in tiles_org.overlapping_order.items() for (key,value) in v.items()}


    futures = []
    for cpl, chunk_coords in unfolded_overlapping_regions_dict.items():

        future = client.submit(register_cpl_fresh_nuclei,cpl, chunk_coords, 
                            unfolded_overlapping_order_dict[cpl],
                            metadata,
                            experiment_fpath)

        futures.append(future)
    all_registrations = client.gather(futures)


    all_registrations = [reg for reg in all_registrations if reg ]
    all_registrations_dict = {}

    for output_dict in all_registrations:
        all_registrations_dict.update(output_dict)


    overlapping_coords_reorganized = {}
    for idx, cpl_dict in tiles_org.overlapping_regions.items():
        overlapping_coords_reorganized.update(cpl_dict)

    all_registrations_removed_large_shift = {k:v for (k,v) in all_registrations_dict.items() if np.all(np.abs(v[0]) &lt; 20)}

    cpls = all_registrations_removed_large_shift.keys()
    # cpls = list(unfolded_overlapping_regions_dict.keys())
    total_cpls = len(cpls)
    nr_tiles = tiles_org.tile_corners_coords_pxl.shape[0]

    weights_err1 = np.zeros((total_cpls * nr_dim))
    weights_err2 = np.zeros((total_cpls * nr_dim))
    P = np.zeros(total_cpls * nr_dim)
    ZQ = np.zeros((total_cpls * nr_dim,nr_tiles * nr_dim))

    weights_err = np.zeros((total_cpls * nr_dim))
    for i, (a, b) in enumerate(cpls):
        shift = all_registrations_removed_large_shift[(a,b)][0]
        dr = shift[0]
        dc = shift[1]
        P[i * nr_dim] = dr
        P[i * nr_dim +1 ] = dc
        weights_err[i * nr_dim:i * nr_dim + nr_dim] = all_registrations_removed_large_shift[(a,b)][1]

    for i, (a, b) in enumerate(cpls):
        # Y row:
        Z = np.zeros((nr_tiles * nr_dim))
        Z[nr_dim * a:nr_dim * a + 1] = -1
        Z[nr_dim * b:nr_dim * b + 1] = 1
        ZQ[i * nr_dim, :] = Z
        # X row
        Z = np.zeros((nr_tiles * nr_dim))
        Z[nr_dim * a + 1:nr_dim * a + 2] = -1
        Z[nr_dim * b + 1:nr_dim * b + 2] = 1
        ZQ[i * nr_dim + 1, :] = Z

    lrg = linmod.LinearRegression(fit_intercept=False)
    lrg.fit(ZQ,P)
    global_translrg = lrg.coef_.reshape(nr_tiles, nr_dim)
    gb =  -1 * (-lrg.coef_.reshape((nr_tiles, nr_dim)) \
                                + lrg.coef_.reshape((nr_tiles, nr_dim))[0:1, :])
    global_shift = gb.astype(int)
    adjusted_coords = tiles_org.tile_corners_coords_pxl + global_shift

    # Determine shift of missing tiles

    out_level = 1000
    low = np.where(global_shift&lt; -out_level)[0]
    high = np.where(global_shift&gt; out_level)[0]
    low_high = np.hstack((low,high))

    missing_tiles_id = np.unique(low_high)
    missing_tiles_coords = tiles_org.tile_corners_coords_pxl[missing_tiles_id,:]

    if missing_tiles_coords.shape[0] &gt;0:
        coords_cl = np.delete(tiles_org.tile_corners_coords_pxl, missing_tiles_id, 0)
        ad_coords_cl = np.delete(adjusted_coords, missing_tiles_id, 0 )
        tst = linmod.LinearRegression(fit_intercept=False)
        tst.fit(coords_cl,ad_coords_cl)
        corrected_missing = tst.predict(missing_tiles_coords)

        for idx, tile_id in enumerate(missing_tiles_id):
            adjusted_coords[tile_id] = corrected_missing[idx]


    dec_fpath = (experiment_fpath / &#39;results&#39;).glob(&#39;*_decoded_fov*&#39;)
    for fpath in dec_fpath:
        global_stitched_decoded_df = stitch_using_coords_general(fpath,
                                    adjusted_coords,
                                    tiles_org.reference_corner_fov_position,
                                    metadata,
                                    &#39;global_stitched_nuclei&#39;)
        if isinstance(global_stitched_decoded_df,pd.DataFrame):
            global_stitched_decoded_df.to_parquet(fpath)

    global_shift = tiles_org.tile_corners_coords_pxl - adjusted_coords
    pickle.dump(global_shift,open(experiment_fpath / &#39;results&#39;/ &#39;stitching_global_shift.pkl&#39;,&#39;wb&#39;))
    pickle.dump(adjusted_coords,open(experiment_fpath / &#39;results&#39;/ &#39;global_stitched_coords.pkl&#39;,&#39;wb&#39;))

    return adjusted_coords</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pysmFISH.stitching.organize_square_tiles"><code class="flex name class">
<span>class <span class="ident">organize_square_tiles</span></span>
<span>(</span><span>experiment_fpath:Â str, dataset:Â pandas.core.frame.DataFrame, metadata:Â Dict, round_num:Â int)</span>
</code></dt>
<dd>
<div class="desc"><p>Class designed to determine the tile organization and identify the coords of the
overlapping regions between the tiles. </p>
<p>IMPORTANT: The normalize_coords method should be adjusted according to the
setup of the microscope. </p>
<p>Class initialization</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the experiment to process</dd>
<dt><strong><code>dataset</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Properties of the images of the experiment</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>Dict</code></dt>
<dd>Metadata describing the experiment</dd>
<dt><strong><code>round_num</code></strong> :&ensp;<code>int</code></dt>
<dd>Reference acquisition round number</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class organize_square_tiles():
    
    &#34;&#34;&#34;Class designed to determine the tile organization and identify the coords of the
    overlapping regions between the tiles. 
    
    IMPORTANT: The normalize_coords method should be adjusted according to the
                setup of the microscope. 

    &#34;&#34;&#34;
   
    def __init__(self, experiment_fpath:str,dataset: pd.DataFrame, 
                                    metadata:Dict,round_num:int):
        &#34;&#34;&#34;Class initialization

        Args:
            experiment_fpath (str): Path to the experiment to process
            dataset (pd.DataFrame): Properties of the images of the experiment
            metadata (Dict): Metadata describing the experiment
            round_num (int): Reference acquisition round number
        &#34;&#34;&#34;

        
        self.logger = selected_logger()
        self.experiment_fpath = Path(experiment_fpath)
        self.dataset = dataset
        self.metadata = metadata
        self.round_num = round_num
        
        self.experiment_name = self.metadata[&#39;experiment_name&#39;]
        self.stitching_channel = self.metadata[&#39;stitching_channel&#39;]
        self.overlapping_percentage = int(self.metadata[&#39;overlapping_percentage&#39;]) / 100
         
        self.pixel_size = self.metadata[&#39;pixel_microns&#39;]
        self.img_width = self.metadata[&#39;img_width&#39;]
        self.img_height = self.metadata[&#39;img_height&#39;]
        
        logging.getLogger(&#39;matplotlib.font_manager&#39;).disabled = True
        
        if  self.img_width ==  self.img_height:
            self.img_size = self.img_width
        else:
            self.logger.error(f&#39;the images to stitch are not square&#39;)
            sys.exit(f&#39;the images to stitch are not square&#39;)
            
    
    def extract_microscope_coords(self): 
        &#34;&#34;&#34;Method to extract images coords in the stage reference
        system&#34;&#34;&#34;
        

        selected = self.dataset.loc[self.dataset.round_num == self.round_num, 
                                    [&#39;round_num&#39;,&#39;fov_num&#39;,&#39;fov_acquisition_coords_x&#39;,&#39;fov_acquisition_coords_y&#39;]]
        selected.drop_duplicates(subset=[&#39;fov_num&#39;],inplace=True)
        selected.sort_values(by=&#39;fov_num&#39;, ascending=True, inplace=True)
        self.x_coords = selected.loc[:,&#39;fov_acquisition_coords_x&#39;].to_numpy()
        self.y_coords = selected.loc[:,&#39;fov_acquisition_coords_y&#39;].to_numpy()

    
    def normalize_coords(self):
        &#34;&#34;&#34;
        Normalize the coords according to how the stage/camera are set.
        This function must be modified according to the stage/camera setup.

        ROBOFISH1 has stage with x increasing left-&gt; right and y top-&gt;bottom 
            ------&gt; (x)
            |
            |
            V (y)
        
        ROBOFISH2 has stage with x increasing right-&gt; left and y top-&gt;bottom 
        (x) &lt;------
                  |
                  |
                  V (y)
        

        ROBOFISH3 has stage with x increasing left-&gt; right and y bottom-&gt;top 
            ^ (y)
            |
            |
            ------&gt; (x)

        Axis modifications steps:
        (1) The reference system will be first converted to image style:
            ------&gt; (x)
            |
            |
            V (y)

        This step will cause a change in the position of the reference corner
        for each fov. After image acquisition the reference corner is top-left
        however after converting the axis direction to image-style the reference corner
        will change postion:
        ROBOFISH1: top-left --&gt; top-left
        ROBOFISH2: top-left --&gt; top-right
        ROBOFISH3: top-left --&gt; bottom-left

        (2) The coords will be translated to (0,0)

        (3) then to matrix (python) notation
            ------&gt; (columns)
            |
            |
            V (rows)

        &#34;&#34;&#34;

        # port the coords to image type coords
        if self.metadata[&#39;machine&#39;] == &#39;ROBOFISH2&#39;:
            self.x_coords = - self.x_coords
            self.reference_corner_fov_position = &#39;top-right&#39;
        elif self.metadata[&#39;machine&#39;] == &#39;ROBOFISH3&#39;:
            self.x_coords = - self.x_coords
            self.y_coords = - self.y_coords
            self.reference_corner_fov_position = &#39;bottom-left&#39;
        elif self.metadata[&#39;machine&#39;] == &#39;ROBOFISH1&#39;:
            self.reference_corner_fov_position = &#39;top-left&#39;
        elif self.metadata[&#39;machine&#39;] == &#39;NOT_DEFINED&#39;:
            self.logger.error(f&#39;Need to define the specs for stitching NOT_DEFINED machine&#39;)
            sys.exit(f&#39;Need to define the specs for stitching NOT_DEFINED machine&#39;)
        else:
            self.logger.error(f&#39;define the right machine used to collected the data&#39;)
            sys.exit(f&#39;define the right machine used to collected the data&#39;)

        # shift the coords to reference point (0,0) 
        # consider that we get the top-right corner of the image as well
        y_min = np.amin(self.y_coords)
        x_min = np.amin(self.x_coords)
        x_max = np.amax(self.x_coords)
        y_max = np.amax(self.y_coords)


        # Put the coords to zero
        if x_min &gt;=0 :
            self.x_coords = self.x_coords - x_min
        else:
            self.x_coords = self.x_coords + np.abs(x_min)
        
        if y_min&gt;0:
            self.y_coords = self.y_coords - y_min
        else:
            self.y_coords = self.y_coords + np.abs(y_min)


        # if x_max &gt;=0 :
        #     self.x_coords = self.x_coords - x_min
        # else:
        #     self.x_coords = self.x_coords + np.abs(x_min)
        
        # if y_max&gt;0:
        #     self.y_coords = self.y_coords - y_min
        # else:
        #     self.y_coords = self.y_coords + np.abs(y_min)

        # change the coords from x,y to r,c
        adjusted_coords = np.zeros([self.x_coords.shape[0],2])
        adjusted_coords[:,0] = self.y_coords
        adjusted_coords[:,1] = self.x_coords

        # move coords to pxl space
        self.tile_corners_coords_pxl = adjusted_coords / self.pixel_size


    
    # def save_graph_original_coords(self):
    # to correct because I already converted the coords to image
    #     # Turn interactive plotting off
    #     saving_fpath = self.experiment_fpath / &#39;output_figures&#39; / &#39;microscope_space_tiles_organization.png&#39;
    #     plt.ioff()
    #     # Create image type axes
    #     labels = [str(nr) for nr in np.arange(self.x_coords.shape[0])]
    #     fig = plt.figure(figsize=(20,10))
    #     plt.plot(self.x_coords,self.y_coords,&#39;or&#39;)

    #     for label, x, y in zip(labels, self.x_coords,self.y_coords):
    #         plt.annotate(
    #             label,
    #             xy=(x,y), xytext=(-2, 2),
    #             textcoords=&#39;offset points&#39;, ha=&#39;center&#39;, va=&#39;bottom&#39;,fontsize=12)
    #     plt.tight_layout()
    #     plt.savefig(saving_fpath)
    
    
    def save_graph_image_space_coords(self):
        &#34;&#34;&#34;Method used to save the organization of the tiles
        &#34;&#34;&#34;
        # Turn interactive plotting off
        saving_fpath = self.experiment_fpath / &#39;output_figures&#39; / &#39;image_space_tiles_organization.png&#39;
        plt.ioff()
        # Create image type axes
        labels = [str(nr) for nr in np.arange(self.tile_corners_coords_pxl.shape[0])]
        fig = plt.figure(figsize=(20,10))
        plt.gca().invert_yaxis()
        plt.plot(self.tile_corners_coords_pxl[:,1],self.tile_corners_coords_pxl[:,0],&#39;or&#39;)

        for label, x, y in zip(labels, self.tile_corners_coords_pxl[:,1],self.tile_corners_coords_pxl[:,0]):
            plt.annotate(
                label,
                xy=(x,y), xytext=(-2, 2),
                textcoords=&#39;offset points&#39;, ha=&#39;center&#39;, va=&#39;bottom&#39;,fontsize=12)
        plt.tight_layout()
        plt.savefig(saving_fpath)
        
    
    def identify_adjacent_tiles(self):
        &#34;&#34;&#34;Method that use Nearest neighbors to identify the beighbouring tiles
        &#34;&#34;&#34;
        shift_percent_tolerance = 0.05
        searching_radius = self.img_size - (self.img_size*self.overlapping_percentage) + (self.img_size*shift_percent_tolerance)
        nn = NearestNeighbors(n_neighbors=5,radius=searching_radius, metric=&#39;euclidean&#39;)
        nn.fit(self.tile_corners_coords_pxl)
        self.dists, self.indices = nn.kneighbors(self.tile_corners_coords_pxl, return_distance=True)


    def determine_overlapping_regions(self):
        &#34;&#34;&#34;Method used to calculate the coords of the overlapping regions between the tiles.
        &#34;&#34;&#34;
        # remember that overlapping region can be an empty dictionary
        self.overlapping_regions = {}
        self.overlapping_order ={}
        for idx in np.arange(self.indices.shape[0]):
            self.overlapping_regions[idx] = {}
            self.overlapping_order[idx] = {}
        for idx in np.arange(self.indices.shape[0]):
            # Determine the indices that identify the correct adjacent
            processing_indices = self.indices[idx,:]
            processing_dists = self.dists[idx,:]
            ref_tile = processing_indices[0]
            self.overlapping_regions[ref_tile] = {}
            self.overlapping_order[ref_tile] = {}
            trimmed_indices = processing_indices[1:]
            trimmed_dists = processing_dists[1:]

            idx_adj = np.where(trimmed_dists &lt; self.img_size)
            adj_tiles_id = trimmed_indices[idx_adj]
            adj_cpls = [(ref_tile, adj_tile) for adj_tile in adj_tiles_id]
            
            # remove pairs that are already selected
            only_new_cpls = [cpl for cpl in adj_cpls if (cpl[1],cpl[0]) not in self.overlapping_regions[cpl[1]].keys()]
            # only_new_cpls = [cpl for cpl in adj_cpls]

            if self.reference_corner_fov_position == &#39;top-left&#39;:
                for cpl in only_new_cpls:
                    tile1_r_coords = self.tile_corners_coords_pxl[cpl[0]][0]
                    tile2_r_coords = self.tile_corners_coords_pxl[cpl[1]][0]
                    tile1_c_coords = self.tile_corners_coords_pxl[cpl[0]][1]
                    tile2_c_coords = self.tile_corners_coords_pxl[cpl[1]][1]

                    if tile1_r_coords &gt; tile2_r_coords:
                            r_tl = tile1_r_coords
                            r_br = tile2_r_coords + self.img_height

                            row_order = (&#39;bottom&#39;,&#39;top&#39;)

                    else:
                        r_tl = tile2_r_coords
                        r_br = tile1_r_coords + self.img_height

                        row_order = (&#39;top&#39;,&#39;bottom&#39;)

                    if tile1_c_coords &gt; tile2_c_coords:
                        c_tl = tile1_c_coords
                        c_br = tile2_c_coords + self.img_width

                        col_order = (&#39;right&#39;,&#39;left&#39;)

                    else:
                        c_tl = tile2_c_coords
                        c_br = tile1_c_coords + self.img_width

                        col_order = (&#39;left&#39;,&#39;right&#39;)

                    self.overlapping_regions[ref_tile][cpl] = [r_tl, r_br, c_tl, c_br]
                    self.overlapping_order[ref_tile][cpl] = {&#39;row_order&#39;:row_order,&#39;column_order&#39;:col_order}
            
            elif self.reference_corner_fov_position == &#39;top-right&#39;:
                for cpl in only_new_cpls:
                    tile1_r_coords = self.tile_corners_coords_pxl[cpl[0]][0]
                    tile2_r_coords = self.tile_corners_coords_pxl[cpl[1]][0]
                    tile1_c_coords = self.tile_corners_coords_pxl[cpl[0]][1]
                    tile2_c_coords = self.tile_corners_coords_pxl[cpl[1]][1]

                    if tile1_r_coords &gt; tile2_r_coords:
                            r_tl = tile1_r_coords
                            r_br = tile2_r_coords + self.img_height

                            row_order = (&#39;bottom&#39;,&#39;top&#39;)

                    else:
                        r_tl = tile2_r_coords
                        r_br = tile1_r_coords + self.img_height

                        row_order = (&#39;top&#39;,&#39;bottom&#39;)

                    if tile1_c_coords &gt; tile2_c_coords:
                        c_tl = tile1_c_coords - self.img_width
                        c_br = tile2_c_coords 
                        col_order = (&#39;right&#39;,&#39;left&#39;)

                    else:
                        c_tl = tile2_c_coords - self.img_width
                        c_br = tile1_c_coords

                        col_order = (&#39;left&#39;,&#39;right&#39;)

                    self.overlapping_regions[ref_tile][cpl] = [r_tl, r_br, c_tl, c_br]
                    self.overlapping_order[ref_tile][cpl] = {&#39;row_order&#39;:row_order,&#39;column_order&#39;:col_order}


            elif self.reference_corner_fov_position == &#39;bottom-left&#39;:
                for cpl in only_new_cpls:
                    tile1_r_coords = self.tile_corners_coords_pxl[cpl[0]][0]
                    tile2_r_coords = self.tile_corners_coords_pxl[cpl[1]][0]
                    tile1_c_coords = self.tile_corners_coords_pxl[cpl[0]][1]
                    tile2_c_coords = self.tile_corners_coords_pxl[cpl[1]][1]

                    if tile1_r_coords &gt; tile2_r_coords:
                            r_tl = tile1_r_coords - self.img_height
                            r_br = tile2_r_coords

                            row_order = (&#39;bottom&#39;,&#39;top&#39;)

                    else:
                        r_tl = tile2_r_coords - self.img_height
                        r_br = tile1_r_coords

                        row_order = (&#39;top&#39;,&#39;bottom&#39;)

                    if tile1_c_coords &gt; tile2_c_coords:
                        c_tl = tile1_c_coords
                        c_br = tile2_c_coords + self.img_width 
                        col_order = (&#39;right&#39;,&#39;left&#39;)

                    else:
                        c_tl = tile2_c_coords 
                        c_br = tile1_c_coords + self.img_width 

                        col_order = (&#39;left&#39;,&#39;right&#39;)

                    self.overlapping_regions[ref_tile][cpl] = [r_tl, r_br, c_tl, c_br]
                    self.overlapping_order[ref_tile][cpl] = {&#39;row_order&#39;:row_order,&#39;column_order&#39;:col_order}


    def run_tiles_organization(self):
        &#34;&#34;&#34;Method used to run all the methods
        &#34;&#34;&#34;
        self.extract_microscope_coords()
        # self.save_graph_original_coords()
        self.normalize_coords()
        self.save_graph_image_space_coords()
        self.identify_adjacent_tiles()
        self.determine_overlapping_regions()
        fname = self.experiment_fpath / &#39;results&#39; / &#39;microscope_tile_corners_coords_pxl.npy&#39;
        np.save(fname,self.tile_corners_coords_pxl)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pysmFISH.stitching.organize_square_tiles.determine_overlapping_regions"><code class="name flex">
<span>def <span class="ident">determine_overlapping_regions</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Method used to calculate the coords of the overlapping regions between the tiles.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def determine_overlapping_regions(self):
    &#34;&#34;&#34;Method used to calculate the coords of the overlapping regions between the tiles.
    &#34;&#34;&#34;
    # remember that overlapping region can be an empty dictionary
    self.overlapping_regions = {}
    self.overlapping_order ={}
    for idx in np.arange(self.indices.shape[0]):
        self.overlapping_regions[idx] = {}
        self.overlapping_order[idx] = {}
    for idx in np.arange(self.indices.shape[0]):
        # Determine the indices that identify the correct adjacent
        processing_indices = self.indices[idx,:]
        processing_dists = self.dists[idx,:]
        ref_tile = processing_indices[0]
        self.overlapping_regions[ref_tile] = {}
        self.overlapping_order[ref_tile] = {}
        trimmed_indices = processing_indices[1:]
        trimmed_dists = processing_dists[1:]

        idx_adj = np.where(trimmed_dists &lt; self.img_size)
        adj_tiles_id = trimmed_indices[idx_adj]
        adj_cpls = [(ref_tile, adj_tile) for adj_tile in adj_tiles_id]
        
        # remove pairs that are already selected
        only_new_cpls = [cpl for cpl in adj_cpls if (cpl[1],cpl[0]) not in self.overlapping_regions[cpl[1]].keys()]
        # only_new_cpls = [cpl for cpl in adj_cpls]

        if self.reference_corner_fov_position == &#39;top-left&#39;:
            for cpl in only_new_cpls:
                tile1_r_coords = self.tile_corners_coords_pxl[cpl[0]][0]
                tile2_r_coords = self.tile_corners_coords_pxl[cpl[1]][0]
                tile1_c_coords = self.tile_corners_coords_pxl[cpl[0]][1]
                tile2_c_coords = self.tile_corners_coords_pxl[cpl[1]][1]

                if tile1_r_coords &gt; tile2_r_coords:
                        r_tl = tile1_r_coords
                        r_br = tile2_r_coords + self.img_height

                        row_order = (&#39;bottom&#39;,&#39;top&#39;)

                else:
                    r_tl = tile2_r_coords
                    r_br = tile1_r_coords + self.img_height

                    row_order = (&#39;top&#39;,&#39;bottom&#39;)

                if tile1_c_coords &gt; tile2_c_coords:
                    c_tl = tile1_c_coords
                    c_br = tile2_c_coords + self.img_width

                    col_order = (&#39;right&#39;,&#39;left&#39;)

                else:
                    c_tl = tile2_c_coords
                    c_br = tile1_c_coords + self.img_width

                    col_order = (&#39;left&#39;,&#39;right&#39;)

                self.overlapping_regions[ref_tile][cpl] = [r_tl, r_br, c_tl, c_br]
                self.overlapping_order[ref_tile][cpl] = {&#39;row_order&#39;:row_order,&#39;column_order&#39;:col_order}
        
        elif self.reference_corner_fov_position == &#39;top-right&#39;:
            for cpl in only_new_cpls:
                tile1_r_coords = self.tile_corners_coords_pxl[cpl[0]][0]
                tile2_r_coords = self.tile_corners_coords_pxl[cpl[1]][0]
                tile1_c_coords = self.tile_corners_coords_pxl[cpl[0]][1]
                tile2_c_coords = self.tile_corners_coords_pxl[cpl[1]][1]

                if tile1_r_coords &gt; tile2_r_coords:
                        r_tl = tile1_r_coords
                        r_br = tile2_r_coords + self.img_height

                        row_order = (&#39;bottom&#39;,&#39;top&#39;)

                else:
                    r_tl = tile2_r_coords
                    r_br = tile1_r_coords + self.img_height

                    row_order = (&#39;top&#39;,&#39;bottom&#39;)

                if tile1_c_coords &gt; tile2_c_coords:
                    c_tl = tile1_c_coords - self.img_width
                    c_br = tile2_c_coords 
                    col_order = (&#39;right&#39;,&#39;left&#39;)

                else:
                    c_tl = tile2_c_coords - self.img_width
                    c_br = tile1_c_coords

                    col_order = (&#39;left&#39;,&#39;right&#39;)

                self.overlapping_regions[ref_tile][cpl] = [r_tl, r_br, c_tl, c_br]
                self.overlapping_order[ref_tile][cpl] = {&#39;row_order&#39;:row_order,&#39;column_order&#39;:col_order}


        elif self.reference_corner_fov_position == &#39;bottom-left&#39;:
            for cpl in only_new_cpls:
                tile1_r_coords = self.tile_corners_coords_pxl[cpl[0]][0]
                tile2_r_coords = self.tile_corners_coords_pxl[cpl[1]][0]
                tile1_c_coords = self.tile_corners_coords_pxl[cpl[0]][1]
                tile2_c_coords = self.tile_corners_coords_pxl[cpl[1]][1]

                if tile1_r_coords &gt; tile2_r_coords:
                        r_tl = tile1_r_coords - self.img_height
                        r_br = tile2_r_coords

                        row_order = (&#39;bottom&#39;,&#39;top&#39;)

                else:
                    r_tl = tile2_r_coords - self.img_height
                    r_br = tile1_r_coords

                    row_order = (&#39;top&#39;,&#39;bottom&#39;)

                if tile1_c_coords &gt; tile2_c_coords:
                    c_tl = tile1_c_coords
                    c_br = tile2_c_coords + self.img_width 
                    col_order = (&#39;right&#39;,&#39;left&#39;)

                else:
                    c_tl = tile2_c_coords 
                    c_br = tile1_c_coords + self.img_width 

                    col_order = (&#39;left&#39;,&#39;right&#39;)

                self.overlapping_regions[ref_tile][cpl] = [r_tl, r_br, c_tl, c_br]
                self.overlapping_order[ref_tile][cpl] = {&#39;row_order&#39;:row_order,&#39;column_order&#39;:col_order}</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.organize_square_tiles.extract_microscope_coords"><code class="name flex">
<span>def <span class="ident">extract_microscope_coords</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Method to extract images coords in the stage reference
system</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extract_microscope_coords(self): 
    &#34;&#34;&#34;Method to extract images coords in the stage reference
    system&#34;&#34;&#34;
    

    selected = self.dataset.loc[self.dataset.round_num == self.round_num, 
                                [&#39;round_num&#39;,&#39;fov_num&#39;,&#39;fov_acquisition_coords_x&#39;,&#39;fov_acquisition_coords_y&#39;]]
    selected.drop_duplicates(subset=[&#39;fov_num&#39;],inplace=True)
    selected.sort_values(by=&#39;fov_num&#39;, ascending=True, inplace=True)
    self.x_coords = selected.loc[:,&#39;fov_acquisition_coords_x&#39;].to_numpy()
    self.y_coords = selected.loc[:,&#39;fov_acquisition_coords_y&#39;].to_numpy()</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.organize_square_tiles.identify_adjacent_tiles"><code class="name flex">
<span>def <span class="ident">identify_adjacent_tiles</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Method that use Nearest neighbors to identify the beighbouring tiles</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def identify_adjacent_tiles(self):
    &#34;&#34;&#34;Method that use Nearest neighbors to identify the beighbouring tiles
    &#34;&#34;&#34;
    shift_percent_tolerance = 0.05
    searching_radius = self.img_size - (self.img_size*self.overlapping_percentage) + (self.img_size*shift_percent_tolerance)
    nn = NearestNeighbors(n_neighbors=5,radius=searching_radius, metric=&#39;euclidean&#39;)
    nn.fit(self.tile_corners_coords_pxl)
    self.dists, self.indices = nn.kneighbors(self.tile_corners_coords_pxl, return_distance=True)</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.organize_square_tiles.normalize_coords"><code class="name flex">
<span>def <span class="ident">normalize_coords</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Normalize the coords according to how the stage/camera are set.
This function must be modified according to the stage/camera setup.</p>
<p>ROBOFISH1 has stage with x increasing left-&gt; right and y top-&gt;bottom
------&gt; (x)
|
|
V (y)</p>
<p>ROBOFISH2 has stage with x increasing right-&gt; left and y top-&gt;bottom
(x) &lt;------
|
|
V (y)</p>
<p>ROBOFISH3 has stage with x increasing left-&gt; right and y bottom-&gt;top
^ (y)
|
|
------&gt; (x)</p>
<p>Axis modifications steps:
(1) The reference system will be first converted to image style:
------&gt; (x)
|
|
V (y)</p>
<p>This step will cause a change in the position of the reference corner
for each fov. After image acquisition the reference corner is top-left
however after converting the axis direction to image-style the reference corner
will change postion:
ROBOFISH1: top-left &ndash;&gt; top-left
ROBOFISH2: top-left &ndash;&gt; top-right
ROBOFISH3: top-left &ndash;&gt; bottom-left</p>
<p>(2) The coords will be translated to (0,0)</p>
<p>(3) then to matrix (python) notation
------&gt; (columns)
|
|
V (rows)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def normalize_coords(self):
    &#34;&#34;&#34;
    Normalize the coords according to how the stage/camera are set.
    This function must be modified according to the stage/camera setup.

    ROBOFISH1 has stage with x increasing left-&gt; right and y top-&gt;bottom 
        ------&gt; (x)
        |
        |
        V (y)
    
    ROBOFISH2 has stage with x increasing right-&gt; left and y top-&gt;bottom 
    (x) &lt;------
              |
              |
              V (y)
    

    ROBOFISH3 has stage with x increasing left-&gt; right and y bottom-&gt;top 
        ^ (y)
        |
        |
        ------&gt; (x)

    Axis modifications steps:
    (1) The reference system will be first converted to image style:
        ------&gt; (x)
        |
        |
        V (y)

    This step will cause a change in the position of the reference corner
    for each fov. After image acquisition the reference corner is top-left
    however after converting the axis direction to image-style the reference corner
    will change postion:
    ROBOFISH1: top-left --&gt; top-left
    ROBOFISH2: top-left --&gt; top-right
    ROBOFISH3: top-left --&gt; bottom-left

    (2) The coords will be translated to (0,0)

    (3) then to matrix (python) notation
        ------&gt; (columns)
        |
        |
        V (rows)

    &#34;&#34;&#34;

    # port the coords to image type coords
    if self.metadata[&#39;machine&#39;] == &#39;ROBOFISH2&#39;:
        self.x_coords = - self.x_coords
        self.reference_corner_fov_position = &#39;top-right&#39;
    elif self.metadata[&#39;machine&#39;] == &#39;ROBOFISH3&#39;:
        self.x_coords = - self.x_coords
        self.y_coords = - self.y_coords
        self.reference_corner_fov_position = &#39;bottom-left&#39;
    elif self.metadata[&#39;machine&#39;] == &#39;ROBOFISH1&#39;:
        self.reference_corner_fov_position = &#39;top-left&#39;
    elif self.metadata[&#39;machine&#39;] == &#39;NOT_DEFINED&#39;:
        self.logger.error(f&#39;Need to define the specs for stitching NOT_DEFINED machine&#39;)
        sys.exit(f&#39;Need to define the specs for stitching NOT_DEFINED machine&#39;)
    else:
        self.logger.error(f&#39;define the right machine used to collected the data&#39;)
        sys.exit(f&#39;define the right machine used to collected the data&#39;)

    # shift the coords to reference point (0,0) 
    # consider that we get the top-right corner of the image as well
    y_min = np.amin(self.y_coords)
    x_min = np.amin(self.x_coords)
    x_max = np.amax(self.x_coords)
    y_max = np.amax(self.y_coords)


    # Put the coords to zero
    if x_min &gt;=0 :
        self.x_coords = self.x_coords - x_min
    else:
        self.x_coords = self.x_coords + np.abs(x_min)
    
    if y_min&gt;0:
        self.y_coords = self.y_coords - y_min
    else:
        self.y_coords = self.y_coords + np.abs(y_min)


    # if x_max &gt;=0 :
    #     self.x_coords = self.x_coords - x_min
    # else:
    #     self.x_coords = self.x_coords + np.abs(x_min)
    
    # if y_max&gt;0:
    #     self.y_coords = self.y_coords - y_min
    # else:
    #     self.y_coords = self.y_coords + np.abs(y_min)

    # change the coords from x,y to r,c
    adjusted_coords = np.zeros([self.x_coords.shape[0],2])
    adjusted_coords[:,0] = self.y_coords
    adjusted_coords[:,1] = self.x_coords

    # move coords to pxl space
    self.tile_corners_coords_pxl = adjusted_coords / self.pixel_size</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.organize_square_tiles.run_tiles_organization"><code class="name flex">
<span>def <span class="ident">run_tiles_organization</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Method used to run all the methods</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_tiles_organization(self):
    &#34;&#34;&#34;Method used to run all the methods
    &#34;&#34;&#34;
    self.extract_microscope_coords()
    # self.save_graph_original_coords()
    self.normalize_coords()
    self.save_graph_image_space_coords()
    self.identify_adjacent_tiles()
    self.determine_overlapping_regions()
    fname = self.experiment_fpath / &#39;results&#39; / &#39;microscope_tile_corners_coords_pxl.npy&#39;
    np.save(fname,self.tile_corners_coords_pxl)</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.organize_square_tiles.save_graph_image_space_coords"><code class="name flex">
<span>def <span class="ident">save_graph_image_space_coords</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Method used to save the organization of the tiles</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_graph_image_space_coords(self):
    &#34;&#34;&#34;Method used to save the organization of the tiles
    &#34;&#34;&#34;
    # Turn interactive plotting off
    saving_fpath = self.experiment_fpath / &#39;output_figures&#39; / &#39;image_space_tiles_organization.png&#39;
    plt.ioff()
    # Create image type axes
    labels = [str(nr) for nr in np.arange(self.tile_corners_coords_pxl.shape[0])]
    fig = plt.figure(figsize=(20,10))
    plt.gca().invert_yaxis()
    plt.plot(self.tile_corners_coords_pxl[:,1],self.tile_corners_coords_pxl[:,0],&#39;or&#39;)

    for label, x, y in zip(labels, self.tile_corners_coords_pxl[:,1],self.tile_corners_coords_pxl[:,0]):
        plt.annotate(
            label,
            xy=(x,y), xytext=(-2, 2),
            textcoords=&#39;offset points&#39;, ha=&#39;center&#39;, va=&#39;bottom&#39;,fontsize=12)
    plt.tight_layout()
    plt.savefig(saving_fpath)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pysmFISH.stitching.organize_square_tiles_old_room"><code class="flex name class">
<span>class <span class="ident">organize_square_tiles_old_room</span></span>
<span>(</span><span>experiment_fpath:Â str, dataset, metadata:Â Dict, round_num:Â int)</span>
</code></dt>
<dd>
<div class="desc"><p>Class used to identify the orgabnization of the tiles before the
reorganization of the Robofish room of April 2021 when Robofish3
was assembled.</p>
<p>round_num = int
reference channel</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class organize_square_tiles_old_room():

    &#34;&#34;&#34;
    Class used to identify the orgabnization of the tiles before the
    reorganization of the Robofish room of April 2021 when Robofish3
    was assembled.
    &#34;&#34;&#34;

    def __init__(self, experiment_fpath:str,dataset, metadata:Dict,round_num:int):
        &#34;&#34;&#34;
        round_num = int
            reference channel
        &#34;&#34;&#34;
        
        self.logger = selected_logger()
        self.experiment_fpath = Path(experiment_fpath)
        self.dataset = dataset
        self.metadata = metadata
        self.round_num = round_num
        
        self.experiment_name = self.metadata[&#39;experiment_name&#39;]
        self.stitching_channel = self.metadata[&#39;stitching_channel&#39;]
        self.overlapping_percentage = int(self.metadata[&#39;overlapping_percentage&#39;]) / 100
         
        self.pixel_size = self.metadata[&#39;pixel_microns&#39;]
        self.img_width = self.metadata[&#39;img_width&#39;]
        self.img_height = self.metadata[&#39;img_height&#39;]
        
        logging.getLogger(&#39;matplotlib.font_manager&#39;).disabled = True
        
        if  self.img_width ==  self.img_height:
            self.img_size = self.img_width
        else:
            self.logger.error(f&#39;the images to stitch are not square&#39;)
            sys.exit(f&#39;the images to stitch are not square&#39;)
            
    
    def extract_microscope_coords(self): 
        

        selected = self.dataset.loc[self.dataset.round_num == self.round_num, 
                                    [&#39;round_num&#39;,&#39;fov_num&#39;,&#39;fov_acquisition_coords_x&#39;,&#39;fov_acquisition_coords_y&#39;]]
        selected.drop_duplicates(subset=[&#39;fov_num&#39;],inplace=True)
        selected.sort_values(by=&#39;fov_num&#39;, ascending=True, inplace=True)
        self.x_coords = selected.loc[:,&#39;fov_acquisition_coords_x&#39;].to_numpy()
        self.y_coords = selected.loc[:,&#39;fov_acquisition_coords_y&#39;].to_numpy()


    def normalize_coords(self):

        if self.metadata[&#39;machine&#39;] == &#39;ROBOFISH2&#39;:
            # RobofishII has stage with reference point
            # in the center (0,0)
            # consider that we get the top-right corner of the image as well

            self.reference_corner_fov_position = &#39;old-room-robofish2&#39;  # Not sure (i don&#39;t remember)
            # consider that we get the top-right corner of the image as well
            y_min = np.amin(self.y_coords)
            x_min = np.amin(self.x_coords)
            x_max = np.amax(self.x_coords)
            y_max = np.amax(self.y_coords)

            # Put the coords to zero
    
            if x_max &gt;=0 :
                self.x_coords = self.x_coords - x_min
            else:
                self.x_coords = self.x_coords + np.abs(x_min)
            
            if y_max&gt;0:
                self.y_coords = self.y_coords - y_min
            else:
                self.y_coords = self.y_coords + np.abs(y_min)

            # flip y_axis
            self.y_coords = self.y_coords - self.y_coords.max()
            self.y_coords = - self.y_coords


            # change the coords from x,y to r,c
            adjusted_coords = np.zeros([self.x_coords.shape[0],2])
            adjusted_coords[:,0] = self.y_coords
            adjusted_coords[:,1] = self.x_coords

        elif self.metadata[&#39;machine&#39;] == &#39;ROBOFISH1&#39;:
            # The current system has stage ref coords BOTTOM-RIGH
            self.reference_corner_fov_position = &#39;bottom-right&#39;
            # Normalize to (0,0) still BOTTOM-RIGHT
            y_min = np.amin(self.y_coords)
            x_min = np.amin(self.x_coords)

            self.x_coords = self.x_coords - x_min
            self.y_coords = self.y_coords - y_min

            # flip axis to move (0,0) on TOP-LEF
            self.x_coords = self.x_coords - self.x_coords.max()
            self.x_coords = - self.x_coords

            self.y_coords = self.y_coords - self.y_coords.max()
            self.y_coords = - self.y_coords

            # change the coords from x,y to r,c
            adjusted_coords = np.zeros([self.x_coords.shape[0],2])
            adjusted_coords[:,0] = self.y_coords
            adjusted_coords[:,1] = self.x_coords
        
        elif self.metadata[&#39;machine&#39;] == &#39;NOT_DEFINED&#39;:
            self.logger.error(f&#39;Need to define the specs for stitching NOT_DEFINED machine&#39;)
            sys.exit(f&#39;Need to define the specs for stitching NOT_DEFINED machine&#39;)
            
        else:
            self.logger.error(f&#39;define the right machine used to collected the data&#39;)
            sys.exit(f&#39;define the right machine used to collected the data&#39;)
        
        self.tile_corners_coords_pxl = adjusted_coords / self.pixel_size
    
    
    def save_graph_original_coords(self):
        # Turn interactive plotting off
        saving_fpath = self.experiment_fpath / &#39;output_figures&#39; / &#39;microscope_space_tiles_organization.png&#39;
        plt.ioff()
        # Create image type axes
        labels = [str(nr) for nr in np.arange(self.x_coords.shape[0])]
        fig = plt.figure(figsize=(20,10))
        plt.plot(self.x_coords,self.y_coords,&#39;or&#39;)

        for label, x, y in zip(labels, self.x_coords,self.y_coords):
            plt.annotate(
                label,
                xy=(x,y), xytext=(-2, 2),
                textcoords=&#39;offset points&#39;, ha=&#39;center&#39;, va=&#39;bottom&#39;,fontsize=12)
        plt.tight_layout()
        plt.savefig(saving_fpath)
    
    
    def save_graph_image_space_coords(self):
        # Turn interactive plotting off
        saving_fpath = self.experiment_fpath / &#39;output_figures&#39; / &#39;image_space_tiles_organization.png&#39;
        plt.ioff()
        # Create image type axes
        labels = [str(nr) for nr in np.arange(self.tile_corners_coords_pxl.shape[0])]
        fig = plt.figure(figsize=(20,10))
        plt.gca().invert_yaxis()
        plt.plot(self.tile_corners_coords_pxl[:,1],self.tile_corners_coords_pxl[:,0],&#39;or&#39;)

        for label, x, y in zip(labels, self.tile_corners_coords_pxl[:,1],self.tile_corners_coords_pxl[:,0]):
            plt.annotate(
                label,
                xy=(x,y), xytext=(-2, 2),
                textcoords=&#39;offset points&#39;, ha=&#39;center&#39;, va=&#39;bottom&#39;,fontsize=12)
        plt.tight_layout()
        plt.savefig(saving_fpath)
        
    
    def identify_adjacent_tiles(self):
        shift_percent_tolerance = 0.05
        searching_radius = self.img_size - (self.img_size*self.overlapping_percentage) + (self.img_size*shift_percent_tolerance)
        nn = NearestNeighbors(n_neighbors=5,radius=searching_radius, metric=&#39;euclidean&#39;)
        nn.fit(self.tile_corners_coords_pxl)
        self.dists, self.indices = nn.kneighbors(self.tile_corners_coords_pxl, return_distance=True)


    def determine_overlapping_regions(self):
        # remember that overlapping region can be an empty dictionary
        self.overlapping_regions = {}
        self.overlapping_order ={}
        for idx in np.arange(self.indices.shape[0]):
            self.overlapping_regions[idx] = {}
            self.overlapping_order[idx] = {}
        for idx in np.arange(self.indices.shape[0]):
            # Determine the indices that identify the correct adjacent
            processing_indices = self.indices[idx,:]
            processing_dists = self.dists[idx,:]
            ref_tile = processing_indices[0]
            self.overlapping_regions[ref_tile] = {}
            self.overlapping_order[ref_tile] = {}
            trimmed_indices = processing_indices[1:]
            trimmed_dists = processing_dists[1:]

            idx_adj = np.where(trimmed_dists &lt; self.img_size)
            adj_tiles_id = trimmed_indices[idx_adj]
            adj_cpls = [(ref_tile, adj_tile) for adj_tile in adj_tiles_id]
            
            # remove pairs that are already selected
            only_new_cpls = [cpl for cpl in adj_cpls if (cpl[1],cpl[0]) not in self.overlapping_regions[cpl[1]].keys()]
            # only_new_cpls = [cpl for cpl in adj_cpls]

            if self.metadata[&#39;machine&#39;] == &#39;ROBOFISH2&#39;:
                # If tile coords are top left
                for cpl in only_new_cpls:

                    tile1_r_coords = self.tile_corners_coords_pxl[cpl[0]][0]
                    tile2_r_coords = self.tile_corners_coords_pxl[cpl[1]][0]
                    tile1_c_coords = self.tile_corners_coords_pxl[cpl[0]][1]
                    tile2_c_coords = self.tile_corners_coords_pxl[cpl[1]][1]

                    if tile1_r_coords &gt; tile2_r_coords:
                        r_tl = tile1_r_coords
                        r_br = tile2_r_coords + self.img_size

                        r_bl = tile2_c_coords + self.img_size
                        r_tr = tile1_c_coords

                        row_order = (&#39;bottom&#39;,&#39;top&#39;)

                    else:
                        r_tl = tile2_r_coords
                        r_br = tile1_r_coords + self.img_size

                        r_bl = tile1_r_coords + self.img_size
                        r_tr = tile2_r_coords

                        row_order = (&#39;top&#39;,&#39;bottom&#39;)

                    if tile1_c_coords &gt; tile2_c_coords:
                        c_tl = tile1_c_coords
                        c_br = tile2_c_coords + self.img_size

                        c_tr = tile2_c_coords + self.img_size
                        c_bl = tile1_c_coords

                        col_order = (&#39;right&#39;,&#39;left&#39;)

                    else:
                        c_tl = tile2_c_coords
                        c_br = tile1_c_coords + self.img_size

                        c_bl = tile2_c_coords
                        c_tr = tile1_c_coords + self.img_size

                        col_order = (&#39;left&#39;,&#39;right&#39;)

                

            elif self.metadata[&#39;machine&#39;] == &#39;ROBOFISH1&#39;:
                # If tile coords are bottom right
                for cpl in only_new_cpls:

                    tile1_r_coords = self.tile_corners_coords_pxl[cpl[0]][0]
                    tile2_r_coords = self.tile_corners_coords_pxl[cpl[1]][0]
                    tile1_c_coords = self.tile_corners_coords_pxl[cpl[0]][1]
                    tile2_c_coords = self.tile_corners_coords_pxl[cpl[1]][1]

                    if tile1_r_coords &gt; tile2_r_coords:
                        r_tl = tile1_r_coords - self.img_size
                        r_br = tile2_r_coords

                        r_bl = tile2_c_coords
                        r_tr = tile1_c_coords - self.img_size

                        row_order = (&#39;bottom&#39;,&#39;top&#39;)

                    else:
                        r_tl = tile2_r_coords - self.img_size
                        r_br = tile1_r_coords 

                        r_bl = tile1_r_coords 
                        r_tr = tile2_r_coords - self.img_size

                        row_order = (&#39;top&#39;,&#39;bottom&#39;)

                    if tile1_c_coords &gt; tile2_c_coords:
                        c_tl = tile1_c_coords - self.img_size
                        c_br = tile2_c_coords 

                        c_tr = tile2_c_coords
                        c_bl = tile1_c_coords - self.img_size

                        col_order = (&#39;right&#39;,&#39;left&#39;)

                    else:
                        c_tl = tile2_c_coords - self.img_size
                        c_br = tile1_c_coords 

                        c_bl = tile2_c_coords - self.img_size
                        c_tr = tile1_c_coords 

                        col_order = (&#39;left&#39;,&#39;right&#39;)
            else:
                pass

            self.overlapping_regions[ref_tile][cpl] = [r_tl, r_br, c_tl, c_br]
            self.overlapping_order[ref_tile][cpl] = {&#39;row_order&#39;:row_order,&#39;column_order&#39;:col_order}

    def run_tiles_organization(self):
        self.extract_microscope_coords()
        self.save_graph_original_coords()
        self.normalize_coords()
        self.save_graph_image_space_coords()
        self.identify_adjacent_tiles()
        self.determine_overlapping_regions()
        fname = self.experiment_fpath / &#39;results&#39; / &#39;microscope_tile_corners_coords_pxl.npy&#39;
        np.save(fname,self.tile_corners_coords_pxl)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pysmFISH.stitching.organize_square_tiles_old_room.determine_overlapping_regions"><code class="name flex">
<span>def <span class="ident">determine_overlapping_regions</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def determine_overlapping_regions(self):
    # remember that overlapping region can be an empty dictionary
    self.overlapping_regions = {}
    self.overlapping_order ={}
    for idx in np.arange(self.indices.shape[0]):
        self.overlapping_regions[idx] = {}
        self.overlapping_order[idx] = {}
    for idx in np.arange(self.indices.shape[0]):
        # Determine the indices that identify the correct adjacent
        processing_indices = self.indices[idx,:]
        processing_dists = self.dists[idx,:]
        ref_tile = processing_indices[0]
        self.overlapping_regions[ref_tile] = {}
        self.overlapping_order[ref_tile] = {}
        trimmed_indices = processing_indices[1:]
        trimmed_dists = processing_dists[1:]

        idx_adj = np.where(trimmed_dists &lt; self.img_size)
        adj_tiles_id = trimmed_indices[idx_adj]
        adj_cpls = [(ref_tile, adj_tile) for adj_tile in adj_tiles_id]
        
        # remove pairs that are already selected
        only_new_cpls = [cpl for cpl in adj_cpls if (cpl[1],cpl[0]) not in self.overlapping_regions[cpl[1]].keys()]
        # only_new_cpls = [cpl for cpl in adj_cpls]

        if self.metadata[&#39;machine&#39;] == &#39;ROBOFISH2&#39;:
            # If tile coords are top left
            for cpl in only_new_cpls:

                tile1_r_coords = self.tile_corners_coords_pxl[cpl[0]][0]
                tile2_r_coords = self.tile_corners_coords_pxl[cpl[1]][0]
                tile1_c_coords = self.tile_corners_coords_pxl[cpl[0]][1]
                tile2_c_coords = self.tile_corners_coords_pxl[cpl[1]][1]

                if tile1_r_coords &gt; tile2_r_coords:
                    r_tl = tile1_r_coords
                    r_br = tile2_r_coords + self.img_size

                    r_bl = tile2_c_coords + self.img_size
                    r_tr = tile1_c_coords

                    row_order = (&#39;bottom&#39;,&#39;top&#39;)

                else:
                    r_tl = tile2_r_coords
                    r_br = tile1_r_coords + self.img_size

                    r_bl = tile1_r_coords + self.img_size
                    r_tr = tile2_r_coords

                    row_order = (&#39;top&#39;,&#39;bottom&#39;)

                if tile1_c_coords &gt; tile2_c_coords:
                    c_tl = tile1_c_coords
                    c_br = tile2_c_coords + self.img_size

                    c_tr = tile2_c_coords + self.img_size
                    c_bl = tile1_c_coords

                    col_order = (&#39;right&#39;,&#39;left&#39;)

                else:
                    c_tl = tile2_c_coords
                    c_br = tile1_c_coords + self.img_size

                    c_bl = tile2_c_coords
                    c_tr = tile1_c_coords + self.img_size

                    col_order = (&#39;left&#39;,&#39;right&#39;)

            

        elif self.metadata[&#39;machine&#39;] == &#39;ROBOFISH1&#39;:
            # If tile coords are bottom right
            for cpl in only_new_cpls:

                tile1_r_coords = self.tile_corners_coords_pxl[cpl[0]][0]
                tile2_r_coords = self.tile_corners_coords_pxl[cpl[1]][0]
                tile1_c_coords = self.tile_corners_coords_pxl[cpl[0]][1]
                tile2_c_coords = self.tile_corners_coords_pxl[cpl[1]][1]

                if tile1_r_coords &gt; tile2_r_coords:
                    r_tl = tile1_r_coords - self.img_size
                    r_br = tile2_r_coords

                    r_bl = tile2_c_coords
                    r_tr = tile1_c_coords - self.img_size

                    row_order = (&#39;bottom&#39;,&#39;top&#39;)

                else:
                    r_tl = tile2_r_coords - self.img_size
                    r_br = tile1_r_coords 

                    r_bl = tile1_r_coords 
                    r_tr = tile2_r_coords - self.img_size

                    row_order = (&#39;top&#39;,&#39;bottom&#39;)

                if tile1_c_coords &gt; tile2_c_coords:
                    c_tl = tile1_c_coords - self.img_size
                    c_br = tile2_c_coords 

                    c_tr = tile2_c_coords
                    c_bl = tile1_c_coords - self.img_size

                    col_order = (&#39;right&#39;,&#39;left&#39;)

                else:
                    c_tl = tile2_c_coords - self.img_size
                    c_br = tile1_c_coords 

                    c_bl = tile2_c_coords - self.img_size
                    c_tr = tile1_c_coords 

                    col_order = (&#39;left&#39;,&#39;right&#39;)
        else:
            pass

        self.overlapping_regions[ref_tile][cpl] = [r_tl, r_br, c_tl, c_br]
        self.overlapping_order[ref_tile][cpl] = {&#39;row_order&#39;:row_order,&#39;column_order&#39;:col_order}</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.organize_square_tiles_old_room.extract_microscope_coords"><code class="name flex">
<span>def <span class="ident">extract_microscope_coords</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extract_microscope_coords(self): 
    

    selected = self.dataset.loc[self.dataset.round_num == self.round_num, 
                                [&#39;round_num&#39;,&#39;fov_num&#39;,&#39;fov_acquisition_coords_x&#39;,&#39;fov_acquisition_coords_y&#39;]]
    selected.drop_duplicates(subset=[&#39;fov_num&#39;],inplace=True)
    selected.sort_values(by=&#39;fov_num&#39;, ascending=True, inplace=True)
    self.x_coords = selected.loc[:,&#39;fov_acquisition_coords_x&#39;].to_numpy()
    self.y_coords = selected.loc[:,&#39;fov_acquisition_coords_y&#39;].to_numpy()</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.organize_square_tiles_old_room.identify_adjacent_tiles"><code class="name flex">
<span>def <span class="ident">identify_adjacent_tiles</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def identify_adjacent_tiles(self):
    shift_percent_tolerance = 0.05
    searching_radius = self.img_size - (self.img_size*self.overlapping_percentage) + (self.img_size*shift_percent_tolerance)
    nn = NearestNeighbors(n_neighbors=5,radius=searching_radius, metric=&#39;euclidean&#39;)
    nn.fit(self.tile_corners_coords_pxl)
    self.dists, self.indices = nn.kneighbors(self.tile_corners_coords_pxl, return_distance=True)</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.organize_square_tiles_old_room.normalize_coords"><code class="name flex">
<span>def <span class="ident">normalize_coords</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def normalize_coords(self):

    if self.metadata[&#39;machine&#39;] == &#39;ROBOFISH2&#39;:
        # RobofishII has stage with reference point
        # in the center (0,0)
        # consider that we get the top-right corner of the image as well

        self.reference_corner_fov_position = &#39;old-room-robofish2&#39;  # Not sure (i don&#39;t remember)
        # consider that we get the top-right corner of the image as well
        y_min = np.amin(self.y_coords)
        x_min = np.amin(self.x_coords)
        x_max = np.amax(self.x_coords)
        y_max = np.amax(self.y_coords)

        # Put the coords to zero

        if x_max &gt;=0 :
            self.x_coords = self.x_coords - x_min
        else:
            self.x_coords = self.x_coords + np.abs(x_min)
        
        if y_max&gt;0:
            self.y_coords = self.y_coords - y_min
        else:
            self.y_coords = self.y_coords + np.abs(y_min)

        # flip y_axis
        self.y_coords = self.y_coords - self.y_coords.max()
        self.y_coords = - self.y_coords


        # change the coords from x,y to r,c
        adjusted_coords = np.zeros([self.x_coords.shape[0],2])
        adjusted_coords[:,0] = self.y_coords
        adjusted_coords[:,1] = self.x_coords

    elif self.metadata[&#39;machine&#39;] == &#39;ROBOFISH1&#39;:
        # The current system has stage ref coords BOTTOM-RIGH
        self.reference_corner_fov_position = &#39;bottom-right&#39;
        # Normalize to (0,0) still BOTTOM-RIGHT
        y_min = np.amin(self.y_coords)
        x_min = np.amin(self.x_coords)

        self.x_coords = self.x_coords - x_min
        self.y_coords = self.y_coords - y_min

        # flip axis to move (0,0) on TOP-LEF
        self.x_coords = self.x_coords - self.x_coords.max()
        self.x_coords = - self.x_coords

        self.y_coords = self.y_coords - self.y_coords.max()
        self.y_coords = - self.y_coords

        # change the coords from x,y to r,c
        adjusted_coords = np.zeros([self.x_coords.shape[0],2])
        adjusted_coords[:,0] = self.y_coords
        adjusted_coords[:,1] = self.x_coords
    
    elif self.metadata[&#39;machine&#39;] == &#39;NOT_DEFINED&#39;:
        self.logger.error(f&#39;Need to define the specs for stitching NOT_DEFINED machine&#39;)
        sys.exit(f&#39;Need to define the specs for stitching NOT_DEFINED machine&#39;)
        
    else:
        self.logger.error(f&#39;define the right machine used to collected the data&#39;)
        sys.exit(f&#39;define the right machine used to collected the data&#39;)
    
    self.tile_corners_coords_pxl = adjusted_coords / self.pixel_size</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.organize_square_tiles_old_room.run_tiles_organization"><code class="name flex">
<span>def <span class="ident">run_tiles_organization</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_tiles_organization(self):
    self.extract_microscope_coords()
    self.save_graph_original_coords()
    self.normalize_coords()
    self.save_graph_image_space_coords()
    self.identify_adjacent_tiles()
    self.determine_overlapping_regions()
    fname = self.experiment_fpath / &#39;results&#39; / &#39;microscope_tile_corners_coords_pxl.npy&#39;
    np.save(fname,self.tile_corners_coords_pxl)</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.organize_square_tiles_old_room.save_graph_image_space_coords"><code class="name flex">
<span>def <span class="ident">save_graph_image_space_coords</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_graph_image_space_coords(self):
    # Turn interactive plotting off
    saving_fpath = self.experiment_fpath / &#39;output_figures&#39; / &#39;image_space_tiles_organization.png&#39;
    plt.ioff()
    # Create image type axes
    labels = [str(nr) for nr in np.arange(self.tile_corners_coords_pxl.shape[0])]
    fig = plt.figure(figsize=(20,10))
    plt.gca().invert_yaxis()
    plt.plot(self.tile_corners_coords_pxl[:,1],self.tile_corners_coords_pxl[:,0],&#39;or&#39;)

    for label, x, y in zip(labels, self.tile_corners_coords_pxl[:,1],self.tile_corners_coords_pxl[:,0]):
        plt.annotate(
            label,
            xy=(x,y), xytext=(-2, 2),
            textcoords=&#39;offset points&#39;, ha=&#39;center&#39;, va=&#39;bottom&#39;,fontsize=12)
    plt.tight_layout()
    plt.savefig(saving_fpath)</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.organize_square_tiles_old_room.save_graph_original_coords"><code class="name flex">
<span>def <span class="ident">save_graph_original_coords</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_graph_original_coords(self):
    # Turn interactive plotting off
    saving_fpath = self.experiment_fpath / &#39;output_figures&#39; / &#39;microscope_space_tiles_organization.png&#39;
    plt.ioff()
    # Create image type axes
    labels = [str(nr) for nr in np.arange(self.x_coords.shape[0])]
    fig = plt.figure(figsize=(20,10))
    plt.plot(self.x_coords,self.y_coords,&#39;or&#39;)

    for label, x, y in zip(labels, self.x_coords,self.y_coords):
        plt.annotate(
            label,
            xy=(x,y), xytext=(-2, 2),
            textcoords=&#39;offset points&#39;, ha=&#39;center&#39;, va=&#39;bottom&#39;,fontsize=12)
    plt.tight_layout()
    plt.savefig(saving_fpath)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pysmFISH.stitching.r_c_chunking"><code class="flex name class">
<span>class <span class="ident">r_c_chunking</span></span>
<span>(</span><span>region_dimensions, r_chunk_size, c_chunk_size, tl_coords)</span>
</code></dt>
<dd>
<div class="desc"><p>Utility class used to chunk and arbitrary region and obtain the coords if the chunks.
The chunking can be different between row and
columns</p>
<h2 id="parameters">Parameters:</h2>
<p>region_dimensions: np.ndarray
number of rows and columns of the region to chunk
r_chunk_size: float
size of the chunks along the rows
c_chunk_size: float
size of the chunks along the columns
tl_coords: np.ndarray
coordinate of the top left corner of the region to chunk
to use to calculate the coords of the chunks</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class r_c_chunking():
    &#34;&#34;&#34;
    Utility class used to chunk and arbitrary region and obtain the coords if the chunks.
    The chunking can be different between row and 
    columns

    Parameters:
    -----------

    region_dimensions: np.ndarray
        number of rows and columns of the region to chunk
    r_chunk_size: float
        size of the chunks along the rows
    c_chunk_size: float
        size of the chunks along the columns
    tl_coords: np.ndarray
        coordinate of the top left corner of the region to chunk
        to use to calculate the coords of the chunks

    &#34;&#34;&#34;

    def __init__(self, region_dimensions, r_chunk_size, c_chunk_size, tl_coords):
        self.region_dimensions = region_dimensions
        self.r_chunk_size = r_chunk_size
        self.c_chunk_size = c_chunk_size
        self.tl_coords = tl_coords
    

    @staticmethod
    def block_chunks_calculator(dimension,chunk_size):
        &#34;&#34;&#34;
        Helper function to calculate the size of the chunks created according
        the length of the vector and the chunk size.

        Parameters:
        -----------

        dimension: int
            Length of the vector to Chunk
        chunkSize: int 
            Dimension of the Chunks

        Returns:
        -----------

        chunks_sizes: np.array 
            Array of the sizes of the created chunks. It deals with conditions 
            when the expected chunks size do not fit an even number of times in the 
            dimension
        &#34;&#34;&#34;
        number_even_chunks=int(dimension//chunk_size)
        total_size_even_chunks=number_even_chunks*chunk_size
        odd_tile_size=dimension-total_size_even_chunks
        chunk_sizes=[]
        chunks_sizes=list(np.repeat(chunk_size,number_even_chunks-1))
        if odd_tile_size &lt; chunk_size:
            chunks_sizes.append(chunk_size+odd_tile_size)
        else:
            chunks_sizes.append(odd_tile_size)
        return tuple(chunks_sizes)
    
    def block_chunking(self):
        &#34;&#34;&#34;
        Function used to generate the coords of the images according to the
        chunking 

        Notes:
        ------

        For both lists each np.array contains the coords in the following order:
        [row_tl,row_br,col_tl,col_br]

        &#34;&#34;&#34;
        num_r,num_c = self.region_dimensions
        self.starting_position = self.tl_coords
        self.end_position = self.tl_coords + self.region_dimensions

        # Calculate the size of the chunks
        r_chunks_size = self.block_chunks_calculator(num_r,self.r_chunk_size)
        
        c_chunks_size = self.block_chunks_calculator(num_c,self.c_chunk_size)
        
        # Calculate the total numbers of chunks
        nr_chunks = len(r_chunks_size)
        
        nc_chunks = len(c_chunks_size)
       


        # Coords top left corner (tl)
        if nr_chunks == 1:
            r_coords_tl = self.starting_position[0]
        else: 
            r_coords_tl = [self.starting_position[0]]
            for i in np.arange(1,nr_chunks):
                r_coords_tl.append(r_coords_tl[i-1] + self.r_chunk_size )
            r_coords_tl = np.array(r_coords_tl)
            # r_coords_tl = np.arange(self.starting_position[0],(self.starting_position[0]+self.r_chunk_size*(nr_chunks)),self.r_chunk_size)
            
        if nc_chunks == 1:
            c_coords_tl = self.starting_position[1]
        else:
            c_coords_tl = [self.starting_position[1]]
            for i in np.arange(1,nc_chunks):
                c_coords_tl.append(c_coords_tl[i-1] + self.c_chunk_size )
            c_coords_tl = np.array(c_coords_tl)

            # c_coords_tl = np.arange(self.starting_position[1],(self.starting_position[1]+self.c_chunk_size*(nc_chunks)),self.c_chunk_size)

        
        # Coords of all the tl in the image
        r_coords_tl_all,c_coords_tl_all = np.meshgrid(r_coords_tl,c_coords_tl,indexing=&#39;ij&#39;)
        self.coords_all_to_test = [r_coords_tl_all,c_coords_tl_all]
        # Calculate all the br coords
        r_coords_br_all = r_coords_tl_all.copy()
        c_coords_br_all = c_coords_tl_all.copy()

        for c in np.arange(0,r_coords_tl_all.shape[1]):
            r_coords_br_all[:,c] = r_coords_br_all[:,c]+r_chunks_size

        for r in np.arange(0,r_coords_tl_all.shape[0]):
             c_coords_br_all[r,:] = c_coords_br_all[r,:]+c_chunks_size

        
        # The coords list are generated as:
        # row_tl,row_br,col_tl,col_br


        # Create a list for the padded coords
        self.coords_chunks_list = list()
        for r in np.arange(0,r_coords_tl_all.shape[0]):
            for c in np.arange(0,r_coords_tl_all.shape[1]):
                self.coords_chunks_list.append(np.array([r_coords_tl_all[r][c],\
                                                           r_coords_br_all[r][c],\
                                                           c_coords_tl_all[r][c],\
                                                           c_coords_br_all[r][c]])) </code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="pysmFISH.stitching.r_c_chunking.block_chunks_calculator"><code class="name flex">
<span>def <span class="ident">block_chunks_calculator</span></span>(<span>dimension, chunk_size)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper function to calculate the size of the chunks created according
the length of the vector and the chunk size.</p>
<h2 id="parameters">Parameters:</h2>
<p>dimension: int
Length of the vector to Chunk
chunkSize: int
Dimension of the Chunks</p>
<h2 id="returns">Returns:</h2>
<p>chunks_sizes: np.array
Array of the sizes of the created chunks. It deals with conditions
when the expected chunks size do not fit an even number of times in the
dimension</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def block_chunks_calculator(dimension,chunk_size):
    &#34;&#34;&#34;
    Helper function to calculate the size of the chunks created according
    the length of the vector and the chunk size.

    Parameters:
    -----------

    dimension: int
        Length of the vector to Chunk
    chunkSize: int 
        Dimension of the Chunks

    Returns:
    -----------

    chunks_sizes: np.array 
        Array of the sizes of the created chunks. It deals with conditions 
        when the expected chunks size do not fit an even number of times in the 
        dimension
    &#34;&#34;&#34;
    number_even_chunks=int(dimension//chunk_size)
    total_size_even_chunks=number_even_chunks*chunk_size
    odd_tile_size=dimension-total_size_even_chunks
    chunk_sizes=[]
    chunks_sizes=list(np.repeat(chunk_size,number_even_chunks-1))
    if odd_tile_size &lt; chunk_size:
        chunks_sizes.append(chunk_size+odd_tile_size)
    else:
        chunks_sizes.append(odd_tile_size)
    return tuple(chunks_sizes)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pysmFISH.stitching.r_c_chunking.block_chunking"><code class="name flex">
<span>def <span class="ident">block_chunking</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Function used to generate the coords of the images according to the
chunking </p>
<h2 id="notes">Notes:</h2>
<p>For both lists each np.array contains the coords in the following order:
[row_tl,row_br,col_tl,col_br]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def block_chunking(self):
    &#34;&#34;&#34;
    Function used to generate the coords of the images according to the
    chunking 

    Notes:
    ------

    For both lists each np.array contains the coords in the following order:
    [row_tl,row_br,col_tl,col_br]

    &#34;&#34;&#34;
    num_r,num_c = self.region_dimensions
    self.starting_position = self.tl_coords
    self.end_position = self.tl_coords + self.region_dimensions

    # Calculate the size of the chunks
    r_chunks_size = self.block_chunks_calculator(num_r,self.r_chunk_size)
    
    c_chunks_size = self.block_chunks_calculator(num_c,self.c_chunk_size)
    
    # Calculate the total numbers of chunks
    nr_chunks = len(r_chunks_size)
    
    nc_chunks = len(c_chunks_size)
   


    # Coords top left corner (tl)
    if nr_chunks == 1:
        r_coords_tl = self.starting_position[0]
    else: 
        r_coords_tl = [self.starting_position[0]]
        for i in np.arange(1,nr_chunks):
            r_coords_tl.append(r_coords_tl[i-1] + self.r_chunk_size )
        r_coords_tl = np.array(r_coords_tl)
        # r_coords_tl = np.arange(self.starting_position[0],(self.starting_position[0]+self.r_chunk_size*(nr_chunks)),self.r_chunk_size)
        
    if nc_chunks == 1:
        c_coords_tl = self.starting_position[1]
    else:
        c_coords_tl = [self.starting_position[1]]
        for i in np.arange(1,nc_chunks):
            c_coords_tl.append(c_coords_tl[i-1] + self.c_chunk_size )
        c_coords_tl = np.array(c_coords_tl)

        # c_coords_tl = np.arange(self.starting_position[1],(self.starting_position[1]+self.c_chunk_size*(nc_chunks)),self.c_chunk_size)

    
    # Coords of all the tl in the image
    r_coords_tl_all,c_coords_tl_all = np.meshgrid(r_coords_tl,c_coords_tl,indexing=&#39;ij&#39;)
    self.coords_all_to_test = [r_coords_tl_all,c_coords_tl_all]
    # Calculate all the br coords
    r_coords_br_all = r_coords_tl_all.copy()
    c_coords_br_all = c_coords_tl_all.copy()

    for c in np.arange(0,r_coords_tl_all.shape[1]):
        r_coords_br_all[:,c] = r_coords_br_all[:,c]+r_chunks_size

    for r in np.arange(0,r_coords_tl_all.shape[0]):
         c_coords_br_all[r,:] = c_coords_br_all[r,:]+c_chunks_size

    
    # The coords list are generated as:
    # row_tl,row_br,col_tl,col_br


    # Create a list for the padded coords
    self.coords_chunks_list = list()
    for r in np.arange(0,r_coords_tl_all.shape[0]):
        for c in np.arange(0,r_coords_tl_all.shape[1]):
            self.coords_chunks_list.append(np.array([r_coords_tl_all[r][c],\
                                                       r_coords_br_all[r][c],\
                                                       c_coords_tl_all[r][c],\
                                                       c_coords_br_all[r][c]])) </code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pysmFISH.stitching.triangles_based_dots_stitching"><code class="flex name class">
<span>class <span class="ident">triangles_based_dots_stitching</span></span>
<span>(</span><span>ref_overlapping_counts, comp_overlapping_counts, chunk_coords)</span>
</code></dt>
<dd>
<div class="desc"><p>Class used to register the different rounds by searaching and
matching all possible triangles formed by the dots in the reference
and translated image. This function run only a registration to the reference
round</p>
<p>The calculation of the triangle is based on list processing and may
be improved in ported to numpy.
<a href="https://stackoverflow.com/questions/43126580/match-set-of-x-y-points-to-another-set-that-is-scaled-rotated-translated-and">https://stackoverflow.com/questions/43126580/match-set-of-x-y-points-to-another-set-that-is-scaled-rotated-translated-and</a></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class triangles_based_dots_stitching():
    &#34;&#34;&#34;
    Class used to register the different rounds by searaching and
    matching all possible triangles formed by the dots in the reference
    and translated image. This function run only a registration to the reference
    round
    
    The calculation of the triangle is based on list processing and may 
    be improved in ported to numpy.
    https://stackoverflow.com/questions/43126580/match-set-of-x-y-points-to-another-set-that-is-scaled-rotated-translated-and

    &#34;&#34;&#34;

    
    def __init__(self, ref_overlapping_counts, comp_overlapping_counts, chunk_coords):
        self.ref_overlapping_counts = ref_overlapping_counts
        self.comp_overlapping_counts = comp_overlapping_counts
        self.chunk_coords = chunk_coords
        
        self.r_tl = self.chunk_coords[0]
        self.r_br = self.chunk_coords[1]
        self.c_tl = self.chunk_coords[2]
        self.c_br = self.chunk_coords[3]
        
        
        num_r = np.abs(np.abs(self.r_tl) - np.abs(self.r_br))
        num_c = np.abs(np.abs(self.c_tl) - np.abs(self.c_br))
        self.overlapping_region_dimensions = np.array([num_r,num_c])
        
        if num_r &gt; num_c:
            self.chunk_search_ax = &#39;r&#39;
            self.r_chunk_size = num_c
            self.c_chunk_size = num_c
            self.max_chunk_size = num_r
        else:
            self.chunk_search_ax = &#39;c&#39;
            self.r_chunk_size = num_r
            self.c_chunk_size = num_r
            self.max_chunk_size = num_c
        
        self.min_dots_chunk = 6
        self.min_error_triangles = 1
        self.max_dots = 12
        self.logger = logging.getLogger(__name__)
        self.tl_coords = np.array([self.r_tl, self.c_tl])
          

    @staticmethod
    def obj_fun(pars,x,src):
        tx, ty = pars
        H = np.array([[1, 0, tx],\
            [0, 1, ty]])
        src1 = np.c_[src,np.ones(src.shape[0])]
        return np.sum( (x - src1.dot(H.T)[:,:2])**2 )

    @staticmethod
    def apply_transform(pars, src):
        tx, ty = pars
        H = np.array([[1, 0, tx],\
            [0, 1, ty]])
        src1 = np.c_[src,np.ones(src.shape[0])]
        return src1.dot(H.T)[:,:2]

    @staticmethod
    def distance(x1,y1,x2,y2):
        return math.sqrt((x2 - x1)**2 + (y2 - y1)**2 )

    @staticmethod
    def list_subtract(list1,list2):
        return np.absolute(np.array(list1)-np.array(list2))

    def tri_sides(self,set_x, set_x_tri):

        triangles = []
        for i in range(len(set_x_tri)):

            point1 = set_x_tri[i][0]
            point2 = set_x_tri[i][1]
            point3 = set_x_tri[i][2]

            point1x, point1y = set_x[point1][0], set_x[point1][1]
            point2x, point2y = set_x[point2][0], set_x[point2][1]
            point3x, point3y = set_x[point3][0], set_x[point3][1] 

            len1 = self.distance(point1x,point1y,point2x,point2y)
            len2 = self.distance(point1x,point1y,point3x,point3y)
            len3 = self.distance(point2x,point2y,point3x,point3y)

            # you need to normalize in case the ref and the tran
            # are warped
            #min_side = min(len1,len2,len3)
            #len1/=min_side
            #len2/=min_side
            #len3/=min_side
            t=[len1,len2,len3]
            t.sort()
            triangles.append(t)

        return triangles


    def identify_matching_coords(self,set_A, set_B, threshold):
        match_A_pts = []
        match_B_pts = []
        set_A_tri = list(itertools.combinations(range(len(set_A)), 3))
        set_B_tri = list(itertools.combinations(range(len(set_B)), 3))
        A_triangles = self.tri_sides(set_A, set_A_tri)
        B_triangles = self.tri_sides(set_B, set_B_tri)
        sums = []
        for i in range(len(A_triangles)):
            for j in range(len(B_triangles)):
                k = sum(self.list_subtract(A_triangles[i], B_triangles[j]))
                if k &lt; threshold:
                    sums.append([i,j,k])
        # sort by smallest sum
        sums = sorted(sums, key=operator.itemgetter(2))
        if len(sums):
            match_A = set_A_tri[sums[0][0]]
            match_B = set_B_tri[sums[0][1]]
            for i in range(3):
                match_A_pts.append(set_A[match_A[i]])
                match_B_pts.append(set_B[match_B[i]])
        return (match_A_pts,match_B_pts)



    def calculate_chunks(self):
        self.chunks = r_c_chunking(self.overlapping_region_dimensions,self.r_chunk_size,
                        self.c_chunk_size,self.tl_coords)   
        self.chunks.block_chunking()
        self.coords_chunks_list = self.chunks.coords_chunks_list
        
    def calculate_dots_chunks(self,coords,chunk_coords):  
        r_tl = chunk_coords[0]
        r_br = chunk_coords[1]
        c_tl = chunk_coords[2]
        c_br = chunk_coords[3]

        # Select only the coords in the trimmed region
        coords_in_chunk = coords[((r_tl &lt; coords[:,0]) &amp; (coords[:,0]&lt;r_br)\
                    &amp; (c_tl &lt;coords[:,1]) &amp;(coords[:,1]&lt;c_br)),: ]
        return coords_in_chunk


    def optimize_chunking(self,ref_coords, tran_coords):       
        self.enough_dots = False
        if self.chunk_search_ax == &#39;c&#39;:
            chunk_size = self.c_chunk_size
        else:
            chunk_size = self.r_chunk_size
        
        while chunk_size &lt; self.max_chunk_size:
            chunks = r_c_chunking(self.overlapping_region_dimensions,self.r_chunk_size,
                        self.c_chunk_size,self.tl_coords)
            chunks.block_chunking()
            coords_chunks_list = chunks.coords_chunks_list
            ref_max_number_dots = []
            tran_max_number_dots = []
            ref_total = []
            tran_total = []
            for chunk_coords in coords_chunks_list:
                ref_coords_in_chunk = self.calculate_dots_chunks(ref_coords,chunk_coords)
                tran_coords_in_chunk = self.calculate_dots_chunks(tran_coords,chunk_coords)
                if ref_coords_in_chunk.shape[0] &gt; self.min_dots_chunk and tran_coords_in_chunk.shape[0] &gt; self.min_dots_chunk:
                        self.enough_dots = True
                        break
            if self.enough_dots:
                break
            else:
                self.enough_dots = False
                chunk_size += 200
                if self.chunk_search_ax == &#39;c&#39;:
                    self.c_chunk_size += 200
                else:
                    self.r_chunk_size += 200
                                  
        if self.enough_dots:
            # Collect the ref and tran coords from the chunks with enough dots
            self.ref_tran_screening_list = []
            for chunk_coords in coords_chunks_list:
                ref_coords_in_chunk = self.calculate_dots_chunks(ref_coords,chunk_coords)
                tran_coords_in_chunk = self.calculate_dots_chunks(tran_coords,chunk_coords)
                if ref_coords_in_chunk.shape[0] &gt; self.min_dots_chunk and tran_coords_in_chunk.shape[0] &gt; self.min_dots_chunk:
                    self.ref_tran_screening_list.append((ref_coords_in_chunk,tran_coords_in_chunk,chunk_coords))

    def register(self,ref_coords,tran_coords):
        self.optimize_chunking(ref_coords, tran_coords)
        self.completed_registration = False
        if self.enough_dots:
            match_ref_pts_all = []
            match_tran_pts_all = []
            # Collect all matching dots in all chunked regions with number of dots above threshold
            for ref_coords_in_chunk,tran_coords_in_chunk, chunk_coords in self.ref_tran_screening_list:
                    match_ref_pts, match_tran_pts = self.identify_matching_coords(ref_coords_in_chunk,tran_coords_in_chunk,self.min_error_triangles)
                    if len(match_ref_pts) and len(match_tran_pts):
                        match_ref_pts_all.append(match_ref_pts)
                        match_tran_pts_all.append(match_tran_pts)
                    if len(match_ref_pts_all) &gt; self.max_dots:
                        break
            match_ref_pts_all = [pts for grp in match_ref_pts_all for pts in grp]
            match_tran_pts_all = [pts for grp in match_tran_pts_all for pts in grp]

            if len(match_ref_pts_all):
                match_ref_pts_all = np.vstack(match_ref_pts_all)
                match_tran_pts_all = np.vstack(match_tran_pts_all)
                minimization_output = minimize(self.obj_fun,[0,0],args=(match_ref_pts_all,match_tran_pts_all), method=&#39;Nelder-Mead&#39;)
                if minimization_output.success:
                    self.tran_registered_coords = self.apply_transform(minimization_output.x, tran_coords)
                    self.transformation_matrix = minimization_output.x
                    self.completed_registration = True
                else:
                    self.logger.info(f&#39;chunk {chunk_coords} failed minimization of distances&#39;)
            else:
                self.logger.info(f&#39;chunk {chunk_coords} did not find matching triangles&#39;)

        else:
            self.logger.info(f&#39;cannot register rounds not enough dots&#39;)
            self.tran_registered_coords = tran_coords
            self.transformation_matrix = np.empty([1,2])
            self.transformation_matrix[:] = np.nan

        if not self.completed_registration:
            self.logger.info(f&#39;was not possible to register &#39;)
            self.tran_registered_coords = tran_coords
            self.transformation_matrix = np.empty([1,2])
            self.transformation_matrix[:] = np.nan</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="pysmFISH.stitching.triangles_based_dots_stitching.apply_transform"><code class="name flex">
<span>def <span class="ident">apply_transform</span></span>(<span>pars, src)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def apply_transform(pars, src):
    tx, ty = pars
    H = np.array([[1, 0, tx],\
        [0, 1, ty]])
    src1 = np.c_[src,np.ones(src.shape[0])]
    return src1.dot(H.T)[:,:2]</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.triangles_based_dots_stitching.distance"><code class="name flex">
<span>def <span class="ident">distance</span></span>(<span>x1, y1, x2, y2)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def distance(x1,y1,x2,y2):
    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2 )</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.triangles_based_dots_stitching.list_subtract"><code class="name flex">
<span>def <span class="ident">list_subtract</span></span>(<span>list1, list2)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def list_subtract(list1,list2):
    return np.absolute(np.array(list1)-np.array(list2))</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.triangles_based_dots_stitching.obj_fun"><code class="name flex">
<span>def <span class="ident">obj_fun</span></span>(<span>pars, x, src)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def obj_fun(pars,x,src):
    tx, ty = pars
    H = np.array([[1, 0, tx],\
        [0, 1, ty]])
    src1 = np.c_[src,np.ones(src.shape[0])]
    return np.sum( (x - src1.dot(H.T)[:,:2])**2 )</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pysmFISH.stitching.triangles_based_dots_stitching.calculate_chunks"><code class="name flex">
<span>def <span class="ident">calculate_chunks</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_chunks(self):
    self.chunks = r_c_chunking(self.overlapping_region_dimensions,self.r_chunk_size,
                    self.c_chunk_size,self.tl_coords)   
    self.chunks.block_chunking()
    self.coords_chunks_list = self.chunks.coords_chunks_list</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.triangles_based_dots_stitching.calculate_dots_chunks"><code class="name flex">
<span>def <span class="ident">calculate_dots_chunks</span></span>(<span>self, coords, chunk_coords)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_dots_chunks(self,coords,chunk_coords):  
    r_tl = chunk_coords[0]
    r_br = chunk_coords[1]
    c_tl = chunk_coords[2]
    c_br = chunk_coords[3]

    # Select only the coords in the trimmed region
    coords_in_chunk = coords[((r_tl &lt; coords[:,0]) &amp; (coords[:,0]&lt;r_br)\
                &amp; (c_tl &lt;coords[:,1]) &amp;(coords[:,1]&lt;c_br)),: ]
    return coords_in_chunk</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.triangles_based_dots_stitching.identify_matching_coords"><code class="name flex">
<span>def <span class="ident">identify_matching_coords</span></span>(<span>self, set_A, set_B, threshold)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def identify_matching_coords(self,set_A, set_B, threshold):
    match_A_pts = []
    match_B_pts = []
    set_A_tri = list(itertools.combinations(range(len(set_A)), 3))
    set_B_tri = list(itertools.combinations(range(len(set_B)), 3))
    A_triangles = self.tri_sides(set_A, set_A_tri)
    B_triangles = self.tri_sides(set_B, set_B_tri)
    sums = []
    for i in range(len(A_triangles)):
        for j in range(len(B_triangles)):
            k = sum(self.list_subtract(A_triangles[i], B_triangles[j]))
            if k &lt; threshold:
                sums.append([i,j,k])
    # sort by smallest sum
    sums = sorted(sums, key=operator.itemgetter(2))
    if len(sums):
        match_A = set_A_tri[sums[0][0]]
        match_B = set_B_tri[sums[0][1]]
        for i in range(3):
            match_A_pts.append(set_A[match_A[i]])
            match_B_pts.append(set_B[match_B[i]])
    return (match_A_pts,match_B_pts)</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.triangles_based_dots_stitching.optimize_chunking"><code class="name flex">
<span>def <span class="ident">optimize_chunking</span></span>(<span>self, ref_coords, tran_coords)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def optimize_chunking(self,ref_coords, tran_coords):       
    self.enough_dots = False
    if self.chunk_search_ax == &#39;c&#39;:
        chunk_size = self.c_chunk_size
    else:
        chunk_size = self.r_chunk_size
    
    while chunk_size &lt; self.max_chunk_size:
        chunks = r_c_chunking(self.overlapping_region_dimensions,self.r_chunk_size,
                    self.c_chunk_size,self.tl_coords)
        chunks.block_chunking()
        coords_chunks_list = chunks.coords_chunks_list
        ref_max_number_dots = []
        tran_max_number_dots = []
        ref_total = []
        tran_total = []
        for chunk_coords in coords_chunks_list:
            ref_coords_in_chunk = self.calculate_dots_chunks(ref_coords,chunk_coords)
            tran_coords_in_chunk = self.calculate_dots_chunks(tran_coords,chunk_coords)
            if ref_coords_in_chunk.shape[0] &gt; self.min_dots_chunk and tran_coords_in_chunk.shape[0] &gt; self.min_dots_chunk:
                    self.enough_dots = True
                    break
        if self.enough_dots:
            break
        else:
            self.enough_dots = False
            chunk_size += 200
            if self.chunk_search_ax == &#39;c&#39;:
                self.c_chunk_size += 200
            else:
                self.r_chunk_size += 200
                              
    if self.enough_dots:
        # Collect the ref and tran coords from the chunks with enough dots
        self.ref_tran_screening_list = []
        for chunk_coords in coords_chunks_list:
            ref_coords_in_chunk = self.calculate_dots_chunks(ref_coords,chunk_coords)
            tran_coords_in_chunk = self.calculate_dots_chunks(tran_coords,chunk_coords)
            if ref_coords_in_chunk.shape[0] &gt; self.min_dots_chunk and tran_coords_in_chunk.shape[0] &gt; self.min_dots_chunk:
                self.ref_tran_screening_list.append((ref_coords_in_chunk,tran_coords_in_chunk,chunk_coords))</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.triangles_based_dots_stitching.register"><code class="name flex">
<span>def <span class="ident">register</span></span>(<span>self, ref_coords, tran_coords)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def register(self,ref_coords,tran_coords):
    self.optimize_chunking(ref_coords, tran_coords)
    self.completed_registration = False
    if self.enough_dots:
        match_ref_pts_all = []
        match_tran_pts_all = []
        # Collect all matching dots in all chunked regions with number of dots above threshold
        for ref_coords_in_chunk,tran_coords_in_chunk, chunk_coords in self.ref_tran_screening_list:
                match_ref_pts, match_tran_pts = self.identify_matching_coords(ref_coords_in_chunk,tran_coords_in_chunk,self.min_error_triangles)
                if len(match_ref_pts) and len(match_tran_pts):
                    match_ref_pts_all.append(match_ref_pts)
                    match_tran_pts_all.append(match_tran_pts)
                if len(match_ref_pts_all) &gt; self.max_dots:
                    break
        match_ref_pts_all = [pts for grp in match_ref_pts_all for pts in grp]
        match_tran_pts_all = [pts for grp in match_tran_pts_all for pts in grp]

        if len(match_ref_pts_all):
            match_ref_pts_all = np.vstack(match_ref_pts_all)
            match_tran_pts_all = np.vstack(match_tran_pts_all)
            minimization_output = minimize(self.obj_fun,[0,0],args=(match_ref_pts_all,match_tran_pts_all), method=&#39;Nelder-Mead&#39;)
            if minimization_output.success:
                self.tran_registered_coords = self.apply_transform(minimization_output.x, tran_coords)
                self.transformation_matrix = minimization_output.x
                self.completed_registration = True
            else:
                self.logger.info(f&#39;chunk {chunk_coords} failed minimization of distances&#39;)
        else:
            self.logger.info(f&#39;chunk {chunk_coords} did not find matching triangles&#39;)

    else:
        self.logger.info(f&#39;cannot register rounds not enough dots&#39;)
        self.tran_registered_coords = tran_coords
        self.transformation_matrix = np.empty([1,2])
        self.transformation_matrix[:] = np.nan

    if not self.completed_registration:
        self.logger.info(f&#39;was not possible to register &#39;)
        self.tran_registered_coords = tran_coords
        self.transformation_matrix = np.empty([1,2])
        self.transformation_matrix[:] = np.nan</code></pre>
</details>
</dd>
<dt id="pysmFISH.stitching.triangles_based_dots_stitching.tri_sides"><code class="name flex">
<span>def <span class="ident">tri_sides</span></span>(<span>self, set_x, set_x_tri)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tri_sides(self,set_x, set_x_tri):

    triangles = []
    for i in range(len(set_x_tri)):

        point1 = set_x_tri[i][0]
        point2 = set_x_tri[i][1]
        point3 = set_x_tri[i][2]

        point1x, point1y = set_x[point1][0], set_x[point1][1]
        point2x, point2y = set_x[point2][0], set_x[point2][1]
        point3x, point3y = set_x[point3][0], set_x[point3][1] 

        len1 = self.distance(point1x,point1y,point2x,point2y)
        len2 = self.distance(point1x,point1y,point3x,point3y)
        len3 = self.distance(point2x,point2y,point3x,point3y)

        # you need to normalize in case the ref and the tran
        # are warped
        #min_side = min(len1,len2,len3)
        #len1/=min_side
        #len2/=min_side
        #len3/=min_side
        t=[len1,len2,len3]
        t.sort()
        triangles.append(t)

    return triangles</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pysmFISH" href="index.html">pysmFISH</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pysmFISH.stitching.clean_from_duplicated_dots" href="#pysmFISH.stitching.clean_from_duplicated_dots">clean_from_duplicated_dots</a></code></li>
<li><code><a title="pysmFISH.stitching.get_all_dots_in_overlapping_regions" href="#pysmFISH.stitching.get_all_dots_in_overlapping_regions">get_all_dots_in_overlapping_regions</a></code></li>
<li><code><a title="pysmFISH.stitching.get_dots_in_overlapping_regions" href="#pysmFISH.stitching.get_dots_in_overlapping_regions">get_dots_in_overlapping_regions</a></code></li>
<li><code><a title="pysmFISH.stitching.identify_duplicated_dots" href="#pysmFISH.stitching.identify_duplicated_dots">identify_duplicated_dots</a></code></li>
<li><code><a title="pysmFISH.stitching.identify_duplicated_dots_NNDescend" href="#pysmFISH.stitching.identify_duplicated_dots_NNDescend">identify_duplicated_dots_NNDescend</a></code></li>
<li><code><a title="pysmFISH.stitching.identify_duplicated_dots_sklearn" href="#pysmFISH.stitching.identify_duplicated_dots_sklearn">identify_duplicated_dots_sklearn</a></code></li>
<li><code><a title="pysmFISH.stitching.register_adj_tiles" href="#pysmFISH.stitching.register_adj_tiles">register_adj_tiles</a></code></li>
<li><code><a title="pysmFISH.stitching.register_coords_obj" href="#pysmFISH.stitching.register_coords_obj">register_coords_obj</a></code></li>
<li><code><a title="pysmFISH.stitching.register_cpl" href="#pysmFISH.stitching.register_cpl">register_cpl</a></code></li>
<li><code><a title="pysmFISH.stitching.register_cpl_fresh_nuclei" href="#pysmFISH.stitching.register_cpl_fresh_nuclei">register_cpl_fresh_nuclei</a></code></li>
<li><code><a title="pysmFISH.stitching.remove_duplicated_dots_graph" href="#pysmFISH.stitching.remove_duplicated_dots_graph">remove_duplicated_dots_graph</a></code></li>
<li><code><a title="pysmFISH.stitching.remove_overlapping_dots_fov" href="#pysmFISH.stitching.remove_overlapping_dots_fov">remove_overlapping_dots_fov</a></code></li>
<li><code><a title="pysmFISH.stitching.remove_overlapping_dots_from_gene" href="#pysmFISH.stitching.remove_overlapping_dots_from_gene">remove_overlapping_dots_from_gene</a></code></li>
<li><code><a title="pysmFISH.stitching.stitch_using_coords_general" href="#pysmFISH.stitching.stitch_using_coords_general">stitch_using_coords_general</a></code></li>
<li><code><a title="pysmFISH.stitching.stitch_using_coords_general_df" href="#pysmFISH.stitching.stitch_using_coords_general_df">stitch_using_coords_general_df</a></code></li>
<li><code><a title="pysmFISH.stitching.stitch_using_coords_general_segmented_objects" href="#pysmFISH.stitching.stitch_using_coords_general_segmented_objects">stitch_using_coords_general_segmented_objects</a></code></li>
<li><code><a title="pysmFISH.stitching.stitched_beads_on_nuclei_fresh_tissue" href="#pysmFISH.stitching.stitched_beads_on_nuclei_fresh_tissue">stitched_beads_on_nuclei_fresh_tissue</a></code></li>
<li><code><a title="pysmFISH.stitching.stitching_graph" href="#pysmFISH.stitching.stitching_graph">stitching_graph</a></code></li>
<li><code><a title="pysmFISH.stitching.stitching_graph_fresh_nuclei" href="#pysmFISH.stitching.stitching_graph_fresh_nuclei">stitching_graph_fresh_nuclei</a></code></li>
<li><code><a title="pysmFISH.stitching.stitching_graph_serial_nuclei" href="#pysmFISH.stitching.stitching_graph_serial_nuclei">stitching_graph_serial_nuclei</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pysmFISH.stitching.organize_square_tiles" href="#pysmFISH.stitching.organize_square_tiles">organize_square_tiles</a></code></h4>
<ul class="">
<li><code><a title="pysmFISH.stitching.organize_square_tiles.determine_overlapping_regions" href="#pysmFISH.stitching.organize_square_tiles.determine_overlapping_regions">determine_overlapping_regions</a></code></li>
<li><code><a title="pysmFISH.stitching.organize_square_tiles.extract_microscope_coords" href="#pysmFISH.stitching.organize_square_tiles.extract_microscope_coords">extract_microscope_coords</a></code></li>
<li><code><a title="pysmFISH.stitching.organize_square_tiles.identify_adjacent_tiles" href="#pysmFISH.stitching.organize_square_tiles.identify_adjacent_tiles">identify_adjacent_tiles</a></code></li>
<li><code><a title="pysmFISH.stitching.organize_square_tiles.normalize_coords" href="#pysmFISH.stitching.organize_square_tiles.normalize_coords">normalize_coords</a></code></li>
<li><code><a title="pysmFISH.stitching.organize_square_tiles.run_tiles_organization" href="#pysmFISH.stitching.organize_square_tiles.run_tiles_organization">run_tiles_organization</a></code></li>
<li><code><a title="pysmFISH.stitching.organize_square_tiles.save_graph_image_space_coords" href="#pysmFISH.stitching.organize_square_tiles.save_graph_image_space_coords">save_graph_image_space_coords</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pysmFISH.stitching.organize_square_tiles_old_room" href="#pysmFISH.stitching.organize_square_tiles_old_room">organize_square_tiles_old_room</a></code></h4>
<ul class="">
<li><code><a title="pysmFISH.stitching.organize_square_tiles_old_room.determine_overlapping_regions" href="#pysmFISH.stitching.organize_square_tiles_old_room.determine_overlapping_regions">determine_overlapping_regions</a></code></li>
<li><code><a title="pysmFISH.stitching.organize_square_tiles_old_room.extract_microscope_coords" href="#pysmFISH.stitching.organize_square_tiles_old_room.extract_microscope_coords">extract_microscope_coords</a></code></li>
<li><code><a title="pysmFISH.stitching.organize_square_tiles_old_room.identify_adjacent_tiles" href="#pysmFISH.stitching.organize_square_tiles_old_room.identify_adjacent_tiles">identify_adjacent_tiles</a></code></li>
<li><code><a title="pysmFISH.stitching.organize_square_tiles_old_room.normalize_coords" href="#pysmFISH.stitching.organize_square_tiles_old_room.normalize_coords">normalize_coords</a></code></li>
<li><code><a title="pysmFISH.stitching.organize_square_tiles_old_room.run_tiles_organization" href="#pysmFISH.stitching.organize_square_tiles_old_room.run_tiles_organization">run_tiles_organization</a></code></li>
<li><code><a title="pysmFISH.stitching.organize_square_tiles_old_room.save_graph_image_space_coords" href="#pysmFISH.stitching.organize_square_tiles_old_room.save_graph_image_space_coords">save_graph_image_space_coords</a></code></li>
<li><code><a title="pysmFISH.stitching.organize_square_tiles_old_room.save_graph_original_coords" href="#pysmFISH.stitching.organize_square_tiles_old_room.save_graph_original_coords">save_graph_original_coords</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pysmFISH.stitching.r_c_chunking" href="#pysmFISH.stitching.r_c_chunking">r_c_chunking</a></code></h4>
<ul class="">
<li><code><a title="pysmFISH.stitching.r_c_chunking.block_chunking" href="#pysmFISH.stitching.r_c_chunking.block_chunking">block_chunking</a></code></li>
<li><code><a title="pysmFISH.stitching.r_c_chunking.block_chunks_calculator" href="#pysmFISH.stitching.r_c_chunking.block_chunks_calculator">block_chunks_calculator</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pysmFISH.stitching.triangles_based_dots_stitching" href="#pysmFISH.stitching.triangles_based_dots_stitching">triangles_based_dots_stitching</a></code></h4>
<ul class="">
<li><code><a title="pysmFISH.stitching.triangles_based_dots_stitching.apply_transform" href="#pysmFISH.stitching.triangles_based_dots_stitching.apply_transform">apply_transform</a></code></li>
<li><code><a title="pysmFISH.stitching.triangles_based_dots_stitching.calculate_chunks" href="#pysmFISH.stitching.triangles_based_dots_stitching.calculate_chunks">calculate_chunks</a></code></li>
<li><code><a title="pysmFISH.stitching.triangles_based_dots_stitching.calculate_dots_chunks" href="#pysmFISH.stitching.triangles_based_dots_stitching.calculate_dots_chunks">calculate_dots_chunks</a></code></li>
<li><code><a title="pysmFISH.stitching.triangles_based_dots_stitching.distance" href="#pysmFISH.stitching.triangles_based_dots_stitching.distance">distance</a></code></li>
<li><code><a title="pysmFISH.stitching.triangles_based_dots_stitching.identify_matching_coords" href="#pysmFISH.stitching.triangles_based_dots_stitching.identify_matching_coords">identify_matching_coords</a></code></li>
<li><code><a title="pysmFISH.stitching.triangles_based_dots_stitching.list_subtract" href="#pysmFISH.stitching.triangles_based_dots_stitching.list_subtract">list_subtract</a></code></li>
<li><code><a title="pysmFISH.stitching.triangles_based_dots_stitching.obj_fun" href="#pysmFISH.stitching.triangles_based_dots_stitching.obj_fun">obj_fun</a></code></li>
<li><code><a title="pysmFISH.stitching.triangles_based_dots_stitching.optimize_chunking" href="#pysmFISH.stitching.triangles_based_dots_stitching.optimize_chunking">optimize_chunking</a></code></li>
<li><code><a title="pysmFISH.stitching.triangles_based_dots_stitching.register" href="#pysmFISH.stitching.triangles_based_dots_stitching.register">register</a></code></li>
<li><code><a title="pysmFISH.stitching.triangles_based_dots_stitching.tri_sides" href="#pysmFISH.stitching.triangles_based_dots_stitching.tri_sides">tri_sides</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>