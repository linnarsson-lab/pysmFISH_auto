<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>pysmFISH.qc_utils API documentation</title>
<meta name="description" content="set of useful function to determine if different process steps
that terminated without error generated the correct output.
Ex. missing positions after …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pysmFISH.qc_utils</code></h1>
</header>
<section id="section-intro">
<p>set of useful function to determine if different process steps
that terminated without error generated the correct output.
Ex. missing positions after parsing the data</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
set of useful function to determine if different process steps
that terminated without error generated the correct output.
Ex. missing positions after parsing the data
&#34;&#34;&#34;

from typing import *
import re
import sys
import pandas as pd
import numpy as np
from pathlib import Path

from dask import dataframe as dd

import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import matplotlib.patches as mpatches

from pysmFISH.logger_utils import selected_logger
from pysmFISH.configuration_files import load_experiment_config_file


class QC_registration_error():
    &#34;&#34;&#34;Class use to evaluate the performance of the regstration
    of the different rounds of hybridization
    &#34;&#34;&#34;

    def __init__(self, client, experiment_fpath: str, 
                analysis_parameters: dict, metadata: Dict, tiles_coords: np.ndarray):
        &#34;&#34;&#34;Class initialization

        Args:
            client (distributed.Client): Clients that orchesterate the
                processing of some of the QC steps
            experiment_fpath (str): Path to the experiment to process
            analysis_parameters (dict): Parameters for the processing
            metadata (dict): Overall experimental parameters
            tiles_coords (np.ndarray): Stage coords of the acquired FOVS
        &#34;&#34;&#34;
    # def __init__(self, client, experiment_fpath, analysis_parameters, tiles_coords, img_width, img_height):
        self.client = client
        self.experiment_fpath = Path(experiment_fpath)
        self.analysis_parameters = analysis_parameters
        self.metadata = metadata
        self.tiles_coords = tiles_coords
        # self.img_width = img_width
        # self.img_height = img_height
        matplotlib.use(&#34;Agg&#34;)

    def create_error_df(self):
        &#34;&#34;&#34;Method used to collect the error information from
        the processed data
        &#34;&#34;&#34;
        all_counts_folder = self.experiment_fpath / &#39;results&#39;
        search_key = &#39;*_decoded_fov_*&#39;
        self.error_output_df= pd.DataFrame()
        all_counts_dd = dd.read_parquet(all_counts_folder / search_key)
        registration_error_df = all_counts_dd.groupby(&#39;fov_num&#39;).agg({&#39;min_number_matching_dots_registration&#39;: [&#39;min&#39;]}).compute()
        for idx, row in registration_error_df.itertuples():
            search_key = &#39;*decoded_fov_&#39; + str(int(idx)) +&#39;.parquet&#39;
            fname = list(all_counts_folder.glob(search_key))[0]
            fov_data_df = pd.read_parquet(fname)
            matching_rounds = fov_data_df.loc[(fov_data_df.fov_num == idx) &amp;
                        (fov_data_df.min_number_matching_dots_registration == row),
                        [&#39;fov_num&#39;,&#39;min_number_matching_dots_registration&#39;,&#39;round_num&#39;]]
            self.error_output_df = pd.concat([self.error_output_df,matching_rounds.iloc[0]],axis=1)
        self.error_output_df = self.error_output_df.T
        # #     RegistrationMinMatchingBeads = analysis_parameters[&#39;RegistrationMinMatchingBeads&#39;]
        #     registration_error_df.columns = [&#34;_&#34;.join(x) for x in registration_error_df.columns.ravel()]
        self.error_output_df.to_parquet(self.experiment_fpath / &#39;results&#39; / &#39;registration_error.parquet&#39;)

        
    def plot_error(self):
        &#34;&#34;&#34;Method used to visualize the error for the different tiles
        &#34;&#34;&#34;
        plt.ioff()
        scale_value = 5
        self.tiles_coords = self.tiles_coords / scale_value
        RegistrationMinMatchingBeads = self.analysis_parameters[&#39;RegistrationMinMatchingBeads&#39;]
        fovs = self.error_output_df[&#39;fov_num&#39;].values.astype(int)
        rounds_num = self.error_output_df[&#39;round_num&#39;].values.astype(int)
        min_errors = self.error_output_df[&#39;min_number_matching_dots_registration&#39;].values.astype(int)


        colors = np.zeros_like(min_errors,dtype=&#39;U10&#39;)

        # Vlist correspond to the errors in the registration

        vlist = [-6,-5,-4,-3,-2]
        clist = [&#39;black&#39;,&#39;dimgrey&#39;,&#39;silver&#39;,&#39;orange&#39;,&#39;green&#39;]

        for v,c in zip(vlist,clist):
                colors[min_errors == v] = c

        colors[min_errors &gt; 0] = &#39;steelblue&#39;
        #colors[(min_errors &lt; RegistrationMinMatchingBeads) &amp; (min_errors &gt; 0)] = &#39;tomato&#39;


        fig = plt.figure(figsize=(30,20))
        ax = fig.add_subplot(111)

        r_coords = self.tiles_coords[:,0]
        c_coords = self.tiles_coords[:,1]
        r_coords_min = r_coords.min()
        c_coords_min = c_coords.min()
        to_zero_r_coords = r_coords - r_coords_min
        to_zero_c_coords = c_coords - c_coords_min


        # errors_normalized = (min_errors -min(min_errors)) / (max(min_errors -min(min_errors)))
        # threshold = (RegistrationMinMatchingBeads-min(min_errors)) / (max(min_errors -min(min_errors)))
        # nodes = [0,threshold, threshold, 1.0]

        # colors = [&#34;black&#34;, &#34;black&#34;, &#34;blue&#34;, &#34;magenta&#34;]
        # cmap = LinearSegmentedColormap.from_list(&#34;&#34;, list(zip(nodes, colors)))
        # cmap.set_under(&#34;black&#34;)
        # sc = ax.scatter(to_zero_c_coords,to_zero_r_coords,c=errors_normalized,cmap=cmap, s = 1000)
        
        sc = ax.scatter(to_zero_c_coords,to_zero_r_coords,c=colors, s = 1000)
        plt.gca().invert_yaxis()
        for fov, round_num, match, x, y in zip(fovs,rounds_num, min_errors, to_zero_c_coords,to_zero_r_coords):
            
            ax.annotate(
                fov,
                xy=(x,y), xytext=(-0, 10),
                textcoords=&#39;offset points&#39;, ha=&#39;center&#39;, va=&#39;center&#39;,fontsize=5,color=&#39;white&#39;, weight=&#39;bold&#39;)
            
            ax.annotate(round_num, (x, y), color=&#39;white&#39;, weight=&#39;bold&#39;, 
                            fontsize=10, ha=&#39;center&#39;, va=&#39;center&#39;)
            
            ax.annotate(&#39;m&#39; + str(match), xy=(x, y), xytext=(0, -10), color=&#39;white&#39;, weight=&#39;bold&#39;, 
                            textcoords=&#39;offset points&#39;, fontsize=5, ha=&#39;center&#39;, va=&#39;center&#39;)
    
        patch_1 = mpatches.Patch(color=&#39;black&#39;, label=&#39;missing_counts_fish_channel&#39;)
        patch_2 = mpatches.Patch(color=&#39;dimgrey&#39;, label=&#39;missing_counts_reg_channel&#39;)
        patch_3 = mpatches.Patch(color=&#39;silver&#39;, label=&#39;missing_counts_reference_round&#39;)
        patch_4 = mpatches.Patch(color=&#39;orange&#39;, label=&#39;missing_counts_in_round&#39;)
        patch_5 = mpatches.Patch(color=&#39;green&#39;, label=&#39;number_beads_below_tolerance_counts&#39;)
        
        plt.legend(handles=[patch_1,patch_2,patch_3,patch_4,patch_5])    
    
        ax.set_aspect(&#39;equal&#39;)
        ax.axis(&#39;off&#39;)
        plt.tight_layout()

        plt.savefig(self.experiment_fpath / &#39;output_figures&#39; / &#39;registration_error.png&#39;,dpi=200,pad_inches=0)


    def run_qc(self):
        &#34;&#34;&#34;Method that runs all the QC steps
        &#34;&#34;&#34;
        self.create_error_df()
        self.plot_error()


def QC_check_experiment_yaml_file(experiment_fpath:str):
    &#34;&#34;&#34;
    This function is used to check that the parameter
    needed for processing are included in the experiment_name.yaml
    file and have the expected values
    
    Args:
        experiment_fpath: str
            str with the path to the folder of the experiment to process
    &#34;&#34;&#34;
    experiment_fpath = Path(experiment_fpath)
    logger = selected_logger()
    
    try:
        experiment_info = load_experiment_config_file(experiment_fpath)
    except:
        logger.error(f&#39;missing experiment info yaml file&#39;)
        sys.exit(f&#39;missing experiment info yaml file&#39;)
    else:

        codebooks_list = (experiment_fpath.parent / &#39;codebooks&#39;).glob(&#39;*&#39;)
        probe_sets_list = (experiment_fpath.parent / &#39;probes_sets&#39;).glob(&#39;*&#39;)

        codebooks_list = [el.name for el in codebooks_list]
        probe_sets_list = [el.name for el in probe_sets_list]
        


        experiment_info_keys = list(experiment_info.keys())

        required_keys = [&#39;Stitching_type&#39;,
                            &#39;Experiment_type&#39;,
                            &#39;Barcode_length&#39;,
                            &#39;Barcode&#39;,
                            &#39;Codebooks&#39;,
                            &#39;Machine&#39;,
                            &#39;Operator&#39;,
                            &#39;Overlapping_percentage&#39;,
                            &#39;Probes_FASTA&#39;,
                            &#39;Species&#39;,
                            &#39;Start_date&#39;,
                            &#39;Strain&#39;,
                            &#39;Tissue&#39;,
                            &#39;Pipeline&#39;]

        for key in required_keys:
            if key not in experiment_info_keys:
                logger.error(f&#39;{key} field is missing in the experiment file&#39;)
                sys.exit(f&#39;{key} field is missing in the experiment file&#39;)
        

        if &#39;serial&#39; not in experiment_info[&#39;Experiment_type&#39;]:
            if not experiment_info[&#39;Codebooks&#39;]:
                logger.error(f&#34;The experiment type {experiment_info[&#39;Experiment_type&#39;]} needs a codebook&#34;)
                sys.exit(f&#34;The experiment type {experiment_info[&#39;Experiment_type&#39;]} needs a codebook&#34;)
            else:
                missing_codebooks = []
                for idx, codebook in experiment_info[&#39;Codebooks&#39;].items():
                    if codebook == &#39;None&#39;:
                        logger.info(f&#39;{idx} has None as codebook&#39;)
                    elif (codebook not in codebooks_list) and (codebook != &#39;None&#39;):
                        missing_codebooks.append(codebook)
                if missing_codebooks:
                    for missing_codebook in missing_codebooks:
                        logger.error(f&#39;{missing_codebook} is missing from the database&#39;)
                    sys.exit(f&#39;Specified codebook is missing from the database&#39;)

            if experiment_info[&#39;Barcode&#39;] not in [&#39;True&#39;, &#39;False&#39;]:
                logger.error(f&#39;Value corresponding to Barcode keyword must be True or False &#39;)
                sys.exit(f&#39;Value corresponding to Barcode keyword must be True or False &#39;)
        
            if experiment_info[&#39;Barcode&#39;] == &#39;True&#39;:
                if &#39;Barcode_length&#39; not in experiment_info_keys:
                    logger.error(f&#39;Barcode_length keyword in the experiment file&#39;)
                    sys.exit(f&#39;Barcode_length keyword in the experiment file&#39;)
                elif experiment_info[&#39;Barcode_length&#39;] != 16:
                    logger.error(f&#39;Wrong barcode length&#39;)
                    sys.exit(f&#39;Barcode_length keyword in the experiment file&#39;)
            
        if experiment_info[&#39;Machine&#39;] not in [&#39;ROBOFISH1&#39;, &#39;ROBOFISH2&#39;,&#39;ROBOFISH3&#39;, &#39;NOT-DEFINED&#39;]:
            logger.error(f&#39;Wrong machine name&#39;)
            sys.exit(f&#39;Wrong machine name&#39;)
        
        if experiment_info[&#39;Stitching_type&#39;] not in [&#39;small-beads&#39;, &#39;large-beads&#39;,&#39;both-beads&#39;, &#39;nuclei&#39;]:
            logger.error(f&#39;Wrong Stitching_type selected in the experiment file&#39;)
            sys.exit(f&#39;Wrong Stitching_type selected in the experiment file&#39;)
        
        if experiment_info[&#39;Experiment_type&#39;] not in [&#39;smfish-serial&#39;, &#39;smfish-barcoded&#39;, &#39;eel-barcoded&#39;]:
            logger.error(f&#39;Wrong Experiment_type selected in the experiment file&#39;)
            sys.exit(f&#39;Wrong Experiment_type selected in the experiment file&#39;)

        if not experiment_info[&#39;Probes_FASTA&#39;]:
            logger.error(f&#39;Experiment require the probes name&#39;)
            sys.exit(f&#39;Probes keyword in the experiment file&#39;)
        else:
            missing_probes = []
            for idx, probe in experiment_info[&#39;Probes_FASTA&#39;].items():
                if probe == &#39;None&#39;:
                        logger.debug(f&#39;{idx} has None as probe&#39;)
                elif (probe not in probe_sets_list) and (probe !=&#39;None&#39;):
                    missing_probes.append(probe)
            if missing_probes:
                for mprobes in missing_probes:
                    logger.error(f&#39;{mprobes} is missing from the database&#39;)
                sys.exit(f&#39;Specified probes are missing from the database&#39;)


def QC_matching_nd2_metadata_robofish(all_raw_files:list):
    &#34;&#34;&#34;
    This function is used to check that each of the nd2 files
    generated by the microscope has a matching pkl metadata
    file generated by robofish

    Args:
        all_raw_files: list
            list with all the paths of the nd2 files to process

    &#34;&#34;&#34;

    logger = selected_logger()
    experiment_fpath = all_raw_files[0].parent
    all_info_files = list(experiment_fpath.glob(&#39;*.pkl&#39;))
  
    if len(all_info_files) == 0:
        logger.error(f&#34;no .pkl files in the folder&#34;)
        sys.exit(f&#34;no .pkl files in the folder&#34;)

    # Determine if there are multiple metadata files with same number
    all_codes = []
    for meta_file_path in all_info_files:
        # collect the count code
        count_code = re.search(r&#39;(Count)\d{5}&#39;, meta_file_path.stem)
        assert count_code, logger.error(f&#39;{meta_file_path.stem} does not contain the CountXXXXX code&#39;)
        count_code = count_code.group()
        all_codes. append(count_code)
    
    if all_codes:
        all_codes_counts_dict = {i:all_codes.count(i) for i in all_codes}
        all_codes_counts_array = np.array(list(all_codes_counts_dict.values()))
        if np.any(all_codes_counts_array&gt;1):
            for count_code,value in all_codes_counts_dict.items():
                if value &gt;1:
                    logger.error(f&#39; multiple pkl files with {count_code}&#39;)
                    sys.exit(f&#39; multiple pkl files with {count_code}&#39;)
            
            logger.error(f&#39;fix naming of the files with the repeated codes&#39;)
            sys.exit(f&#39;fix naming of the files with the repeated codes&#39;)

    missing_pkl = []
    for nd2_file_path in all_raw_files:
        # collect the count code
        try:
            count_code = re.search(r&#39;(Count)\d{5}&#39;, nd2_file_path.stem).group()
        except:
            count_code = None
            logger.error(f&#39;{nd2_file_path.stem} does not contain the CountXXXXX code&#39;)
            sys.exit(f&#39;{nd2_file_path.stem} does not contain the CountXXXXX code&#39;)
        else:
            try:
                info_file = [info_file for info_file in all_info_files if count_code  in info_file.stem][0]
            except IndexError:
                logger.error(f&#39;{nd2_file_path.stem} does not have the corresponding pkl file&#39;)
                missing_pkl.append(nd2_file_path.stem)

    if missing_pkl:
        logger.error(f&#39;collect the missing pkl for {missing_pkl} before parsing&#39;)
        sys.exit(f&#39;collect the missing pkl for {missing_pkl} before parsing&#39;)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pysmFISH.qc_utils.QC_check_experiment_yaml_file"><code class="name flex">
<span>def <span class="ident">QC_check_experiment_yaml_file</span></span>(<span>experiment_fpath: str)</span>
</code></dt>
<dd>
<div class="desc"><p>This function is used to check that the parameter
needed for processing are included in the experiment_name.yaml
file and have the expected values</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>experiment_fpath</code></strong></dt>
<dd>str
str with the path to the folder of the experiment to process</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def QC_check_experiment_yaml_file(experiment_fpath:str):
    &#34;&#34;&#34;
    This function is used to check that the parameter
    needed for processing are included in the experiment_name.yaml
    file and have the expected values
    
    Args:
        experiment_fpath: str
            str with the path to the folder of the experiment to process
    &#34;&#34;&#34;
    experiment_fpath = Path(experiment_fpath)
    logger = selected_logger()
    
    try:
        experiment_info = load_experiment_config_file(experiment_fpath)
    except:
        logger.error(f&#39;missing experiment info yaml file&#39;)
        sys.exit(f&#39;missing experiment info yaml file&#39;)
    else:

        codebooks_list = (experiment_fpath.parent / &#39;codebooks&#39;).glob(&#39;*&#39;)
        probe_sets_list = (experiment_fpath.parent / &#39;probes_sets&#39;).glob(&#39;*&#39;)

        codebooks_list = [el.name for el in codebooks_list]
        probe_sets_list = [el.name for el in probe_sets_list]
        


        experiment_info_keys = list(experiment_info.keys())

        required_keys = [&#39;Stitching_type&#39;,
                            &#39;Experiment_type&#39;,
                            &#39;Barcode_length&#39;,
                            &#39;Barcode&#39;,
                            &#39;Codebooks&#39;,
                            &#39;Machine&#39;,
                            &#39;Operator&#39;,
                            &#39;Overlapping_percentage&#39;,
                            &#39;Probes_FASTA&#39;,
                            &#39;Species&#39;,
                            &#39;Start_date&#39;,
                            &#39;Strain&#39;,
                            &#39;Tissue&#39;,
                            &#39;Pipeline&#39;]

        for key in required_keys:
            if key not in experiment_info_keys:
                logger.error(f&#39;{key} field is missing in the experiment file&#39;)
                sys.exit(f&#39;{key} field is missing in the experiment file&#39;)
        

        if &#39;serial&#39; not in experiment_info[&#39;Experiment_type&#39;]:
            if not experiment_info[&#39;Codebooks&#39;]:
                logger.error(f&#34;The experiment type {experiment_info[&#39;Experiment_type&#39;]} needs a codebook&#34;)
                sys.exit(f&#34;The experiment type {experiment_info[&#39;Experiment_type&#39;]} needs a codebook&#34;)
            else:
                missing_codebooks = []
                for idx, codebook in experiment_info[&#39;Codebooks&#39;].items():
                    if codebook == &#39;None&#39;:
                        logger.info(f&#39;{idx} has None as codebook&#39;)
                    elif (codebook not in codebooks_list) and (codebook != &#39;None&#39;):
                        missing_codebooks.append(codebook)
                if missing_codebooks:
                    for missing_codebook in missing_codebooks:
                        logger.error(f&#39;{missing_codebook} is missing from the database&#39;)
                    sys.exit(f&#39;Specified codebook is missing from the database&#39;)

            if experiment_info[&#39;Barcode&#39;] not in [&#39;True&#39;, &#39;False&#39;]:
                logger.error(f&#39;Value corresponding to Barcode keyword must be True or False &#39;)
                sys.exit(f&#39;Value corresponding to Barcode keyword must be True or False &#39;)
        
            if experiment_info[&#39;Barcode&#39;] == &#39;True&#39;:
                if &#39;Barcode_length&#39; not in experiment_info_keys:
                    logger.error(f&#39;Barcode_length keyword in the experiment file&#39;)
                    sys.exit(f&#39;Barcode_length keyword in the experiment file&#39;)
                elif experiment_info[&#39;Barcode_length&#39;] != 16:
                    logger.error(f&#39;Wrong barcode length&#39;)
                    sys.exit(f&#39;Barcode_length keyword in the experiment file&#39;)
            
        if experiment_info[&#39;Machine&#39;] not in [&#39;ROBOFISH1&#39;, &#39;ROBOFISH2&#39;,&#39;ROBOFISH3&#39;, &#39;NOT-DEFINED&#39;]:
            logger.error(f&#39;Wrong machine name&#39;)
            sys.exit(f&#39;Wrong machine name&#39;)
        
        if experiment_info[&#39;Stitching_type&#39;] not in [&#39;small-beads&#39;, &#39;large-beads&#39;,&#39;both-beads&#39;, &#39;nuclei&#39;]:
            logger.error(f&#39;Wrong Stitching_type selected in the experiment file&#39;)
            sys.exit(f&#39;Wrong Stitching_type selected in the experiment file&#39;)
        
        if experiment_info[&#39;Experiment_type&#39;] not in [&#39;smfish-serial&#39;, &#39;smfish-barcoded&#39;, &#39;eel-barcoded&#39;]:
            logger.error(f&#39;Wrong Experiment_type selected in the experiment file&#39;)
            sys.exit(f&#39;Wrong Experiment_type selected in the experiment file&#39;)

        if not experiment_info[&#39;Probes_FASTA&#39;]:
            logger.error(f&#39;Experiment require the probes name&#39;)
            sys.exit(f&#39;Probes keyword in the experiment file&#39;)
        else:
            missing_probes = []
            for idx, probe in experiment_info[&#39;Probes_FASTA&#39;].items():
                if probe == &#39;None&#39;:
                        logger.debug(f&#39;{idx} has None as probe&#39;)
                elif (probe not in probe_sets_list) and (probe !=&#39;None&#39;):
                    missing_probes.append(probe)
            if missing_probes:
                for mprobes in missing_probes:
                    logger.error(f&#39;{mprobes} is missing from the database&#39;)
                sys.exit(f&#39;Specified probes are missing from the database&#39;)</code></pre>
</details>
</dd>
<dt id="pysmFISH.qc_utils.QC_matching_nd2_metadata_robofish"><code class="name flex">
<span>def <span class="ident">QC_matching_nd2_metadata_robofish</span></span>(<span>all_raw_files: list)</span>
</code></dt>
<dd>
<div class="desc"><p>This function is used to check that each of the nd2 files
generated by the microscope has a matching pkl metadata
file generated by robofish</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>all_raw_files</code></strong></dt>
<dd>list
list with all the paths of the nd2 files to process</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def QC_matching_nd2_metadata_robofish(all_raw_files:list):
    &#34;&#34;&#34;
    This function is used to check that each of the nd2 files
    generated by the microscope has a matching pkl metadata
    file generated by robofish

    Args:
        all_raw_files: list
            list with all the paths of the nd2 files to process

    &#34;&#34;&#34;

    logger = selected_logger()
    experiment_fpath = all_raw_files[0].parent
    all_info_files = list(experiment_fpath.glob(&#39;*.pkl&#39;))
  
    if len(all_info_files) == 0:
        logger.error(f&#34;no .pkl files in the folder&#34;)
        sys.exit(f&#34;no .pkl files in the folder&#34;)

    # Determine if there are multiple metadata files with same number
    all_codes = []
    for meta_file_path in all_info_files:
        # collect the count code
        count_code = re.search(r&#39;(Count)\d{5}&#39;, meta_file_path.stem)
        assert count_code, logger.error(f&#39;{meta_file_path.stem} does not contain the CountXXXXX code&#39;)
        count_code = count_code.group()
        all_codes. append(count_code)
    
    if all_codes:
        all_codes_counts_dict = {i:all_codes.count(i) for i in all_codes}
        all_codes_counts_array = np.array(list(all_codes_counts_dict.values()))
        if np.any(all_codes_counts_array&gt;1):
            for count_code,value in all_codes_counts_dict.items():
                if value &gt;1:
                    logger.error(f&#39; multiple pkl files with {count_code}&#39;)
                    sys.exit(f&#39; multiple pkl files with {count_code}&#39;)
            
            logger.error(f&#39;fix naming of the files with the repeated codes&#39;)
            sys.exit(f&#39;fix naming of the files with the repeated codes&#39;)

    missing_pkl = []
    for nd2_file_path in all_raw_files:
        # collect the count code
        try:
            count_code = re.search(r&#39;(Count)\d{5}&#39;, nd2_file_path.stem).group()
        except:
            count_code = None
            logger.error(f&#39;{nd2_file_path.stem} does not contain the CountXXXXX code&#39;)
            sys.exit(f&#39;{nd2_file_path.stem} does not contain the CountXXXXX code&#39;)
        else:
            try:
                info_file = [info_file for info_file in all_info_files if count_code  in info_file.stem][0]
            except IndexError:
                logger.error(f&#39;{nd2_file_path.stem} does not have the corresponding pkl file&#39;)
                missing_pkl.append(nd2_file_path.stem)

    if missing_pkl:
        logger.error(f&#39;collect the missing pkl for {missing_pkl} before parsing&#39;)
        sys.exit(f&#39;collect the missing pkl for {missing_pkl} before parsing&#39;)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pysmFISH.qc_utils.QC_registration_error"><code class="flex name class">
<span>class <span class="ident">QC_registration_error</span></span>
<span>(</span><span>client, experiment_fpath: str, analysis_parameters: dict, metadata: Dict, tiles_coords: numpy.ndarray)</span>
</code></dt>
<dd>
<div class="desc"><p>Class use to evaluate the performance of the regstration
of the different rounds of hybridization</p>
<p>Class initialization</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>client</code></strong> :&ensp;<code>distributed.Client</code></dt>
<dd>Clients that orchesterate the
processing of some of the QC steps</dd>
<dt><strong><code>experiment_fpath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the experiment to process</dd>
<dt><strong><code>analysis_parameters</code></strong> :&ensp;<code>dict</code></dt>
<dd>Parameters for the processing</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>dict</code></dt>
<dd>Overall experimental parameters</dd>
<dt><strong><code>tiles_coords</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Stage coords of the acquired FOVS</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class QC_registration_error():
    &#34;&#34;&#34;Class use to evaluate the performance of the regstration
    of the different rounds of hybridization
    &#34;&#34;&#34;

    def __init__(self, client, experiment_fpath: str, 
                analysis_parameters: dict, metadata: Dict, tiles_coords: np.ndarray):
        &#34;&#34;&#34;Class initialization

        Args:
            client (distributed.Client): Clients that orchesterate the
                processing of some of the QC steps
            experiment_fpath (str): Path to the experiment to process
            analysis_parameters (dict): Parameters for the processing
            metadata (dict): Overall experimental parameters
            tiles_coords (np.ndarray): Stage coords of the acquired FOVS
        &#34;&#34;&#34;
    # def __init__(self, client, experiment_fpath, analysis_parameters, tiles_coords, img_width, img_height):
        self.client = client
        self.experiment_fpath = Path(experiment_fpath)
        self.analysis_parameters = analysis_parameters
        self.metadata = metadata
        self.tiles_coords = tiles_coords
        # self.img_width = img_width
        # self.img_height = img_height
        matplotlib.use(&#34;Agg&#34;)

    def create_error_df(self):
        &#34;&#34;&#34;Method used to collect the error information from
        the processed data
        &#34;&#34;&#34;
        all_counts_folder = self.experiment_fpath / &#39;results&#39;
        search_key = &#39;*_decoded_fov_*&#39;
        self.error_output_df= pd.DataFrame()
        all_counts_dd = dd.read_parquet(all_counts_folder / search_key)
        registration_error_df = all_counts_dd.groupby(&#39;fov_num&#39;).agg({&#39;min_number_matching_dots_registration&#39;: [&#39;min&#39;]}).compute()
        for idx, row in registration_error_df.itertuples():
            search_key = &#39;*decoded_fov_&#39; + str(int(idx)) +&#39;.parquet&#39;
            fname = list(all_counts_folder.glob(search_key))[0]
            fov_data_df = pd.read_parquet(fname)
            matching_rounds = fov_data_df.loc[(fov_data_df.fov_num == idx) &amp;
                        (fov_data_df.min_number_matching_dots_registration == row),
                        [&#39;fov_num&#39;,&#39;min_number_matching_dots_registration&#39;,&#39;round_num&#39;]]
            self.error_output_df = pd.concat([self.error_output_df,matching_rounds.iloc[0]],axis=1)
        self.error_output_df = self.error_output_df.T
        # #     RegistrationMinMatchingBeads = analysis_parameters[&#39;RegistrationMinMatchingBeads&#39;]
        #     registration_error_df.columns = [&#34;_&#34;.join(x) for x in registration_error_df.columns.ravel()]
        self.error_output_df.to_parquet(self.experiment_fpath / &#39;results&#39; / &#39;registration_error.parquet&#39;)

        
    def plot_error(self):
        &#34;&#34;&#34;Method used to visualize the error for the different tiles
        &#34;&#34;&#34;
        plt.ioff()
        scale_value = 5
        self.tiles_coords = self.tiles_coords / scale_value
        RegistrationMinMatchingBeads = self.analysis_parameters[&#39;RegistrationMinMatchingBeads&#39;]
        fovs = self.error_output_df[&#39;fov_num&#39;].values.astype(int)
        rounds_num = self.error_output_df[&#39;round_num&#39;].values.astype(int)
        min_errors = self.error_output_df[&#39;min_number_matching_dots_registration&#39;].values.astype(int)


        colors = np.zeros_like(min_errors,dtype=&#39;U10&#39;)

        # Vlist correspond to the errors in the registration

        vlist = [-6,-5,-4,-3,-2]
        clist = [&#39;black&#39;,&#39;dimgrey&#39;,&#39;silver&#39;,&#39;orange&#39;,&#39;green&#39;]

        for v,c in zip(vlist,clist):
                colors[min_errors == v] = c

        colors[min_errors &gt; 0] = &#39;steelblue&#39;
        #colors[(min_errors &lt; RegistrationMinMatchingBeads) &amp; (min_errors &gt; 0)] = &#39;tomato&#39;


        fig = plt.figure(figsize=(30,20))
        ax = fig.add_subplot(111)

        r_coords = self.tiles_coords[:,0]
        c_coords = self.tiles_coords[:,1]
        r_coords_min = r_coords.min()
        c_coords_min = c_coords.min()
        to_zero_r_coords = r_coords - r_coords_min
        to_zero_c_coords = c_coords - c_coords_min


        # errors_normalized = (min_errors -min(min_errors)) / (max(min_errors -min(min_errors)))
        # threshold = (RegistrationMinMatchingBeads-min(min_errors)) / (max(min_errors -min(min_errors)))
        # nodes = [0,threshold, threshold, 1.0]

        # colors = [&#34;black&#34;, &#34;black&#34;, &#34;blue&#34;, &#34;magenta&#34;]
        # cmap = LinearSegmentedColormap.from_list(&#34;&#34;, list(zip(nodes, colors)))
        # cmap.set_under(&#34;black&#34;)
        # sc = ax.scatter(to_zero_c_coords,to_zero_r_coords,c=errors_normalized,cmap=cmap, s = 1000)
        
        sc = ax.scatter(to_zero_c_coords,to_zero_r_coords,c=colors, s = 1000)
        plt.gca().invert_yaxis()
        for fov, round_num, match, x, y in zip(fovs,rounds_num, min_errors, to_zero_c_coords,to_zero_r_coords):
            
            ax.annotate(
                fov,
                xy=(x,y), xytext=(-0, 10),
                textcoords=&#39;offset points&#39;, ha=&#39;center&#39;, va=&#39;center&#39;,fontsize=5,color=&#39;white&#39;, weight=&#39;bold&#39;)
            
            ax.annotate(round_num, (x, y), color=&#39;white&#39;, weight=&#39;bold&#39;, 
                            fontsize=10, ha=&#39;center&#39;, va=&#39;center&#39;)
            
            ax.annotate(&#39;m&#39; + str(match), xy=(x, y), xytext=(0, -10), color=&#39;white&#39;, weight=&#39;bold&#39;, 
                            textcoords=&#39;offset points&#39;, fontsize=5, ha=&#39;center&#39;, va=&#39;center&#39;)
    
        patch_1 = mpatches.Patch(color=&#39;black&#39;, label=&#39;missing_counts_fish_channel&#39;)
        patch_2 = mpatches.Patch(color=&#39;dimgrey&#39;, label=&#39;missing_counts_reg_channel&#39;)
        patch_3 = mpatches.Patch(color=&#39;silver&#39;, label=&#39;missing_counts_reference_round&#39;)
        patch_4 = mpatches.Patch(color=&#39;orange&#39;, label=&#39;missing_counts_in_round&#39;)
        patch_5 = mpatches.Patch(color=&#39;green&#39;, label=&#39;number_beads_below_tolerance_counts&#39;)
        
        plt.legend(handles=[patch_1,patch_2,patch_3,patch_4,patch_5])    
    
        ax.set_aspect(&#39;equal&#39;)
        ax.axis(&#39;off&#39;)
        plt.tight_layout()

        plt.savefig(self.experiment_fpath / &#39;output_figures&#39; / &#39;registration_error.png&#39;,dpi=200,pad_inches=0)


    def run_qc(self):
        &#34;&#34;&#34;Method that runs all the QC steps
        &#34;&#34;&#34;
        self.create_error_df()
        self.plot_error()</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pysmFISH.qc_utils.QC_registration_error.create_error_df"><code class="name flex">
<span>def <span class="ident">create_error_df</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Method used to collect the error information from
the processed data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_error_df(self):
    &#34;&#34;&#34;Method used to collect the error information from
    the processed data
    &#34;&#34;&#34;
    all_counts_folder = self.experiment_fpath / &#39;results&#39;
    search_key = &#39;*_decoded_fov_*&#39;
    self.error_output_df= pd.DataFrame()
    all_counts_dd = dd.read_parquet(all_counts_folder / search_key)
    registration_error_df = all_counts_dd.groupby(&#39;fov_num&#39;).agg({&#39;min_number_matching_dots_registration&#39;: [&#39;min&#39;]}).compute()
    for idx, row in registration_error_df.itertuples():
        search_key = &#39;*decoded_fov_&#39; + str(int(idx)) +&#39;.parquet&#39;
        fname = list(all_counts_folder.glob(search_key))[0]
        fov_data_df = pd.read_parquet(fname)
        matching_rounds = fov_data_df.loc[(fov_data_df.fov_num == idx) &amp;
                    (fov_data_df.min_number_matching_dots_registration == row),
                    [&#39;fov_num&#39;,&#39;min_number_matching_dots_registration&#39;,&#39;round_num&#39;]]
        self.error_output_df = pd.concat([self.error_output_df,matching_rounds.iloc[0]],axis=1)
    self.error_output_df = self.error_output_df.T
    # #     RegistrationMinMatchingBeads = analysis_parameters[&#39;RegistrationMinMatchingBeads&#39;]
    #     registration_error_df.columns = [&#34;_&#34;.join(x) for x in registration_error_df.columns.ravel()]
    self.error_output_df.to_parquet(self.experiment_fpath / &#39;results&#39; / &#39;registration_error.parquet&#39;)</code></pre>
</details>
</dd>
<dt id="pysmFISH.qc_utils.QC_registration_error.plot_error"><code class="name flex">
<span>def <span class="ident">plot_error</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Method used to visualize the error for the different tiles</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_error(self):
    &#34;&#34;&#34;Method used to visualize the error for the different tiles
    &#34;&#34;&#34;
    plt.ioff()
    scale_value = 5
    self.tiles_coords = self.tiles_coords / scale_value
    RegistrationMinMatchingBeads = self.analysis_parameters[&#39;RegistrationMinMatchingBeads&#39;]
    fovs = self.error_output_df[&#39;fov_num&#39;].values.astype(int)
    rounds_num = self.error_output_df[&#39;round_num&#39;].values.astype(int)
    min_errors = self.error_output_df[&#39;min_number_matching_dots_registration&#39;].values.astype(int)


    colors = np.zeros_like(min_errors,dtype=&#39;U10&#39;)

    # Vlist correspond to the errors in the registration

    vlist = [-6,-5,-4,-3,-2]
    clist = [&#39;black&#39;,&#39;dimgrey&#39;,&#39;silver&#39;,&#39;orange&#39;,&#39;green&#39;]

    for v,c in zip(vlist,clist):
            colors[min_errors == v] = c

    colors[min_errors &gt; 0] = &#39;steelblue&#39;
    #colors[(min_errors &lt; RegistrationMinMatchingBeads) &amp; (min_errors &gt; 0)] = &#39;tomato&#39;


    fig = plt.figure(figsize=(30,20))
    ax = fig.add_subplot(111)

    r_coords = self.tiles_coords[:,0]
    c_coords = self.tiles_coords[:,1]
    r_coords_min = r_coords.min()
    c_coords_min = c_coords.min()
    to_zero_r_coords = r_coords - r_coords_min
    to_zero_c_coords = c_coords - c_coords_min


    # errors_normalized = (min_errors -min(min_errors)) / (max(min_errors -min(min_errors)))
    # threshold = (RegistrationMinMatchingBeads-min(min_errors)) / (max(min_errors -min(min_errors)))
    # nodes = [0,threshold, threshold, 1.0]

    # colors = [&#34;black&#34;, &#34;black&#34;, &#34;blue&#34;, &#34;magenta&#34;]
    # cmap = LinearSegmentedColormap.from_list(&#34;&#34;, list(zip(nodes, colors)))
    # cmap.set_under(&#34;black&#34;)
    # sc = ax.scatter(to_zero_c_coords,to_zero_r_coords,c=errors_normalized,cmap=cmap, s = 1000)
    
    sc = ax.scatter(to_zero_c_coords,to_zero_r_coords,c=colors, s = 1000)
    plt.gca().invert_yaxis()
    for fov, round_num, match, x, y in zip(fovs,rounds_num, min_errors, to_zero_c_coords,to_zero_r_coords):
        
        ax.annotate(
            fov,
            xy=(x,y), xytext=(-0, 10),
            textcoords=&#39;offset points&#39;, ha=&#39;center&#39;, va=&#39;center&#39;,fontsize=5,color=&#39;white&#39;, weight=&#39;bold&#39;)
        
        ax.annotate(round_num, (x, y), color=&#39;white&#39;, weight=&#39;bold&#39;, 
                        fontsize=10, ha=&#39;center&#39;, va=&#39;center&#39;)
        
        ax.annotate(&#39;m&#39; + str(match), xy=(x, y), xytext=(0, -10), color=&#39;white&#39;, weight=&#39;bold&#39;, 
                        textcoords=&#39;offset points&#39;, fontsize=5, ha=&#39;center&#39;, va=&#39;center&#39;)

    patch_1 = mpatches.Patch(color=&#39;black&#39;, label=&#39;missing_counts_fish_channel&#39;)
    patch_2 = mpatches.Patch(color=&#39;dimgrey&#39;, label=&#39;missing_counts_reg_channel&#39;)
    patch_3 = mpatches.Patch(color=&#39;silver&#39;, label=&#39;missing_counts_reference_round&#39;)
    patch_4 = mpatches.Patch(color=&#39;orange&#39;, label=&#39;missing_counts_in_round&#39;)
    patch_5 = mpatches.Patch(color=&#39;green&#39;, label=&#39;number_beads_below_tolerance_counts&#39;)
    
    plt.legend(handles=[patch_1,patch_2,patch_3,patch_4,patch_5])    

    ax.set_aspect(&#39;equal&#39;)
    ax.axis(&#39;off&#39;)
    plt.tight_layout()

    plt.savefig(self.experiment_fpath / &#39;output_figures&#39; / &#39;registration_error.png&#39;,dpi=200,pad_inches=0)</code></pre>
</details>
</dd>
<dt id="pysmFISH.qc_utils.QC_registration_error.run_qc"><code class="name flex">
<span>def <span class="ident">run_qc</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Method that runs all the QC steps</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_qc(self):
    &#34;&#34;&#34;Method that runs all the QC steps
    &#34;&#34;&#34;
    self.create_error_df()
    self.plot_error()</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pysmFISH" href="index.html">pysmFISH</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pysmFISH.qc_utils.QC_check_experiment_yaml_file" href="#pysmFISH.qc_utils.QC_check_experiment_yaml_file">QC_check_experiment_yaml_file</a></code></li>
<li><code><a title="pysmFISH.qc_utils.QC_matching_nd2_metadata_robofish" href="#pysmFISH.qc_utils.QC_matching_nd2_metadata_robofish">QC_matching_nd2_metadata_robofish</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pysmFISH.qc_utils.QC_registration_error" href="#pysmFISH.qc_utils.QC_registration_error">QC_registration_error</a></code></h4>
<ul class="">
<li><code><a title="pysmFISH.qc_utils.QC_registration_error.create_error_df" href="#pysmFISH.qc_utils.QC_registration_error.create_error_df">create_error_df</a></code></li>
<li><code><a title="pysmFISH.qc_utils.QC_registration_error.plot_error" href="#pysmFISH.qc_utils.QC_registration_error.plot_error">plot_error</a></code></li>
<li><code><a title="pysmFISH.qc_utils.QC_registration_error.run_qc" href="#pysmFISH.qc_utils.QC_registration_error.run_qc">run_qc</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>